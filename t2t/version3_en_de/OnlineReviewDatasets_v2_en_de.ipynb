{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate t2t data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable TF Eager execution\n",
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "import generate_problem # self-defined 'generate_problem.py' file in the same folder.\n",
    "\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD'\n",
    "TMP_DIR = './tmp' # Where data files from internet stored\n",
    "DATA_LOC = './data' # Where pre-prcessed data is stored\n",
    "\n",
    "# Init problem T2T object the generated training data\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate_cosine_cycle_steps': 250000, 'norm_type': 'layer', 'warm_start_from_second': '', 'use_fixed_batch_size': False, 'min_length': 0, 'kernel_width': 1, 'moe_hidden_sizes': '2048', 'split_to_length': 0, 'optimizer_adafactor_factored': True, 'symbol_dropout': 0.0, 'sampling_method': 'argmax', 'norm_epsilon': 1e-06, 'hidden_size': 512, 'max_relative_position': 0, 'daisy_chain_variables': True, 'optimizer_adafactor_clipping_threshold': 1.0, 'max_input_seq_length': 0, 'mlperf_mode': False, 'attention_key_channels': 0, 'max_length': 0, 'scheduled_sampling_warmup_steps': 50000, 'optimizer_adafactor_decay_type': 'pow', 'attention_dropout': 0.1, 'dropout': 0.2, 'overload_eval_metric_name': '', 'length_bucket_step': 1.1, 'video_num_target_frames': 1, 'prepend_mode': 'prepend_inputs_masked_attention', 'moe_overhead_eval': 2.0, 'layer_prepostprocess_dropout': 0.1, 'layer_prepostprocess_dropout_broadcast_dims': '', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'pretrained_model_dir': '', 'nbr_decoder_problems': 1, 'attention_value_channels': 0, 'eval_drop_long_sequences': False, 'proximity_bias': False, 'attention_dropout_broadcast_dims': '', 'label_smoothing': 0.1, 'attention_variables_3d': False, 'learning_rate_constant': 1.0, 'kernel_height': 3, 'shared_embedding': False, 'layer_postprocess_sequence': 'da', 'sampling_temp': 1.0, 'moe_num_experts': 16, 'batch_shuffle_size': 512, 'tpu_enable_host_call': False, 'weight_decay': 0.0, 'shared_embedding_and_softmax_weights': True, 'batch_size': 512, 'conv_first_kernel': 3, 'multiproblem_mixing_schedule': 'constant', 'num_heads': 8, 'learning_rate_decay_rate': 1.0, 'multiply_embedding_mode': 'sqrt_depth', 'optimizer_adam_epsilon': 1e-09, 'factored_logits': False, 'activation_dtype': 'float32', 'num_decoder_layers': 0, 'moe_k': 2, 'video_num_input_frames': 1, 'optimizer_adam_beta2': 0.98, 'multiproblem_schedule_threshold': 0.5, 'learning_rate': 0.2, 'optimizer_adafactor_beta2': 0.999, 'learning_rate_minimum': None, 'optimizer_adafactor_memory_exponent': 0.8, 'symbol_modality_num_shards': 16, 'learning_rate_decay_scheme': 'noam', 'multiproblem_max_input_length': -1, 'moe_loss_coef': 0.001, 'multiproblem_reweight_label_loss': False, 'eval_run_autoregressive': False, 'modality': {}, 'causal_decoder_self_attention': True, 'optimizer_adafactor_beta1': 0.0, 'layer_preprocess_sequence': 'n', 'pos': 'timing', 'max_target_seq_length': 0, 'compress_steps': 0, 'optimizer_adam_beta1': 0.9, 'add_relative_to_values': False, 'parameter_attention_key_channels': 0, 'scheduled_sampling_gold_mixin_prob': 0.5, 'pad_batch': False, 'relu_dropout_broadcast_dims': '', 'scheduled_sampling_prob': 0.0, 'summarize_vars': False, 'learning_rate_warmup_steps': 8000, 'optimizer_momentum_momentum': 0.9, 'weight_dtype': 'float32', 'multiproblem_per_task_threshold': '', 'num_hidden_layers': 6, 'heads_share_relative_embedding': False, 'clip_grad_norm': 0.0, 'vocab_divisor': 1, 'ffn_layer': 'dense_relu_dense', 'optimizer': 'Adam', 'multiproblem_vocab_size': -1, 'optimizer_multistep_accumulate_steps': None, 'parameter_attention_value_channels': 0, 'self_attention_type': 'dot_product', 'learning_rate_schedule': 'legacy', 'initializer': 'uniform_unit_scaling', 'optimizer_zero_grads': False, 'min_length_bucket': 8, 'summarize_grads': False, 'no_data_parallelism': False, 'relu_dropout': 0.1, 'use_pad_remover': True, 'use_target_space_embedding': True, 'learning_rate_decay_staircase': False, 'weight_noise': 0.0, 'num_encoder_layers': 0, 'multiproblem_max_target_length': -1, 'optimizer_momentum_nesterov': False, 'moe_overhead_train': 1.0, 'learning_rate_decay_steps': 5000, 'initializer_gain': 1.0, 'symbol_modality_skip_top': False, 'force_full_predict': False, 'grad_noise_scale': 0.0, 'filter_size': 2048, 'multiproblem_target_eval_only': False, 'multiproblem_fixed_train_length': -1, 'multiproblem_schedule_max_examples': 10000000.0, 'multiproblem_label_weight': 0.5, 'unidirectional_encoder': False}\n"
     ]
    }
   ],
   "source": [
    "# from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "# import json\n",
    "# # Init Hparams object from T2T Problem\n",
    "# hparams = create_hparams(HPARAMS)\n",
    "# hparams.batch_size = 512\n",
    "# # hparams.learning_rate_warmup_steps = 45000\n",
    "# # hparams.learning_rate = .4\n",
    "\n",
    "# # Can see all Hparams with code below\n",
    "# print(json.loads(hparams.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f4bfbb68080>, 't2t_device_info': {'num_async_replicas': 1}, '_num_worker_replicas': 0, '_log_step_count_steps': 100, '_environment': 'local', '_keep_checkpoint_max': 20, '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_task_id': 0, '_save_checkpoints_steps': 1000, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4bfbb680b8>, '_tf_random_seed': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_protocol': None, '_master': '', '_eval_distribute': None, '_is_chief': True, '_device_fn': None, '_save_summary_steps': 100, '_num_ps_replicas': 0, 'use_tpu': False, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_model_dir': 'model_files_v1'}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f4bfbe398c8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "Time: 0.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "\n",
    "# # running time calculation\n",
    "# import timeit\n",
    "# start = timeit.default_timer()\n",
    "\n",
    "# # Initi Run COnfig for Model Training\n",
    "# RUN_CONFIG = create_run_config(\n",
    "#     model_name=MODEL,# Location of where model file is store\n",
    "#     model_dir=TRAIN_DIR\n",
    "#       # More Params here in this fucntion for controling how noften to tave checkpoints and more. \n",
    "# )\n",
    "\n",
    "# # Create Tensorflow Experiment Object\n",
    "# tensorflow_exp_fn = create_experiment(\n",
    "#         run_config=RUN_CONFIG,\n",
    "#         hparams=hparams,\n",
    "#         model_name=MODEL,\n",
    "#         problem_name= t2t_problem, #PROBLEM,\n",
    "# #         t2t_usr_dir='./',\n",
    "#         data_dir='./data', \n",
    "#         train_steps=40000, # Total number of train steps for all Epochs\n",
    "#         eval_steps=200 # Number of steps to perform for each evaluation\n",
    "#     )\n",
    "\n",
    "# # Kick off Training\n",
    "# tensorflow_exp_fn.train_and_evaluate()\n",
    "\n",
    "# # running time check (running on 1GPU server)\n",
    "# stop = timeit.default_timer()\n",
    "# print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~4h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. using encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ende_problem = t2t_problem\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "DATA_LOC = './data'\n",
    "encoders = ende_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n"
     ]
    }
   ],
   "source": [
    "# Create hparams and the model\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "\n",
    "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
    "# Layer and so subsequent instantiations will have different variable scopes\n",
    "# that will not match the checkpoint.\n",
    "t2t_model = tensorflow_exp_fn #registry.model(MODEL)(hparams, Modes.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the pretrained checkpoint locally\n",
    "# ckpt_name = \"transformer_ende_test\"\n",
    "# gs_ckpt = os.path.join(gs_ckpt_dir, ckpt_name)\n",
    "# !gsutil -q cp -R {gs_ckpt} {checkpoint_dir}\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_v1/model.ckpt\")\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: The animal didn't cross the street because it was too tired\n",
      "Outputs: horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible\n"
     ]
    }
   ],
   "source": [
    "# tensorflow_exp_fnx\n",
    "#Restore and translate!\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = t2t_model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "inputs = \"The animal didn't cross the street because it was too tired\"\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
