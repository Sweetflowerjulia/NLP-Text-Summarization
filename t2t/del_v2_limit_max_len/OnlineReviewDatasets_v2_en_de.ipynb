{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate t2t data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable TF Eager execution\n",
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "import generate_problem # self-defined 'generate_problem.py' file in the same folder.\n",
    "\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD'\n",
    "TMP_DIR = './tmp' # Where data files from internet stored\n",
    "DATA_LOC = './data' # Where pre-prcessed data is stored\n",
    "\n",
    "# Init problem T2T object the generated training data\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_num_input_frames': 1, 'use_fixed_batch_size': False, 'kernel_width': 1, 'multiproblem_mixing_schedule': 'constant', 'moe_hidden_sizes': '2048', 'optimizer_zero_grads': False, 'unidirectional_encoder': False, 'pretrained_model_dir': '', 'batch_size': 512, 'multiproblem_max_input_length': -1, 'proximity_bias': False, 'attention_value_channels': 0, 'optimizer_adam_epsilon': 1e-09, 'eval_drop_long_sequences': False, 'prepend_mode': 'prepend_inputs_masked_attention', 'eval_run_autoregressive': False, 'min_length': 0, 'optimizer_adafactor_clipping_threshold': 1.0, 'kernel_height': 3, 'attention_dropout': 0.1, 'length_bucket_step': 1.1, 'multiproblem_reweight_label_loss': False, 'parameter_attention_value_channels': 0, 'layer_prepostprocess_dropout_broadcast_dims': '', 'use_target_space_embedding': True, 'optimizer_adafactor_beta2': 0.999, 'filter_size': 2048, 'summarize_grads': False, 'moe_overhead_train': 1.0, 'ffn_layer': 'dense_relu_dense', 'max_input_seq_length': 0, 'scheduled_sampling_prob': 0.0, 'optimizer_adafactor_factored': True, 'multiproblem_fixed_train_length': -1, 'optimizer_momentum_momentum': 0.9, 'summarize_vars': False, 'activation_dtype': 'float32', 'optimizer_adam_beta2': 0.98, 'conv_first_kernel': 3, 'initializer_gain': 1.0, 'symbol_modality_skip_top': False, 'num_heads': 8, 'multiproblem_label_weight': 0.5, 'optimizer_adafactor_memory_exponent': 0.8, 'sampling_method': 'argmax', 'max_target_seq_length': 0, 'layer_preprocess_sequence': 'n', 'layer_prepostprocess_dropout': 0.1, 'optimizer_multistep_accumulate_steps': None, 'num_hidden_layers': 6, 'norm_type': 'layer', 'multiproblem_schedule_max_examples': 10000000.0, 'batch_shuffle_size': 512, 'use_pad_remover': True, 'clip_grad_norm': 0.0, 'causal_decoder_self_attention': True, 'scheduled_sampling_gold_mixin_prob': 0.5, 'multiproblem_schedule_threshold': 0.5, 'attention_dropout_broadcast_dims': '', 'grad_noise_scale': 0.0, 'daisy_chain_variables': True, 'moe_overhead_eval': 2.0, 'symbol_dropout': 0.0, 'sampling_temp': 1.0, 'relu_dropout': 0.1, 'multiproblem_target_eval_only': False, 'dropout': 0.2, 'min_length_bucket': 8, 'learning_rate_cosine_cycle_steps': 250000, 'optimizer': 'Adam', 'factored_logits': False, 'relu_dropout_broadcast_dims': '', 'mlperf_mode': False, 'multiproblem_per_task_threshold': '', 'learning_rate_warmup_steps': 8000, 'video_num_target_frames': 1, 'warm_start_from_second': '', 'add_relative_to_values': False, 'attention_variables_3d': False, 'vocab_divisor': 1, 'modality': {}, 'optimizer_adam_beta1': 0.9, 'parameter_attention_key_channels': 0, 'num_encoder_layers': 0, 'norm_epsilon': 1e-06, 'tpu_enable_host_call': False, 'nbr_decoder_problems': 1, 'learning_rate_minimum': None, 'split_to_length': 0, 'attention_key_channels': 0, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'learning_rate': 0.2, 'learning_rate_decay_rate': 1.0, 'num_decoder_layers': 0, 'shared_embedding_and_softmax_weights': True, 'moe_loss_coef': 0.001, 'learning_rate_constant': 1.0, 'force_full_predict': False, 'weight_noise': 0.0, 'multiproblem_max_target_length': -1, 'learning_rate_decay_steps': 5000, 'weight_decay': 0.0, 'moe_k': 2, 'moe_num_experts': 16, 'initializer': 'uniform_unit_scaling', 'label_smoothing': 0.1, 'optimizer_adafactor_beta1': 0.0, 'pos': 'timing', 'multiproblem_vocab_size': -1, 'no_data_parallelism': False, 'pad_batch': False, 'learning_rate_schedule': 'legacy', 'max_length': 0, 'heads_share_relative_embedding': False, 'max_relative_position': 0, 'learning_rate_decay_scheme': 'noam', 'compress_steps': 0, 'layer_postprocess_sequence': 'da', 'learning_rate_decay_staircase': False, 'weight_dtype': 'float32', 'overload_eval_metric_name': '', 'multiply_embedding_mode': 'sqrt_depth', 'shared_embedding': False, 'hidden_size': 512, 'optimizer_momentum_nesterov': False, 'optimizer_adafactor_decay_type': 'pow', 'self_attention_type': 'dot_product', 'scheduled_sampling_warmup_steps': 50000, 'symbol_modality_num_shards': 16}\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "# Init Hparams object from T2T Problem\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 512\n",
    "# hparams.learning_rate_warmup_steps = 45000\n",
    "# hparams.learning_rate = .4\n",
    "\n",
    "# Can see all Hparams with code below\n",
    "print(json.loads(hparams.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_environment': 'local', 'use_tpu': False, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_eval_distribute': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f245f82b9e8>, '_task_id': 0, '_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 0, 't2t_device_info': {'num_async_replicas': 1}, '_tf_random_seed': None, '_save_summary_steps': 100, '_train_distribute': None, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f245f82b9b0>, '_save_checkpoints_steps': 1000, '_protocol': None, '_evaluation_master': '', '_log_step_count_steps': 100, '_device_fn': None, '_is_chief': True, '_keep_checkpoint_max': 20, '_model_dir': 'model_files'}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f245f7b0e18>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "Time: 0.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "\n",
    "# running time calculation\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Initi Run COnfig for Model Training\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,# Location of where model file is store\n",
    "    model_dir=TRAIN_DIR\n",
    "      # More Params here in this fucntion for controling how noften to tave checkpoints and more. \n",
    ")\n",
    "\n",
    "# Create Tensorflow Experiment Object\n",
    "tensorflow_exp_fn = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name= t2t_problem, #PROBLEM,\n",
    "#         t2t_usr_dir='./',\n",
    "        data_dir='./data', \n",
    "        train_steps=40000, # Total number of train steps for all Epochs\n",
    "        eval_steps=200 # Number of steps to perform for each evaluation\n",
    "    )\n",
    "\n",
    "# Kick off Training\n",
    "tensorflow_exp_fn.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()s\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~4h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. using encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Generate and view the data\n",
    "# This cell is commented out because WMT data generation can take hours\n",
    "\n",
    "# ende_problem.generate_data(data_dir, tmp_dir)\n",
    "example = tfe.Iterator(t2t_problem.dataset(Modes.TRAIN, DATA_LOC)).next()\n",
    "inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
    "targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs, encoded:\n",
      "[6832, 10831, 4, 6832, 377, 2569, 7601, 2461, 26, 5, 3841, 1]\n",
      "Inputs, decoded:\n",
      "integers [6832, 10831, 4, 6832, 377, 2569, 7601, 2461, 26, 5, 3841]\n",
      "targets <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fcc845c6128>\n",
      "disposable razors and disposable 6 razor scam blades are a trap\n",
      "------------------------------\n",
      "Targets, encoded:\n",
      "[75, 216, 1445, 3, 4, 26, 30, 2040, 10, 15, 74, 9, 2, 3260, 122, 5, 2159, 2569, 250, 5614, 3, 2, 579, 8, 145, 24482, 18562, 652, 6832, 2461, 9, 7557, 10, 4, 34, 1780, 10, 139, 110, 6, 75, 2461, 4, 5, 2159, 2569, 10, 59, 561, 4, 1177, 27, 31, 647, 17, 1]\n",
      "Targets, decoded:\n",
      "integers [75, 216, 1445, 3, 4, 26, 30, 2040, 10, 15, 74, 9, 2, 3260, 122, 5, 2159, 2569, 250, 5614, 3, 2, 579, 8, 145, 24482, 18562, 652, 6832, 2461, 9, 7557, 10, 4, 34, 1780, 10, 139, 110, 6, 75, 2461, 4, 5, 2159, 2569, 10, 59, 561, 4, 1177, 27, 31, 647, 17]\n",
      "targets <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fcc845c6128>\n",
      "these last forever, and are so inexpensive  not only is the shave off a safety razor less irritating, the cost of those environmentally disastrous huge disposable blades is absurd  and all marketing  go back to these blades and a safety razor  your face and pocket book will thank you\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example inputs as int-tensor.\n",
    "print(\"Inputs, encoded:\")\n",
    "print(inputs)\n",
    "print(\"Inputs, decoded:\")\n",
    "# Example inputs as a sentence.\n",
    "print(decode(inputs))\n",
    "\n",
    "print(\"---\"*10)\n",
    "# Example targets as int-tensor.\n",
    "print(\"Targets, encoded:\")\n",
    "print(targets)\n",
    "# Example targets as a sentence.\n",
    "print(\"Targets, decoded:\")\n",
    "print(decode(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fcc8c2db8d0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fcc8c2db908>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fcc8ccceac8>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fcc8ccceac8>}), ('was_copy', False), ('was_reversed', True)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ende_problem = t2t_problem\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "DATA_LOC = './data'\n",
    "encoders = ende_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    print(\"inputs\",inputs)\n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "        print(\"integers\", integers)\n",
    "        print(\"targets\", encoders[\"targets\"])\n",
    "    return encoders[\"targets\"].decode(np.squeeze(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hparams and the model\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.problem_hparams.was_reversed =False\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_files/model.ckpt-40000'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_files/model.ckpt-40000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# latest = tf.train.latest_checkpoint('./model_files/')\n",
    "# latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [35548, 3852, 35554, 25, 306, 18, 347, 89, 196, 11, 271, 5, 165, 483, 73, 537, 35548, 9301, 35554, 25, 1]\n",
      "integers [193, 3852, 193, 25, 306, 18, 347, 89, 196, 11, 271, 5, 165, 483, 73, 537]\n",
      "targets <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fcc845c6128>\n",
      "Inputs: \n",
      "happy with purchase even though it came a lot later than expected.\n",
      "Outputs: each 10each happy with purchase even though it came a lot later than expected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "# inputs = '''\n",
    "# the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "# '''\n",
    "inputs = '''\n",
    "happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "\n",
      "Outputs: when 10so the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe styboth physical and moral challenges and through which heshe cost with a renewed spirit, transformed by the his his ble of she ations ies, both real real and imagined  sara gruens engaging water for elephants is an\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_decode_on_eval_data(self):\n",
    "    \"\"\"Decode from dataset on new checkpoint.\"\"\"\n",
    "    if self._hparams.mlperf_mode:\n",
    "      ckpt_generator = next_undecoded_checkpoint(\n",
    "          self._hparams.model_dir, self._decode_hparams.decode_timeout_mins)\n",
    "    else:\n",
    "      ckpt_generator = next_checkpoint(self._hparams.model_dir,\n",
    "                                       self._decode_hparams.decode_timeout_mins)\n",
    "\n",
    "    for ckpt in ckpt_generator:\n",
    "      current_step = decoding.get_step_from_ckpt_path(ckpt)\n",
    "      tf.logging.info(\"Decoding step %d\" % current_step)\n",
    "      # Skip checkpoint 0.\n",
    "      if current_step == 0:\n",
    "        continue\n",
    "      # Decode the latest checkpoint by default.\n",
    "      checkpoint_path = None\n",
    "      if self._hparams.mlperf_mode:\n",
    "        self._decode_hparams.mlperf_decode_step = current_step\n",
    "        checkpoint_path = ckpt\n",
    "\n",
    "      mlperf_log.transformer_print(key=mlperf_log.EVAL_START)\n",
    "      self.decode(\n",
    "          dataset_split=tf.estimator.ModeKeys.EVAL,\n",
    "          checkpoint_path=checkpoint_path)\n",
    "      d_hparams = self._decode_hparams\n",
    "      if self._hparams.mlperf_mode and d_hparams.mlperf_success:\n",
    "        mlperf_log.transformer_print(\n",
    "            key=mlperf_log.RUN_STOP, value={\"success\": \"true\"})\n",
    "        break\n",
    "\n",
    "    d_hparams = self._decode_hparams\n",
    "    if self._hparams.mlperf_mode and not d_hparams.mlperf_success:\n",
    "      mlperf_log.transformer_print(\n",
    "          key=mlperf_log.RUN_STOP, value={\"success\": \"false\"})\n",
    "\n",
    "  def continuous_decode_from_file(self):\n",
    "    \"\"\"Decode from file on new checkpoint.\"\"\"\n",
    "    for _ in next_checkpoint(self._hparams.model_dir,\n",
    "                             self._decode_hparams.decode_timeout_mins):\n",
    "      self.decode(decode_from_file=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
