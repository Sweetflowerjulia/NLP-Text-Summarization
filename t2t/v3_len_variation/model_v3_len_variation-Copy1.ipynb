{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_v3 Max length variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable TF Eager execution ==> for decoder later\n",
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate t2t data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When generate the t2t dataset by running \"generate_problem.py\", \n",
    "#### reviews that the summary contains exactly same sentences with review text are dropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generating vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.13028883934020996 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.2605276107788086 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5203197002410889 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0484089851379395 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9898045063018799 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 154505\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [p72s] took 0.13037824630737305 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [sexdrenched] took 0.2606990337371826 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5677199363708496 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 57824\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [writtenandperformed] took 0.13028526306152344 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [abandonmentbondingvulnerabilityangerguilt] took 0.260542631149292 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5274672508239746 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [3931126986] took 0.5206947326660156 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58666\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [coretorso] took 0.13055968284606934 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [openingentry] took 0.26056861877441406 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5170743465423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [splatchee] took 0.5205607414245605 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58604\n",
      "INFO:tensorflow:Trying min_count 750\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.13007497787475586 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.2607400417327881 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5210700035095215 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0469472408294678 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9826095104217529 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 123494\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [bucklewidth] took 0.1300661563873291 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [whollydifferentlooking] took 0.260667085647583 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5783379077911377 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 46447\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [comgpproductb003tw9bemrefcm] took 0.13071250915527344 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [____ _____ _____ ____ ____ ____ ____ ____ ____ ____ ____ _____ ____ ____  ____ ____ ___  ___ ___ ___] took 0.26169514656066895 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5144784450531006 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [prerequisitesconcentrationmajorbased] took 0.522036075592041 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 47187\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [comreviewr2dcpu8cjsr1iarefcm] took 0.13087129592895508 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [blocksplextor] took 0.2604668140411377 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5342991352081299 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [transcent] took 0.5205895900726318 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 47104\n",
      "INFO:tensorflow:Trying min_count 875\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.1301712989807129 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.26335835456848145 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5231857299804688 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.050382137298584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9771933555603027 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 113344\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [pugrave] took 0.13061738014221191 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [afffffffffffffffffffffffffffffffffffffffffffffffffeeeeeee] took 0.2604358196258545 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5921616554260254 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 42727\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [notmidnight] took 0.13027215003967285 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [uefimode] took 0.26021456718444824 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.523848295211792 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [womenpredictable] took 0.5218384265899658 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 43428\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [logicallyconsistent] took 0.1302480697631836 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [harshanitmainstream] took 0.2609424591064453 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.541226863861084 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [barracudaheatwave] took 0.5219767093658447 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 43372\n",
      "INFO:tensorflow:Trying min_count 938\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.13018465042114258 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.26036548614501953 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5228848457336426 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0481090545654297 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9789378643035889 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 109099\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [filmanyway] took 0.13042831420898438 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [airconditionersdehumidifiers] took 0.2604832649230957 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.588813304901123 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [update10253013this] took 0.5242905616760254 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41160\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [reviewbasically] took 0.1305379867553711 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [touchpressing] took 0.2604527473449707 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5256466865539551 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [areinlovesoicanmakemygirlfriendboyfriendjealous] took 0.5222604274749756 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41833\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [thoughtfulsensitive] took 0.13029861450195312 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [lindansen3] took 0.260606050491333 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5460531711578369 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [dvdswhich] took 0.524092435836792 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41789\n",
      "INFO:tensorflow:Trying min_count 969\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.13002920150756836 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.26071643829345703 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5224792957305908 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.04921555519104 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9779431819915771 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 107241\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [seersuckertype] took 0.13019084930419922 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amusingbyzantinecompelling] took 0.2607581615447998 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5940389633178711 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [sickofrealitytv] took 0.5504162311553955 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40525\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [034inch] took 0.13039755821228027 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [cbmsnsf] took 0.26027441024780273 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5242342948913574 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [mcconougheys] took 0.5234544277191162 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41165\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [dorsalstyle] took 0.13022232055664062 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [flewcrashed] took 0.26063966751098633 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5479881763458252 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [subjectbuying] took 0.5242347717285156 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41104\n",
      "INFO:tensorflow:Trying min_count 985\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.1302335262298584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.2605926990509033 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5251455307006836 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0491890907287598 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9798867702484131 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 106204\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [paltrowben] took 0.13044190406799316 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [jesusslife] took 0.2608320713043213 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5934972763061523 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [portbeacon] took 0.5221171379089355 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40146\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [418644u] took 0.13036227226257324 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [commentssimply] took 0.2604484558105469 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5270864963531494 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [numenorscions] took 0.5230312347412109 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40770\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [onwardexcept] took 0.1302652359008789 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [marivingions] took 0.26009225845336914 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5462942123413086 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [lullabyinspired] took 0.5221652984619141 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40736\n",
      "INFO:tensorflow:Trying min_count 993\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.12993073463439941 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.26049232482910156 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5225241184234619 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0638608932495117 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9785809516906738 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 105719\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [02track] took 0.13027572631835938 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [secularmusic] took 0.26082706451416016 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5911974906921387 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [comfirstthrillsleechildebookdpb0050idgairefsr] took 0.5206968784332275 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39958\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [ortograacute] took 0.1299881935119629 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [rollerwiththestickytapestuff] took 0.26004672050476074 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5307366847991943 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [musicyet] took 0.533336877822876 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40571\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [bruntononsea] took 0.1300516128540039 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [wrotecowrotewarrior] took 0.26023173332214355 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5496599674224854 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [formmaintaining] took 0.5236852169036865 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40521\n",
      "INFO:tensorflow:Trying min_count 997\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.13010358810424805 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.26114487648010254 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5231142044067383 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0513761043548584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9800469875335693 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 105466\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [11391140that] took 0.13027215003967285 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [combinablerefinable] took 0.2609384059906006 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5935020446777344 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [byguerrillas] took 0.5217475891113281 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39885\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [1024screenheight] took 0.1322643756866455 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [comuh800smasst6pkpinstripeseamlessathleticmulticoloredproductreviewsb005iqcjhirefcm] took 0.2644829750061035 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.536156415939331 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [submetrics] took 0.5279867649078369 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40496\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [minutesseries] took 0.1335606575012207 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [landgrave] took 0.26401543617248535 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5692448616027832 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [awesomeindies] took 0.5303730964660645 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40435\n",
      "INFO:tensorflow:Trying min_count 999\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.13256192207336426 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.26412463188171387 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5297458171844482 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0628530979156494 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9939100742340088 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 105339\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [com9signsyouhaveanunhealthyrelationshipwithyourdog] took 0.1314868927001953 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [videosclasses] took 0.26442885398864746 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.6076664924621582 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [jonsons] took 0.5306437015533447 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39838\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [nourireluctantly] took 0.13191008567810059 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [comuh800smasst6pkpinstripeseamlessathleticmulticoloredproductreviewsb005iqcjhirefcm] took 0.2650156021118164 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5370252132415771 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [carcinogenicity] took 0.5287821292877197 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40466\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [recordingplayback] took 0.13235688209533691 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gibsonlivonia] took 0.2619452476501465 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5623831748962402 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [ffffffinnn] took 0.5439937114715576 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40398\n",
      "INFO:tensorflow:Trying min_count 1000\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [irrelevancies] took 0.1317298412322998 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [silversmithstoynbee] took 0.26293158531188965 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [electrodynamicsresults] took 0.5343809127807617 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amazonvelodyne] took 1.0656509399414062 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.0035374164581299 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size = 105281\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [comgpcustomermediacustomergallerya130vgg4p4pw5j] took 0.13168740272521973 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [microperfwhatever] took 0.2649219036102295 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.6087322235107422 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [cellotape] took 0.5294716358184814 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39832\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [selectionsimilar] took 0.13238048553466797 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [comuh800smasst6pkpinstripeseamlessathleticmulticoloredproductreviewsb005iqcjhirefcm] took 0.2643260955810547 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5445024967193604 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [tolerateslamming] took 0.5324587821960449 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40441\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [historicalfigureturneddetective] took 0.1313621997833252 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [stylishtextured] took 0.2660694122314453 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5582356452941895 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [nickelbackcreed] took 0.543621301651001 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40385\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n",
      "INFO:tensorflow:Generating case 3000000.\n",
      "INFO:tensorflow:Generating case 3100000.\n",
      "INFO:tensorflow:Generating case 3200000.\n",
      "INFO:tensorflow:Generating case 3300000.\n",
      "INFO:tensorflow:Generating case 3400000.\n",
      "INFO:tensorflow:Generating case 3500000.\n",
      "INFO:tensorflow:Generating case 3600000.\n",
      "INFO:tensorflow:Generating case 3700000.\n",
      "INFO:tensorflow:Generating case 3800000.\n",
      "INFO:tensorflow:Generated 3820633 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:467: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "import generate_problem # self-defined 'generate_problem.py' file in the same folder.\n",
    "\n",
    "# define the directory for generated data\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' # Where data files from internet stored\n",
    "DATA_LOC = './data' # Where pre-prcessed data is stored\n",
    "\n",
    "# Generated training data\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the transformer model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyper params and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate_schedule': 'legacy', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'multiproblem_schedule_threshold': 0.5, 'optimizer_adam_epsilon': 1e-09, 'scheduled_sampling_prob': 0.0, 'kernel_width': 1, 'multiproblem_target_eval_only': False, 'ffn_layer': 'dense_relu_dense', 'num_encoder_layers': 6, 'parameter_attention_value_channels': 0, 'optimizer_adafactor_beta1': 0.0, 'use_fixed_batch_size': False, 'label_smoothing': 0.1, 'moe_num_experts': 16, 'max_relative_position': 0, 'moe_hidden_sizes': '2048', 'multiproblem_label_weight': 0.5, 'optimizer_zero_grads': False, 'prepend_mode': 'prepend_inputs_masked_attention', 'daisy_chain_variables': True, 'num_decoder_layers': 6, 'pretrained_model_dir': '', 'optimizer': 'Adam', 'multiproblem_schedule_max_examples': 10000000.0, 'warm_start_from_second': '', 'self_attention_type': 'dot_product', 'learning_rate_warmup_steps': 8000, 'scheduled_sampling_gold_mixin_prob': 0.5, 'optimizer_adafactor_memory_exponent': 0.8, 'attention_value_channels': 0, 'weight_decay': 0.0, 'video_num_target_frames': 1, 'learning_rate_constant': 1.0, 'factored_logits': False, 'relu_dropout_broadcast_dims': '', 'initializer': 'uniform_unit_scaling', 'optimizer_momentum_momentum': 0.9, 'multiply_embedding_mode': 'sqrt_depth', 'conv_first_kernel': 3, 'eval_run_autoregressive': False, 'force_full_predict': False, 'optimizer_momentum_nesterov': False, 'symbol_modality_num_shards': 16, 'multiproblem_max_input_length': -1, 'layer_postprocess_sequence': 'da', 'optimizer_adafactor_factored': True, 'batch_size': 1024, 'max_input_seq_length': 0, 'learning_rate_decay_staircase': False, 'video_num_input_frames': 1, 'max_length': 0, 'heads_share_relative_embedding': False, 'split_to_length': 0, 'attention_key_channels': 0, 'compress_steps': 0, 'add_relative_to_values': False, 'unidirectional_encoder': False, 'num_hidden_layers': 6, 'moe_k': 2, 'hidden_size': 512, 'attention_variables_3d': False, 'summarize_vars': False, 'optimizer_adafactor_clipping_threshold': 1.0, 'num_heads': 8, 'activation_dtype': 'float32', 'optimizer_multistep_accumulate_steps': None, 'layer_prepostprocess_dropout': 0.1, 'relu_dropout': 0.1, 'sampling_temp': 1.0, 'learning_rate_decay_rate': 1.0, 'vocab_divisor': 1, 'shared_embedding_and_softmax_weights': True, 'weight_dtype': 'float32', 'multiproblem_per_task_threshold': '', 'proximity_bias': False, 'weight_noise': 0.0, 'learning_rate': 0.2, 'grad_noise_scale': 0.0, 'filter_size': 2048, 'parameter_attention_key_channels': 0, 'layer_prepostprocess_dropout_broadcast_dims': '', 'multiproblem_reweight_label_loss': False, 'pad_batch': False, 'symbol_modality_skip_top': False, 'attention_dropout_broadcast_dims': '', 'symbol_dropout': 0.0, 'eval_drop_long_sequences': False, 'kernel_height': 3, 'moe_overhead_train': 1.0, 'shared_embedding': False, 'optimizer_adam_beta2': 0.98, 'sampling_method': 'argmax', 'multiproblem_fixed_train_length': -1, 'scheduled_sampling_warmup_steps': 50000, 'learning_rate_minimum': None, 'overload_eval_metric_name': '', 'learning_rate_cosine_cycle_steps': 250000, 'clip_grad_norm': 0.0, 'length_bucket_step': 1.1, 'nbr_decoder_problems': 1, 'learning_rate_decay_scheme': 'noam', 'multiproblem_mixing_schedule': 'constant', 'min_length_bucket': 8, 'optimizer_adam_beta1': 0.9, 'moe_loss_coef': 0.001, 'attention_dropout': 0.1, 'layer_preprocess_sequence': 'n', 'multiproblem_max_target_length': -1, 'no_data_parallelism': False, 'summarize_grads': False, 'initializer_gain': 1.0, 'moe_overhead_eval': 2.0, 'max_target_seq_length': 0, 'mlperf_mode': False, 'norm_type': 'layer', 'batch_shuffle_size': 512, 'pos': 'timing', 'optimizer_adafactor_decay_type': 'pow', 'dropout': 0.2, 'min_length': 0, 'optimizer_adafactor_beta2': 0.999, 'use_pad_remover': True, 'use_target_space_embedding': True, 'tpu_enable_host_call': False, 'learning_rate_decay_steps': 5000, 'causal_decoder_self_attention': True, 'multiproblem_vocab_size': -1, 'norm_epsilon': 1e-06, 'modality': {}}\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "# Define hparams\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 #512 \n",
    "hparams.learning_rate = 0.2 \n",
    "hparams.num_encoder_layers = 6 \n",
    "hparams.num_decoder_layers = 6 \n",
    "# hparams.max_input_seq_length = \n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 0, '_task_id': 0, '_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_environment': 'local', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc462059b38>, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 20, '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_is_chief': True, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, '_train_distribute': None, '_save_checkpoints_steps': 1000, '_model_dir': 'model_files_full', '_log_step_count_steps': 100, '_master': '', '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_device_fn': None, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc462059c88>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc4620c5488>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64797184\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.776205, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.46171\n",
      "INFO:tensorflow:loss = 8.084997, step = 100 (40.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82414\n",
      "INFO:tensorflow:loss = 7.267791, step = 200 (35.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82941\n",
      "INFO:tensorflow:loss = 6.9000206, step = 300 (35.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7493\n",
      "INFO:tensorflow:loss = 5.919374, step = 400 (36.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84659\n",
      "INFO:tensorflow:loss = 6.2715425, step = 500 (35.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7191\n",
      "INFO:tensorflow:loss = 5.9310794, step = 600 (36.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72935\n",
      "INFO:tensorflow:loss = 6.4163136, step = 700 (36.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80978\n",
      "INFO:tensorflow:loss = 5.919359, step = 800 (35.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.846\n",
      "INFO:tensorflow:loss = 5.657292, step = 900 (35.136 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.31459\n",
      "INFO:tensorflow:loss = 5.22914, step = 1000 (43.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88753\n",
      "INFO:tensorflow:loss = 5.7838755, step = 1100 (34.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79235\n",
      "INFO:tensorflow:loss = 5.7386637, step = 1200 (35.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75472\n",
      "INFO:tensorflow:loss = 5.4578104, step = 1300 (36.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75405\n",
      "INFO:tensorflow:loss = 6.6702967, step = 1400 (36.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82649\n",
      "INFO:tensorflow:loss = 5.756113, step = 1500 (35.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86961\n",
      "INFO:tensorflow:loss = 5.3906474, step = 1600 (34.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83243\n",
      "INFO:tensorflow:loss = 5.2825847, step = 1700 (35.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8219\n",
      "INFO:tensorflow:loss = 6.010115, step = 1800 (35.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78301\n",
      "INFO:tensorflow:loss = 5.458184, step = 1900 (35.933 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.27466\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:235: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T16:05:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-16:07:30\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.0128124105, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.047663994, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.20477778\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_files_full/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.047663994, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.20477778, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.0128124105, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 5.2082124, step = 2000 (166.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.63676\n",
      "INFO:tensorflow:loss = 5.118482, step = 2100 (34.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84946\n",
      "INFO:tensorflow:loss = 6.2413726, step = 2200 (35.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80176\n",
      "INFO:tensorflow:loss = 5.543572, step = 2300 (35.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83889\n",
      "INFO:tensorflow:loss = 4.7863927, step = 2400 (35.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81254\n",
      "INFO:tensorflow:loss = 4.743927, step = 2500 (35.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78719\n",
      "INFO:tensorflow:loss = 5.6951203, step = 2600 (35.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74043\n",
      "INFO:tensorflow:loss = 5.760691, step = 2700 (36.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88747\n",
      "INFO:tensorflow:loss = 4.9931087, step = 2800 (34.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71898\n",
      "INFO:tensorflow:loss = 5.205969, step = 2900 (36.778 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21981\n",
      "INFO:tensorflow:loss = 4.221641, step = 3000 (45.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83423\n",
      "INFO:tensorflow:loss = 5.45786, step = 3100 (35.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79516\n",
      "INFO:tensorflow:loss = 5.7348585, step = 3200 (35.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81577\n",
      "INFO:tensorflow:loss = 4.8372836, step = 3300 (35.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85294\n",
      "INFO:tensorflow:loss = 4.8094664, step = 3400 (35.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77208\n",
      "INFO:tensorflow:loss = 5.4799027, step = 3500 (36.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85164\n",
      "INFO:tensorflow:loss = 5.2676373, step = 3600 (35.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76202\n",
      "INFO:tensorflow:loss = 4.948615, step = 3700 (36.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81079\n",
      "INFO:tensorflow:loss = 5.0210238, step = 3800 (35.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85632\n",
      "INFO:tensorflow:loss = 4.87431, step = 3900 (35.010 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.29917\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T16:19:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-16:21:41\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.031498335, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.084470235, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.25550568\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_files_full/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.084470235, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.25550568, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.031498335, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 4.3501015, step = 4000 (166.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.631265\n",
      "INFO:tensorflow:loss = 5.3810782, step = 4100 (35.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82281\n",
      "INFO:tensorflow:loss = 4.866682, step = 4200 (35.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76135\n",
      "INFO:tensorflow:loss = 5.271386, step = 4300 (36.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79125\n",
      "INFO:tensorflow:loss = 4.4391317, step = 4400 (35.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7584\n",
      "INFO:tensorflow:loss = 3.7531557, step = 4500 (36.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82186\n",
      "INFO:tensorflow:loss = 3.167525, step = 4600 (35.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82659\n",
      "INFO:tensorflow:loss = 5.091064, step = 4700 (35.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77584\n",
      "INFO:tensorflow:loss = 4.324139, step = 4800 (36.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85033\n",
      "INFO:tensorflow:loss = 4.1919136, step = 4900 (35.085 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.2667\n",
      "INFO:tensorflow:loss = 3.2327256, step = 5000 (44.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83739\n",
      "INFO:tensorflow:loss = 3.0959527, step = 5100 (35.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81078\n",
      "INFO:tensorflow:loss = 4.860825, step = 5200 (35.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79977\n",
      "INFO:tensorflow:loss = 5.060632, step = 5300 (35.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85683\n",
      "INFO:tensorflow:loss = 3.463132, step = 5400 (35.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70636\n",
      "INFO:tensorflow:loss = 4.454733, step = 5500 (36.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78935\n",
      "INFO:tensorflow:loss = 4.529982, step = 5600 (35.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81237\n",
      "INFO:tensorflow:loss = 2.282896, step = 5700 (35.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8049\n",
      "INFO:tensorflow:loss = 3.9899433, step = 5800 (35.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7661\n",
      "INFO:tensorflow:loss = 3.4518628, step = 5900 (36.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.22804\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T16:34:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-16:36:02\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.20377071, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.28287596, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.47033828\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_files_full/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.28287596, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.47033828, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.20377071, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 3.4870415, step = 6000 (174.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.607958\n",
      "INFO:tensorflow:loss = 2.3943784, step = 6100 (34.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84211\n",
      "INFO:tensorflow:loss = 1.8083428, step = 6200 (35.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8239\n",
      "INFO:tensorflow:loss = 2.7680974, step = 6300 (35.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82983\n",
      "INFO:tensorflow:loss = 3.2615228, step = 6400 (35.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77854\n",
      "INFO:tensorflow:loss = 5.380438, step = 6500 (35.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81996\n",
      "INFO:tensorflow:loss = 3.6293023, step = 6600 (35.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7932\n",
      "INFO:tensorflow:loss = 2.365358, step = 6700 (35.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73836\n",
      "INFO:tensorflow:loss = 4.942936, step = 6800 (36.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79354\n",
      "INFO:tensorflow:loss = 2.8097646, step = 6900 (35.799 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.28032\n",
      "INFO:tensorflow:loss = 1.9202957, step = 7000 (43.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79339\n",
      "INFO:tensorflow:loss = 2.7710962, step = 7100 (35.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76649\n",
      "INFO:tensorflow:loss = 3.0448885, step = 7200 (36.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76801\n",
      "INFO:tensorflow:loss = 2.8445477, step = 7300 (36.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84537\n",
      "INFO:tensorflow:loss = 3.9050717, step = 7400 (35.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78579\n",
      "INFO:tensorflow:loss = 4.7713575, step = 7500 (35.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76512\n",
      "INFO:tensorflow:loss = 3.9573746, step = 7600 (36.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79656\n",
      "INFO:tensorflow:loss = 1.6797063, step = 7700 (35.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81264\n",
      "INFO:tensorflow:loss = 5.2941976, step = 7800 (35.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8183\n",
      "INFO:tensorflow:loss = 3.8457484, step = 7900 (35.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.28702\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T16:48:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-16:50:17\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.35572842, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.43280572, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.5988732\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_files_full/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.43280572, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.5988732, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.35572842, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 4.054183, step = 8000 (168.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.626523\n",
      "INFO:tensorflow:loss = 2.589958, step = 8100 (34.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.796\n",
      "INFO:tensorflow:loss = 4.358995, step = 8200 (35.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79007\n",
      "INFO:tensorflow:loss = 2.5164063, step = 8300 (35.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80751\n",
      "INFO:tensorflow:loss = 2.0673897, step = 8400 (35.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79027\n",
      "INFO:tensorflow:loss = 2.5742123, step = 8500 (35.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80771\n",
      "INFO:tensorflow:loss = 2.408018, step = 8600 (35.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84581\n",
      "INFO:tensorflow:loss = 2.4031534, step = 8700 (35.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81239\n",
      "INFO:tensorflow:loss = 1.3809483, step = 8800 (35.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90057\n",
      "INFO:tensorflow:loss = 1.8803076, step = 8900 (34.477 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.29011\n",
      "INFO:tensorflow:loss = 3.55721, step = 9000 (43.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81878\n",
      "INFO:tensorflow:loss = 1.9614613, step = 9100 (35.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72618\n",
      "INFO:tensorflow:loss = 3.4809067, step = 9200 (36.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75666\n",
      "INFO:tensorflow:loss = 2.8774216, step = 9300 (36.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72662\n",
      "INFO:tensorflow:loss = 1.3794267, step = 9400 (36.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82551\n",
      "INFO:tensorflow:loss = 1.3927072, step = 9500 (35.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78593\n",
      "INFO:tensorflow:loss = 2.7484145, step = 9600 (35.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83572\n",
      "INFO:tensorflow:loss = 3.085215, step = 9700 (35.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77285\n",
      "INFO:tensorflow:loss = 2.1782935, step = 9800 (36.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7884\n",
      "INFO:tensorflow:loss = 1.4354887, step = 9900 (35.862 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21372\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T17:02:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-17:04:31\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.49991935, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.5678292, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.71030784\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_files_full/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.5678292, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.71030784, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.49991935, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 3.0125995, step = 10000 (168.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.626725\n",
      "INFO:tensorflow:loss = 4.129762, step = 10100 (36.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84101\n",
      "INFO:tensorflow:loss = 3.486023, step = 10200 (35.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75821\n",
      "INFO:tensorflow:loss = 2.8082964, step = 10300 (36.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84767\n",
      "INFO:tensorflow:loss = 1.6921791, step = 10400 (35.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78055\n",
      "INFO:tensorflow:loss = 1.7015591, step = 10500 (35.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87617\n",
      "INFO:tensorflow:loss = 2.6078315, step = 10600 (34.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82984\n",
      "INFO:tensorflow:loss = 1.3690665, step = 10700 (35.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88258\n",
      "INFO:tensorflow:loss = 2.014291, step = 10800 (34.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80271\n",
      "INFO:tensorflow:loss = 3.6840742, step = 10900 (35.681 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25308\n",
      "INFO:tensorflow:loss = 2.6817997, step = 11000 (44.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82157\n",
      "INFO:tensorflow:loss = 2.2817128, step = 11100 (35.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8028\n",
      "INFO:tensorflow:loss = 4.0280104, step = 11200 (35.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8147\n",
      "INFO:tensorflow:loss = 0.69117844, step = 11300 (35.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89182\n",
      "INFO:tensorflow:loss = 1.3427274, step = 11400 (34.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74681\n",
      "INFO:tensorflow:loss = 2.3736897, step = 11500 (36.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8848\n",
      "INFO:tensorflow:loss = 1.5507466, step = 11600 (34.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85929\n",
      "INFO:tensorflow:loss = 1.9270203, step = 11700 (34.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7784\n",
      "INFO:tensorflow:loss = 3.0931368, step = 11800 (35.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73145\n",
      "INFO:tensorflow:loss = 1.4750861, step = 11900 (36.609 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.30853\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T17:16:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-17:18:40\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.5831738, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.6457318, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.76561385\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_files_full/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.6457318, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.76561385, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.5831738, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.4322765, step = 12000 (164.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.6369\n",
      "INFO:tensorflow:loss = 1.7270321, step = 12100 (35.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82885\n",
      "INFO:tensorflow:loss = 2.2541373, step = 12200 (35.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76836\n",
      "INFO:tensorflow:loss = 1.7244179, step = 12300 (36.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76614\n",
      "INFO:tensorflow:loss = 2.5652308, step = 12400 (36.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72182\n",
      "INFO:tensorflow:loss = 3.0013182, step = 12500 (36.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7414\n",
      "INFO:tensorflow:loss = 3.646745, step = 12600 (36.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76101\n",
      "INFO:tensorflow:loss = 1.0824858, step = 12700 (36.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76082\n",
      "INFO:tensorflow:loss = 2.989363, step = 12800 (36.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78316\n",
      "INFO:tensorflow:loss = 3.039558, step = 12900 (35.931 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21701\n",
      "INFO:tensorflow:loss = 1.266637, step = 13000 (45.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84378\n",
      "INFO:tensorflow:loss = 0.999669, step = 13100 (35.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92612\n",
      "INFO:tensorflow:loss = 1.255933, step = 13200 (34.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85202\n",
      "INFO:tensorflow:loss = 2.5735314, step = 13300 (35.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82099\n",
      "INFO:tensorflow:loss = 1.0267149, step = 13400 (35.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80798\n",
      "INFO:tensorflow:loss = 1.2293874, step = 13500 (35.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85024\n",
      "INFO:tensorflow:loss = 1.8290181, step = 13600 (35.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77478\n",
      "INFO:tensorflow:loss = 2.1984267, step = 13700 (36.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77788\n",
      "INFO:tensorflow:loss = 1.1058168, step = 13800 (35.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77798\n",
      "INFO:tensorflow:loss = 2.0629158, step = 13900 (35.997 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.29438\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T17:30:59Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-17:32:52\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.63250566, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.68507963, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7940075\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_files_full/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.68507963, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7940075, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.63250566, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.8591403, step = 14000 (163.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.641632\n",
      "INFO:tensorflow:loss = 0.76988316, step = 14100 (36.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79892\n",
      "INFO:tensorflow:loss = 0.91140467, step = 14200 (35.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80268\n",
      "INFO:tensorflow:loss = 0.7546943, step = 14300 (35.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83475\n",
      "INFO:tensorflow:loss = 1.2888759, step = 14400 (35.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76996\n",
      "INFO:tensorflow:loss = 1.1339461, step = 14500 (36.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81046\n",
      "INFO:tensorflow:loss = 1.3135762, step = 14600 (35.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78107\n",
      "INFO:tensorflow:loss = 1.8572551, step = 14700 (35.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91308\n",
      "INFO:tensorflow:loss = 1.6999072, step = 14800 (34.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80111\n",
      "INFO:tensorflow:loss = 0.69284993, step = 14900 (35.701 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23673\n",
      "INFO:tensorflow:loss = 0.99632996, step = 15000 (44.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81202\n",
      "INFO:tensorflow:loss = 2.562629, step = 15100 (35.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7931\n",
      "INFO:tensorflow:loss = 1.7326249, step = 15200 (35.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79249\n",
      "INFO:tensorflow:loss = 1.5108999, step = 15300 (35.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8235\n",
      "INFO:tensorflow:loss = 1.2070383, step = 15400 (35.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83144\n",
      "INFO:tensorflow:loss = 1.4397626, step = 15500 (35.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78665\n",
      "INFO:tensorflow:loss = 1.5594504, step = 15600 (35.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8285\n",
      "INFO:tensorflow:loss = 1.0597957, step = 15700 (35.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73197\n",
      "INFO:tensorflow:loss = 1.5953387, step = 15800 (36.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86548\n",
      "INFO:tensorflow:loss = 2.6299765, step = 15900 (34.899 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.2682\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T17:45:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-17:47:01\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6661545, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.71493584, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8102051\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_files_full/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.71493584, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8102051, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6661545, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 0.7367645, step = 16000 (163.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.646498\n",
      "INFO:tensorflow:loss = 0.7109847, step = 16100 (35.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75752\n",
      "INFO:tensorflow:loss = 2.6845167, step = 16200 (36.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86337\n",
      "INFO:tensorflow:loss = 1.8420326, step = 16300 (34.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7415\n",
      "INFO:tensorflow:loss = 3.289079, step = 16400 (36.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77474\n",
      "INFO:tensorflow:loss = 1.8416572, step = 16500 (36.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85855\n",
      "INFO:tensorflow:loss = 0.954303, step = 16600 (34.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76675\n",
      "INFO:tensorflow:loss = 1.412068, step = 16700 (36.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78697\n",
      "INFO:tensorflow:loss = 3.1957345, step = 16800 (35.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73305\n",
      "INFO:tensorflow:loss = 1.4421166, step = 16900 (36.589 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26501\n",
      "INFO:tensorflow:loss = 0.93778574, step = 17000 (44.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8925\n",
      "INFO:tensorflow:loss = 0.66716444, step = 17100 (34.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75827\n",
      "INFO:tensorflow:loss = 1.1892856, step = 17200 (36.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79347\n",
      "INFO:tensorflow:loss = 1.4621842, step = 17300 (35.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8631\n",
      "INFO:tensorflow:loss = 0.9029739, step = 17400 (34.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81157\n",
      "INFO:tensorflow:loss = 0.8473304, step = 17500 (35.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79658\n",
      "INFO:tensorflow:loss = 1.1965482, step = 17600 (35.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81535\n",
      "INFO:tensorflow:loss = 1.5400679, step = 17700 (35.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78854\n",
      "INFO:tensorflow:loss = 0.85129905, step = 17800 (35.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80466\n",
      "INFO:tensorflow:loss = 1.5450366, step = 17900 (35.655 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25422\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T17:59:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-18:01:11\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6863528, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.73289984, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8235811\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_files_full/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.73289984, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8235811, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6863528, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.7912909, step = 18000 (163.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.648894\n",
      "INFO:tensorflow:loss = 1.0678056, step = 18100 (35.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8052\n",
      "INFO:tensorflow:loss = 0.7403763, step = 18200 (35.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.833\n",
      "INFO:tensorflow:loss = 1.6250874, step = 18300 (35.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79907\n",
      "INFO:tensorflow:loss = 0.5988245, step = 18400 (35.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78512\n",
      "INFO:tensorflow:loss = 2.5323596, step = 18500 (35.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84143\n",
      "INFO:tensorflow:loss = 0.56710744, step = 18600 (35.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82608\n",
      "INFO:tensorflow:loss = 1.4430038, step = 18700 (35.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87917\n",
      "INFO:tensorflow:loss = 1.564221, step = 18800 (34.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79611\n",
      "INFO:tensorflow:loss = 1.1644684, step = 18900 (35.765 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20418\n",
      "INFO:tensorflow:loss = 1.7440679, step = 19000 (45.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74684\n",
      "INFO:tensorflow:loss = 1.022204, step = 19100 (36.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7115\n",
      "INFO:tensorflow:loss = 0.8683649, step = 19200 (36.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73086\n",
      "INFO:tensorflow:loss = 0.84018207, step = 19300 (36.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80485\n",
      "INFO:tensorflow:loss = 0.99096847, step = 19400 (35.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80857\n",
      "INFO:tensorflow:loss = 1.1569899, step = 19500 (35.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85285\n",
      "INFO:tensorflow:loss = 3.2375813, step = 19600 (35.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74876\n",
      "INFO:tensorflow:loss = 1.7970088, step = 19700 (36.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8763\n",
      "INFO:tensorflow:loss = 0.67733437, step = 19800 (34.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87771\n",
      "INFO:tensorflow:loss = 0.920292, step = 19900 (34.749 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_files_full/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 2.24429\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T18:13:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-18:15:21\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7065783, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.75062126, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.83450997\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_files_full/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.75062126, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.83450997, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7065783, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.3751113, step = 20000 (163.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.646883\n",
      "INFO:tensorflow:loss = 1.3077171, step = 20100 (35.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76693\n",
      "INFO:tensorflow:loss = 0.73993695, step = 20200 (36.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83427\n",
      "INFO:tensorflow:loss = 1.1460564, step = 20300 (35.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70626\n",
      "INFO:tensorflow:loss = 1.0442839, step = 20400 (36.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74511\n",
      "INFO:tensorflow:loss = 1.8221664, step = 20500 (36.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86177\n",
      "INFO:tensorflow:loss = 0.75595236, step = 20600 (34.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77576\n",
      "INFO:tensorflow:loss = 0.72246015, step = 20700 (36.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76051\n",
      "INFO:tensorflow:loss = 1.0649583, step = 20800 (36.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82325\n",
      "INFO:tensorflow:loss = 1.3502252, step = 20900 (35.421 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25255\n",
      "INFO:tensorflow:loss = 0.8990756, step = 21000 (44.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87465\n",
      "INFO:tensorflow:loss = 1.1258105, step = 21100 (34.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78378\n",
      "INFO:tensorflow:loss = 0.7036476, step = 21200 (35.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80568\n",
      "INFO:tensorflow:loss = 0.71362245, step = 21300 (35.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80821\n",
      "INFO:tensorflow:loss = 0.8850017, step = 21400 (35.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80047\n",
      "INFO:tensorflow:loss = 1.1684321, step = 21500 (35.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85109\n",
      "INFO:tensorflow:loss = 1.7371615, step = 21600 (35.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77859\n",
      "INFO:tensorflow:loss = 0.6947077, step = 21700 (35.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80953\n",
      "INFO:tensorflow:loss = 1.0951449, step = 21800 (35.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83726\n",
      "INFO:tensorflow:loss = 1.3916174, step = 21900 (35.247 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21194\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T18:27:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-18:29:33\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7222691, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7657261, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.843201\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_files_full/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7657261, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.843201, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7222691, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.3643425, step = 22000 (165.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.640897\n",
      "INFO:tensorflow:loss = 1.1751096, step = 22100 (35.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85314\n",
      "INFO:tensorflow:loss = 0.75518554, step = 22200 (35.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81099\n",
      "INFO:tensorflow:loss = 0.9167583, step = 22300 (35.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81724\n",
      "INFO:tensorflow:loss = 1.313825, step = 22400 (35.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76519\n",
      "INFO:tensorflow:loss = 2.8895564, step = 22500 (36.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80096\n",
      "INFO:tensorflow:loss = 1.4320518, step = 22600 (35.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79258\n",
      "INFO:tensorflow:loss = 1.0859901, step = 22700 (35.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7822\n",
      "INFO:tensorflow:loss = 1.207106, step = 22800 (35.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79896\n",
      "INFO:tensorflow:loss = 0.91026783, step = 22900 (35.728 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25499\n",
      "INFO:tensorflow:loss = 1.1246479, step = 23000 (44.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84832\n",
      "INFO:tensorflow:loss = 0.7676479, step = 23100 (35.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80971\n",
      "INFO:tensorflow:loss = 1.1851677, step = 23200 (35.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82353\n",
      "INFO:tensorflow:loss = 2.6666934, step = 23300 (35.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79376\n",
      "INFO:tensorflow:loss = 1.2019328, step = 23400 (35.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71221\n",
      "INFO:tensorflow:loss = 0.75997174, step = 23500 (36.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74419\n",
      "INFO:tensorflow:loss = 0.6575418, step = 23600 (36.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81901\n",
      "INFO:tensorflow:loss = 0.71212256, step = 23700 (35.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78729\n",
      "INFO:tensorflow:loss = 0.4662567, step = 23800 (35.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8051\n",
      "INFO:tensorflow:loss = 1.1035144, step = 23900 (35.650 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24502\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T18:41:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-18:43:44\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.73116183, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7728789, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8474802\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_files_full/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7728789, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8474802, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.73116183, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.4594088, step = 24000 (162.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.647033\n",
      "INFO:tensorflow:loss = 1.2511016, step = 24100 (36.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80009\n",
      "INFO:tensorflow:loss = 1.4078374, step = 24200 (35.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77852\n",
      "INFO:tensorflow:loss = 1.4796273, step = 24300 (35.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86254\n",
      "INFO:tensorflow:loss = 1.1998711, step = 24400 (34.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7874\n",
      "INFO:tensorflow:loss = 0.92892134, step = 24500 (35.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81782\n",
      "INFO:tensorflow:loss = 1.3943052, step = 24600 (35.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79325\n",
      "INFO:tensorflow:loss = 1.6647828, step = 24700 (35.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77725\n",
      "INFO:tensorflow:loss = 2.2569122, step = 24800 (36.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82205\n",
      "INFO:tensorflow:loss = 0.51430804, step = 24900 (35.436 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21346\n",
      "INFO:tensorflow:loss = 1.7901576, step = 25000 (45.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80106\n",
      "INFO:tensorflow:loss = 1.8492134, step = 25100 (35.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85004\n",
      "INFO:tensorflow:loss = 0.71853256, step = 25200 (35.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81389\n",
      "INFO:tensorflow:loss = 1.1759948, step = 25300 (35.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8279\n",
      "INFO:tensorflow:loss = 0.6227274, step = 25400 (35.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84814\n",
      "INFO:tensorflow:loss = 1.3340027, step = 25500 (35.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79339\n",
      "INFO:tensorflow:loss = 0.7838867, step = 25600 (35.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75103\n",
      "INFO:tensorflow:loss = 1.124357, step = 25700 (36.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7436\n",
      "INFO:tensorflow:loss = 0.59513044, step = 25800 (36.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8035\n",
      "INFO:tensorflow:loss = 0.8046873, step = 25900 (35.670 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.22657\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T18:56:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-18:57:55\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7489721, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.78909457, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8571916\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_files_full/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.78909457, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8571916, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7489721, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 0.43471676, step = 26000 (163.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.647874\n",
      "INFO:tensorflow:loss = 2.9716024, step = 26100 (35.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80887\n",
      "INFO:tensorflow:loss = 0.8406388, step = 26200 (35.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.864\n",
      "INFO:tensorflow:loss = 0.7969899, step = 26300 (34.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77016\n",
      "INFO:tensorflow:loss = 0.80603534, step = 26400 (36.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82406\n",
      "INFO:tensorflow:loss = 0.8780515, step = 26500 (35.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82304\n",
      "INFO:tensorflow:loss = 1.0129198, step = 26600 (35.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79782\n",
      "INFO:tensorflow:loss = 1.8453869, step = 26700 (35.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81585\n",
      "INFO:tensorflow:loss = 1.0813979, step = 26800 (35.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73992\n",
      "INFO:tensorflow:loss = 1.1538959, step = 26900 (36.499 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24808\n",
      "INFO:tensorflow:loss = 0.5562456, step = 27000 (44.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82345\n",
      "INFO:tensorflow:loss = 1.0655527, step = 27100 (35.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82922\n",
      "INFO:tensorflow:loss = 1.2742505, step = 27200 (35.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7937\n",
      "INFO:tensorflow:loss = 0.42373824, step = 27300 (35.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77385\n",
      "INFO:tensorflow:loss = 0.66239, step = 27400 (36.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70279\n",
      "INFO:tensorflow:loss = 1.0241485, step = 27500 (36.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73797\n",
      "INFO:tensorflow:loss = 0.75453573, step = 27600 (36.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79339\n",
      "INFO:tensorflow:loss = 1.0114568, step = 27700 (35.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84485\n",
      "INFO:tensorflow:loss = 1.8388953, step = 27800 (35.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81782\n",
      "INFO:tensorflow:loss = 1.0154994, step = 27900 (35.488 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23192\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T19:10:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-19:12:06\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.75058305, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7905001, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.85909307\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_files_full/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7905001, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.85909307, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.75058305, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.6019806, step = 28000 (163.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.64746\n",
      "INFO:tensorflow:loss = 0.93167007, step = 28100 (35.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80643\n",
      "INFO:tensorflow:loss = 0.6813688, step = 28200 (35.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81667\n",
      "INFO:tensorflow:loss = 0.5159442, step = 28300 (35.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82768\n",
      "INFO:tensorflow:loss = 0.92116433, step = 28400 (35.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80602\n",
      "INFO:tensorflow:loss = 1.0239999, step = 28500 (35.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85258\n",
      "INFO:tensorflow:loss = 1.7620451, step = 28600 (35.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81625\n",
      "INFO:tensorflow:loss = 0.95737964, step = 28700 (35.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8031\n",
      "INFO:tensorflow:loss = 0.7074366, step = 28800 (35.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78184\n",
      "INFO:tensorflow:loss = 1.8731545, step = 28900 (35.949 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.22669\n",
      "INFO:tensorflow:loss = 1.6930946, step = 29000 (44.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77919\n",
      "INFO:tensorflow:loss = 1.3745184, step = 29100 (35.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83285\n",
      "INFO:tensorflow:loss = 1.3818678, step = 29200 (35.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70729\n",
      "INFO:tensorflow:loss = 0.84829974, step = 29300 (36.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8269\n",
      "INFO:tensorflow:loss = 0.39742595, step = 29400 (35.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83259\n",
      "INFO:tensorflow:loss = 1.1121478, step = 29500 (35.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76426\n",
      "INFO:tensorflow:loss = 0.42836353, step = 29600 (36.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82749\n",
      "INFO:tensorflow:loss = 1.7865984, step = 29700 (35.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86748\n",
      "INFO:tensorflow:loss = 0.8997077, step = 29800 (34.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83472\n",
      "INFO:tensorflow:loss = 0.57158244, step = 29900 (35.277 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.2141\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T19:24:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-19:26:15\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7640891, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8023638, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8657652\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_files_full/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8023638, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8657652, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7640891, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.4656055, step = 30000 (163.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.652589\n",
      "INFO:tensorflow:loss = 0.54104084, step = 30100 (35.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82273\n",
      "INFO:tensorflow:loss = 1.139172, step = 30200 (35.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83149\n",
      "INFO:tensorflow:loss = 0.66695225, step = 30300 (35.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77073\n",
      "INFO:tensorflow:loss = 0.5143195, step = 30400 (36.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82042\n",
      "INFO:tensorflow:loss = 1.3291354, step = 30500 (35.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74692\n",
      "INFO:tensorflow:loss = 1.3189633, step = 30600 (36.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78401\n",
      "INFO:tensorflow:loss = 0.7765396, step = 30700 (35.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77043\n",
      "INFO:tensorflow:loss = 0.7979597, step = 30800 (36.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79211\n",
      "INFO:tensorflow:loss = 0.9842884, step = 30900 (35.816 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.2611\n",
      "INFO:tensorflow:loss = 1.0417242, step = 31000 (44.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75623\n",
      "INFO:tensorflow:loss = 0.8529313, step = 31100 (36.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76048\n",
      "INFO:tensorflow:loss = 0.9916332, step = 31200 (36.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82559\n",
      "INFO:tensorflow:loss = 0.5361335, step = 31300 (35.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86045\n",
      "INFO:tensorflow:loss = 0.5367102, step = 31400 (34.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7418\n",
      "INFO:tensorflow:loss = 1.0162266, step = 31500 (36.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85052\n",
      "INFO:tensorflow:loss = 0.7907778, step = 31600 (35.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76582\n",
      "INFO:tensorflow:loss = 0.5440786, step = 31700 (36.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7888\n",
      "INFO:tensorflow:loss = 0.99222517, step = 31800 (35.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73707\n",
      "INFO:tensorflow:loss = 1.746248, step = 31900 (36.536 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24064\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T19:38:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-19:40:27\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7695575, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.80634856, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8688422\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_files_full/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.80634856, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8688422, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7695575, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 0.98401326, step = 32000 (162.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650748\n",
      "INFO:tensorflow:loss = 0.52187896, step = 32100 (35.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78995\n",
      "INFO:tensorflow:loss = 0.86957467, step = 32200 (35.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75793\n",
      "INFO:tensorflow:loss = 0.7713637, step = 32300 (36.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84418\n",
      "INFO:tensorflow:loss = 1.0396627, step = 32400 (35.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85597\n",
      "INFO:tensorflow:loss = 0.80518687, step = 32500 (35.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77882\n",
      "INFO:tensorflow:loss = 0.6610431, step = 32600 (35.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81743\n",
      "INFO:tensorflow:loss = 0.9285358, step = 32700 (35.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82805\n",
      "INFO:tensorflow:loss = 0.956529, step = 32800 (35.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.67688\n",
      "INFO:tensorflow:loss = 1.1311582, step = 32900 (37.358 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25335\n",
      "INFO:tensorflow:loss = 1.3213853, step = 33000 (44.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78316\n",
      "INFO:tensorflow:loss = 0.84856987, step = 33100 (35.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85928\n",
      "INFO:tensorflow:loss = 0.6559852, step = 33200 (34.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82122\n",
      "INFO:tensorflow:loss = 0.41861734, step = 33300 (35.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79451\n",
      "INFO:tensorflow:loss = 0.5496907, step = 33400 (35.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83193\n",
      "INFO:tensorflow:loss = 0.77187407, step = 33500 (35.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.828\n",
      "INFO:tensorflow:loss = 0.30157968, step = 33600 (35.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83031\n",
      "INFO:tensorflow:loss = 1.0517656, step = 33700 (35.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.6899\n",
      "INFO:tensorflow:loss = 0.73272306, step = 33800 (37.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82965\n",
      "INFO:tensorflow:loss = 0.85670716, step = 33900 (35.340 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.19021\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T19:52:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-19:54:37\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.77250946, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8096279, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87106574\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_files_full/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8096279, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87106574, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.77250946, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 0.54977745, step = 34000 (162.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.654874\n",
      "INFO:tensorflow:loss = 1.0627781, step = 34100 (35.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83634\n",
      "INFO:tensorflow:loss = 0.55973935, step = 34200 (35.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84019\n",
      "INFO:tensorflow:loss = 1.1828322, step = 34300 (35.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87381\n",
      "INFO:tensorflow:loss = 0.9919042, step = 34400 (34.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81097\n",
      "INFO:tensorflow:loss = 0.66985536, step = 34500 (35.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80644\n",
      "INFO:tensorflow:loss = 0.75181407, step = 34600 (35.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80891\n",
      "INFO:tensorflow:loss = 1.0944513, step = 34700 (35.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85851\n",
      "INFO:tensorflow:loss = 0.6799771, step = 34800 (34.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75824\n",
      "INFO:tensorflow:loss = 0.63624734, step = 34900 (36.256 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23306\n",
      "INFO:tensorflow:loss = 1.0435891, step = 35000 (44.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79274\n",
      "INFO:tensorflow:loss = 1.0205368, step = 35100 (35.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79951\n",
      "INFO:tensorflow:loss = 1.8550578, step = 35200 (35.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80203\n",
      "INFO:tensorflow:loss = 2.1025076, step = 35300 (35.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81575\n",
      "INFO:tensorflow:loss = 0.66087496, step = 35400 (35.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87058\n",
      "INFO:tensorflow:loss = 0.7244407, step = 35500 (34.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75972\n",
      "INFO:tensorflow:loss = 0.47902784, step = 35600 (36.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.761\n",
      "INFO:tensorflow:loss = 0.7510335, step = 35700 (36.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75755\n",
      "INFO:tensorflow:loss = 1.1568112, step = 35800 (36.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.27232\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T20:06:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-20:08:44\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7773877, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.81291497, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8728213\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_files_full/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.81291497, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8728213, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7773877, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 1.3391247, step = 36000 (161.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.653412\n",
      "INFO:tensorflow:loss = 0.68285483, step = 36100 (35.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7812\n",
      "INFO:tensorflow:loss = 0.89428264, step = 36200 (35.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77309\n",
      "INFO:tensorflow:loss = 0.5473299, step = 36300 (36.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.781\n",
      "INFO:tensorflow:loss = 0.5627859, step = 36400 (35.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80288\n",
      "INFO:tensorflow:loss = 1.5385294, step = 36500 (35.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89608\n",
      "INFO:tensorflow:loss = 0.72617835, step = 36600 (34.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85676\n",
      "INFO:tensorflow:loss = 1.8463349, step = 36700 (35.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82676\n",
      "INFO:tensorflow:loss = 0.68194926, step = 36800 (35.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73314\n",
      "INFO:tensorflow:loss = 0.56858313, step = 36900 (36.589 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20826\n",
      "INFO:tensorflow:loss = 1.4422804, step = 37000 (45.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85995\n",
      "INFO:tensorflow:loss = 0.53058946, step = 37100 (34.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82245\n",
      "INFO:tensorflow:loss = 0.45616844, step = 37200 (35.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84445\n",
      "INFO:tensorflow:loss = 0.48249832, step = 37300 (35.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78227\n",
      "INFO:tensorflow:loss = 0.35241407, step = 37400 (35.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80062\n",
      "INFO:tensorflow:loss = 0.4966393, step = 37500 (35.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79824\n",
      "INFO:tensorflow:loss = 0.6123184, step = 37600 (35.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83079\n",
      "INFO:tensorflow:loss = 0.6782154, step = 37700 (35.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82483\n",
      "INFO:tensorflow:loss = 0.55993587, step = 37800 (35.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76981\n",
      "INFO:tensorflow:loss = 1.5679879, step = 37900 (36.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26974\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T20:21:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-20:22:52\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7718613, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.80753917, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8715491\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_files_full/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.80753917, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8715491, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7718613, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 0.5452254, step = 38000 (162.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.653811\n",
      "INFO:tensorflow:loss = 0.9876474, step = 38100 (34.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82681\n",
      "INFO:tensorflow:loss = 0.4124171, step = 38200 (35.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81644\n",
      "INFO:tensorflow:loss = 1.2381263, step = 38300 (35.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76354\n",
      "INFO:tensorflow:loss = 1.5468172, step = 38400 (36.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76525\n",
      "INFO:tensorflow:loss = 1.1631536, step = 38500 (36.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77962\n",
      "INFO:tensorflow:loss = 0.4462737, step = 38600 (35.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76906\n",
      "INFO:tensorflow:loss = 0.8690252, step = 38700 (36.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83071\n",
      "INFO:tensorflow:loss = 0.39333552, step = 38800 (35.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81384\n",
      "INFO:tensorflow:loss = 0.48114523, step = 38900 (35.540 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.29013\n",
      "INFO:tensorflow:loss = 0.86073226, step = 39000 (43.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79336\n",
      "INFO:tensorflow:loss = 2.7627017, step = 39100 (35.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80924\n",
      "INFO:tensorflow:loss = 0.66571, step = 39200 (35.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72919\n",
      "INFO:tensorflow:loss = 2.7528718, step = 39300 (36.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71149\n",
      "INFO:tensorflow:loss = 0.7668061, step = 39400 (36.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72917\n",
      "INFO:tensorflow:loss = 2.074387, step = 39500 (36.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78493\n",
      "INFO:tensorflow:loss = 0.4502248, step = 39600 (35.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84487\n",
      "INFO:tensorflow:loss = 0.47640648, step = 39700 (35.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72228\n",
      "INFO:tensorflow:loss = 1.2002472, step = 39800 (36.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77986\n",
      "INFO:tensorflow:loss = 0.8675699, step = 39900 (35.973 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26907\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T20:35:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_full/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-20:37:04\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.787529, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8226779, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87980163\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: model_files_full/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40000): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8226779, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87980163, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.787529, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0\n",
      "INFO:tensorflow:loss = 0.6166023, step = 40000 (162.016 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_full/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6166023.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'timeit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cd6b12927e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# running time check (running on 1GPU server)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time: {} s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timeit' is not defined"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "# create run config\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "t2t_model = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, \n",
    "        data_dir='./data', \n",
    "        train_steps=40001,\n",
    "        eval_steps=200\n",
    "    )\n",
    "\n",
    "# training\n",
    "t2t_model.train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f5ae955a048>, '_is_chief': True, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_eval_distribute': None, '_task_type': None, 'use_tpu': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ae955a128>, '_num_ps_replicas': 0, '_device_fn': None, '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_master': '', 't2t_device_info': {'num_async_replicas': 1}, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_num_worker_replicas': 0, '_evaluation_master': '', '_train_distribute': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_environment': 'local', '_keep_checkpoint_max': 20, '_model_dir': 'model_files', '_save_checkpoints_steps': 1000}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f59f5427488>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64797184\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_files/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.754492, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.45387\n",
      "INFO:tensorflow:loss = 7.963124, step = 100 (40.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76769\n",
      "INFO:tensorflow:loss = 7.2162547, step = 200 (36.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75789\n",
      "INFO:tensorflow:loss = 6.28202, step = 300 (36.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79966\n",
      "INFO:tensorflow:loss = 6.142589, step = 400 (35.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75995\n",
      "INFO:tensorflow:loss = 6.446216, step = 500 (36.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87439\n",
      "INFO:tensorflow:loss = 5.604197, step = 600 (34.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74242\n",
      "INFO:tensorflow:loss = 6.345299, step = 700 (36.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80986\n",
      "INFO:tensorflow:loss = 5.658699, step = 800 (35.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76463\n",
      "INFO:tensorflow:loss = 5.5203457, step = 900 (36.172 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.04354\n",
      "INFO:tensorflow:loss = 5.6091228, step = 1000 (48.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82313\n",
      "INFO:tensorflow:loss = 6.082591, step = 1100 (35.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75467\n",
      "INFO:tensorflow:loss = 5.8436813, step = 1200 (36.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81162\n",
      "INFO:tensorflow:loss = 5.081661, step = 1300 (35.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81004\n",
      "INFO:tensorflow:loss = 5.373406, step = 1400 (35.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84993\n",
      "INFO:tensorflow:loss = 4.908943, step = 1500 (35.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79909\n",
      "INFO:tensorflow:loss = 5.188394, step = 1600 (35.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80109\n",
      "INFO:tensorflow:loss = 5.542469, step = 1700 (35.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82326\n",
      "INFO:tensorflow:loss = 5.429357, step = 1800 (35.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80111\n",
      "INFO:tensorflow:loss = 5.058107, step = 1900 (35.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.91368\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T11:39:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-11:41:14\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.013314554, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.04765475, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.20643672\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_files/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.04765475, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.013314554, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.20643672\n",
      "INFO:tensorflow:loss = 5.160063, step = 2000 (166.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.665331\n",
      "INFO:tensorflow:loss = 5.8443165, step = 2100 (36.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82221\n",
      "INFO:tensorflow:loss = 5.279058, step = 2200 (35.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80745\n",
      "INFO:tensorflow:loss = 4.9255266, step = 2300 (35.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88646\n",
      "INFO:tensorflow:loss = 5.10085, step = 2400 (34.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79357\n",
      "INFO:tensorflow:loss = 5.7626643, step = 2500 (35.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79979\n",
      "INFO:tensorflow:loss = 5.2320113, step = 2600 (35.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77733\n",
      "INFO:tensorflow:loss = 6.4921412, step = 2700 (36.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89167\n",
      "INFO:tensorflow:loss = 4.9186697, step = 2800 (34.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84167\n",
      "INFO:tensorflow:loss = 5.29222, step = 2900 (35.191 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.12794\n",
      "INFO:tensorflow:loss = 5.122961, step = 3000 (46.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79137\n",
      "INFO:tensorflow:loss = 4.854396, step = 3100 (35.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80289\n",
      "INFO:tensorflow:loss = 5.2264404, step = 3200 (35.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8187\n",
      "INFO:tensorflow:loss = 5.330108, step = 3300 (35.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84536\n",
      "INFO:tensorflow:loss = 5.2862644, step = 3400 (35.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82127\n",
      "INFO:tensorflow:loss = 4.8308115, step = 3500 (35.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84396\n",
      "INFO:tensorflow:loss = 4.8676267, step = 3600 (35.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81491\n",
      "INFO:tensorflow:loss = 4.6832094, step = 3700 (35.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80794\n",
      "INFO:tensorflow:loss = 3.5739071, step = 3800 (35.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82267\n",
      "INFO:tensorflow:loss = 5.578686, step = 3900 (35.429 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.06465\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T11:54:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-11:56:12\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.040099967, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.09518269, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.26737246\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_files/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.09518269, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.040099967, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.26737246\n",
      "INFO:tensorflow:loss = 4.7799044, step = 4000 (217.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.629918\n",
      "INFO:tensorflow:loss = 5.1774945, step = 4100 (35.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77527\n",
      "INFO:tensorflow:loss = 4.5272627, step = 4200 (35.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8247\n",
      "INFO:tensorflow:loss = 4.6615734, step = 4300 (35.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75453\n",
      "INFO:tensorflow:loss = 5.053758, step = 4400 (36.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81734\n",
      "INFO:tensorflow:loss = 4.6018357, step = 4500 (36.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75589\n",
      "INFO:tensorflow:loss = 4.195736, step = 4600 (35.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7074\n",
      "INFO:tensorflow:loss = 5.0555077, step = 4700 (36.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75928\n",
      "INFO:tensorflow:loss = 4.6922374, step = 4800 (36.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83849\n",
      "INFO:tensorflow:loss = 5.3977294, step = 4900 (35.232 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.44722\n",
      "INFO:tensorflow:loss = 4.2465587, step = 5000 (69.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85956\n",
      "INFO:tensorflow:loss = 4.960731, step = 5100 (34.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79954\n",
      "INFO:tensorflow:loss = 3.94234, step = 5200 (35.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85122\n",
      "INFO:tensorflow:loss = 3.3502977, step = 5300 (35.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75323\n",
      "INFO:tensorflow:loss = 3.5295808, step = 5400 (36.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7994\n",
      "INFO:tensorflow:loss = 4.818104, step = 5500 (35.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77442\n",
      "INFO:tensorflow:loss = 2.2951884, step = 5600 (36.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70213\n",
      "INFO:tensorflow:loss = 4.3149076, step = 5700 (37.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86677\n",
      "INFO:tensorflow:loss = 5.0480714, step = 5800 (34.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79894\n",
      "INFO:tensorflow:loss = 4.6555724, step = 5900 (35.728 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.05111\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T12:09:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-12:10:58\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.23264775, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.31688112, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.5062643\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_files/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.31688112, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.23264775, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.5062643\n",
      "INFO:tensorflow:loss = 3.4170184, step = 6000 (166.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.645772\n",
      "INFO:tensorflow:loss = 4.5178356, step = 6100 (36.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81698\n",
      "INFO:tensorflow:loss = 3.5726264, step = 6200 (35.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81402\n",
      "INFO:tensorflow:loss = 2.9019864, step = 6300 (35.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8656\n",
      "INFO:tensorflow:loss = 4.055276, step = 6400 (34.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82902\n",
      "INFO:tensorflow:loss = 4.047493, step = 6500 (35.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82675\n",
      "INFO:tensorflow:loss = 1.9004886, step = 6600 (35.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87212\n",
      "INFO:tensorflow:loss = 2.4450467, step = 6700 (34.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75568\n",
      "INFO:tensorflow:loss = 2.9888535, step = 6800 (36.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90133\n",
      "INFO:tensorflow:loss = 3.0836022, step = 6900 (34.468 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.10301\n",
      "INFO:tensorflow:loss = 3.2508187, step = 7000 (90.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77097\n",
      "INFO:tensorflow:loss = 3.1133327, step = 7100 (36.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86047\n",
      "INFO:tensorflow:loss = 1.9242848, step = 7200 (34.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80913\n",
      "INFO:tensorflow:loss = 3.4641047, step = 7300 (35.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87561\n",
      "INFO:tensorflow:loss = 5.533516, step = 7400 (34.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84352\n",
      "INFO:tensorflow:loss = 4.0933805, step = 7500 (35.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81482\n",
      "INFO:tensorflow:loss = 2.4189904, step = 7600 (35.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84773\n",
      "INFO:tensorflow:loss = 3.8938625, step = 7700 (35.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73472\n",
      "INFO:tensorflow:loss = 1.5862266, step = 7800 (36.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82971\n",
      "INFO:tensorflow:loss = 1.639364, step = 7900 (35.340 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.14638\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T12:24:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-12:25:49\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.40683165, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.48058453, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.64317816\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_files/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.48058453, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.40683165, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.64317816\n",
      "INFO:tensorflow:loss = 1.4092975, step = 8000 (162.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65806\n",
      "INFO:tensorflow:loss = 2.616431, step = 8100 (35.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81335\n",
      "INFO:tensorflow:loss = 4.352346, step = 8200 (35.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75282\n",
      "INFO:tensorflow:loss = 3.5426702, step = 8300 (36.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72555\n",
      "INFO:tensorflow:loss = 4.061024, step = 8400 (36.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83109\n",
      "INFO:tensorflow:loss = 3.9111807, step = 8500 (35.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74609\n",
      "INFO:tensorflow:loss = 1.8990922, step = 8600 (36.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86403\n",
      "INFO:tensorflow:loss = 1.8131291, step = 8700 (34.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7643\n",
      "INFO:tensorflow:loss = 1.3124036, step = 8800 (36.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81692\n",
      "INFO:tensorflow:loss = 3.17609, step = 8900 (35.582 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.0546\n",
      "INFO:tensorflow:loss = 2.1926517, step = 9000 (48.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80357\n",
      "INFO:tensorflow:loss = 1.910402, step = 9100 (35.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84544\n",
      "INFO:tensorflow:loss = 1.1231215, step = 9200 (35.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85089\n",
      "INFO:tensorflow:loss = 2.8232365, step = 9300 (35.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85939\n",
      "INFO:tensorflow:loss = 1.0341858, step = 9400 (34.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84382\n",
      "INFO:tensorflow:loss = 2.2011595, step = 9500 (35.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84808\n",
      "INFO:tensorflow:loss = 2.9264736, step = 9600 (35.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80518\n",
      "INFO:tensorflow:loss = 2.3337438, step = 9700 (35.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75122\n",
      "INFO:tensorflow:loss = 3.1480198, step = 9800 (36.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72392\n",
      "INFO:tensorflow:loss = 1.5446683, step = 9900 (36.710 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.14764\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T12:38:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-12:40:06\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.5449675, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.61081034, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.73758334\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_files/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.61081034, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.5449675, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.73758334\n",
      "INFO:tensorflow:loss = 2.8166523, step = 10000 (165.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.645805\n",
      "INFO:tensorflow:loss = 1.1194724, step = 10100 (36.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79305\n",
      "INFO:tensorflow:loss = 0.9991714, step = 10200 (35.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79501\n",
      "INFO:tensorflow:loss = 4.510461, step = 10300 (35.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81264\n",
      "INFO:tensorflow:loss = 2.6716802, step = 10400 (35.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81548\n",
      "INFO:tensorflow:loss = 1.2025278, step = 10500 (35.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80452\n",
      "INFO:tensorflow:loss = 2.7524126, step = 10600 (35.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71144\n",
      "INFO:tensorflow:loss = 1.6206173, step = 10700 (36.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86927\n",
      "INFO:tensorflow:loss = 3.584229, step = 10800 (34.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8046\n",
      "INFO:tensorflow:loss = 1.628996, step = 10900 (35.703 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21204\n",
      "INFO:tensorflow:loss = 1.3660676, step = 11000 (45.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89259\n",
      "INFO:tensorflow:loss = 2.7287657, step = 11100 (34.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82696\n",
      "INFO:tensorflow:loss = 0.8611979, step = 11200 (35.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86221\n",
      "INFO:tensorflow:loss = 1.5919853, step = 11300 (34.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80779\n",
      "INFO:tensorflow:loss = 0.8938838, step = 11400 (35.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78343\n",
      "INFO:tensorflow:loss = 1.0628544, step = 11500 (35.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84754\n",
      "INFO:tensorflow:loss = 2.9312842, step = 11600 (35.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75569\n",
      "INFO:tensorflow:loss = 1.8346846, step = 11700 (36.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74466\n",
      "INFO:tensorflow:loss = 1.064371, step = 11800 (36.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72522\n",
      "INFO:tensorflow:loss = 1.6007742, step = 11900 (36.695 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18935\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T12:52:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-12:54:14\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.62052286, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.673727, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7837743\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_files/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.673727, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.62052286, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7837743\n",
      "INFO:tensorflow:loss = 1.4111173, step = 12000 (159.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.665432\n",
      "INFO:tensorflow:loss = 0.86901253, step = 12100 (36.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83043\n",
      "INFO:tensorflow:loss = 1.3047041, step = 12200 (35.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88177\n",
      "INFO:tensorflow:loss = 1.3083041, step = 12300 (34.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74415\n",
      "INFO:tensorflow:loss = 1.7175784, step = 12400 (36.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7824\n",
      "INFO:tensorflow:loss = 3.961069, step = 12500 (35.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85193\n",
      "INFO:tensorflow:loss = 3.2032034, step = 12600 (35.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68458\n",
      "INFO:tensorflow:loss = 2.6566226, step = 12700 (37.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8144\n",
      "INFO:tensorflow:loss = 2.307276, step = 12800 (35.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89836\n",
      "INFO:tensorflow:loss = 1.3479371, step = 12900 (34.506 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25894\n",
      "INFO:tensorflow:loss = 0.5919811, step = 13000 (44.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84052\n",
      "INFO:tensorflow:loss = 1.3103925, step = 13100 (35.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76537\n",
      "INFO:tensorflow:loss = 1.4295713, step = 13200 (36.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78505\n",
      "INFO:tensorflow:loss = 0.8594673, step = 13300 (35.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74626\n",
      "INFO:tensorflow:loss = 3.5219643, step = 13400 (36.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75358\n",
      "INFO:tensorflow:loss = 0.7368039, step = 13500 (36.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79728\n",
      "INFO:tensorflow:loss = 2.5483823, step = 13600 (35.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75405\n",
      "INFO:tensorflow:loss = 1.6129949, step = 13700 (36.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76949\n",
      "INFO:tensorflow:loss = 1.1077735, step = 13800 (36.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82398\n",
      "INFO:tensorflow:loss = 1.4815218, step = 13900 (35.411 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.2105\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T13:06:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-13:08:21\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.66052634, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7106688, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8063618\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_files/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7106688, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.66052634, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8063618\n",
      "INFO:tensorflow:loss = 1.3906738, step = 14000 (159.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67004\n",
      "INFO:tensorflow:loss = 1.6277795, step = 14100 (35.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70486\n",
      "INFO:tensorflow:loss = 3.508738, step = 14200 (36.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70686\n",
      "INFO:tensorflow:loss = 0.64422154, step = 14300 (36.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82379\n",
      "INFO:tensorflow:loss = 0.7955709, step = 14400 (35.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80644\n",
      "INFO:tensorflow:loss = 1.1514659, step = 14500 (35.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81198\n",
      "INFO:tensorflow:loss = 1.2532436, step = 14600 (35.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85845\n",
      "INFO:tensorflow:loss = 1.2154808, step = 14700 (34.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80133\n",
      "INFO:tensorflow:loss = 1.1598592, step = 14800 (35.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7862\n",
      "INFO:tensorflow:loss = 0.77710813, step = 14900 (35.895 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.09988\n",
      "INFO:tensorflow:loss = 1.9375077, step = 15000 (47.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82296\n",
      "INFO:tensorflow:loss = 0.7798744, step = 15100 (35.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84067\n",
      "INFO:tensorflow:loss = 1.8174039, step = 15200 (35.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79216\n",
      "INFO:tensorflow:loss = 1.5348654, step = 15300 (35.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8533\n",
      "INFO:tensorflow:loss = 2.2818494, step = 15400 (35.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79232\n",
      "INFO:tensorflow:loss = 1.6887215, step = 15500 (35.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79406\n",
      "INFO:tensorflow:loss = 2.8054113, step = 15600 (35.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8083\n",
      "INFO:tensorflow:loss = 1.0409157, step = 15700 (35.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88228\n",
      "INFO:tensorflow:loss = 1.7675267, step = 15800 (34.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79789\n",
      "INFO:tensorflow:loss = 1.1780878, step = 15900 (35.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.19978\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T13:20:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-13:22:30\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.690421, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7351187, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.82364345\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_files/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7351187, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.690421, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.82364345\n",
      "INFO:tensorflow:loss = 0.79300165, step = 16000 (159.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.664706\n",
      "INFO:tensorflow:loss = 1.3666164, step = 16100 (36.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77379\n",
      "INFO:tensorflow:loss = 2.6789975, step = 16200 (36.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81939\n",
      "INFO:tensorflow:loss = 1.308026, step = 16300 (35.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81635\n",
      "INFO:tensorflow:loss = 1.3256303, step = 16400 (35.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8155\n",
      "INFO:tensorflow:loss = 1.1046331, step = 16500 (35.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77339\n",
      "INFO:tensorflow:loss = 1.278322, step = 16600 (36.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84878\n",
      "INFO:tensorflow:loss = 1.4725772, step = 16700 (35.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80541\n",
      "INFO:tensorflow:loss = 2.0623813, step = 16800 (35.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76797\n",
      "INFO:tensorflow:loss = 3.0406256, step = 16900 (36.131 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20884\n",
      "INFO:tensorflow:loss = 2.8189774, step = 17000 (45.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81539\n",
      "INFO:tensorflow:loss = 2.718636, step = 17100 (35.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88781\n",
      "INFO:tensorflow:loss = 0.9226608, step = 17200 (34.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86793\n",
      "INFO:tensorflow:loss = 1.170877, step = 17300 (34.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71848\n",
      "INFO:tensorflow:loss = 1.930308, step = 17400 (36.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76962\n",
      "INFO:tensorflow:loss = 0.94814914, step = 17500 (36.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88087\n",
      "INFO:tensorflow:loss = 1.8091038, step = 17600 (34.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81091\n",
      "INFO:tensorflow:loss = 0.46545836, step = 17700 (35.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77946\n",
      "INFO:tensorflow:loss = 1.1900538, step = 17800 (35.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76385\n",
      "INFO:tensorflow:loss = 0.45741418, step = 17900 (36.181 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.19133\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T13:34:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-13:36:36\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.70696485, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7520111, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.83244234\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_files/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7520111, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.70696485, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.83244234\n",
      "INFO:tensorflow:loss = 0.8799293, step = 18000 (158.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672384\n",
      "INFO:tensorflow:loss = 1.0025325, step = 18100 (35.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8303\n",
      "INFO:tensorflow:loss = 0.5107049, step = 18200 (35.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87048\n",
      "INFO:tensorflow:loss = 0.71914506, step = 18300 (34.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83219\n",
      "INFO:tensorflow:loss = 0.84099305, step = 18400 (35.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76789\n",
      "INFO:tensorflow:loss = 1.2756, step = 18500 (36.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70635\n",
      "INFO:tensorflow:loss = 1.6278877, step = 18600 (36.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81409\n",
      "INFO:tensorflow:loss = 0.99107724, step = 18700 (35.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8089\n",
      "INFO:tensorflow:loss = 0.8047692, step = 18800 (35.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82599\n",
      "INFO:tensorflow:loss = 1.0474645, step = 18900 (35.388 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20697\n",
      "INFO:tensorflow:loss = 1.4159358, step = 19000 (45.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84565\n",
      "INFO:tensorflow:loss = 1.0073909, step = 19100 (35.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80014\n",
      "INFO:tensorflow:loss = 0.9840753, step = 19200 (35.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77501\n",
      "INFO:tensorflow:loss = 2.4689, step = 19300 (36.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8214\n",
      "INFO:tensorflow:loss = 1.1035239, step = 19400 (35.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80895\n",
      "INFO:tensorflow:loss = 1.9914063, step = 19500 (35.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76717\n",
      "INFO:tensorflow:loss = 1.3809088, step = 19600 (36.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79057\n",
      "INFO:tensorflow:loss = 0.78260636, step = 19700 (35.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75329\n",
      "INFO:tensorflow:loss = 0.81796116, step = 19800 (36.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80524\n",
      "INFO:tensorflow:loss = 1.0401728, step = 19900 (35.648 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_files/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 2.26672\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T13:48:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-13:50:41\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7245933, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7664661, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8429942\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_files/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7664661, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7245933, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8429942\n",
      "INFO:tensorflow:loss = 0.85037225, step = 20000 (156.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673487\n",
      "INFO:tensorflow:loss = 1.4027714, step = 20100 (35.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70892\n",
      "INFO:tensorflow:loss = 2.2197466, step = 20200 (36.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76229\n",
      "INFO:tensorflow:loss = 2.0789926, step = 20300 (36.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80637\n",
      "INFO:tensorflow:loss = 0.8867459, step = 20400 (35.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78138\n",
      "INFO:tensorflow:loss = 1.5604192, step = 20500 (35.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79161\n",
      "INFO:tensorflow:loss = 1.19106, step = 20600 (35.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81709\n",
      "INFO:tensorflow:loss = 0.9373274, step = 20700 (35.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75718\n",
      "INFO:tensorflow:loss = 1.0569614, step = 20800 (36.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80154\n",
      "INFO:tensorflow:loss = 1.2663759, step = 20900 (35.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25986\n",
      "INFO:tensorflow:loss = 3.0375662, step = 21000 (44.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78642\n",
      "INFO:tensorflow:loss = 0.76604754, step = 21100 (35.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72201\n",
      "INFO:tensorflow:loss = 2.5242465, step = 21200 (36.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77411\n",
      "INFO:tensorflow:loss = 0.92630213, step = 21300 (36.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81154\n",
      "INFO:tensorflow:loss = 1.0403979, step = 21400 (35.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79147\n",
      "INFO:tensorflow:loss = 1.849355, step = 21500 (35.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71212\n",
      "INFO:tensorflow:loss = 1.2297174, step = 21600 (36.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87765\n",
      "INFO:tensorflow:loss = 1.2661746, step = 21700 (34.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91302\n",
      "INFO:tensorflow:loss = 0.66533434, step = 21800 (34.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75689\n",
      "INFO:tensorflow:loss = 0.86965394, step = 21900 (36.273 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25529\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T14:03:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-14:04:48\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.74070257, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.77962446, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.85194784\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_files/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.77962446, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.74070257, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.85194784\n",
      "INFO:tensorflow:loss = 0.7659163, step = 22000 (156.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.679601\n",
      "INFO:tensorflow:loss = 1.9229875, step = 22100 (35.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76375\n",
      "INFO:tensorflow:loss = 1.3412794, step = 22200 (36.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78237\n",
      "INFO:tensorflow:loss = 1.9711645, step = 22300 (35.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82676\n",
      "INFO:tensorflow:loss = 0.638708, step = 22400 (35.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84295\n",
      "INFO:tensorflow:loss = 0.8346895, step = 22500 (35.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75175\n",
      "INFO:tensorflow:loss = 0.69013053, step = 22600 (36.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88036\n",
      "INFO:tensorflow:loss = 0.8209954, step = 22700 (34.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85193\n",
      "INFO:tensorflow:loss = 0.7621598, step = 22800 (35.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8029\n",
      "INFO:tensorflow:loss = 0.7529304, step = 22900 (35.680 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21827\n",
      "INFO:tensorflow:loss = 0.7441119, step = 23000 (45.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86077\n",
      "INFO:tensorflow:loss = 1.004271, step = 23100 (34.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80718\n",
      "INFO:tensorflow:loss = 0.9768755, step = 23200 (35.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74203\n",
      "INFO:tensorflow:loss = 1.5374868, step = 23300 (36.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8108\n",
      "INFO:tensorflow:loss = 1.2348969, step = 23400 (35.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80978\n",
      "INFO:tensorflow:loss = 1.7568707, step = 23500 (35.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77485\n",
      "INFO:tensorflow:loss = 0.59520113, step = 23600 (36.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73202\n",
      "INFO:tensorflow:loss = 0.7735316, step = 23700 (36.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8312\n",
      "INFO:tensorflow:loss = 0.7310724, step = 23800 (35.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79347\n",
      "INFO:tensorflow:loss = 0.96929324, step = 23900 (35.798 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26925\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T14:17:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-14:18:51\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.75062746, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.78751045, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8579763\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_files/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.78751045, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.75062746, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8579763\n",
      "INFO:tensorflow:loss = 0.7160718, step = 24000 (156.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674359\n",
      "INFO:tensorflow:loss = 0.98698926, step = 24100 (36.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71573\n",
      "INFO:tensorflow:loss = 0.8877855, step = 24200 (36.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78745\n",
      "INFO:tensorflow:loss = 0.49367967, step = 24300 (35.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77596\n",
      "INFO:tensorflow:loss = 0.9312747, step = 24400 (36.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86691\n",
      "INFO:tensorflow:loss = 0.6580615, step = 24500 (34.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82331\n",
      "INFO:tensorflow:loss = 0.62738204, step = 24600 (35.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76555\n",
      "INFO:tensorflow:loss = 0.4987484, step = 24700 (36.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77937\n",
      "INFO:tensorflow:loss = 1.2892628, step = 24800 (35.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90773\n",
      "INFO:tensorflow:loss = 0.72402364, step = 24900 (34.393 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25377\n",
      "INFO:tensorflow:loss = 1.861328, step = 25000 (44.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8023\n",
      "INFO:tensorflow:loss = 0.98357946, step = 25100 (35.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80483\n",
      "INFO:tensorflow:loss = 0.8442243, step = 25200 (35.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77654\n",
      "INFO:tensorflow:loss = 1.0336186, step = 25300 (36.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80521\n",
      "INFO:tensorflow:loss = 1.28334, step = 25400 (35.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80342\n",
      "INFO:tensorflow:loss = 1.0558454, step = 25500 (35.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80477\n",
      "INFO:tensorflow:loss = 1.1503563, step = 25600 (35.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83437\n",
      "INFO:tensorflow:loss = 1.283384, step = 25700 (35.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78425\n",
      "INFO:tensorflow:loss = 1.5403545, step = 25800 (35.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81648\n",
      "INFO:tensorflow:loss = 2.5783963, step = 25900 (35.506 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.22485\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T14:31:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-14:32:54\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7584196, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.79556817, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8628361\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_files/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.79556817, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7584196, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8628361\n",
      "INFO:tensorflow:loss = 0.69198847, step = 26000 (156.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.684449\n",
      "INFO:tensorflow:loss = 1.5494057, step = 26100 (35.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72764\n",
      "INFO:tensorflow:loss = 1.8864931, step = 26200 (36.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77582\n",
      "INFO:tensorflow:loss = 2.6044996, step = 26300 (36.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73068\n",
      "INFO:tensorflow:loss = 0.82772654, step = 26400 (36.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72154\n",
      "INFO:tensorflow:loss = 0.9320988, step = 26500 (36.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84888\n",
      "INFO:tensorflow:loss = 0.46964443, step = 26600 (35.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85683\n",
      "INFO:tensorflow:loss = 0.6636701, step = 26700 (35.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80956\n",
      "INFO:tensorflow:loss = 0.70385575, step = 26800 (35.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83263\n",
      "INFO:tensorflow:loss = 1.033048, step = 26900 (35.306 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.27208\n",
      "INFO:tensorflow:loss = 1.13208, step = 27000 (44.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79008\n",
      "INFO:tensorflow:loss = 0.58884275, step = 27100 (35.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81982\n",
      "INFO:tensorflow:loss = 1.5463312, step = 27200 (35.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79943\n",
      "INFO:tensorflow:loss = 1.3320018, step = 27300 (35.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81297\n",
      "INFO:tensorflow:loss = 0.50246036, step = 27400 (35.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90702\n",
      "INFO:tensorflow:loss = 0.95427483, step = 27500 (34.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76031\n",
      "INFO:tensorflow:loss = 0.64662606, step = 27600 (36.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78479\n",
      "INFO:tensorflow:loss = 0.6578885, step = 27700 (35.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74613\n",
      "INFO:tensorflow:loss = 0.75673425, step = 27800 (36.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81681\n",
      "INFO:tensorflow:loss = 0.8103811, step = 27900 (35.501 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25655\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T14:45:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-14:46:56\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.76826906, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8055113, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.86850095\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_files/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8055113, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.76826906, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.86850095\n",
      "INFO:tensorflow:loss = 0.5799833, step = 28000 (155.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.68262\n",
      "INFO:tensorflow:loss = 0.5101404, step = 28100 (35.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8571\n",
      "INFO:tensorflow:loss = 1.0069621, step = 28200 (34.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88321\n",
      "INFO:tensorflow:loss = 0.49346638, step = 28300 (34.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7828\n",
      "INFO:tensorflow:loss = 0.66115427, step = 28400 (35.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82409\n",
      "INFO:tensorflow:loss = 0.5799256, step = 28500 (35.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85732\n",
      "INFO:tensorflow:loss = 0.94539326, step = 28600 (34.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77584\n",
      "INFO:tensorflow:loss = 0.59014744, step = 28700 (36.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75819\n",
      "INFO:tensorflow:loss = 0.6933573, step = 28800 (36.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79242\n",
      "INFO:tensorflow:loss = 0.44595405, step = 28900 (35.813 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26417\n",
      "INFO:tensorflow:loss = 1.4598609, step = 29000 (44.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76588\n",
      "INFO:tensorflow:loss = 0.68063694, step = 29100 (36.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79702\n",
      "INFO:tensorflow:loss = 0.65176606, step = 29200 (35.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80075\n",
      "INFO:tensorflow:loss = 0.87517655, step = 29300 (35.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71578\n",
      "INFO:tensorflow:loss = 0.8454247, step = 29400 (36.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79185\n",
      "INFO:tensorflow:loss = 0.92319584, step = 29500 (35.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84124\n",
      "INFO:tensorflow:loss = 0.59596443, step = 29600 (35.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85503\n",
      "INFO:tensorflow:loss = 0.5856357, step = 29700 (35.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75485\n",
      "INFO:tensorflow:loss = 0.90093446, step = 29800 (36.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68404\n",
      "INFO:tensorflow:loss = 0.51665723, step = 29900 (37.257 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.31478\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T14:59:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-15:00:58\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.77155936, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8083221, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87033975\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_files/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8083221, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.77155936, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87033975\n",
      "INFO:tensorflow:loss = 1.0169699, step = 30000 (154.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.680489\n",
      "INFO:tensorflow:loss = 1.0396416, step = 30100 (35.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79091\n",
      "INFO:tensorflow:loss = 0.62132716, step = 30200 (35.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74432\n",
      "INFO:tensorflow:loss = 1.3187689, step = 30300 (36.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79232\n",
      "INFO:tensorflow:loss = 1.7358001, step = 30400 (35.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93794\n",
      "INFO:tensorflow:loss = 0.6783009, step = 30500 (34.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80225\n",
      "INFO:tensorflow:loss = 0.97526854, step = 30600 (35.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81915\n",
      "INFO:tensorflow:loss = 1.3332525, step = 30700 (35.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74432\n",
      "INFO:tensorflow:loss = 0.49154994, step = 30800 (36.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81683\n",
      "INFO:tensorflow:loss = 1.3035684, step = 30900 (35.504 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.27574\n",
      "INFO:tensorflow:loss = 0.87988377, step = 31000 (43.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.726\n",
      "INFO:tensorflow:loss = 0.905635, step = 31100 (36.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78488\n",
      "INFO:tensorflow:loss = 1.5001246, step = 31200 (35.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77032\n",
      "INFO:tensorflow:loss = 0.9484633, step = 31300 (36.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69195\n",
      "INFO:tensorflow:loss = 0.82578886, step = 31400 (37.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92537\n",
      "INFO:tensorflow:loss = 0.5711489, step = 31500 (34.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82026\n",
      "INFO:tensorflow:loss = 0.74642503, step = 31600 (35.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85983\n",
      "INFO:tensorflow:loss = 1.2027953, step = 31700 (34.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78791\n",
      "INFO:tensorflow:loss = 3.803654, step = 31800 (35.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79917\n",
      "INFO:tensorflow:loss = 0.536654, step = 31900 (35.724 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23352\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T15:13:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-15:15:01\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.77962166, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.81591463, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8752987\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_files/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.81591463, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.77962166, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8752987\n",
      "INFO:tensorflow:loss = 0.86934704, step = 32000 (155.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.682359\n",
      "INFO:tensorflow:loss = 2.315249, step = 32100 (35.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86657\n",
      "INFO:tensorflow:loss = 0.6474992, step = 32200 (34.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88148\n",
      "INFO:tensorflow:loss = 0.56720614, step = 32300 (34.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80074\n",
      "INFO:tensorflow:loss = 0.73529184, step = 32400 (35.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75994\n",
      "INFO:tensorflow:loss = 1.3381723, step = 32500 (36.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85807\n",
      "INFO:tensorflow:loss = 0.48182535, step = 32600 (34.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72217\n",
      "INFO:tensorflow:loss = 0.55370635, step = 32700 (36.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8194\n",
      "INFO:tensorflow:loss = 0.5982501, step = 32800 (35.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82577\n",
      "INFO:tensorflow:loss = 0.7070221, step = 32900 (35.391 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20286\n",
      "INFO:tensorflow:loss = 0.8717283, step = 33000 (45.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79739\n",
      "INFO:tensorflow:loss = 0.73914427, step = 33100 (35.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87796\n",
      "INFO:tensorflow:loss = 1.4299831, step = 33200 (34.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86015\n",
      "INFO:tensorflow:loss = 0.5919174, step = 33300 (34.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72514\n",
      "INFO:tensorflow:loss = 0.61679894, step = 33400 (36.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81116\n",
      "INFO:tensorflow:loss = 0.41462755, step = 33500 (35.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74392\n",
      "INFO:tensorflow:loss = 0.7627488, step = 33600 (36.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72709\n",
      "INFO:tensorflow:loss = 1.7091047, step = 33700 (36.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74521\n",
      "INFO:tensorflow:loss = 0.8371289, step = 33800 (36.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84971\n",
      "INFO:tensorflow:loss = 1.8732909, step = 33900 (35.092 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.28817\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T15:27:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-15:29:04\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7864882, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.821689, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87935853\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_files/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.821689, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7864882, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87935853\n",
      "INFO:tensorflow:loss = 0.9563482, step = 34000 (155.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.681201\n",
      "INFO:tensorflow:loss = 0.7361231, step = 34100 (35.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78404\n",
      "INFO:tensorflow:loss = 0.64946437, step = 34200 (35.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78698\n",
      "INFO:tensorflow:loss = 1.0840659, step = 34300 (35.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81526\n",
      "INFO:tensorflow:loss = 0.65151656, step = 34400 (35.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7803\n",
      "INFO:tensorflow:loss = 1.0552547, step = 34500 (35.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81032\n",
      "INFO:tensorflow:loss = 0.565831, step = 34600 (35.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81598\n",
      "INFO:tensorflow:loss = 1.0438318, step = 34700 (35.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85625\n",
      "INFO:tensorflow:loss = 2.140143, step = 34800 (35.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78813\n",
      "INFO:tensorflow:loss = 1.0647905, step = 34900 (35.868 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.29597\n",
      "INFO:tensorflow:loss = 0.6429992, step = 35000 (43.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80772\n",
      "INFO:tensorflow:loss = 0.84621, step = 35100 (35.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81407\n",
      "INFO:tensorflow:loss = 0.82281953, step = 35200 (35.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85553\n",
      "INFO:tensorflow:loss = 1.0678334, step = 35300 (35.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75005\n",
      "INFO:tensorflow:loss = 2.4002948, step = 35400 (36.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83393\n",
      "INFO:tensorflow:loss = 0.70924896, step = 35500 (35.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89713\n",
      "INFO:tensorflow:loss = 2.0013416, step = 35600 (34.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82196\n",
      "INFO:tensorflow:loss = 1.1977508, step = 35700 (35.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73657\n",
      "INFO:tensorflow:loss = 0.5559996, step = 35800 (36.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76727\n",
      "INFO:tensorflow:loss = 1.2259625, step = 35900 (36.137 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24876\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T15:41:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-15:43:03\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7892562, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.824329, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8820206\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_files/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.824329, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7892562, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8820206\n",
      "INFO:tensorflow:loss = 0.7600731, step = 36000 (155.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.683337\n",
      "INFO:tensorflow:loss = 2.2155933, step = 36100 (35.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75404\n",
      "INFO:tensorflow:loss = 0.96254516, step = 36200 (36.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73822\n",
      "INFO:tensorflow:loss = 0.6424697, step = 36300 (36.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80845\n",
      "INFO:tensorflow:loss = 0.43855637, step = 36400 (35.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76291\n",
      "INFO:tensorflow:loss = 0.372269, step = 36500 (36.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85479\n",
      "INFO:tensorflow:loss = 0.7874245, step = 36600 (35.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87818\n",
      "INFO:tensorflow:loss = 0.9156815, step = 36700 (34.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73586\n",
      "INFO:tensorflow:loss = 2.4766068, step = 36800 (36.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78377\n",
      "INFO:tensorflow:loss = 1.0466831, step = 36900 (35.924 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25967\n",
      "INFO:tensorflow:loss = 1.1217034, step = 37000 (44.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83314\n",
      "INFO:tensorflow:loss = 0.63118476, step = 37100 (35.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77738\n",
      "INFO:tensorflow:loss = 0.4629522, step = 37200 (36.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8272\n",
      "INFO:tensorflow:loss = 2.1042602, step = 37300 (35.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80566\n",
      "INFO:tensorflow:loss = 0.75208175, step = 37400 (35.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76069\n",
      "INFO:tensorflow:loss = 2.1939733, step = 37500 (36.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80814\n",
      "INFO:tensorflow:loss = 1.5460292, step = 37600 (35.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82651\n",
      "INFO:tensorflow:loss = 0.7977321, step = 37700 (35.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75042\n",
      "INFO:tensorflow:loss = 0.66296697, step = 37800 (36.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79352\n",
      "INFO:tensorflow:loss = 0.44419333, step = 37900 (35.797 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.29126\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T15:55:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-15:57:06\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7964108, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.83340186, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8855879\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_files/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.83340186, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7964108, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8855879\n",
      "INFO:tensorflow:loss = 0.4916025, step = 38000 (154.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.680864\n",
      "INFO:tensorflow:loss = 1.2464626, step = 38100 (36.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83815\n",
      "INFO:tensorflow:loss = 0.8482948, step = 38200 (35.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80909\n",
      "INFO:tensorflow:loss = 0.58644015, step = 38300 (35.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86361\n",
      "INFO:tensorflow:loss = 0.69853425, step = 38400 (34.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85038\n",
      "INFO:tensorflow:loss = 0.45874578, step = 38500 (35.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8383\n",
      "INFO:tensorflow:loss = 2.0080552, step = 38600 (35.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75358\n",
      "INFO:tensorflow:loss = 1.0771922, step = 38700 (36.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83925\n",
      "INFO:tensorflow:loss = 0.53698486, step = 38800 (35.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84852\n",
      "INFO:tensorflow:loss = 1.2133753, step = 38900 (35.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.28567\n",
      "INFO:tensorflow:loss = 0.484099, step = 39000 (43.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8178\n",
      "INFO:tensorflow:loss = 1.0857391, step = 39100 (35.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72764\n",
      "INFO:tensorflow:loss = 0.52157736, step = 39200 (36.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81465\n",
      "INFO:tensorflow:loss = 1.1797771, step = 39300 (35.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77019\n",
      "INFO:tensorflow:loss = 0.67173564, step = 39400 (36.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81304\n",
      "INFO:tensorflow:loss = 0.46133405, step = 39500 (35.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80183\n",
      "INFO:tensorflow:loss = 0.6959202, step = 39600 (35.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81098\n",
      "INFO:tensorflow:loss = 0.6184938, step = 39700 (35.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81566\n",
      "INFO:tensorflow:loss = 1.8260666, step = 39800 (35.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75642\n",
      "INFO:tensorflow:loss = 0.5112674, step = 39900 (36.278 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_files/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25903\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T16:09:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-16:11:05\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7992583, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8338487, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.88719743\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: model_files/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8338487, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7992583, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.88719743\n",
      "INFO:tensorflow:loss = 0.9330428, step = 40000 (154.214 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.9330428.\n",
      "Time: 17119.79 s\n"
     ]
    }
   ],
   "source": [
    "# select the transformer model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_2014'\n",
    "\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 \n",
    "hparams.learning_rate = 0.2 # default 0.2\n",
    "hparams.num_encoder_layers = 6 # default 0\n",
    "hparams.num_decoder_layers = 6 # default 0\n",
    "hparams.max_input_seq_length = 1024\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "t2t_model_1024 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, \n",
    "        data_dir='./data', \n",
    "        train_steps=40001,\n",
    "        eval_steps=200\n",
    "    )\n",
    "\n",
    "# training\n",
    "t2t_model_1024.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f5afd1c5a90>, '_is_chief': True, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_eval_distribute': None, '_task_type': None, 'use_tpu': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ae3a8f048>, '_num_ps_replicas': 0, '_device_fn': None, '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_master': '', 't2t_device_info': {'num_async_replicas': 1}, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_num_worker_replicas': 0, '_evaluation_master': '', '_train_distribute': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_environment': 'local', '_keep_checkpoint_max': 20, '_model_dir': 'model_files_512', '_save_checkpoints_steps': 1000}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f5afbebb8c8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64797184\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.827033, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.64328\n",
      "INFO:tensorflow:loss = 8.066278, step = 100 (37.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03739\n",
      "INFO:tensorflow:loss = 7.018879, step = 200 (32.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03079\n",
      "INFO:tensorflow:loss = 6.5230303, step = 300 (32.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01605\n",
      "INFO:tensorflow:loss = 6.578451, step = 400 (33.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03083\n",
      "INFO:tensorflow:loss = 5.785222, step = 500 (32.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10591\n",
      "INFO:tensorflow:loss = 5.8204184, step = 600 (32.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0776\n",
      "INFO:tensorflow:loss = 5.652633, step = 700 (32.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09021\n",
      "INFO:tensorflow:loss = 5.633853, step = 800 (32.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09214\n",
      "INFO:tensorflow:loss = 5.533131, step = 900 (32.342 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.4825\n",
      "INFO:tensorflow:loss = 7.111091, step = 1000 (40.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09417\n",
      "INFO:tensorflow:loss = 5.225651, step = 1100 (32.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09408\n",
      "INFO:tensorflow:loss = 5.541403, step = 1200 (32.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09932\n",
      "INFO:tensorflow:loss = 5.390214, step = 1300 (32.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06573\n",
      "INFO:tensorflow:loss = 5.635201, step = 1400 (32.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.13823\n",
      "INFO:tensorflow:loss = 4.7547555, step = 1500 (31.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04009\n",
      "INFO:tensorflow:loss = 5.962553, step = 1600 (32.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08139\n",
      "INFO:tensorflow:loss = 5.837856, step = 1700 (32.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09075\n",
      "INFO:tensorflow:loss = 5.2643304, step = 1800 (32.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10354\n",
      "INFO:tensorflow:loss = 4.948774, step = 1900 (32.222 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.47187\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T16:23:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-16:24:42\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.014305366, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.04994907, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.21086217\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_files_512/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.04994907, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.014305366, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.21086217\n",
      "INFO:tensorflow:loss = 6.370265, step = 2000 (125.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.852217\n",
      "INFO:tensorflow:loss = 5.1761456, step = 2100 (32.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11709\n",
      "INFO:tensorflow:loss = 6.8480186, step = 2200 (32.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07213\n",
      "INFO:tensorflow:loss = 5.9935293, step = 2300 (32.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06314\n",
      "INFO:tensorflow:loss = 5.010822, step = 2400 (32.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07402\n",
      "INFO:tensorflow:loss = 5.189879, step = 2500 (32.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06982\n",
      "INFO:tensorflow:loss = 5.0816936, step = 2600 (32.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03674\n",
      "INFO:tensorflow:loss = 5.4161158, step = 2700 (32.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11544\n",
      "INFO:tensorflow:loss = 5.791018, step = 2800 (32.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0493\n",
      "INFO:tensorflow:loss = 6.8218384, step = 2900 (32.796 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.44295\n",
      "INFO:tensorflow:loss = 5.3701663, step = 3000 (40.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07192\n",
      "INFO:tensorflow:loss = 5.468223, step = 3100 (32.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09565\n",
      "INFO:tensorflow:loss = 4.368238, step = 3200 (32.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08211\n",
      "INFO:tensorflow:loss = 5.161366, step = 3300 (32.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09274\n",
      "INFO:tensorflow:loss = 5.098403, step = 3400 (32.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08786\n",
      "INFO:tensorflow:loss = 5.524887, step = 3500 (32.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05907\n",
      "INFO:tensorflow:loss = 6.016069, step = 3600 (32.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03582\n",
      "INFO:tensorflow:loss = 4.8720665, step = 3700 (32.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0598\n",
      "INFO:tensorflow:loss = 5.0120363, step = 3800 (32.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07999\n",
      "INFO:tensorflow:loss = 5.097745, step = 3900 (32.469 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41833\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T16:35:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-16:37:14\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.018925518, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.062312484, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.2224077\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_files_512/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.062312484, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.018925518, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.2224077\n",
      "INFO:tensorflow:loss = 5.278789, step = 4000 (125.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.85114\n",
      "INFO:tensorflow:loss = 4.6541524, step = 4100 (33.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06704\n",
      "INFO:tensorflow:loss = 5.0417337, step = 4200 (32.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95995\n",
      "INFO:tensorflow:loss = 6.0587506, step = 4300 (33.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02267\n",
      "INFO:tensorflow:loss = 4.889881, step = 4400 (33.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11309\n",
      "INFO:tensorflow:loss = 5.6023064, step = 4500 (32.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11709\n",
      "INFO:tensorflow:loss = 5.8016934, step = 4600 (32.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02188\n",
      "INFO:tensorflow:loss = 4.3760257, step = 4700 (33.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07186\n",
      "INFO:tensorflow:loss = 5.4537954, step = 4800 (32.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08472\n",
      "INFO:tensorflow:loss = 5.6194854, step = 4900 (32.422 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.45132\n",
      "INFO:tensorflow:loss = 4.9626694, step = 5000 (40.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06778\n",
      "INFO:tensorflow:loss = 4.5064178, step = 5100 (32.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09893\n",
      "INFO:tensorflow:loss = 4.9729834, step = 5200 (32.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01365\n",
      "INFO:tensorflow:loss = 5.2441053, step = 5300 (33.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04358\n",
      "INFO:tensorflow:loss = 5.9003315, step = 5400 (32.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05362\n",
      "INFO:tensorflow:loss = 4.678287, step = 5500 (32.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00639\n",
      "INFO:tensorflow:loss = 5.332348, step = 5600 (33.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.088\n",
      "INFO:tensorflow:loss = 5.537587, step = 5700 (32.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06281\n",
      "INFO:tensorflow:loss = 5.2997074, step = 5800 (32.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07699\n",
      "INFO:tensorflow:loss = 4.6507616, step = 5900 (32.499 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.44768\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T16:48:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-16:49:52\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.11027319, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.17915846, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.37409934\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_files_512/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.17915846, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.11027319, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.37409934\n",
      "INFO:tensorflow:loss = 4.351892, step = 6000 (127.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.838112\n",
      "INFO:tensorflow:loss = 4.7003713, step = 6100 (32.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00116\n",
      "INFO:tensorflow:loss = 4.878038, step = 6200 (33.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09743\n",
      "INFO:tensorflow:loss = 4.3558173, step = 6300 (32.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98714\n",
      "INFO:tensorflow:loss = 4.9936166, step = 6400 (33.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04925\n",
      "INFO:tensorflow:loss = 4.181719, step = 6500 (32.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07101\n",
      "INFO:tensorflow:loss = 2.30316, step = 6600 (32.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05248\n",
      "INFO:tensorflow:loss = 4.4354544, step = 6700 (32.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04728\n",
      "INFO:tensorflow:loss = 3.8245761, step = 6800 (32.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0898\n",
      "INFO:tensorflow:loss = 3.5412176, step = 6900 (32.365 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42862\n",
      "INFO:tensorflow:loss = 4.074508, step = 7000 (41.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0622\n",
      "INFO:tensorflow:loss = 4.057094, step = 7100 (32.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9719\n",
      "INFO:tensorflow:loss = 4.401554, step = 7200 (33.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07655\n",
      "INFO:tensorflow:loss = 2.999943, step = 7300 (32.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05648\n",
      "INFO:tensorflow:loss = 3.8784847, step = 7400 (32.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10216\n",
      "INFO:tensorflow:loss = 4.2501507, step = 7500 (32.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02904\n",
      "INFO:tensorflow:loss = 3.6954627, step = 7600 (33.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03731\n",
      "INFO:tensorflow:loss = 3.7302346, step = 7700 (32.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12453\n",
      "INFO:tensorflow:loss = 3.258063, step = 7800 (32.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04873\n",
      "INFO:tensorflow:loss = 3.7409725, step = 7900 (32.801 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.38408\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T17:01:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-17:02:29\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.20142119, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.2893994, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.49868053\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_files_512/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.2893994, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.20142119, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.49868053\n",
      "INFO:tensorflow:loss = 4.307233, step = 8000 (126.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.847319\n",
      "INFO:tensorflow:loss = 3.5576513, step = 8100 (33.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01774\n",
      "INFO:tensorflow:loss = 2.6431274, step = 8200 (33.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06386\n",
      "INFO:tensorflow:loss = 3.1485558, step = 8300 (32.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14905\n",
      "INFO:tensorflow:loss = 2.466576, step = 8400 (31.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00971\n",
      "INFO:tensorflow:loss = 3.4840896, step = 8500 (33.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0788\n",
      "INFO:tensorflow:loss = 3.574886, step = 8600 (32.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10597\n",
      "INFO:tensorflow:loss = 3.2193892, step = 8700 (32.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01314\n",
      "INFO:tensorflow:loss = 2.801157, step = 8800 (33.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07637\n",
      "INFO:tensorflow:loss = 2.0590124, step = 8900 (32.507 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.45523\n",
      "INFO:tensorflow:loss = 3.3238773, step = 9000 (40.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01695\n",
      "INFO:tensorflow:loss = 2.8155951, step = 9100 (33.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0458\n",
      "INFO:tensorflow:loss = 3.837891, step = 9200 (32.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02817\n",
      "INFO:tensorflow:loss = 3.3966238, step = 9300 (33.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11942\n",
      "INFO:tensorflow:loss = 2.3179922, step = 9400 (32.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07844\n",
      "INFO:tensorflow:loss = 1.9532909, step = 9500 (32.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06673\n",
      "INFO:tensorflow:loss = 2.970145, step = 9600 (32.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0183\n",
      "INFO:tensorflow:loss = 4.0788517, step = 9700 (33.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05735\n",
      "INFO:tensorflow:loss = 3.5595815, step = 9800 (32.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05405\n",
      "INFO:tensorflow:loss = 1.9659916, step = 9900 (32.743 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.46977\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T17:13:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-17:15:02\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.3653483, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.45410064, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.6484513\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_files_512/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.45410064, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.3653483, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.6484513\n",
      "INFO:tensorflow:loss = 1.9945855, step = 10000 (123.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.865753\n",
      "INFO:tensorflow:loss = 2.9639337, step = 10100 (32.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05486\n",
      "INFO:tensorflow:loss = 1.3414559, step = 10200 (32.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07815\n",
      "INFO:tensorflow:loss = 3.502935, step = 10300 (32.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04502\n",
      "INFO:tensorflow:loss = 3.9443564, step = 10400 (32.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02426\n",
      "INFO:tensorflow:loss = 3.168826, step = 10500 (33.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09257\n",
      "INFO:tensorflow:loss = 1.7107016, step = 10600 (32.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07768\n",
      "INFO:tensorflow:loss = 2.19635, step = 10700 (32.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11906\n",
      "INFO:tensorflow:loss = 3.1854215, step = 10800 (32.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07814\n",
      "INFO:tensorflow:loss = 3.1016486, step = 10900 (32.490 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41131\n",
      "INFO:tensorflow:loss = 2.6905072, step = 11000 (41.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0783\n",
      "INFO:tensorflow:loss = 5.9207087, step = 11100 (32.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04147\n",
      "INFO:tensorflow:loss = 2.1124, step = 11200 (32.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09001\n",
      "INFO:tensorflow:loss = 2.709023, step = 11300 (32.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03698\n",
      "INFO:tensorflow:loss = 3.2367923, step = 11400 (32.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08082\n",
      "INFO:tensorflow:loss = 2.798788, step = 11500 (32.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00654\n",
      "INFO:tensorflow:loss = 1.8331808, step = 11600 (33.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01128\n",
      "INFO:tensorflow:loss = 2.3168588, step = 11700 (33.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05454\n",
      "INFO:tensorflow:loss = 2.3454857, step = 11800 (32.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05131\n",
      "INFO:tensorflow:loss = 1.9866586, step = 11900 (32.772 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42675\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T17:26:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-17:27:37\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.49857453, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.577635, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.73567057\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_files_512/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.577635, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.49857453, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.73567057\n",
      "INFO:tensorflow:loss = 1.988035, step = 12000 (124.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.862558\n",
      "INFO:tensorflow:loss = 2.8849866, step = 12100 (32.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03635\n",
      "INFO:tensorflow:loss = 1.4357176, step = 12200 (32.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09953\n",
      "INFO:tensorflow:loss = 1.4437892, step = 12300 (32.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14355\n",
      "INFO:tensorflow:loss = 2.6737478, step = 12400 (31.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07531\n",
      "INFO:tensorflow:loss = 2.9069219, step = 12500 (32.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11399\n",
      "INFO:tensorflow:loss = 2.401322, step = 12600 (32.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99495\n",
      "INFO:tensorflow:loss = 1.916665, step = 12700 (33.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1131\n",
      "INFO:tensorflow:loss = 2.8049026, step = 12800 (32.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05913\n",
      "INFO:tensorflow:loss = 1.6759299, step = 12900 (32.690 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.45879\n",
      "INFO:tensorflow:loss = 1.4322827, step = 13000 (40.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05738\n",
      "INFO:tensorflow:loss = 1.7878902, step = 13100 (32.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05731\n",
      "INFO:tensorflow:loss = 1.4993006, step = 13200 (32.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05721\n",
      "INFO:tensorflow:loss = 3.1669557, step = 13300 (32.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04328\n",
      "INFO:tensorflow:loss = 2.5838337, step = 13400 (32.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06408\n",
      "INFO:tensorflow:loss = 1.5073837, step = 13500 (32.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09545\n",
      "INFO:tensorflow:loss = 2.4547205, step = 13600 (32.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02034\n",
      "INFO:tensorflow:loss = 1.4667969, step = 13700 (33.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03491\n",
      "INFO:tensorflow:loss = 3.4917624, step = 13800 (32.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11012\n",
      "INFO:tensorflow:loss = 2.4651837, step = 13900 (32.153 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.47278\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T17:38:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-17:40:08\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.53775877, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.6126361, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.76018506\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_files_512/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.6126361, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.53775877, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.76018506\n",
      "INFO:tensorflow:loss = 1.9028801, step = 14000 (123.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.865455\n",
      "INFO:tensorflow:loss = 1.9473183, step = 14100 (32.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00408\n",
      "INFO:tensorflow:loss = 1.5334182, step = 14200 (33.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05797\n",
      "INFO:tensorflow:loss = 1.3330635, step = 14300 (32.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01198\n",
      "INFO:tensorflow:loss = 1.4367079, step = 14400 (33.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07848\n",
      "INFO:tensorflow:loss = 1.9234031, step = 14500 (32.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10003\n",
      "INFO:tensorflow:loss = 1.7055309, step = 14600 (32.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09376\n",
      "INFO:tensorflow:loss = 2.787623, step = 14700 (32.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06534\n",
      "INFO:tensorflow:loss = 1.1982453, step = 14800 (32.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0323\n",
      "INFO:tensorflow:loss = 1.756388, step = 14900 (32.979 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.4065\n",
      "INFO:tensorflow:loss = 3.2071097, step = 15000 (41.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08929\n",
      "INFO:tensorflow:loss = 1.6303138, step = 15100 (32.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08623\n",
      "INFO:tensorflow:loss = 2.6662035, step = 15200 (32.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10277\n",
      "INFO:tensorflow:loss = 3.0684304, step = 15300 (32.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11324\n",
      "INFO:tensorflow:loss = 2.1229286, step = 15400 (32.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07082\n",
      "INFO:tensorflow:loss = 1.8911073, step = 15500 (32.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98316\n",
      "INFO:tensorflow:loss = 1.6519957, step = 15600 (33.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06407\n",
      "INFO:tensorflow:loss = 1.4073119, step = 15700 (32.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07637\n",
      "INFO:tensorflow:loss = 2.864106, step = 15800 (32.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05857\n",
      "INFO:tensorflow:loss = 1.907665, step = 15900 (32.695 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41841\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T17:51:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-17:52:42\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6002724, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.66622335, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7945677\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_files_512/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.66622335, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6002724, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7945677\n",
      "INFO:tensorflow:loss = 2.4570043, step = 16000 (125.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.844599\n",
      "INFO:tensorflow:loss = 1.5741818, step = 16100 (33.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10782\n",
      "INFO:tensorflow:loss = 1.2277299, step = 16200 (32.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07888\n",
      "INFO:tensorflow:loss = 1.2901369, step = 16300 (32.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14721\n",
      "INFO:tensorflow:loss = 2.8183498, step = 16400 (31.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12165\n",
      "INFO:tensorflow:loss = 1.685533, step = 16500 (32.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.031\n",
      "INFO:tensorflow:loss = 0.9372779, step = 16600 (32.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04561\n",
      "INFO:tensorflow:loss = 0.8780004, step = 16700 (32.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01206\n",
      "INFO:tensorflow:loss = 2.809299, step = 16800 (33.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01319\n",
      "INFO:tensorflow:loss = 1.6798917, step = 16900 (33.188 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42888\n",
      "INFO:tensorflow:loss = 1.1606114, step = 17000 (41.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01982\n",
      "INFO:tensorflow:loss = 0.99186724, step = 17100 (33.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04828\n",
      "INFO:tensorflow:loss = 1.9677228, step = 17200 (32.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06701\n",
      "INFO:tensorflow:loss = 2.0205724, step = 17300 (32.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05105\n",
      "INFO:tensorflow:loss = 1.1427345, step = 17400 (32.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04583\n",
      "INFO:tensorflow:loss = 1.9933127, step = 17500 (32.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12089\n",
      "INFO:tensorflow:loss = 1.0900284, step = 17600 (32.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02665\n",
      "INFO:tensorflow:loss = 1.7290164, step = 17700 (33.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03841\n",
      "INFO:tensorflow:loss = 1.9737656, step = 17800 (32.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0876\n",
      "INFO:tensorflow:loss = 1.5102475, step = 17900 (32.387 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40262\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T18:04:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-18:05:18\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6275911, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.69053805, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8092287\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_files_512/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.69053805, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6275911, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8092287\n",
      "INFO:tensorflow:loss = 2.2772164, step = 18000 (125.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.853317\n",
      "INFO:tensorflow:loss = 1.5918213, step = 18100 (33.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09567\n",
      "INFO:tensorflow:loss = 1.3060292, step = 18200 (32.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10473\n",
      "INFO:tensorflow:loss = 1.6736643, step = 18300 (32.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04072\n",
      "INFO:tensorflow:loss = 1.1721745, step = 18400 (32.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08874\n",
      "INFO:tensorflow:loss = 1.5482275, step = 18500 (32.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07435\n",
      "INFO:tensorflow:loss = 1.6098965, step = 18600 (32.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05486\n",
      "INFO:tensorflow:loss = 2.4846425, step = 18700 (32.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02465\n",
      "INFO:tensorflow:loss = 1.6302289, step = 18800 (33.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01975\n",
      "INFO:tensorflow:loss = 1.9730465, step = 18900 (33.116 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.37123\n",
      "INFO:tensorflow:loss = 1.7909461, step = 19000 (42.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01669\n",
      "INFO:tensorflow:loss = 2.875832, step = 19100 (33.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06485\n",
      "INFO:tensorflow:loss = 2.0488868, step = 19200 (32.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04669\n",
      "INFO:tensorflow:loss = 1.6814029, step = 19300 (32.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08667\n",
      "INFO:tensorflow:loss = 1.0907923, step = 19400 (32.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98135\n",
      "INFO:tensorflow:loss = 1.1497726, step = 19500 (33.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03418\n",
      "INFO:tensorflow:loss = 1.3717092, step = 19600 (32.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04464\n",
      "INFO:tensorflow:loss = 1.259609, step = 19700 (32.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04329\n",
      "INFO:tensorflow:loss = 2.6644294, step = 19800 (32.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12067\n",
      "INFO:tensorflow:loss = 1.6125258, step = 19900 (32.044 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39352\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T18:16:38Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-18:17:56\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6639874, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.72141653, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.82832\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_files_512/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.72141653, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.6639874, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.82832\n",
      "INFO:tensorflow:loss = 2.5215533, step = 20000 (125.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.853851\n",
      "INFO:tensorflow:loss = 1.4000797, step = 20100 (32.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10684\n",
      "INFO:tensorflow:loss = 0.88680464, step = 20200 (32.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03441\n",
      "INFO:tensorflow:loss = 1.373039, step = 20300 (32.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08678\n",
      "INFO:tensorflow:loss = 2.06562, step = 20400 (32.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07664\n",
      "INFO:tensorflow:loss = 1.3411193, step = 20500 (32.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99913\n",
      "INFO:tensorflow:loss = 1.0493219, step = 20600 (33.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04884\n",
      "INFO:tensorflow:loss = 2.26714, step = 20700 (32.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02543\n",
      "INFO:tensorflow:loss = 1.3479488, step = 20800 (33.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07297\n",
      "INFO:tensorflow:loss = 0.7676003, step = 20900 (32.543 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41295\n",
      "INFO:tensorflow:loss = 1.638145, step = 21000 (41.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08991\n",
      "INFO:tensorflow:loss = 1.9260691, step = 21100 (32.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07503\n",
      "INFO:tensorflow:loss = 1.4277933, step = 21200 (32.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04082\n",
      "INFO:tensorflow:loss = 1.0557679, step = 21300 (32.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05349\n",
      "INFO:tensorflow:loss = 1.4663725, step = 21400 (32.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07645\n",
      "INFO:tensorflow:loss = 1.5773994, step = 21500 (32.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03987\n",
      "INFO:tensorflow:loss = 1.6066022, step = 21600 (32.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03083\n",
      "INFO:tensorflow:loss = 1.0760456, step = 21700 (32.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07862\n",
      "INFO:tensorflow:loss = 0.9439555, step = 21800 (32.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.066\n",
      "INFO:tensorflow:loss = 1.7760783, step = 21900 (32.616 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43315\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T18:29:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-18:30:30\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.67872065, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7336143, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.83592653\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_files_512/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7336143, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.67872065, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.83592653\n",
      "INFO:tensorflow:loss = 1.1474154, step = 22000 (123.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.866341\n",
      "INFO:tensorflow:loss = 1.2543637, step = 22100 (32.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05283\n",
      "INFO:tensorflow:loss = 1.6732869, step = 22200 (32.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03401\n",
      "INFO:tensorflow:loss = 1.4630373, step = 22300 (32.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06804\n",
      "INFO:tensorflow:loss = 1.0719115, step = 22400 (32.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1019\n",
      "INFO:tensorflow:loss = 1.1524545, step = 22500 (32.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10472\n",
      "INFO:tensorflow:loss = 1.1820915, step = 22600 (32.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05673\n",
      "INFO:tensorflow:loss = 1.618222, step = 22700 (32.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04402\n",
      "INFO:tensorflow:loss = 1.0079136, step = 22800 (32.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00426\n",
      "INFO:tensorflow:loss = 1.6527389, step = 22900 (33.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.45406\n",
      "INFO:tensorflow:loss = 1.5005114, step = 23000 (40.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98113\n",
      "INFO:tensorflow:loss = 1.305986, step = 23100 (33.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05046\n",
      "INFO:tensorflow:loss = 2.1022804, step = 23200 (32.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0421\n",
      "INFO:tensorflow:loss = 1.5421098, step = 23300 (32.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06542\n",
      "INFO:tensorflow:loss = 1.3463892, step = 23400 (32.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98155\n",
      "INFO:tensorflow:loss = 1.6439457, step = 23500 (33.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10717\n",
      "INFO:tensorflow:loss = 1.5990789, step = 23600 (32.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06913\n",
      "INFO:tensorflow:loss = 1.5318586, step = 23700 (32.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11833\n",
      "INFO:tensorflow:loss = 0.86608994, step = 23800 (32.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06163\n",
      "INFO:tensorflow:loss = 1.12891, step = 23900 (32.662 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40963\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T18:41:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-18:43:06\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.69787633, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.75034064, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.84477156\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_files_512/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.75034064, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.69787633, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.84477156\n",
      "INFO:tensorflow:loss = 1.0542761, step = 24000 (126.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.852817\n",
      "INFO:tensorflow:loss = 1.8008908, step = 24100 (32.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09739\n",
      "INFO:tensorflow:loss = 0.9048866, step = 24200 (32.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03265\n",
      "INFO:tensorflow:loss = 2.032191, step = 24300 (32.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96258\n",
      "INFO:tensorflow:loss = 1.2507489, step = 24400 (33.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05033\n",
      "INFO:tensorflow:loss = 1.2069474, step = 24500 (32.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06548\n",
      "INFO:tensorflow:loss = 1.444352, step = 24600 (32.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.15634\n",
      "INFO:tensorflow:loss = 2.179311, step = 24700 (31.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98724\n",
      "INFO:tensorflow:loss = 0.8674618, step = 24800 (33.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04733\n",
      "INFO:tensorflow:loss = 1.4529455, step = 24900 (32.815 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42455\n",
      "INFO:tensorflow:loss = 2.5320916, step = 25000 (41.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09099\n",
      "INFO:tensorflow:loss = 0.8437948, step = 25100 (32.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06587\n",
      "INFO:tensorflow:loss = 2.40307, step = 25200 (32.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02484\n",
      "INFO:tensorflow:loss = 0.5639893, step = 25300 (33.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0783\n",
      "INFO:tensorflow:loss = 1.3493409, step = 25400 (32.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11113\n",
      "INFO:tensorflow:loss = 1.4629917, step = 25500 (32.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0294\n",
      "INFO:tensorflow:loss = 1.552357, step = 25600 (33.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10566\n",
      "INFO:tensorflow:loss = 0.99716973, step = 25700 (32.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04939\n",
      "INFO:tensorflow:loss = 1.5939548, step = 25800 (32.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04632\n",
      "INFO:tensorflow:loss = 0.96096313, step = 25900 (32.828 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43584\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T18:54:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-18:55:41\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.71000624, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.76156145, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8515053\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_files_512/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.76156145, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.71000624, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8515053\n",
      "INFO:tensorflow:loss = 0.9852918, step = 26000 (125.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.859571\n",
      "INFO:tensorflow:loss = 1.332066, step = 26100 (32.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08798\n",
      "INFO:tensorflow:loss = 2.3674107, step = 26200 (32.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08016\n",
      "INFO:tensorflow:loss = 1.5658941, step = 26300 (32.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04736\n",
      "INFO:tensorflow:loss = 1.9033562, step = 26400 (32.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0574\n",
      "INFO:tensorflow:loss = 1.0960379, step = 26500 (32.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05993\n",
      "INFO:tensorflow:loss = 1.5982188, step = 26600 (32.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00338\n",
      "INFO:tensorflow:loss = 1.2593999, step = 26700 (33.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00079\n",
      "INFO:tensorflow:loss = 3.2461667, step = 26800 (33.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04826\n",
      "INFO:tensorflow:loss = 1.5926107, step = 26900 (32.807 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39208\n",
      "INFO:tensorflow:loss = 1.4070183, step = 27000 (41.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07846\n",
      "INFO:tensorflow:loss = 0.9165108, step = 27100 (32.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02077\n",
      "INFO:tensorflow:loss = 0.7479269, step = 27200 (33.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10163\n",
      "INFO:tensorflow:loss = 1.359826, step = 27300 (32.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05036\n",
      "INFO:tensorflow:loss = 1.0893519, step = 27400 (32.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01532\n",
      "INFO:tensorflow:loss = 1.2615377, step = 27500 (33.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08059\n",
      "INFO:tensorflow:loss = 1.9577788, step = 27600 (32.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03459\n",
      "INFO:tensorflow:loss = 0.9149988, step = 27700 (32.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11584\n",
      "INFO:tensorflow:loss = 1.4118717, step = 27800 (32.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09288\n",
      "INFO:tensorflow:loss = 1.6755915, step = 27900 (32.332 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36421\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T19:07:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-19:08:17\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7145394, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.76522696, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.85362387\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_files_512/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.76522696, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7145394, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.85362387\n",
      "INFO:tensorflow:loss = 3.0119066, step = 28000 (126.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.857783\n",
      "INFO:tensorflow:loss = 1.3121647, step = 28100 (32.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07217\n",
      "INFO:tensorflow:loss = 1.2340648, step = 28200 (32.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08195\n",
      "INFO:tensorflow:loss = 1.1114159, step = 28300 (32.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00849\n",
      "INFO:tensorflow:loss = 1.880935, step = 28400 (33.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05097\n",
      "INFO:tensorflow:loss = 1.0553783, step = 28500 (32.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05021\n",
      "INFO:tensorflow:loss = 0.8118784, step = 28600 (32.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07426\n",
      "INFO:tensorflow:loss = 1.1905681, step = 28700 (32.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05208\n",
      "INFO:tensorflow:loss = 1.0448328, step = 28800 (32.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0982\n",
      "INFO:tensorflow:loss = 1.4159521, step = 28900 (32.278 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39154\n",
      "INFO:tensorflow:loss = 1.0284698, step = 29000 (41.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06977\n",
      "INFO:tensorflow:loss = 0.67011106, step = 29100 (32.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99577\n",
      "INFO:tensorflow:loss = 1.5656637, step = 29200 (33.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0966\n",
      "INFO:tensorflow:loss = 1.1328373, step = 29300 (32.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08435\n",
      "INFO:tensorflow:loss = 1.2623092, step = 29400 (32.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05692\n",
      "INFO:tensorflow:loss = 0.96363384, step = 29500 (32.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07356\n",
      "INFO:tensorflow:loss = 1.5056084, step = 29600 (32.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03456\n",
      "INFO:tensorflow:loss = 0.59684265, step = 29700 (32.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01119\n",
      "INFO:tensorflow:loss = 1.4613584, step = 29800 (33.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11247\n",
      "INFO:tensorflow:loss = 1.4696698, step = 29900 (32.129 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40821\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T19:19:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-19:20:52\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7355787, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7812306, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8637835\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_files_512/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7812306, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7355787, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8637835\n",
      "INFO:tensorflow:loss = 1.0982863, step = 30000 (124.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.864863\n",
      "INFO:tensorflow:loss = 0.7870741, step = 30100 (32.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0494\n",
      "INFO:tensorflow:loss = 1.2056998, step = 30200 (32.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09193\n",
      "INFO:tensorflow:loss = 1.4762337, step = 30300 (32.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07072\n",
      "INFO:tensorflow:loss = 0.89814216, step = 30400 (32.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06894\n",
      "INFO:tensorflow:loss = 1.0251594, step = 30500 (32.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07729\n",
      "INFO:tensorflow:loss = 2.6429381, step = 30600 (32.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09985\n",
      "INFO:tensorflow:loss = 0.9391847, step = 30700 (32.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06804\n",
      "INFO:tensorflow:loss = 1.2172781, step = 30800 (32.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12587\n",
      "INFO:tensorflow:loss = 0.99632406, step = 30900 (31.991 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.38934\n",
      "INFO:tensorflow:loss = 2.1740658, step = 31000 (41.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05064\n",
      "INFO:tensorflow:loss = 1.282546, step = 31100 (32.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09548\n",
      "INFO:tensorflow:loss = 1.7335149, step = 31200 (32.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1009\n",
      "INFO:tensorflow:loss = 1.2636024, step = 31300 (32.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95494\n",
      "INFO:tensorflow:loss = 1.4750596, step = 31400 (33.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1226\n",
      "INFO:tensorflow:loss = 2.4000134, step = 31500 (32.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.13099\n",
      "INFO:tensorflow:loss = 0.7939223, step = 31600 (31.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02328\n",
      "INFO:tensorflow:loss = 1.4220929, step = 31700 (33.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99419\n",
      "INFO:tensorflow:loss = 1.229056, step = 31800 (33.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01545\n",
      "INFO:tensorflow:loss = 1.6187062, step = 31900 (33.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.38982\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T19:32:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-19:33:27\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.73852944, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7824165, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.86538297\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_files_512/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.7824165, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.73852944, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.86538297\n",
      "INFO:tensorflow:loss = 0.71440315, step = 32000 (126.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.85381\n",
      "INFO:tensorflow:loss = 1.2424296, step = 32100 (32.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0984\n",
      "INFO:tensorflow:loss = 0.91812474, step = 32200 (32.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1218\n",
      "INFO:tensorflow:loss = 0.9865969, step = 32300 (32.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04396\n",
      "INFO:tensorflow:loss = 1.1855552, step = 32400 (32.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06616\n",
      "INFO:tensorflow:loss = 1.1185935, step = 32500 (32.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0089\n",
      "INFO:tensorflow:loss = 0.9378539, step = 32600 (33.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04046\n",
      "INFO:tensorflow:loss = 0.8691381, step = 32700 (32.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11256\n",
      "INFO:tensorflow:loss = 1.4513756, step = 32800 (32.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04331\n",
      "INFO:tensorflow:loss = 1.352817, step = 32900 (32.860 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41268\n",
      "INFO:tensorflow:loss = 1.7578659, step = 33000 (41.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06294\n",
      "INFO:tensorflow:loss = 1.5929582, step = 33100 (32.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10237\n",
      "INFO:tensorflow:loss = 1.1823575, step = 33200 (32.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.061\n",
      "INFO:tensorflow:loss = 1.0144467, step = 33300 (32.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04077\n",
      "INFO:tensorflow:loss = 1.025654, step = 33400 (32.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09931\n",
      "INFO:tensorflow:loss = 1.1997151, step = 33500 (32.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0784\n",
      "INFO:tensorflow:loss = 0.97979057, step = 33600 (32.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09364\n",
      "INFO:tensorflow:loss = 1.1794513, step = 33700 (32.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02672\n",
      "INFO:tensorflow:loss = 1.5179956, step = 33800 (33.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04062\n",
      "INFO:tensorflow:loss = 2.2662838, step = 33900 (32.888 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42901\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T19:44:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-19:46:00\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7450378, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.78844076, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8687832\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_files_512/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.78844076, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7450378, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8687832\n",
      "INFO:tensorflow:loss = 0.97526336, step = 34000 (124.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.853128\n",
      "INFO:tensorflow:loss = 1.0519282, step = 34100 (33.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06169\n",
      "INFO:tensorflow:loss = 0.77961373, step = 34200 (32.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08901\n",
      "INFO:tensorflow:loss = 1.6380001, step = 34300 (32.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08681\n",
      "INFO:tensorflow:loss = 1.0424033, step = 34400 (32.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09869\n",
      "INFO:tensorflow:loss = 1.8863767, step = 34500 (32.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02872\n",
      "INFO:tensorflow:loss = 0.7247039, step = 34600 (33.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08866\n",
      "INFO:tensorflow:loss = 1.2398396, step = 34700 (32.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05136\n",
      "INFO:tensorflow:loss = 0.81567067, step = 34800 (32.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04637\n",
      "INFO:tensorflow:loss = 0.5865481, step = 34900 (32.827 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36514\n",
      "INFO:tensorflow:loss = 1.0772465, step = 35000 (42.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03038\n",
      "INFO:tensorflow:loss = 0.700489, step = 35100 (32.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07578\n",
      "INFO:tensorflow:loss = 1.7297062, step = 35200 (32.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0534\n",
      "INFO:tensorflow:loss = 1.4017477, step = 35300 (32.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04259\n",
      "INFO:tensorflow:loss = 0.8268479, step = 35400 (32.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07057\n",
      "INFO:tensorflow:loss = 2.2745059, step = 35500 (32.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05335\n",
      "INFO:tensorflow:loss = 0.68694234, step = 35600 (32.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98778\n",
      "INFO:tensorflow:loss = 1.143301, step = 35700 (33.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11619\n",
      "INFO:tensorflow:loss = 1.8273834, step = 35800 (32.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05431\n",
      "INFO:tensorflow:loss = 0.9263446, step = 35900 (32.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.4034\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T19:57:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-19:58:36\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7545034, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.79564667, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8730979\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_files_512/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.79564667, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7545034, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8730979\n",
      "INFO:tensorflow:loss = 0.8116015, step = 36000 (124.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.863316\n",
      "INFO:tensorflow:loss = 0.81839526, step = 36100 (32.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10151\n",
      "INFO:tensorflow:loss = 0.8105361, step = 36200 (32.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04548\n",
      "INFO:tensorflow:loss = 0.95890987, step = 36300 (32.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09886\n",
      "INFO:tensorflow:loss = 1.5778166, step = 36400 (32.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04749\n",
      "INFO:tensorflow:loss = 1.0456274, step = 36500 (32.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01322\n",
      "INFO:tensorflow:loss = 1.3500806, step = 36600 (33.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02413\n",
      "INFO:tensorflow:loss = 0.73989916, step = 36700 (33.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03364\n",
      "INFO:tensorflow:loss = 0.88921094, step = 36800 (32.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04646\n",
      "INFO:tensorflow:loss = 1.2748102, step = 36900 (32.827 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.4082\n",
      "INFO:tensorflow:loss = 1.3908148, step = 37000 (41.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0965\n",
      "INFO:tensorflow:loss = 1.3354152, step = 37100 (32.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98465\n",
      "INFO:tensorflow:loss = 1.633502, step = 37200 (33.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08457\n",
      "INFO:tensorflow:loss = 0.9652295, step = 37300 (32.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07156\n",
      "INFO:tensorflow:loss = 0.75149065, step = 37400 (32.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0535\n",
      "INFO:tensorflow:loss = 1.1725287, step = 37500 (32.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09789\n",
      "INFO:tensorflow:loss = 0.68320525, step = 37600 (32.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0243\n",
      "INFO:tensorflow:loss = 0.9439797, step = 37700 (33.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97701\n",
      "INFO:tensorflow:loss = 0.6555198, step = 37800 (33.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01972\n",
      "INFO:tensorflow:loss = 1.7416539, step = 37900 (33.117 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.3734\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T20:09:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-20:11:14\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7625061, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.80276144, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8769144\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_files_512/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.80276144, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7625061, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8769144\n",
      "INFO:tensorflow:loss = 1.325294, step = 38000 (125.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.852822\n",
      "INFO:tensorflow:loss = 1.1810797, step = 38100 (33.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07836\n",
      "INFO:tensorflow:loss = 0.7331807, step = 38200 (32.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0243\n",
      "INFO:tensorflow:loss = 1.1246034, step = 38300 (33.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09827\n",
      "INFO:tensorflow:loss = 1.6792197, step = 38400 (32.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10849\n",
      "INFO:tensorflow:loss = 0.9090018, step = 38500 (32.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02079\n",
      "INFO:tensorflow:loss = 1.0262691, step = 38600 (33.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01254\n",
      "INFO:tensorflow:loss = 1.5491664, step = 38700 (33.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03763\n",
      "INFO:tensorflow:loss = 0.87387395, step = 38800 (32.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01384\n",
      "INFO:tensorflow:loss = 0.623279, step = 38900 (33.181 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43503\n",
      "INFO:tensorflow:loss = 1.1429058, step = 39000 (41.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03733\n",
      "INFO:tensorflow:loss = 1.6195531, step = 39100 (32.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0274\n",
      "INFO:tensorflow:loss = 1.0065321, step = 39200 (33.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03623\n",
      "INFO:tensorflow:loss = 1.0100535, step = 39300 (32.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08513\n",
      "INFO:tensorflow:loss = 0.86536807, step = 39400 (32.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02096\n",
      "INFO:tensorflow:loss = 0.82177365, step = 39500 (33.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09238\n",
      "INFO:tensorflow:loss = 1.1462668, step = 39600 (32.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05339\n",
      "INFO:tensorflow:loss = 0.70945096, step = 39700 (32.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01273\n",
      "INFO:tensorflow:loss = 1.9922545, step = 39800 (33.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06804\n",
      "INFO:tensorflow:loss = 0.5020714, step = 39900 (32.594 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.38048\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T20:22:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-20:23:51\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.76616746, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.806288, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87864745\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: model_files_512/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.806288, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.76616746, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.87864745\n",
      "INFO:tensorflow:loss = 1.8664279, step = 40000 (124.999 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8664279.\n",
      "Time: 15166.04 s\n"
     ]
    }
   ],
   "source": [
    "# select the transformer model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_512'\n",
    "\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 \n",
    "hparams.learning_rate = 0.2 # default 0.2\n",
    "hparams.num_encoder_layers = 6 # default 0\n",
    "hparams.num_decoder_layers = 6 # default 0\n",
    "hparams.max_input_seq_length = 512\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "t2t_model_512 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, #PROBLEM,\n",
    "        data_dir='./data', \n",
    "        train_steps=40001, \n",
    "        eval_steps=200 \n",
    "    )\n",
    "\n",
    "# training\n",
    "t2t_model_512.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f5ae1bb5588>, '_is_chief': True, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_eval_distribute': None, '_task_type': None, 'use_tpu': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ae1bb5710>, '_num_ps_replicas': 0, '_device_fn': None, '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_master': '', 't2t_device_info': {'num_async_replicas': 1}, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_num_worker_replicas': 0, '_evaluation_master': '', '_train_distribute': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_environment': 'local', '_keep_checkpoint_max': 20, '_model_dir': 'model_files_256', '_save_checkpoints_steps': 1000}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f5ac24f3c80>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64797184\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.77373, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.58213\n",
      "INFO:tensorflow:loss = 7.771161, step = 100 (38.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04868\n",
      "INFO:tensorflow:loss = 7.1471963, step = 200 (32.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04675\n",
      "INFO:tensorflow:loss = 6.3276095, step = 300 (32.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05457\n",
      "INFO:tensorflow:loss = 6.0007095, step = 400 (32.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05734\n",
      "INFO:tensorflow:loss = 5.675232, step = 500 (32.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04305\n",
      "INFO:tensorflow:loss = 5.610528, step = 600 (32.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01469\n",
      "INFO:tensorflow:loss = 5.329995, step = 700 (33.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02759\n",
      "INFO:tensorflow:loss = 5.683745, step = 800 (33.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02393\n",
      "INFO:tensorflow:loss = 5.8116546, step = 900 (33.070 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41721\n",
      "INFO:tensorflow:loss = 5.421645, step = 1000 (41.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0316\n",
      "INFO:tensorflow:loss = 5.052563, step = 1100 (32.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03489\n",
      "INFO:tensorflow:loss = 5.0757113, step = 1200 (32.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0447\n",
      "INFO:tensorflow:loss = 5.292966, step = 1300 (32.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04828\n",
      "INFO:tensorflow:loss = 5.063607, step = 1400 (32.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01474\n",
      "INFO:tensorflow:loss = 5.6520023, step = 1500 (33.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05137\n",
      "INFO:tensorflow:loss = 5.068788, step = 1600 (32.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05885\n",
      "INFO:tensorflow:loss = 5.253014, step = 1700 (32.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06591\n",
      "INFO:tensorflow:loss = 5.395725, step = 1800 (32.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04612\n",
      "INFO:tensorflow:loss = 5.01486, step = 1900 (32.829 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43287\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T20:36:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-20:37:20\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.0332824, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.089564934, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.269559\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_files_256/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.089564934, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.0332824, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.269559\n",
      "INFO:tensorflow:loss = 5.197553, step = 2000 (114.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.936773\n",
      "INFO:tensorflow:loss = 4.723135, step = 2100 (33.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02333\n",
      "INFO:tensorflow:loss = 5.023419, step = 2200 (33.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0452\n",
      "INFO:tensorflow:loss = 3.9278712, step = 2300 (32.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03062\n",
      "INFO:tensorflow:loss = 3.5076456, step = 2400 (32.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04812\n",
      "INFO:tensorflow:loss = 4.6235476, step = 2500 (32.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04886\n",
      "INFO:tensorflow:loss = 5.5130525, step = 2600 (32.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06826\n",
      "INFO:tensorflow:loss = 2.7830281, step = 2700 (32.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0553\n",
      "INFO:tensorflow:loss = 3.6123433, step = 2800 (32.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01635\n",
      "INFO:tensorflow:loss = 3.128107, step = 2900 (33.154 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43512\n",
      "INFO:tensorflow:loss = 2.8505707, step = 3000 (41.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03374\n",
      "INFO:tensorflow:loss = 3.1691027, step = 3100 (32.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02686\n",
      "INFO:tensorflow:loss = 2.1350143, step = 3200 (33.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03201\n",
      "INFO:tensorflow:loss = 2.0997937, step = 3300 (32.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05483\n",
      "INFO:tensorflow:loss = 4.5211377, step = 3400 (32.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05425\n",
      "INFO:tensorflow:loss = 2.4015288, step = 3500 (32.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0113\n",
      "INFO:tensorflow:loss = 3.2805865, step = 3600 (33.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04502\n",
      "INFO:tensorflow:loss = 2.7401748, step = 3700 (32.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04243\n",
      "INFO:tensorflow:loss = 2.6670742, step = 3800 (32.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05043\n",
      "INFO:tensorflow:loss = 1.2027713, step = 3900 (32.782 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42681\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T20:48:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-20:49:47\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.4854674, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.56704134, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7268811\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_files_256/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.56704134, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.4854674, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.7268811\n",
      "INFO:tensorflow:loss = 1.9441694, step = 4000 (114.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.945669\n",
      "INFO:tensorflow:loss = 2.3838544, step = 4100 (32.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01147\n",
      "INFO:tensorflow:loss = 1.3698833, step = 4200 (33.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02629\n",
      "INFO:tensorflow:loss = 1.9746088, step = 4300 (33.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06863\n",
      "INFO:tensorflow:loss = 0.9047865, step = 4400 (32.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05672\n",
      "INFO:tensorflow:loss = 0.7004692, step = 4500 (32.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01881\n",
      "INFO:tensorflow:loss = 1.348737, step = 4600 (33.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03718\n",
      "INFO:tensorflow:loss = 0.9230482, step = 4700 (32.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02961\n",
      "INFO:tensorflow:loss = 1.6955656, step = 4800 (33.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0277\n",
      "INFO:tensorflow:loss = 0.98344916, step = 4900 (33.030 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43084\n",
      "INFO:tensorflow:loss = 1.9815527, step = 5000 (41.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03156\n",
      "INFO:tensorflow:loss = 0.8710214, step = 5100 (32.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04854\n",
      "INFO:tensorflow:loss = 1.0085963, step = 5200 (32.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02166\n",
      "INFO:tensorflow:loss = 1.054075, step = 5300 (33.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02562\n",
      "INFO:tensorflow:loss = 1.0008386, step = 5400 (33.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00968\n",
      "INFO:tensorflow:loss = 0.5882351, step = 5500 (33.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01593\n",
      "INFO:tensorflow:loss = 0.9393703, step = 5600 (33.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03335\n",
      "INFO:tensorflow:loss = 1.054242, step = 5700 (32.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02244\n",
      "INFO:tensorflow:loss = 0.98044324, step = 5800 (33.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02111\n",
      "INFO:tensorflow:loss = 0.5871605, step = 5900 (33.100 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41426\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T21:01:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-21:02:15\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7912075, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.82867515, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8884901\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_files_256/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.82867515, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.7912075, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.8884901\n",
      "INFO:tensorflow:loss = 0.5253049, step = 6000 (112.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.962284\n",
      "INFO:tensorflow:loss = 1.5545658, step = 6100 (32.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0349\n",
      "INFO:tensorflow:loss = 1.578986, step = 6200 (32.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04669\n",
      "INFO:tensorflow:loss = 0.5106977, step = 6300 (32.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01613\n",
      "INFO:tensorflow:loss = 0.92012423, step = 6400 (33.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02236\n",
      "INFO:tensorflow:loss = 0.93541807, step = 6500 (33.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03219\n",
      "INFO:tensorflow:loss = 0.6833605, step = 6600 (32.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05267\n",
      "INFO:tensorflow:loss = 1.0414658, step = 6700 (32.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03276\n",
      "INFO:tensorflow:loss = 0.74540263, step = 6800 (32.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02044\n",
      "INFO:tensorflow:loss = 0.6108716, step = 6900 (33.108 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41124\n",
      "INFO:tensorflow:loss = 0.62140113, step = 7000 (41.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08282\n",
      "INFO:tensorflow:loss = 0.47963908, step = 7100 (32.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03133\n",
      "INFO:tensorflow:loss = 1.0143484, step = 7200 (32.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00687\n",
      "INFO:tensorflow:loss = 1.2088739, step = 7300 (33.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02587\n",
      "INFO:tensorflow:loss = 0.65902317, step = 7400 (33.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04807\n",
      "INFO:tensorflow:loss = 0.8336577, step = 7500 (32.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01228\n",
      "INFO:tensorflow:loss = 0.5191151, step = 7600 (33.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0266\n",
      "INFO:tensorflow:loss = 0.7989609, step = 7700 (33.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06148\n",
      "INFO:tensorflow:loss = 0.721282, step = 7800 (32.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03395\n",
      "INFO:tensorflow:loss = 0.8431558, step = 7900 (32.961 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40437\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T21:13:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-21:14:44\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8165306, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.84951454, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9011747\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_files_256/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.84951454, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8165306, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9011747\n",
      "INFO:tensorflow:loss = 1.0878202, step = 8000 (114.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.942216\n",
      "INFO:tensorflow:loss = 0.5443009, step = 8100 (33.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04676\n",
      "INFO:tensorflow:loss = 0.50363004, step = 8200 (32.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03936\n",
      "INFO:tensorflow:loss = 0.69065017, step = 8300 (32.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04397\n",
      "INFO:tensorflow:loss = 0.85119057, step = 8400 (32.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06113\n",
      "INFO:tensorflow:loss = 0.7269724, step = 8500 (32.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04641\n",
      "INFO:tensorflow:loss = 0.98802185, step = 8600 (32.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02515\n",
      "INFO:tensorflow:loss = 0.81487936, step = 8700 (33.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04058\n",
      "INFO:tensorflow:loss = 0.77625155, step = 8800 (32.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01589\n",
      "INFO:tensorflow:loss = 0.9486456, step = 8900 (33.158 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42362\n",
      "INFO:tensorflow:loss = 0.5390985, step = 9000 (41.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01824\n",
      "INFO:tensorflow:loss = 0.7289833, step = 9100 (33.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02115\n",
      "INFO:tensorflow:loss = 1.0108712, step = 9200 (33.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0117\n",
      "INFO:tensorflow:loss = 1.1399525, step = 9300 (33.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03722\n",
      "INFO:tensorflow:loss = 0.7502306, step = 9400 (32.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07365\n",
      "INFO:tensorflow:loss = 0.95258564, step = 9500 (32.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00982\n",
      "INFO:tensorflow:loss = 0.5764867, step = 9600 (33.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04397\n",
      "INFO:tensorflow:loss = 0.5766508, step = 9700 (32.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03065\n",
      "INFO:tensorflow:loss = 1.0939027, step = 9800 (32.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0221\n",
      "INFO:tensorflow:loss = 0.6284506, step = 9900 (33.089 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41436\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T21:26:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-21:27:13\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.84599024, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.87503934, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.91556466\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_files_256/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.87503934, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.84599024, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.91556466\n",
      "INFO:tensorflow:loss = 0.6621575, step = 10000 (114.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.947606\n",
      "INFO:tensorflow:loss = 0.40242696, step = 10100 (32.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04365\n",
      "INFO:tensorflow:loss = 0.6251605, step = 10200 (32.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04427\n",
      "INFO:tensorflow:loss = 0.4792965, step = 10300 (32.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02568\n",
      "INFO:tensorflow:loss = 0.74294996, step = 10400 (33.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04136\n",
      "INFO:tensorflow:loss = 0.46246377, step = 10500 (32.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0185\n",
      "INFO:tensorflow:loss = 0.8496628, step = 10600 (33.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00388\n",
      "INFO:tensorflow:loss = 0.4590865, step = 10700 (33.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03115\n",
      "INFO:tensorflow:loss = 0.6149514, step = 10800 (32.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02352\n",
      "INFO:tensorflow:loss = 0.55886, step = 10900 (33.073 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42201\n",
      "INFO:tensorflow:loss = 0.4431165, step = 11000 (41.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04595\n",
      "INFO:tensorflow:loss = 0.6478629, step = 11100 (32.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02475\n",
      "INFO:tensorflow:loss = 0.58837795, step = 11200 (33.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01472\n",
      "INFO:tensorflow:loss = 0.3661769, step = 11300 (33.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0171\n",
      "INFO:tensorflow:loss = 0.46313265, step = 11400 (33.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0743\n",
      "INFO:tensorflow:loss = 0.7576116, step = 11500 (32.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04907\n",
      "INFO:tensorflow:loss = 0.45797434, step = 11600 (32.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01414\n",
      "INFO:tensorflow:loss = 0.31553861, step = 11700 (33.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01921\n",
      "INFO:tensorflow:loss = 0.536277, step = 11800 (33.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02523\n",
      "INFO:tensorflow:loss = 0.70602345, step = 11900 (33.055 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40981\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T21:38:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-21:39:41\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8620952, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8893653, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.92337686\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_files_256/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8893653, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8620952, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.92337686\n",
      "INFO:tensorflow:loss = 0.85617393, step = 12000 (113.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.958396\n",
      "INFO:tensorflow:loss = 0.39532313, step = 12100 (32.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03524\n",
      "INFO:tensorflow:loss = 0.48351, step = 12200 (32.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05627\n",
      "INFO:tensorflow:loss = 0.4242012, step = 12300 (32.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02848\n",
      "INFO:tensorflow:loss = 0.5336327, step = 12400 (33.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03454\n",
      "INFO:tensorflow:loss = 0.97178835, step = 12500 (32.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04884\n",
      "INFO:tensorflow:loss = 0.38446423, step = 12600 (32.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03289\n",
      "INFO:tensorflow:loss = 0.4356896, step = 12700 (32.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02495\n",
      "INFO:tensorflow:loss = 0.25727436, step = 12800 (33.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05086\n",
      "INFO:tensorflow:loss = 0.25291902, step = 12900 (32.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41243\n",
      "INFO:tensorflow:loss = 0.37827715, step = 13000 (41.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03346\n",
      "INFO:tensorflow:loss = 0.7222319, step = 13100 (32.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03197\n",
      "INFO:tensorflow:loss = 0.9381901, step = 13200 (32.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02515\n",
      "INFO:tensorflow:loss = 0.8292418, step = 13300 (33.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04111\n",
      "INFO:tensorflow:loss = 0.2926665, step = 13400 (32.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04747\n",
      "INFO:tensorflow:loss = 0.38055313, step = 13500 (32.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02632\n",
      "INFO:tensorflow:loss = 0.36843583, step = 13600 (33.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01698\n",
      "INFO:tensorflow:loss = 0.87795305, step = 13700 (33.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05371\n",
      "INFO:tensorflow:loss = 0.36808312, step = 13800 (32.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01225\n",
      "INFO:tensorflow:loss = 0.63571113, step = 13900 (33.198 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42392\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T21:51:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-21:52:09\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.87398726, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8999211, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9294274\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_files_256/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.8999211, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.87398726, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9294274\n",
      "INFO:tensorflow:loss = 1.033338, step = 14000 (113.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.946902\n",
      "INFO:tensorflow:loss = 0.31826597, step = 14100 (32.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04574\n",
      "INFO:tensorflow:loss = 0.5814546, step = 14200 (32.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03707\n",
      "INFO:tensorflow:loss = 0.74015945, step = 14300 (32.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01397\n",
      "INFO:tensorflow:loss = 0.639831, step = 14400 (33.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00545\n",
      "INFO:tensorflow:loss = 0.3426685, step = 14500 (33.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00453\n",
      "INFO:tensorflow:loss = 0.52907205, step = 14600 (33.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00144\n",
      "INFO:tensorflow:loss = 0.5565257, step = 14700 (33.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04438\n",
      "INFO:tensorflow:loss = 0.87725955, step = 14800 (32.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02124\n",
      "INFO:tensorflow:loss = 0.35938808, step = 14900 (33.100 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.4076\n",
      "INFO:tensorflow:loss = 0.44882593, step = 15000 (41.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00123\n",
      "INFO:tensorflow:loss = 0.42171654, step = 15100 (33.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04042\n",
      "INFO:tensorflow:loss = 0.4510462, step = 15200 (32.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03534\n",
      "INFO:tensorflow:loss = 0.29234645, step = 15300 (32.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02169\n",
      "INFO:tensorflow:loss = 0.44151527, step = 15400 (33.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04164\n",
      "INFO:tensorflow:loss = 0.34580144, step = 15500 (32.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03828\n",
      "INFO:tensorflow:loss = 0.27624974, step = 15600 (32.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01944\n",
      "INFO:tensorflow:loss = 0.28404596, step = 15700 (33.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02448\n",
      "INFO:tensorflow:loss = 0.41128007, step = 15800 (33.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02728\n",
      "INFO:tensorflow:loss = 0.6942836, step = 15900 (33.033 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.4413\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T22:03:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-22:04:39\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.881273, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.90589887, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93252814\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_files_256/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.90589887, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.881273, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93252814\n",
      "INFO:tensorflow:loss = 0.3544377, step = 16000 (113.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.949507\n",
      "INFO:tensorflow:loss = 0.4114315, step = 16100 (33.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03978\n",
      "INFO:tensorflow:loss = 0.42918894, step = 16200 (32.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04405\n",
      "INFO:tensorflow:loss = 0.39923552, step = 16300 (32.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03646\n",
      "INFO:tensorflow:loss = 0.73688257, step = 16400 (32.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01815\n",
      "INFO:tensorflow:loss = 0.34475595, step = 16500 (33.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04515\n",
      "INFO:tensorflow:loss = 0.4143898, step = 16600 (32.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03595\n",
      "INFO:tensorflow:loss = 0.2995612, step = 16700 (32.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00994\n",
      "INFO:tensorflow:loss = 0.41881326, step = 16800 (33.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04288\n",
      "INFO:tensorflow:loss = 0.32238752, step = 16900 (32.865 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43156\n",
      "INFO:tensorflow:loss = 0.55144954, step = 17000 (41.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01924\n",
      "INFO:tensorflow:loss = 0.38452935, step = 17100 (33.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9876\n",
      "INFO:tensorflow:loss = 0.36627486, step = 17200 (33.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02794\n",
      "INFO:tensorflow:loss = 0.66434765, step = 17300 (33.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05702\n",
      "INFO:tensorflow:loss = 0.27522188, step = 17400 (32.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02111\n",
      "INFO:tensorflow:loss = 0.41109493, step = 17500 (33.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00028\n",
      "INFO:tensorflow:loss = 0.7545986, step = 17600 (33.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04089\n",
      "INFO:tensorflow:loss = 0.68970066, step = 17700 (32.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02628\n",
      "INFO:tensorflow:loss = 0.34057036, step = 17800 (33.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01933\n",
      "INFO:tensorflow:loss = 0.35166243, step = 17900 (33.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42562\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T22:16:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-22:17:08\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8853313, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91000575, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9345174\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_files_256/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91000575, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8853313, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9345174\n",
      "INFO:tensorflow:loss = 0.4637049, step = 18000 (112.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.957402\n",
      "INFO:tensorflow:loss = 0.5574458, step = 18100 (32.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99385\n",
      "INFO:tensorflow:loss = 0.4828823, step = 18200 (33.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01082\n",
      "INFO:tensorflow:loss = 0.69394886, step = 18300 (33.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04355\n",
      "INFO:tensorflow:loss = 0.26168743, step = 18400 (32.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01676\n",
      "INFO:tensorflow:loss = 0.37907925, step = 18500 (33.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02724\n",
      "INFO:tensorflow:loss = 0.47965175, step = 18600 (33.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03251\n",
      "INFO:tensorflow:loss = 0.6612657, step = 18700 (32.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02989\n",
      "INFO:tensorflow:loss = 0.3512648, step = 18800 (33.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02541\n",
      "INFO:tensorflow:loss = 0.29007697, step = 18900 (33.054 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41868\n",
      "INFO:tensorflow:loss = 0.2604266, step = 19000 (41.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02359\n",
      "INFO:tensorflow:loss = 0.3392143, step = 19100 (33.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04565\n",
      "INFO:tensorflow:loss = 0.44393146, step = 19200 (32.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03085\n",
      "INFO:tensorflow:loss = 0.3319305, step = 19300 (32.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03692\n",
      "INFO:tensorflow:loss = 0.4307128, step = 19400 (32.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03941\n",
      "INFO:tensorflow:loss = 0.45010594, step = 19500 (32.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03219\n",
      "INFO:tensorflow:loss = 0.6566507, step = 19600 (32.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00354\n",
      "INFO:tensorflow:loss = 0.40966558, step = 19700 (33.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03614\n",
      "INFO:tensorflow:loss = 0.3746515, step = 19800 (32.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04666\n",
      "INFO:tensorflow:loss = 0.4008557, step = 19900 (32.823 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41457\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T22:28:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-22:29:38\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8915775, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9151535, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9373074\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_files_256/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9151535, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8915775, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9373074\n",
      "INFO:tensorflow:loss = 0.40362316, step = 20000 (114.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.940866\n",
      "INFO:tensorflow:loss = 0.6874494, step = 20100 (33.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01318\n",
      "INFO:tensorflow:loss = 0.8596546, step = 20200 (33.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04195\n",
      "INFO:tensorflow:loss = 0.3903609, step = 20300 (32.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02068\n",
      "INFO:tensorflow:loss = 0.6491987, step = 20400 (33.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05003\n",
      "INFO:tensorflow:loss = 0.3127448, step = 20500 (32.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02671\n",
      "INFO:tensorflow:loss = 0.59487724, step = 20600 (33.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03095\n",
      "INFO:tensorflow:loss = 0.3636897, step = 20700 (32.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02959\n",
      "INFO:tensorflow:loss = 0.5276597, step = 20800 (33.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05373\n",
      "INFO:tensorflow:loss = 0.41035834, step = 20900 (32.748 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39858\n",
      "INFO:tensorflow:loss = 0.31592113, step = 21000 (41.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0201\n",
      "INFO:tensorflow:loss = 0.36044952, step = 21100 (33.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04445\n",
      "INFO:tensorflow:loss = 0.4047749, step = 21200 (32.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02285\n",
      "INFO:tensorflow:loss = 0.44282278, step = 21300 (33.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01816\n",
      "INFO:tensorflow:loss = 0.8686652, step = 21400 (33.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04349\n",
      "INFO:tensorflow:loss = 0.27143297, step = 21500 (32.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01948\n",
      "INFO:tensorflow:loss = 0.26637164, step = 21600 (33.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01858\n",
      "INFO:tensorflow:loss = 0.43124765, step = 21700 (33.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03894\n",
      "INFO:tensorflow:loss = 0.57521635, step = 21800 (32.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05032\n",
      "INFO:tensorflow:loss = 0.55303127, step = 21900 (32.784 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39512\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T22:41:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-22:42:08\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8939131, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9190949, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9384126\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_files_256/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9190949, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8939131, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9384126\n",
      "INFO:tensorflow:loss = 0.4501983, step = 22000 (114.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.940262\n",
      "INFO:tensorflow:loss = 0.356395, step = 22100 (33.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0637\n",
      "INFO:tensorflow:loss = 0.43904713, step = 22200 (32.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00505\n",
      "INFO:tensorflow:loss = 0.38351682, step = 22300 (33.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99271\n",
      "INFO:tensorflow:loss = 0.6303743, step = 22400 (33.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.078\n",
      "INFO:tensorflow:loss = 0.40128693, step = 22500 (32.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05084\n",
      "INFO:tensorflow:loss = 0.7691397, step = 22600 (32.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04076\n",
      "INFO:tensorflow:loss = 0.43686906, step = 22700 (32.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02872\n",
      "INFO:tensorflow:loss = 0.46609446, step = 22800 (33.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02364\n",
      "INFO:tensorflow:loss = 0.38119012, step = 22900 (33.074 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.41135\n",
      "INFO:tensorflow:loss = 0.47099617, step = 23000 (41.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02797\n",
      "INFO:tensorflow:loss = 0.5546634, step = 23100 (33.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03728\n",
      "INFO:tensorflow:loss = 0.70592546, step = 23200 (32.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03474\n",
      "INFO:tensorflow:loss = 0.51351595, step = 23300 (32.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04076\n",
      "INFO:tensorflow:loss = 0.2120186, step = 23400 (32.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01471\n",
      "INFO:tensorflow:loss = 0.4226805, step = 23500 (33.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0209\n",
      "INFO:tensorflow:loss = 0.42178917, step = 23600 (33.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99674\n",
      "INFO:tensorflow:loss = 0.40890065, step = 23700 (33.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03575\n",
      "INFO:tensorflow:loss = 0.3330327, step = 23800 (32.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03446\n",
      "INFO:tensorflow:loss = 0.53993285, step = 23900 (32.955 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40161\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T22:53:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-22:54:37\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8915026, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9157788, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93753004\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_files_256/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9157788, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8915026, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93753004\n",
      "INFO:tensorflow:loss = 0.38271156, step = 24000 (113.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.956871\n",
      "INFO:tensorflow:loss = 0.30422008, step = 24100 (32.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0088\n",
      "INFO:tensorflow:loss = 0.43587893, step = 24200 (33.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04464\n",
      "INFO:tensorflow:loss = 0.35146922, step = 24300 (32.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03289\n",
      "INFO:tensorflow:loss = 0.32459745, step = 24400 (32.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05597\n",
      "INFO:tensorflow:loss = 0.38799903, step = 24500 (32.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04139\n",
      "INFO:tensorflow:loss = 0.30188122, step = 24600 (32.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03712\n",
      "INFO:tensorflow:loss = 0.62444663, step = 24700 (32.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03454\n",
      "INFO:tensorflow:loss = 0.39764026, step = 24800 (32.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0533\n",
      "INFO:tensorflow:loss = 0.39296356, step = 24900 (32.752 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39602\n",
      "INFO:tensorflow:loss = 0.32221407, step = 25000 (41.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0281\n",
      "INFO:tensorflow:loss = 0.2743684, step = 25100 (33.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04252\n",
      "INFO:tensorflow:loss = 0.4342724, step = 25200 (32.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04574\n",
      "INFO:tensorflow:loss = 0.55542177, step = 25300 (32.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01598\n",
      "INFO:tensorflow:loss = 0.25581127, step = 25400 (33.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01849\n",
      "INFO:tensorflow:loss = 1.1760355, step = 25500 (33.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01548\n",
      "INFO:tensorflow:loss = 0.2679699, step = 25600 (33.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01467\n",
      "INFO:tensorflow:loss = 0.73866695, step = 25700 (33.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0107\n",
      "INFO:tensorflow:loss = 0.31738588, step = 25800 (33.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03046\n",
      "INFO:tensorflow:loss = 0.31956673, step = 25900 (32.998 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.42435\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T23:06:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-23:07:07\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89319456, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91734385, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9381089\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_files_256/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91734385, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89319456, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9381089\n",
      "INFO:tensorflow:loss = 0.39783087, step = 26000 (114.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.939619\n",
      "INFO:tensorflow:loss = 0.70393294, step = 26100 (32.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0327\n",
      "INFO:tensorflow:loss = 0.890755, step = 26200 (32.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01391\n",
      "INFO:tensorflow:loss = 0.35792017, step = 26300 (33.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04043\n",
      "INFO:tensorflow:loss = 0.30708447, step = 26400 (32.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04227\n",
      "INFO:tensorflow:loss = 0.45060268, step = 26500 (32.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03532\n",
      "INFO:tensorflow:loss = 0.2620547, step = 26600 (32.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01849\n",
      "INFO:tensorflow:loss = 0.48940727, step = 26700 (33.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05023\n",
      "INFO:tensorflow:loss = 0.16578078, step = 26800 (32.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99988\n",
      "INFO:tensorflow:loss = 0.18756182, step = 26900 (33.335 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.3947\n",
      "INFO:tensorflow:loss = 0.44630364, step = 27000 (41.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04987\n",
      "INFO:tensorflow:loss = 0.22991545, step = 27100 (32.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05026\n",
      "INFO:tensorflow:loss = 0.8435537, step = 27200 (32.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02695\n",
      "INFO:tensorflow:loss = 0.28760576, step = 27300 (33.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02668\n",
      "INFO:tensorflow:loss = 0.335776, step = 27400 (33.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03423\n",
      "INFO:tensorflow:loss = 0.6050115, step = 27500 (32.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01845\n",
      "INFO:tensorflow:loss = 0.46589062, step = 27600 (33.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00666\n",
      "INFO:tensorflow:loss = 0.18754637, step = 27700 (33.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04217\n",
      "INFO:tensorflow:loss = 0.2914097, step = 27800 (32.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03482\n",
      "INFO:tensorflow:loss = 0.4949313, step = 27900 (32.951 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39153\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T23:18:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-23:19:37\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89238167, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9162209, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9378804\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_files_256/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9162209, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89238167, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9378804\n",
      "INFO:tensorflow:loss = 0.33653367, step = 28000 (114.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.945381\n",
      "INFO:tensorflow:loss = 0.69293934, step = 28100 (33.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04408\n",
      "INFO:tensorflow:loss = 0.23578328, step = 28200 (32.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02505\n",
      "INFO:tensorflow:loss = 0.31303585, step = 28300 (33.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00284\n",
      "INFO:tensorflow:loss = 0.39884818, step = 28400 (33.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0272\n",
      "INFO:tensorflow:loss = 0.35124522, step = 28500 (33.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0122\n",
      "INFO:tensorflow:loss = 0.7086406, step = 28600 (33.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03842\n",
      "INFO:tensorflow:loss = 0.4465432, step = 28700 (32.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01727\n",
      "INFO:tensorflow:loss = 0.34448662, step = 28800 (33.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02964\n",
      "INFO:tensorflow:loss = 0.18190724, step = 28900 (33.008 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39462\n",
      "INFO:tensorflow:loss = 0.24751122, step = 29000 (41.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03079\n",
      "INFO:tensorflow:loss = 0.61149347, step = 29100 (32.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04994\n",
      "INFO:tensorflow:loss = 0.27629465, step = 29200 (32.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0257\n",
      "INFO:tensorflow:loss = 0.3057385, step = 29300 (33.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02801\n",
      "INFO:tensorflow:loss = 0.29421765, step = 29400 (33.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05033\n",
      "INFO:tensorflow:loss = 0.4857932, step = 29500 (32.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0208\n",
      "INFO:tensorflow:loss = 0.23119923, step = 29600 (33.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02953\n",
      "INFO:tensorflow:loss = 0.20181523, step = 29700 (33.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02212\n",
      "INFO:tensorflow:loss = 0.2498113, step = 29800 (33.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03724\n",
      "INFO:tensorflow:loss = 0.39803183, step = 29900 (32.925 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40516\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T23:31:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-23:32:06\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89141935, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9154612, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93738484\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_files_256/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9154612, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89141935, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93738484\n",
      "INFO:tensorflow:loss = 0.44811073, step = 30000 (112.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.956271\n",
      "INFO:tensorflow:loss = 0.41106674, step = 30100 (33.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02986\n",
      "INFO:tensorflow:loss = 0.3695415, step = 30200 (33.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03785\n",
      "INFO:tensorflow:loss = 0.2457957, step = 30300 (32.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01377\n",
      "INFO:tensorflow:loss = 0.28108874, step = 30400 (33.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04696\n",
      "INFO:tensorflow:loss = 0.21791579, step = 30500 (32.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0403\n",
      "INFO:tensorflow:loss = 0.2193328, step = 30600 (32.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00463\n",
      "INFO:tensorflow:loss = 0.5358041, step = 30700 (33.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05676\n",
      "INFO:tensorflow:loss = 0.5407943, step = 30800 (32.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03247\n",
      "INFO:tensorflow:loss = 0.4612748, step = 30900 (32.977 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39747\n",
      "INFO:tensorflow:loss = 0.2699039, step = 31000 (41.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01948\n",
      "INFO:tensorflow:loss = 0.34975627, step = 31100 (33.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0282\n",
      "INFO:tensorflow:loss = 0.23674685, step = 31200 (33.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02561\n",
      "INFO:tensorflow:loss = 0.7032599, step = 31300 (33.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02589\n",
      "INFO:tensorflow:loss = 0.24264015, step = 31400 (33.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03539\n",
      "INFO:tensorflow:loss = 0.6362975, step = 31500 (32.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01777\n",
      "INFO:tensorflow:loss = 0.4343674, step = 31600 (33.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01933\n",
      "INFO:tensorflow:loss = 0.2522588, step = 31700 (33.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0286\n",
      "INFO:tensorflow:loss = 0.35763696, step = 31800 (33.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04601\n",
      "INFO:tensorflow:loss = 0.16779949, step = 31900 (32.831 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40064\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T23:43:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-23:44:37\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.895152, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9185842, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93900436\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_files_256/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9185842, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.895152, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93900436\n",
      "INFO:tensorflow:loss = 0.28168038, step = 32000 (114.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.94362\n",
      "INFO:tensorflow:loss = 0.26484606, step = 32100 (32.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02956\n",
      "INFO:tensorflow:loss = 0.40420544, step = 32200 (33.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02822\n",
      "INFO:tensorflow:loss = 0.42149365, step = 32300 (33.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0129\n",
      "INFO:tensorflow:loss = 0.469694, step = 32400 (33.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02018\n",
      "INFO:tensorflow:loss = 0.20089199, step = 32500 (33.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01432\n",
      "INFO:tensorflow:loss = 0.3014387, step = 32600 (33.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01565\n",
      "INFO:tensorflow:loss = 0.51799035, step = 32700 (33.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03355\n",
      "INFO:tensorflow:loss = 0.38163033, step = 32800 (32.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02042\n",
      "INFO:tensorflow:loss = 0.39332148, step = 32900 (33.109 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39957\n",
      "INFO:tensorflow:loss = 0.3847238, step = 33000 (41.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00457\n",
      "INFO:tensorflow:loss = 0.68574756, step = 33100 (33.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02891\n",
      "INFO:tensorflow:loss = 0.38234693, step = 33200 (33.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04173\n",
      "INFO:tensorflow:loss = 0.41031, step = 33300 (32.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01062\n",
      "INFO:tensorflow:loss = 0.2346969, step = 33400 (33.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99091\n",
      "INFO:tensorflow:loss = 0.16248702, step = 33500 (33.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02744\n",
      "INFO:tensorflow:loss = 0.53747016, step = 33600 (33.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01861\n",
      "INFO:tensorflow:loss = 0.21848212, step = 33700 (33.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01166\n",
      "INFO:tensorflow:loss = 0.30662867, step = 33800 (33.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00903\n",
      "INFO:tensorflow:loss = 0.5211551, step = 33900 (33.234 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.39242\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-25T23:56:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-25-23:57:09\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8906425, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91516286, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9370188\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_files_256/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91516286, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8906425, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9370188\n",
      "INFO:tensorflow:loss = 0.26245347, step = 34000 (114.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.949288\n",
      "INFO:tensorflow:loss = 0.23209354, step = 34100 (33.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03543\n",
      "INFO:tensorflow:loss = 0.3943886, step = 34200 (32.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00198\n",
      "INFO:tensorflow:loss = 0.26089227, step = 34300 (33.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04122\n",
      "INFO:tensorflow:loss = 0.39127842, step = 34400 (32.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03023\n",
      "INFO:tensorflow:loss = 0.22931409, step = 34500 (33.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02844\n",
      "INFO:tensorflow:loss = 0.32697392, step = 34600 (33.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02981\n",
      "INFO:tensorflow:loss = 0.47844023, step = 34700 (33.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02186\n",
      "INFO:tensorflow:loss = 0.35935462, step = 34800 (33.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01973\n",
      "INFO:tensorflow:loss = 0.22261597, step = 34900 (33.117 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.43154\n",
      "INFO:tensorflow:loss = 0.2911408, step = 35000 (41.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05711\n",
      "INFO:tensorflow:loss = 0.41724247, step = 35100 (32.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05395\n",
      "INFO:tensorflow:loss = 0.5305899, step = 35200 (32.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02314\n",
      "INFO:tensorflow:loss = 0.38766688, step = 35300 (33.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0289\n",
      "INFO:tensorflow:loss = 0.23173782, step = 35400 (33.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02676\n",
      "INFO:tensorflow:loss = 0.7042014, step = 35500 (33.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00712\n",
      "INFO:tensorflow:loss = 0.27136034, step = 35600 (33.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01821\n",
      "INFO:tensorflow:loss = 0.25257823, step = 35700 (33.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03264\n",
      "INFO:tensorflow:loss = 0.32597253, step = 35800 (32.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01511\n",
      "INFO:tensorflow:loss = 0.3999809, step = 35900 (33.167 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.32703\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T00:08:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-00:09:40\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8933889, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91723144, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93820304\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_files_256/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91723144, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8933889, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93820304\n",
      "INFO:tensorflow:loss = 0.16763288, step = 36000 (115.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.951169\n",
      "INFO:tensorflow:loss = 0.47076982, step = 36100 (33.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01667\n",
      "INFO:tensorflow:loss = 0.5471093, step = 36200 (33.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05976\n",
      "INFO:tensorflow:loss = 0.46508214, step = 36300 (32.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03559\n",
      "INFO:tensorflow:loss = 0.42442837, step = 36400 (32.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00242\n",
      "INFO:tensorflow:loss = 0.41826892, step = 36500 (33.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04565\n",
      "INFO:tensorflow:loss = 0.42316005, step = 36600 (32.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02324\n",
      "INFO:tensorflow:loss = 0.5433815, step = 36700 (33.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02677\n",
      "INFO:tensorflow:loss = 0.20228155, step = 36800 (33.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01078\n",
      "INFO:tensorflow:loss = 0.31146765, step = 36900 (33.215 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.38955\n",
      "INFO:tensorflow:loss = 0.35724688, step = 37000 (41.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04899\n",
      "INFO:tensorflow:loss = 0.33771056, step = 37100 (32.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06436\n",
      "INFO:tensorflow:loss = 0.34366915, step = 37200 (32.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.993\n",
      "INFO:tensorflow:loss = 0.2546591, step = 37300 (33.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04164\n",
      "INFO:tensorflow:loss = 0.38926306, step = 37400 (32.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01099\n",
      "INFO:tensorflow:loss = 0.3267718, step = 37500 (33.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04608\n",
      "INFO:tensorflow:loss = 0.21966448, step = 37600 (32.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04767\n",
      "INFO:tensorflow:loss = 0.14470744, step = 37700 (32.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03887\n",
      "INFO:tensorflow:loss = 0.5301996, step = 37800 (32.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02929\n",
      "INFO:tensorflow:loss = 0.33877316, step = 37900 (33.011 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.37954\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T00:21:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-00:22:11\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89326507, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9172153, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9382475\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_files_256/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9172153, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89326507, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.9382475\n",
      "INFO:tensorflow:loss = 0.28007486, step = 38000 (115.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.935565\n",
      "INFO:tensorflow:loss = 0.23363392, step = 38100 (33.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04803\n",
      "INFO:tensorflow:loss = 0.44319835, step = 38200 (32.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01496\n",
      "INFO:tensorflow:loss = 0.4339702, step = 38300 (33.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03099\n",
      "INFO:tensorflow:loss = 0.6752295, step = 38400 (32.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04236\n",
      "INFO:tensorflow:loss = 0.32472774, step = 38500 (32.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03723\n",
      "INFO:tensorflow:loss = 0.34591776, step = 38600 (32.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02479\n",
      "INFO:tensorflow:loss = 0.33968863, step = 38700 (33.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03666\n",
      "INFO:tensorflow:loss = 0.29009834, step = 38800 (32.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0178\n",
      "INFO:tensorflow:loss = 0.25249988, step = 38900 (33.137 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.4129\n",
      "INFO:tensorflow:loss = 0.24065329, step = 39000 (41.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04175\n",
      "INFO:tensorflow:loss = 0.24877435, step = 39100 (32.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0401\n",
      "INFO:tensorflow:loss = 0.47020876, step = 39200 (32.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03498\n",
      "INFO:tensorflow:loss = 0.57260215, step = 39300 (32.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0239\n",
      "INFO:tensorflow:loss = 0.2978805, step = 39400 (33.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01057\n",
      "INFO:tensorflow:loss = 0.28558648, step = 39500 (33.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00826\n",
      "INFO:tensorflow:loss = 0.38550374, step = 39600 (33.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00429\n",
      "INFO:tensorflow:loss = 0.5736809, step = 39700 (33.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03455\n",
      "INFO:tensorflow:loss = 0.581557, step = 39800 (32.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02951\n",
      "INFO:tensorflow:loss = 0.2745548, step = 39900 (33.008 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.40378\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-26T00:33:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-26-00:34:42\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8920721, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9163627, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93788236\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: model_files_256/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40000): metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.9163627, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.8920721, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93788236\n",
      "INFO:tensorflow:loss = 0.17392845, step = 40000 (114.588 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.17392845.\n",
      "Time: 15050.87 s\n"
     ]
    }
   ],
   "source": [
    "# select the transformer model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 \n",
    "hparams.learning_rate = 0.2 # default 0.2\n",
    "hparams.num_encoder_layers = 6 # default 0\n",
    "hparams.num_decoder_layers = 6 # default 0\n",
    "hparams.max_input_seq_length = 256\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, #PROBLEM,\n",
    "        data_dir='./data', \n",
    "        train_steps=40001, \n",
    "        eval_steps=200 \n",
    "    )\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- ###########-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "import generate_problem # self-defined 'generate_problem.py' file in the same folder.\n",
    "\n",
    "# define the directory for generated data\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' # Where data files from internet stored\n",
    "DATA_LOC = './data' # Where pre-prcessed data is stored\n",
    "\n",
    "# Generated training data\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada58>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada90>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada58>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada90>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  def __init__(self, was_reversed=False, was_copy=False):\n",
    "    \"\"\"Create a Problem.\n",
    "    Args:\n",
    "      was_reversed: bool, whether to reverse inputs and targets.\n",
    "      was_copy: bool, whether to copy inputs to targets. Can be composed with\n",
    "        was_reversed so that if both are true, the targets become the inputs,\n",
    "        which are then copied to targets so that the task is targets->targets.\n",
    "    \"\"\"\n",
    "    self._was_reversed = was_reversed\n",
    "    self._was_copy = was_copy\n",
    "    self._encoders = None\n",
    "    self._hparams = None\n",
    "    self._feature_info = None\n",
    "    self._task_id = -1\n",
    "    \n",
    "    Problem\n",
    "    \n",
    "hparams = registry.hparams('transformer_base_single_gpu')\n",
    "hparams.add_hparam(\"data_dir\", DATA_LOC)\n",
    "\n",
    "t2t_problem.get_hparams().was_reversed =False\n",
    "\n",
    "hparams = t2t_problem.get_hparams(hparams)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the transformer model\n",
    "estimator = tf.estimator.Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.utils import decoding\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "\n",
    "decode_to_file = 'decoding_result'\n",
    "output_dir = './'\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "\n",
    "decode_hp = create_decode_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('activation_dtype', 'float32'), ('add_relative_to_values', False), ('attention_dropout', 0.1), ('attention_dropout_broadcast_dims', ''), ('attention_key_channels', 0), ('attention_value_channels', 0), ('attention_variables_3d', False), ('batch_shuffle_size', 512), ('batch_size', 4096), ('causal_decoder_self_attention', True), ('clip_grad_norm', 0.0), ('compress_steps', 0), ('conv_first_kernel', 3), ('daisy_chain_variables', True), ('data_dir', './data'), ('dropout', 0.2), ('eval_drop_long_sequences', False), ('eval_run_autoregressive', False), ('factored_logits', False), ('ffn_layer', 'dense_relu_dense'), ('filter_size', 2048), ('force_full_predict', False), ('grad_noise_scale', 0.0), ('heads_share_relative_embedding', False), ('hidden_size', 512), ('initializer', 'uniform_unit_scaling'), ('initializer_gain', 1.0), ('kernel_height', 3), ('kernel_width', 1), ('label_smoothing', 0.1), ('layer_postprocess_sequence', 'da'), ('layer_prepostprocess_dropout', 0.1), ('layer_prepostprocess_dropout_broadcast_dims', ''), ('layer_preprocess_sequence', 'n'), ('learning_rate', 0.2), ('learning_rate_constant', 1.0), ('learning_rate_cosine_cycle_steps', 250000), ('learning_rate_decay_rate', 1.0), ('learning_rate_decay_scheme', 'noam'), ('learning_rate_decay_staircase', False), ('learning_rate_decay_steps', 5000), ('learning_rate_minimum', None), ('learning_rate_schedule', 'legacy'), ('learning_rate_warmup_steps', 8000), ('length_bucket_step', 1.1), ('max_input_seq_length', 0), ('max_length', 0), ('max_relative_position', 0), ('max_target_seq_length', 0), ('min_length', 0), ('min_length_bucket', 8), ('mlperf_mode', False), ('modality', {}), ('moe_hidden_sizes', '2048'), ('moe_k', 2), ('moe_loss_coef', 0.001), ('moe_num_experts', 16), ('moe_overhead_eval', 2.0), ('moe_overhead_train', 1.0), ('multiply_embedding_mode', 'sqrt_depth'), ('multiproblem_fixed_train_length', -1), ('multiproblem_label_weight', 0.5), ('multiproblem_max_input_length', -1), ('multiproblem_max_target_length', -1), ('multiproblem_mixing_schedule', 'constant'), ('multiproblem_per_task_threshold', ''), ('multiproblem_reweight_label_loss', False), ('multiproblem_schedule_max_examples', 10000000.0), ('multiproblem_schedule_threshold', 0.5), ('multiproblem_target_eval_only', False), ('multiproblem_vocab_size', -1), ('nbr_decoder_problems', 1), ('no_data_parallelism', False), ('norm_epsilon', 1e-06), ('norm_type', 'layer'), ('num_decoder_layers', 0), ('num_encoder_layers', 0), ('num_heads', 8), ('num_hidden_layers', 6), ('optimizer', 'Adam'), ('optimizer_adafactor_beta1', 0.0), ('optimizer_adafactor_beta2', 0.999), ('optimizer_adafactor_clipping_threshold', 1.0), ('optimizer_adafactor_decay_type', 'pow'), ('optimizer_adafactor_factored', True), ('optimizer_adafactor_memory_exponent', 0.8), ('optimizer_adafactor_multiply_by_parameter_scale', True), ('optimizer_adam_beta1', 0.9), ('optimizer_adam_beta2', 0.98), ('optimizer_adam_epsilon', 1e-09), ('optimizer_momentum_momentum', 0.9), ('optimizer_momentum_nesterov', False), ('optimizer_multistep_accumulate_steps', None), ('optimizer_zero_grads', False), ('overload_eval_metric_name', ''), ('pad_batch', False), ('parameter_attention_key_channels', 0), ('parameter_attention_value_channels', 0), ('pos', 'timing'), ('prepend_mode', 'prepend_inputs_masked_attention'), ('pretrained_model_dir', ''), ('proximity_bias', False), ('relu_dropout', 0.1), ('relu_dropout_broadcast_dims', ''), ('sampling_method', 'argmax'), ('sampling_temp', 1.0), ('scheduled_sampling_gold_mixin_prob', 0.5), ('scheduled_sampling_prob', 0.0), ('scheduled_sampling_warmup_steps', 50000), ('self_attention_type', 'dot_product'), ('shared_embedding', False), ('shared_embedding_and_softmax_weights', True), ('split_to_length', 0), ('summarize_grads', False), ('summarize_vars', False), ('symbol_dropout', 0.0), ('symbol_modality_num_shards', 16), ('symbol_modality_skip_top', False), ('tpu_enable_host_call', False), ('unidirectional_encoder', False), ('use_fixed_batch_size', False), ('use_pad_remover', True), ('use_target_space_embedding', True), ('video_num_input_frames', 1), ('video_num_target_frames', 1), ('vocab_divisor', 1), ('warm_start_from_second', ''), ('weight_decay', 0.0), ('weight_dtype', 'float32'), ('weight_noise', 0.0)])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_master': '', 't2t_device_info': {'num_async_replicas': 1}, '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f585c98e470>, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_num_worker_replicas': 0, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_environment': 'local', '_is_chief': True, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f585c98e668>, '_protocol': None, 'use_tpu': False, '_keep_checkpoint_max': 20, '_evaluation_master': '', '_tf_random_seed': None, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_train_distribute': None, '_task_id': 0, '_model_dir': 'model_files_256', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_steps': 1000, '_task_type': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f585cea8598>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "# t2t_trainer\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n",
    "# BEAM_SIZE=4\n",
    "# ALPHA=0.6\n",
    "\n",
    "# data_dir=DATA_LOC\n",
    "# problem = t2t_problem\n",
    "# model = MODEL\n",
    "hparams_set = HPARAMS\n",
    "# output_dir = TRAIN_DIR\n",
    "\n",
    "# decode_to_file = 'decode_from_file'\n",
    "#########\n",
    "t2t_problem.get_hparams().was_reversed =False\n",
    "####\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "\n",
    "####\n",
    "# hparams = registry.hparams('transformer_base_single_gpu')\n",
    "# hparams.add_hparam(\"data_dir\", DATA_LOC)\n",
    "# t2t_problem.get_hparams().was_reversed =False\n",
    "# hparams = t2t_problem.get_hparams(hparams)\n",
    "# hparams\n",
    "######\n",
    "\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada58>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada90>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f597c0ba2e8>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f597c0ba320>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f599c039e48>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f599c039e48>}), ('was_copy', False), ('was_reversed', True)])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2t_problem.get_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_feature_encoders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-f3287950e6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_feature_encoders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_feature_encoders' is not defined"
     ]
    }
   ],
   "source": [
    "get_feature_encoders(DATA_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generate_problem.OnlineRevewProjectUSYD at 0x7f597c3e6320>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "review2 = '''\n",
    "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
    "'''\n",
    "s2 = '''\n",
    "happy with purchase even though it came a lot later than expected.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "Exception ignored in: <generator object EstimatorV2.predict at 0x7f590b83eca8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 639, in predict\n",
      "    for key, value in six.iteritems(preds_evaluated)\n",
      "  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 5253, in get_controller\n",
      "    yield g\n",
      "  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 5069, in get_controller\n",
      "    type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_files_1024/model.ckpt-40001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"i read the did not get the item i ordered.  when the company they got back with back with me.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\"\tScore:-6.397717\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\"i read the did not get the item i ordered.  when the company they got back with back with me.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just tis.\"\tScore:-6.398138\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">q\n"
     ]
    }
   ],
   "source": [
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2t-decoder \\\n",
    "#   --data_dir=$DATA_DIR \\\n",
    "#   --problem=$PROBLEM \\\n",
    "#   --model=$MODEL \\\n",
    "#   --hparams_set=$HPARAMS \\\n",
    "#   --output_dir=$TRAIN_DIR \\\n",
    "#   --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "#   --decode_from_file=$DECODE_FILE \\\n",
    "#   --decode_to_file=translation.en\n",
    "\n",
    "\n",
    "\n",
    "# hp = trainer_lib.create_hparams(\n",
    "#       HPARAMS,\n",
    "# #       FLAGS.hparams,\n",
    "#       data_dir=DATA_LOC,\n",
    "#       problem_name=t2t_problem)\n",
    "\n",
    "# # decode_hp = create_decode_hparams()\n",
    "# decode_hp = decoding.decode_hparams()\n",
    "# # decode_hp.shards = FLAGS.decode_shards\n",
    "# # decode_hp.shard_id = FLAGS.worker_id\n",
    "# # decode_in_memory = FLAGS.decode_in_memory or decode_hp.decode_in_memory\n",
    "# # decode_hp.decode_in_memory = decode_in_memory\n",
    "# decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "# decode_hp.decode_reference = FLAGS.decode_reference\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnrecognizedFlagError",
     "evalue": "Unknown command line flag 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-71143df28b6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                      \u001b[0mdecode_hp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                      \u001b[0mdecode_to_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                      checkpoint_path=None)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_from_file\u001b[0;34m(estimator, filename, hparams, decode_hp, decode_to_file, checkpoint_path)\u001b[0m\n\u001b[1;32m    373\u001b[0m   \u001b[0minputs_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_vocab_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[0mtargets_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m   \u001b[0mproblem_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_shard_to_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing decoding from file (%s).\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# a flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[0;32m--> 633\u001b[0;31m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensor2tensor.utils import decoding\n",
    "\n",
    "filename = 'online_revew_project_usyd-dev-00000-of-00001'\n",
    "problem = t2t_problem\n",
    "decoding.decode_from_file(estimator,\n",
    "                     filename,\n",
    "                     hparams,\n",
    "                     decode_hp,\n",
    "                     decode_to_file=None,\n",
    "                     checkpoint_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Performing local inference from dataset for <generate_problem.OnlineRevewProjectUSYD object at 0x7f5a402405f8>.\n",
      "INFO:tensorflow:Decoding 0\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "WARNING:tensorflow:Padding the batch to ensure that remainder eval batches have a batch size divisible by the number of data shards. This may lead to incorrect metrics for non-zero-padded features, e.g. images. Use a single datashard (i.e. 1 GPU) in that case.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_files_1024/model.ckpt-40001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'OnlineRevewProjectUSYD' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-4aa67724c8de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdecode_hp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     checkpoint_path=ckpt_path)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#     decode_to_file=decode_to_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     dataset_split=\"test\" ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_from_dataset\u001b[0;34m(estimator, problem_name, hparams, decode_hp, decode_to_file, dataset_split, checkpoint_path)\u001b[0m\n\u001b[1;32m    217\u001b[0m                          \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                          \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_in_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                          checkpoint_path=checkpoint_path)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_in_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_once\u001b[0;34m(estimator, problem_name, hparams, infer_input_fn, decode_hp, decode_to_file, output_dir, log_results, checkpoint_path)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0midentity_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             log_results=decode_hp.log_results)\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mdecoded_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_beam_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mlog_decode_results\u001b[0;34m(inputs, outputs, problem_name, prediction_idx, inputs_vocab, targets_vocab, targets, save_images, output_dir, identity_output, log_results)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;31m# TODO(lukaszkaiser) refactor this into feature_encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m   \u001b[0mis_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"video\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblem_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"gym\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblem_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_video\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfix_and_save_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'OnlineRevewProjectUSYD' is not iterable"
     ]
    }
   ],
   "source": [
    "model = MODEL\n",
    "# import tensor2\n",
    "\n",
    "from tensor2tensor.utils.decoding import decode_from_dataset\n",
    "\n",
    "decode(estimator, hparams, decode_hp)\n",
    "\n",
    "decoding.decode_from_dataset(\n",
    "    estimator,\n",
    "    FLAGS.problem,\n",
    "    hparams,\n",
    "    decode_hp,\n",
    "    decode_to_file=FLAGS.decode_to_file,\n",
    "    dataset_split=\"test\" if FLAGS.eval_use_test_set else None,\n",
    "    checkpoint_path=FLAGS.checkpoint_path)\n",
    "\n",
    "decode_from_dataset(\n",
    "    estimator,\n",
    "    t2t_problem,\n",
    "    hparams,\n",
    "    decode_hp,\n",
    "    checkpoint_path=ckpt_path)\n",
    "#     decode_to_file=decode_to_file)\n",
    "#     dataset_split=\"test\" ,\n",
    "\n",
    "#     checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagValues at 0x7f59b732d5f8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnrecognizedFlagError",
     "evalue": "Unknown command line flag 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-422702070fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdecode_hp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_decode_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-422702070fe3>\u001b[0m in \u001b[0;36mcreate_decode_hparams\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_decode_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdecode_hp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdecode_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_shards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdecode_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshard_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdecode_in_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_in_memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# a flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[0;32m--> 633\u001b[0;31m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "flags = tf.flags\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# decode_hp.shards = \n",
    "# decode_hp.decode_in_memory = True\n",
    "\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = tf.flags.FLAGS.decode_shards\n",
    "    decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "\n",
    "decode_hp = create_decode_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infer'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.estimator.ModeKeys.PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/modalities.py:114: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py:621: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:1037: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "inputs = review2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "model_decoder = registry.model(MODEL)(hparams, Modes.EVAL)\n",
    "\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "encoded_inputs = encode(inputs)\n",
    "with tfe.restore_variables_on_create(ckpt_path):\n",
    "    model_output = model_decoder.infer(encoded_inputs)[\"outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "  \"shard\": decode_hp.shards,\n",
    "  \"dataset_split\": None,\n",
    "  \"max_records\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decoder = registry.model(MODEL)(hparams, Modes.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_input_fn = t2t_problem.make_estimator_input_fn(\n",
    "    tf.estimator.ModeKeys.PREDICT, hparams, dataset_kwargs=dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_input_fn = t2t_problem.make_estimator_input_fn(\n",
    "    Modes.PREDICT, hparams, dataset_kwargs=dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'input_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e77265129b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 checkpoint_path=ckpt_path)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_once\u001b[0;34m(estimator, problem_name, hparams, infer_input_fn, decode_hp, decode_to_file, output_dir, log_results, checkpoint_path)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;31m# Get the predictions as an iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   predictions = estimator.predict(infer_input_fn,\n\u001b[0;32m--> 253\u001b[0;31m                                   checkpoint_path=checkpoint_path)\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'input_fn'"
     ]
    }
   ],
   "source": [
    "# infer_input_fn = model_output\n",
    "\n",
    "decoding.decode_once(estimator,\n",
    "                t2t_problem,\n",
    "                hparams,\n",
    "                infer_input_fn,\n",
    "                decode_hp,\n",
    "                decode_to_file,\n",
    "                output_dir,\n",
    "                log_results=True,\n",
    "                checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  Args:\n",
    "    estimator: tf.estimator.Estimator instance. Used to generate encoded\n",
    "      predictions.\n",
    "    problem_name: str. Name of problem.\n",
    "    hparams: HParams instance. HParams for model training.\n",
    "    infer_input_fn: zero-arg function. Input function for estimator.\n",
    "    decode_hp: HParams instance. See decode_hparams() above.\n",
    "    decode_to_file: str. Prefix for filenames. Used to generated filenames to\n",
    "      which decoded predictions are written.\n",
    "    output_dir: str. Output directory. Only used for writing images.\n",
    "    log_results: bool. If False, return encoded predictions without any\n",
    "      further processing.\n",
    "    checkpoint_path: str. Path to load model checkpoint from. If unspecified,\n",
    "      Estimator's default is used.\n",
    "  Returns:\n",
    "    If decode_hp.decode_in_memory is True:\n",
    "      List of dicts, one per example. Values are either numpy arrays or decoded\n",
    "      strings.\n",
    "    If decode_hp.decode_in_memory is False:\n",
    "      An empty list.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fdd24ae2080>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_task_type': None, '_train_distribute': None, '_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", 't2t_device_info': {'num_async_replicas': 1}, '_device_fn': None, '_evaluation_master': '', '_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdd24ae20b8>, '_protocol': None, '_environment': 'local', '_model_dir': 'model_files_256', '_num_worker_replicas': 0, 'use_tpu': False, '_tf_random_seed': None, '_save_checkpoints_steps': 1000, '_task_id': 0, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fdd25abe840>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64797184\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40001\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-28T14:02:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-28-14:03:25\n",
      "INFO:tensorflow:Saving dict for global step 40001: global_step = 40001, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89221823, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91662514, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93793267\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40001: model_files_256/model.ckpt-40001\n",
      "INFO:tensorflow:Validation (step 40002): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, global_step = 40001, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89221823, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91662514, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93793267\n",
      "INFO:tensorflow:loss = 0.39651114, step = 40001\n",
      "INFO:tensorflow:global_step/sec: 0.873113\n",
      "INFO:tensorflow:loss = 0.42706436, step = 40101 (38.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01556\n",
      "INFO:tensorflow:loss = 0.28093913, step = 40201 (33.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00659\n",
      "INFO:tensorflow:loss = 0.5703713, step = 40301 (33.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00643\n",
      "INFO:tensorflow:loss = 0.524451, step = 40401 (33.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07053\n",
      "INFO:tensorflow:loss = 0.32810357, step = 40501 (32.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03513\n",
      "INFO:tensorflow:loss = 0.55903786, step = 40601 (32.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03153\n",
      "INFO:tensorflow:loss = 0.14611869, step = 40701 (32.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02187\n",
      "INFO:tensorflow:loss = 0.41055575, step = 40801 (33.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04566\n",
      "INFO:tensorflow:loss = 0.38706577, step = 40901 (32.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into model_files_256/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 2.3757\n",
      "INFO:tensorflow:loss = 0.26943615, step = 41001 (42.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00123\n",
      "INFO:tensorflow:loss = 0.42616627, step = 41101 (33.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00059\n",
      "INFO:tensorflow:loss = 0.36144212, step = 41201 (33.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02449\n",
      "INFO:tensorflow:loss = 0.40964493, step = 41301 (33.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02828\n",
      "INFO:tensorflow:loss = 0.28787893, step = 41401 (33.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03015\n",
      "INFO:tensorflow:loss = 0.24273534, step = 41501 (33.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02748\n",
      "INFO:tensorflow:loss = 0.2890115, step = 41601 (33.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.023\n",
      "INFO:tensorflow:loss = 0.60741675, step = 41701 (33.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03995\n",
      "INFO:tensorflow:loss = 0.7905096, step = 41801 (32.894 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b6844955f7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mt2t_model_256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# running time check (running on 1GPU server)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_eval_and_decode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m           hooks=self._train_spec.hooks)\n\u001b[0m\u001b[1;32m    473\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_eval_dir_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m       self._estimator.evaluate(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# select the transformer model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 \n",
    "hparams.learning_rate = 0.2 # default 0.2\n",
    "hparams.num_encoder_layers = 6 # default 0\n",
    "hparams.num_decoder_layers = 6 # default 0\n",
    "hparams.max_input_seq_length = 256\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, #PROBLEM,\n",
    "        data_dir='./data', \n",
    "        train_steps=40001, \n",
    "        eval_steps=200 \n",
    "    )\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_eval_and_decode()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensor2tensor.bin import t2t_decoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS \\\n",
    "  --output_dir=$TRAIN_DIR \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --decode_from_file=$DECODE_FILE \\\n",
    "  --decode_to_file=translation.en\n",
    "\n",
    "def main(argv):\n",
    "    t2t_decoder.main(argv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import generate_problem\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' \n",
    "DATA_LOC = './data' \n",
    "\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) \n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_2014'\n",
    "\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registry.model(MODEL)(hparams, Modes.PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_files_1024/model.ckpt-40001'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWS: \n",
      "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
      "\n",
      "PRED_SUMMARY: read 10; i the the did not get the item i ordered.  when its company they got back with me me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase the has 10;\n",
      "GOLD_SUMMARY: \n",
      "happy with purchase even though it came a lot later than expected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review1 = '''\n",
    "we have many of the old , old issue but the number had depleted there were not enough books to allow us to use them regularly with the additional supply the books will be used more often they are a good old standby for gospel singing\n",
    "'''\n",
    "review2 = '''\n",
    "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
    "'''\n",
    "s2 = '''\n",
    "happy with purchase even though it came a lot later than expected.\n",
    "'''\n",
    "\n",
    "summary = summarize(review2)\n",
    "\n",
    "print(\"REVIEWS: %s\" % review2)\n",
    "print(\"PRED_SUMMARY: %s\" % summary)\n",
    "print(\"GOLD_SUMMARY: %s\" % s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
