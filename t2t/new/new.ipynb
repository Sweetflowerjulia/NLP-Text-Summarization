{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_v3 Max length variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable TF Eager execution ==> for decoder later\n",
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh-tensorflow==0.0.5\n",
      "tensor2tensor==1.12.0\n",
      "tensorboard==1.12.2\n",
      "tensorflow-estimator==1.13.0rc0\n",
      "tensorflow-gpu==1.13.0rc1\n",
      "tensorflow-metadata==0.9.0\n",
      "tensorflow-probability==0.5.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Importing user module train from path /tf/jupyter-code/code/t2t/new\n",
      "INFO:tensorflow:Generating problems:\n",
      "    onlinereview:\n",
      "      * onlinereview\n",
      "INFO:tensorflow:Generating data for onlinereview.\n",
      "INFO:tensorflow:Generating vocab file: ./data/vocab.onlinereview.8192.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 100\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 81\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 83\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 83\n",
      "INFO:tensorflow:Trying min_count 250\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 163\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 120\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 122\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 122\n",
      "INFO:tensorflow:Trying min_count 125\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 271\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 183\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 189\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 189\n",
      "INFO:tensorflow:Trying min_count 62\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 456\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 287\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 299\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 295\n",
      "INFO:tensorflow:Trying min_count 31\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 793\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 442\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 458\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 455\n",
      "INFO:tensorflow:Trying min_count 15\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 1465\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 735\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 768\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 766\n",
      "INFO:tensorflow:Trying min_count 7\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 2801\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 1235\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 1316\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 1294\n",
      "INFO:tensorflow:Trying min_count 3\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 5519\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 2209\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 2304\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 2284\n",
      "INFO:tensorflow:Trying min_count 1\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 12071\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 3692\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 3692\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 3692\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generated 99 Examples\n",
      "INFO:tensorflow:Found vocab file: ./data/vocab.onlinereview.8192.subwords\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generated 99 Examples\n",
      "INFO:tensorflow:Found vocab file: ./data/vocab.onlinereview.8192.subwords\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generated 99 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:467: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=./data\n",
    "TMP_DIR=$DATA_DIR/tmp\n",
    "rm -rf $DATA_DIR $TMP_DIR\n",
    "mkdir -p $DATA_DIR $TMP_DIR\n",
    "# Generate data\n",
    "t2t-datagen \\\n",
    "  --t2t_usr_dir=./train \\\n",
    "  --problem=\"onlinereview\" \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --tmp_dir=$TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Importing user module train from path /tf/jupyter-code/code/t2t/new\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_train_distribute': None, '_save_checkpoints_secs': None, 'use_tpu': False, '_task_id': 0, '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fcbfc3d15f8>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_device_fn': None, '_master': '', '_tf_random_seed': None, '_model_dir': './trained_model', '_is_chief': True, '_evaluation_master': '', '_task_type': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, '_protocol': None, 't2t_device_info': {'num_async_replicas': 1}, '_num_worker_replicas': 0, '_num_ps_replicas': 0, '_eval_distribute': None, '_save_checkpoints_steps': 1000, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbfc3d1630>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fcbfc408510>) includes params argument, but params are not passed to Estimator.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "INFO:tensorflow:Trainable Variables Total size: 1399808\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:19.673212: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-06-02 10:36:21.376349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-02 10:36:21.376871: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x80e2e30 executing computations on platform CUDA. Devices:\n",
      "2019-06-02 10:36:21.376886: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5\n",
      "2019-06-02 10:36:21.378531: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3407980000 Hz\n",
      "2019-06-02 10:36:21.378922: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x83ce4e0 executing computations on platform Host. Devices:\n",
      "2019-06-02 10:36:21.378965: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-02 10:36:21.379444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-06-02 10:36:21.379473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:21.380085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:21.380095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:21.380113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:21.380283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "2019-06-02 10:36:28.771530: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "2019-06-02 10:36:39.015856: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:101] Filling up shuffle buffer (this may take a while): 295 of 512\n",
      "2019-06-02 10:36:41.610738: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:140] Shuffle buffer filled.\n",
      "INFO:tensorflow:loss = 7.4019403, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./trained_model/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T10:36:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:50.269893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:50.269940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:50.269958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:50.269961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:50.270065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-10:36:52\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 8.828742, metrics-onlinereview/targets/accuracy = 0.00069252076, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.00069252076, metrics-onlinereview/targets/approx_bleu_score = 0.778015, metrics-onlinereview/targets/neg_log_perplexity = -8.803953, metrics-onlinereview/targets/rouge_2_fscore = 0.84111744, metrics-onlinereview/targets/rouge_L_fscore = 0.8062627\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Loss for final step: 7.4723377.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T10:36:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:57.293478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:57.293510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:57.293515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:57.293518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:57.293611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-10:36:59\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 8.828742, metrics-onlinereview/targets/accuracy = 0.00069252076, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.00069252076, metrics-onlinereview/targets/approx_bleu_score = 0.778015, metrics-onlinereview/targets/neg_log_perplexity = -8.803953, metrics-onlinereview/targets/rouge_2_fscore = 0.84111744, metrics-onlinereview/targets/rouge_L_fscore = 0.8062627\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=./data\n",
    "OUTDIR=./trained_model\n",
    "rm -rf $OUTDIR\n",
    "t2t-trainer \\\n",
    "  --data_dir=./data \\\n",
    "  --t2t_usr_dir=./train \\\n",
    "  --problem=\"onlinereview\" \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=onlinereviewhp \\\n",
    "  --output_dir=$OUTDIR --job-dir=$OUTDIR --train_steps=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate t2t data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When generate the t2t dataset by running \"generate_problem.py\", \n",
    "#### reviews that the summary contains exactly same sentences with review text are dropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generating vocab file: ./data/vocab.online_revew_project_usyd_new.32768.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13096165657043457 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.262683629989624 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.5365941524505615 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0528688430786133 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 153103\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [forhime] took 0.13114404678344727 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5544769763946533 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [moresturdy] took 0.26235508918762207 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 57272\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [nanshinken] took 0.130964994430542 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.509838342666626 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [experiencesinstaloveanddevoteshimselftoonlyonewoman] took 0.2627594470977783 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58117\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [readscoopandvile] took 0.13106560707092285 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5076935291290283 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [ehheheheheeheehehehehehehehehehehhehehhehehehehhehehehehehehhehhehehhehehehehehheehheefreaking] took 0.2635314464569092 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58059\n",
      "INFO:tensorflow:Trying min_count 750\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13042259216308594 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.26241588592529297 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.5345878601074219 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0517544746398926 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 122366\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [templatedparticularly] took 0.13077068328857422 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5704975128173828 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [sounddecline] took 0.2618880271911621 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 45993\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [undisciplinedunruly] took 0.13058161735534668 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5032720565795898 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [bradley11birds] took 0.26251220703125 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [shs320037pros] took 0.5232503414154053 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 46746\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [digimaticaly] took 0.13071823120117188 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.520693302154541 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [ddfgfddfggddfgghgcfggfdfggff] took 0.2618527412414551 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [spareseness] took 0.5250499248504639 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 46687\n",
      "INFO:tensorflow:Trying min_count 875\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13061189651489258 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.26169490814208984 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.4994032382965088 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0540430545806885 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 112348\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [halfbushing] took 0.13145899772644043 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5801115036010742 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [beybzuc2lt8lc] took 0.2635982036590576 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 42333\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [movieworld] took 0.13189268112182617 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5246036052703857 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [turnonandgo] took 0.2635776996612549 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [liebardaugustepeloqueastolphe] took 0.5279412269592285 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 43036\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [keulen] took 0.1323080062866211 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5328922271728516 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [11301500w] took 0.2642219066619873 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [32pppoepppoausername] took 0.5279502868652344 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 42970\n",
      "INFO:tensorflow:Trying min_count 938\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.1313321590423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.2639150619506836 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.491786003112793 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0576083660125732 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 108170\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [musiczeit] took 0.13116717338562012 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5837140083312988 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [elrohirelrohir] took 0.26538515090942383 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40825\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [twolipsreviews] took 0.13132810592651367 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5133266448974609 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [targetedbackstabbedsmeared] took 0.2624800205230713 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [songdayo] took 0.5245606899261475 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41496\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [citizenshippatriotismamerican] took 0.13188433647155762 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.538510799407959 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [someonebroughtintoasecretorganization] took 0.26300930976867676 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [19191945by] took 0.5243678092956543 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41430\n",
      "INFO:tensorflow:Trying min_count 969\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13167476654052734 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.26200222969055176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.4862771034240723 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.053755283355713 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 106207\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [constructioninsulationretrolook] took 0.13123321533203125 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5830802917480469 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [horsekt] took 0.26233530044555664 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40130\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [interviewsquot] took 0.13172578811645508 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5173683166503906 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [disappeardissipates] took 0.2623467445373535 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [telemagic] took 0.5250561237335205 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40759\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [archducal] took 0.13110756874084473 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5457546710968018 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [2440securities15] took 0.2627842426300049 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [b001qhy3ue] took 0.5255756378173828 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40706\n",
      "INFO:tensorflow:Trying min_count 985\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13041949272155762 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.2621653079986572 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.4822330474853516 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0570111274719238 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 105224\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [mhzinstructions] took 0.13074922561645508 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5815105438232422 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [cleanerlunbricatingprotectant] took 0.2699253559112549 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39795\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [dillamonds] took 0.13131046295166016 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5143399238586426 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [perspectiveparablelife] took 0.2621169090270996 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [pgopinathanhotmail] took 0.5229637622833252 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40406\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [livesgemspoints] took 0.13108110427856445 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.539125919342041 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [tunnelsslidesrooms] took 0.26174378395080566 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [modecurrent] took 0.524529218673706 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40336\n",
      "INFO:tensorflow:Trying min_count 993\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13074231147766113 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.2618987560272217 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.4773645401000977 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0509345531463623 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104719\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [4392128fb] took 0.13180780410766602 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.577782392501831 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [tetrapolitan] took 0.2641773223876953 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39626\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [armanibrionivalentino] took 0.1314222812652588 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5091984272003174 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [socialorganizationalfraternity] took 0.2622244358062744 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [rumorssongwriting] took 0.5240206718444824 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40244\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [impressionsoutlander] took 0.13090252876281738 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5388805866241455 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [cr2025dl2025] took 0.2619457244873047 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [weekdayafternoon] took 0.5246379375457764 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40181\n",
      "INFO:tensorflow:Trying min_count 997\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13068580627441406 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.2616739273071289 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.477855920791626 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0511925220489502 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104510\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [comingellis] took 0.13119220733642578 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5813801288604736 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [mebibyte34] took 0.26265597343444824 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39531\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [publicationthan] took 0.1308901309967041 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5108349323272705 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [diminutivesized] took 0.26214146614074707 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [caravka] took 0.5244147777557373 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40183\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [onceaweekdeepcleans] took 0.13616609573364258 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5371131896972656 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [comepsont252520durabritestandardcapacitycartridgedpb00kdiu3fgrefpd] took 0.26296544075012207 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [alternativescharacteristics] took 0.5247085094451904 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40104\n",
      "INFO:tensorflow:Trying min_count 999\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.1310443878173828 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.26253366470336914 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.4800903797149658 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.051666021347046 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104395\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [marxistrelativism] took 0.13106727600097656 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5834581851959229 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [commontypical] took 0.2624821662902832 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39489\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [ultravoxlike] took 0.131638765335083 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5103533267974854 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [dependably] took 0.2628037929534912 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [psc14250] took 0.5239300727844238 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40135\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [gargatuan] took 0.13063621520996094 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5386972427368164 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [combtlrcrkstriplulaldrar15dpb0045r9fimrefsr] took 0.26276588439941406 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [yardbrowniesboggartschangelingspixiessalamandersstray] took 0.5237026214599609 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40073\n",
      "INFO:tensorflow:Trying min_count 1000\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [192mbsecread100mbsecwrite] took 0.13069963455200195 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [davidsonrating] took 0.26273036003112793 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.4811556339263916 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [converastion] took 1.0505695343017578 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104338\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [religionpartucularism] took 0.13107848167419434 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5845775604248047 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [crosbystillsnashetc] took 0.2626457214355469 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39462\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [grittybutintelligent] took 0.13153648376464844 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5114729404449463 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [davisongales] took 0.26232028007507324 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [funkycute] took 0.5249416828155518 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40121\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [proboseidecarlo] took 0.13114213943481445 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5421013832092285 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing token [comepsont252520durabritestandardcapacitycartridgedpb00kdiu3fgrefpd] took 0.2626829147338867 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [designcutoutanything] took 0.5238473415374756 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40055\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-58858cc4ad22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Generated training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mt2t_problem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_problem_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOnlineRevewProjectUSYD_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROBLEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mt2t_problem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_LOC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTMP_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/text_problems.py\u001b[0m in \u001b[0;36mgenerate_data\u001b[0;34m(self, data_dir, tmp_dir, task_id)\u001b[0m\n\u001b[1;32m    333\u001b[0m       generator_utils.generate_files(\n\u001b[1;32m    334\u001b[0m           self.generate_encoded_samples(\n\u001b[0;32m--> 335\u001b[0;31m               data_dir, tmp_dir, problem.DatasetSplit.TRAIN), all_paths)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mgenerator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py\u001b[0m in \u001b[0;36mgenerate_files\u001b[0;34m(generator, output_filenames, max_cases, cycle_every_n)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mwriters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/text_problems.py\u001b[0m in \u001b[0;36mtext2text_generate_encoded\u001b[0;34m(sample_generator, vocab, targets_vocab, has_inputs)\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m       \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEOS_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m     \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m     \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEOS_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/text_encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \"\"\"\n\u001b[1;32m    502\u001b[0m     return self._tokens_to_subtoken_ids(\n\u001b[0;32m--> 503\u001b[0;31m         tokenizer.encode(native_to_unicode(s)))\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode_without_tokenizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/tokenizer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_alnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mis_alnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mu\" \"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken_start\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0mtoken_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # self-defined 'generate_problem.py' file in the same folder.\n",
    "# define the directory for generated data\n",
    "# import tensorflow as tf\n",
    "# from tensor2tensor.utils import registry\n",
    "# from tensor2tensor.models import transformer\n",
    "# from tensor2tensor.data_generators import problem\n",
    "# from tensor2tensor.data_generators import text_encoder\n",
    "# from tensor2tensor.data_generators import text_problems\n",
    "# from tensor2tensor.data_generators import generator_utils\n",
    "\n",
    "# from tensor2tensor.data_generators import problem\n",
    "# from tensor2tensor.data_generators import text_problems\n",
    "# import generate_problem_new\n",
    "\n",
    "from tensor2tensor.bin import t2t_datagen\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    t2t_datagen.main(argv)\n",
    "\n",
    "def main(_):\n",
    "  usr_dir.import_usr_dir(FLAGS.t2t_usr_dir)\n",
    "\n",
    "  # Calculate the list of problems to generate.\n",
    "  problems = sorted(\n",
    "      list(_SUPPORTED_PROBLEM_GENERATORS) + registry.list_base_problems() +\n",
    "      registry.list_env_problems())\n",
    "  for exclude in FLAGS.exclude_problems.split(\",\"):\n",
    "    if exclude:\n",
    "      problems = [p for p in problems if exclude not in p]\n",
    "  if FLAGS.problem and FLAGS.problem[-1] == \"*\":\n",
    "    problems = [p for p in problems if p.startswith(FLAGS.problem[:-1])]\n",
    "  elif FLAGS.problem and \",\" in FLAGS.problem:\n",
    "    problems = [p for p in problems if p in FLAGS.problem.split(\",\")]\n",
    "  elif FLAGS.problem:\n",
    "    problems = [p for p in problems if p == FLAGS.problem]\n",
    "  else:\n",
    "    problems = []\n",
    "\n",
    "  # Remove TIMIT if paths are not given.\n",
    "  if getattr(FLAGS, \"timit_paths\", None):\n",
    "    problems = [p for p in problems if \"timit\" not in p]\n",
    "  # Remove parsing if paths are not given.\n",
    "  if getattr(FLAGS, \"parsing_path\", None):\n",
    "    problems = [p for p in problems if \"parsing_english_ptb\" not in p]\n",
    "\n",
    "  if not problems:\n",
    "    problems_str = \"\\n  * \".join(\n",
    "        sorted(\n",
    "            list(_SUPPORTED_PROBLEM_GENERATORS) +\n",
    "            registry.list_base_problems() + registry.list_env_problems()))\n",
    "    error_msg = (\"You must specify one of the supported problems to \"\n",
    "                 \"generate data for:\\n  * \" + problems_str + \"\\n\")\n",
    "    error_msg += (\"TIMIT and parsing need data_sets specified with \"\n",
    "                  \"--timit_paths and --parsing_path.\")\n",
    "    raise ValueError(error_msg)\n",
    "\n",
    "  if not FLAGS.data_dir:\n",
    "    FLAGS.data_dir = tempfile.gettempdir()\n",
    "    tf.logging.warning(\n",
    "        \"It is strongly recommended to specify --data_dir. \"\n",
    "        \"Data will be written to default data_dir=%s.\", FLAGS.data_dir)\n",
    "  FLAGS.data_dir = os.path.expanduser(FLAGS.data_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.data_dir)\n",
    "\n",
    "  tf.logging.info(\"Generating problems:\\n%s\" %\n",
    "                  registry.display_list_by_prefix(problems, starting_spaces=4))\n",
    "  if FLAGS.only_list:\n",
    "    return\n",
    "  for problem in problems:\n",
    "    set_random_seed()\n",
    "\n",
    "    if problem in _SUPPORTED_PROBLEM_GENERATORS:\n",
    "      generate_data_for_problem(problem)\n",
    "    elif problem in registry.list_base_problems():\n",
    "      generate_data_for_registered_problem(problem)\n",
    "    elif problem in registry.list_env_problems():\n",
    "      generate_data_for_env_problem(problem)\n",
    "    else:\n",
    "      tf.logging.error(\"Problem %s is not a supported problem for datagen.\",\n",
    "                       problem)\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run()\n",
    "    \n",
    "\n",
    "USR_DIR= './train'\n",
    "PROBLEM = 'onlinereview'\n",
    "TMP_DIR = './tmp' \n",
    "DATA_LOC = './data' \n",
    "\n",
    "# Generated training data\n",
    "t2t_problem = generate_problem_new.OnlineRevewProjectUSYD_new(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from train import problem\n",
    "ende_problem = problem.onlinereview('onlinereview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'problems' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2fec35d1af9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mende_problem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'onlinereview'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mende_problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'problems' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ende_problem = problems.problem('onlinereview')\n",
    "# ende_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'problem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-526ab3a89ffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'problem' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USR_DIR= './train'\n",
    "# PROBLEM = 'onlinereview'\n",
    "# TMP_DIR = './tmp' \n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import problems\n",
    "\n",
    "DATA_LOC = './data' \n",
    "ende_problem = problems.problem('onlinereview')\n",
    "vocab_name = \"./train/vocab.onlinereview.8192.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = ende_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    print(\"inputs\",inputs)\n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "        print(\"integers\", integers)\n",
    "        print(\"targets\", encoders[\"targets\"])\n",
    "    return encoders[\"targets\"].decode(np.squeeze(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    }
   ],
   "source": [
    "# Create hparams and the model\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=ende_problem)\n",
    "hparams.problem_hparams.was_reversed =False\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [3669, 3686, 3687, 128, 2, 3667, 3650, 3665, 3660, 3663, 1559, 495, 149, 2844, 5, 1796, 3652, 3650, 3653, 3648, 3667, 3661, 3653, 3654, 3659, 3649, 3648, 3668, 3647, 3654, 3664, 3663, 3650, 950, 50, 3653, 3664, 3643, 3649, 3649, 3663, 3643, 3668, 12, 63, 3660, 3663, 57, 3665, 3653, 3654, 3662, 3650, 3653, 3654, 3648, 1018, 187, 3652, 3660, 3643, 3649, 3659, 3665, 3520, 4, 2330, 3665, 3660, 3667, 3656, 3656, 3663, 3654, 3661, 3663, 1018, 4, 115, 63, 3660, 3663, 57, 3663, 3655, 3663, 3650, 3661, 3663, 1018, 22, 5, 3650, 3663, 3654, 3663, 3645, 2973, 683, 3, 3648, 3650, 3667, 3654, 3649, 3662, 3653, 3650, 3655, 2973, 43, 2, 3665, 3650, 3647, 3665, 3659, 3666, 3656, 1281, 6, 3665, 3653, 3654, 3662, 3650, 3653, 3654, 3648, 3667, 3648, 3659, 3653, 3654, 1018, 22, 3667, 3664, 3646, 3663, 3650, 3649, 3667, 3650, 3659, 3663, 1018, 3, 187, 147, 4, 2615, 42, 427, 2714, 1272, 409, 18, 325, 8, 50, 3663, 3655, 3659, 3654, 3663, 3654, 3648, 3656, 3643, 3668, 495, 162, 3, 528, 12, 2, 3664, 3663, 3652, 3648, 3660, 1018, 6, 2, 1295, 4, 3662, 3663, 3667, 3648, 3647, 3650, 3659, 3654, 1224, 5, 3666, 3650, 3653, 3657, 3663, 3654, 3660, 3663, 3667, 3650, 1661, 135, 104, 895, 3647, 3654, 3652, 3656, 3667, 3654, 3654, 2973, 3663, 3644, 3659, 3649, 3648, 3663, 3654, 3648, 3659, 3520, 3656, 3663, 3667, 1098, 6, 471, 3665, 3667, 3648, 3667, 3652, 3647, 3656, 3648, 1018, 124, 111, 5, 3665, 3660, 3667, 3653, 3648, 3659, 621, 4, 1531, 108, 6, 64, 3669, 3686, 3687, 128, 1]\n",
      "Inputs: \n",
      "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "\n",
      "Outputs: between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "# inputs = '''\n",
    "# happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# ende_problem.generate_data(data_dir, tmp_dir)\n",
    "example = tfe.Iterator(ende_problem.dataset(Modes.TRAIN, DATA_LOC)).next()\n",
    "inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
    "targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs, encoded:\n",
      "[275, 3524, 3243, 8, 50, 386, 407, 6, 362, 165, 3, 32, 49, 7, 1291, 109, 1444, 2, 1318, 6, 2, 294, 687, 57, 23, 5, 199, 6, 10, 2, 145, 25, 85, 622, 12, 2995, 4, 3066, 3, 63, 67, 24, 50, 3531, 3528, 29, 76, 2927, 6, 2, 47, 10, 44, 164, 3, 2, 145, 25, 967, 4, 5, 151, 130, 2093, 3, 63, 155, 44, 40, 531, 1050, 14, 730, 3, 2, 3617, 165, 25, 106, 183, 7, 28, 4, 2135, 10, 1228, 6, 109, 2846, 2665, 2139, 3, 306, 680, 2343, 2398, 3, 194, 24, 2, 1674, 2694, 2064, 3, 194, 1835, 1083, 3161, 363, 10, 1094, 2072, 3, 32, 1515, 2, 2569, 6, 935, 4, 1567, 4, 5, 171, 32, 478, 2, 3065, 6, 2, 66, 2576, 2903, 10, 179, 4, 793, 7, 2, 198, 3, 210, 6, 2, 165, 12, 15, 610, 8, 50, 386, 1876, 18, 77, 44, 259, 125, 2, 2454, 224, 71, 14, 1]\n",
      "Inputs, decoded:\n",
      "integers [275, 3524, 3243, 8, 50, 386, 407, 6, 362, 165, 3, 32, 49, 7, 1291, 109, 1444, 2, 1318, 6, 2, 294, 687, 57, 23, 5, 199, 6, 10, 2, 145, 25, 85, 622, 12, 2995, 4, 3066, 3, 63, 67, 24, 50, 3531, 3528, 29, 76, 2927, 6, 2, 47, 10, 44, 164, 3, 2, 145, 25, 967, 4, 5, 151, 130, 2093, 3, 63, 155, 44, 40, 531, 1050, 14, 730, 3, 2, 3617, 165, 25, 106, 183, 7, 28, 4, 2135, 10, 1228, 6, 109, 2846, 2665, 2139, 3, 306, 680, 2343, 2398, 3, 194, 24, 2, 1674, 2694, 2064, 3, 194, 1835, 1083, 3161, 363, 10, 1094, 2072, 3, 32, 1515, 2, 2569, 6, 935, 4, 1567, 4, 5, 171, 32, 478, 2, 3065, 6, 2, 66, 2576, 2903, 10, 179, 4, 793, 7, 2, 198, 3, 210, 6, 2, 165, 12, 15, 610, 8, 50, 386, 1876, 18, 77, 44, 259, 125, 2, 2454, 224, 71, 14]\n",
      "targets <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f655c1cc978>\n",
      "while agatha christie is an excellent writer of mystery stories, one has to digest them within the context of the english society she was a part of. the characters are very british in dress and demeanor, which can have an adverse affect on your enjoyment of the story. at times, the characters are stiff and a little too proper, which does at time seem quaint.nevertheless, the 13 stories are still fun to read and ponder. four of them feature hercule poirot, three star miss marple, two have the talents harley quin, two showcase personal consultant mr. parker pyne, one utilizes the intellect of tommy and tuppence and a last one describes the demise of the great inspector evans. short and generally to the point, each of the stories in this collection is an excellent selection for reading at night before the lights go out.\n",
      "------------------------------\n",
      "Targets, encoded:\n",
      "[59, 179, 362, 165, 200, 19, 90, 314, 2, 967, 622, 145, 1]\n",
      "Targets, decoded:\n",
      "integers [59, 179, 362, 165, 200, 19, 90, 314, 2, 967, 622, 145]\n",
      "targets <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f655c1cc978>\n",
      "good short mystery stories once you get past the stiff british characters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Example inputs as int-tensor.\n",
    "print(\"Inputs, encoded:\")\n",
    "print(inputs)\n",
    "print(\"Inputs, decoded:\")\n",
    "# Example inputs as a sentence.\n",
    "print(decode(inputs))\n",
    "\n",
    "print(\"---\"*10)\n",
    "# Example targets as int-tensor.\n",
    "print(\"Targets, encoded:\")\n",
    "print(targets)\n",
    "# Example targets as a sentence.\n",
    "print(\"Targets, decoded:\")\n",
    "print(decode(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated 3637767 Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfsefs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyper params and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'add_relative_to_values': False, 'parameter_attention_value_channels': 0, 'mlperf_mode': False, 'clip_grad_norm': 0.0, 'optimizer_adafactor_beta1': 0.0, 'shared_embedding_and_softmax_weights': True, 'layer_prepostprocess_dropout': 0.1, 'learning_rate': 0.1, 'initializer_gain': 1.0, 'optimizer_zero_grads': False, 'self_attention_type': 'dot_product', 'symbol_dropout': 0.0, 'eval_run_autoregressive': False, 'max_input_seq_length': 0, 'multiply_embedding_mode': 'sqrt_depth', 'num_hidden_layers': 6, 'activation_dtype': 'float32', 'multiproblem_max_target_length': -1, 'pos': 'timing', 'warm_start_from_second': '', 'scheduled_sampling_prob': 0.0, 'multiproblem_fixed_train_length': -1, 'moe_overhead_eval': 2.0, 'no_data_parallelism': False, 'optimizer_adafactor_memory_exponent': 0.8, 'multiproblem_schedule_max_examples': 10000000.0, 'optimizer_adam_beta1': 0.9, 'proximity_bias': False, 'video_num_target_frames': 1, 'multiproblem_vocab_size': -1, 'scheduled_sampling_warmup_steps': 50000, 'nbr_decoder_problems': 1, 'moe_k': 2, 'factored_logits': False, 'split_to_length': 0, 'summarize_grads': False, 'kernel_width': 1, 'daisy_chain_variables': True, 'use_pad_remover': True, 'optimizer_momentum_nesterov': False, 'learning_rate_schedule': 'legacy', 'optimizer_adafactor_factored': True, 'moe_num_experts': 16, 'modality': {}, 'heads_share_relative_embedding': False, 'sampling_temp': 1.0, 'force_full_predict': False, 'attention_dropout_broadcast_dims': '', 'min_length': 0, 'norm_type': 'layer', 'weight_noise': 0.0, 'eval_drop_long_sequences': False, 'attention_variables_3d': False, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'multiproblem_mixing_schedule': 'constant', 'learning_rate_warmup_steps': 8000, 'min_length_bucket': 8, 'causal_decoder_self_attention': True, 'summarize_vars': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'moe_hidden_sizes': '2048', 'multiproblem_per_task_threshold': '', 'learning_rate_decay_scheme': 'noam', 'attention_dropout': 0.5, 'compress_steps': 0, 'attention_key_channels': 0, 'optimizer': 'Adam', 'num_heads': 16, 'optimizer_adam_epsilon': 1e-09, 'initializer': 'uniform_unit_scaling', 'norm_epsilon': 1e-06, 'sampling_method': 'argmax', 'batch_size': 1024, 'max_length': 0, 'use_fixed_batch_size': False, 'num_decoder_layers': 2, 'multiproblem_schedule_threshold': 0.5, 'filter_size': 2048, 'hidden_size': 512, 'dropout': 0.4, 'relu_dropout': 0.1, 'parameter_attention_key_channels': 0, 'symbol_modality_num_shards': 16, 'label_smoothing': 0.1, 'moe_overhead_train': 1.0, 'optimizer_adafactor_decay_type': 'pow', 'learning_rate_minimum': None, 'learning_rate_constant': 1.0, 'max_target_seq_length': 0, 'num_encoder_layers': 2, 'use_target_space_embedding': True, 'relu_dropout_broadcast_dims': '', 'optimizer_adafactor_clipping_threshold': 1.0, 'max_relative_position': 0, 'grad_noise_scale': 0.0, 'ffn_layer': 'dense_relu_dense', 'multiproblem_target_eval_only': False, 'symbol_modality_skip_top': False, 'multiproblem_max_input_length': -1, 'learning_rate_decay_staircase': False, 'learning_rate_cosine_cycle_steps': 250000, 'moe_loss_coef': 0.001, 'length_bucket_step': 1.1, 'multiproblem_label_weight': 0.5, 'video_num_input_frames': 1, 'optimizer_adam_beta2': 0.98, 'learning_rate_decay_rate': 1.0, 'multiproblem_reweight_label_loss': False, 'overload_eval_metric_name': '', 'shared_embedding': False, 'pad_batch': False, 'vocab_divisor': 1, 'kernel_height': 3, 'pretrained_model_dir': '', 'optimizer_adafactor_beta2': 0.999, 'optimizer_multistep_accumulate_steps': None, 'layer_preprocess_sequence': 'n', 'batch_shuffle_size': 512, 'optimizer_momentum_momentum': 0.9, 'prepend_mode': 'prepend_inputs_masked_attention', 'attention_value_channels': 0, 'tpu_enable_host_call': False, 'learning_rate_decay_steps': 5000, 'weight_dtype': 'float32', 'conv_first_kernel': 3, 'unidirectional_encoder': False, 'layer_prepostprocess_dropout_broadcast_dims': '', 'weight_decay': 0.0, 'layer_postprocess_sequence': 'da'}\n",
      "{'mlperf_threshold': 25.0, 'shards_start_offset': 0, 'display_decoded_images': False, 'max_input_size': -1, 'decode_in_memory': False, 'mlperf_success': False, 'vgg_ckpt_path': '', 'write_beam_scores': False, 'num_decodes': 1, 'multiproblem_task_id': -1, 'max_display_outputs': 10, 'force_decode_length': False, 'border_percent': 2, 'batch_size': 0, 'frames_per_second': 10, 'eos_penalty': 0.0, 'identity_output': False, 'mlperf_decode_step': 0.0, 'guess_and_check_top_k': 0, 'skip_eos_postprocess': False, 'num_samples': -1, 'decode_to_file': None, 'summaries_log_dir': 'decode', 'decode_timeout_mins': 240, 'log_results': True, 'max_display_decodes': 5, 'block_size': 0, 'return_beams': False, 'alpha': 0.6, 'guess_and_check_epsilon': -1, 'shards': 1, 'shard_id': 0, 'beam_size': 4, 'delimiter': '\\n', 'shard_google_format': False, 'extra_length': 100, 'save_images': False}\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "# Define hparams\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "hparams.num_encoder_layers = 2\n",
    "hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 2 \n",
    "hparams.dropout =0.4\n",
    "hparams.num_heads =16\n",
    "hparams.attention_dropout = 0.5 ##\n",
    "# hparams.max_input_seq_length = ????\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams =False\n",
    "# decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7effd4550cc0>, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_tf_random_seed': None, '_task_id': 0, '_task_type': None, '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7effd4550cf8>, 'use_tpu': False, '_num_ps_replicas': 0, 't2t_device_info': {'num_async_replicas': 1}, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_model_dir': 'model_f', '_master': '', '_keep_checkpoint_max': 20, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_device_fn': None, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_num_worker_replicas': 0, '_protocol': None, '_save_summary_steps': 100, '_environment': 'local', '_train_distribute': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7effd463a730>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7effd4550be0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7effd4550c18>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7effd4661160>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7effd4661160>}), ('was_copy', False), ('was_reversed', True)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 16609280\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_f/model.ckpt.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2,16,304,304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node transformer/parallel_0_5/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1468) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node transformer/parallel_0_5/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/dot_product_attention/Max (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1153) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-c4d421628be9>\", line 26, in <module>\n    t2t_model.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1154, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 392, in model_fn\n    body_out = self.body(transformed_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\", line 210, in body\n    losses=losses)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\", line 161, in decode\n    losses=losses)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\", line 1316, in transformer_decoder\n    vars_3d=hparams.get(\"attention_variables_3d\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py\", line 3467, in multihead_attention\n    dropout_broadcast_dims=dropout_broadcast_dims)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py\", line 1468, in dot_product_attention\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2224, in softmax\n    return _softmax(logits, gen_nn_ops.softmax, axis, name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2157, in _softmax\n    return compute_op(logits, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7785, in softmax\n    \"Softmax\", logits=logits, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2,16,304,304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node transformer/parallel_0_5/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1468) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node transformer/parallel_0_5/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/dot_product_attention/Max (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1153) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2,16,304,304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer/parallel_0_5/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node transformer/parallel_0_5/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/dot_product_attention/Max}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c4d421628be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mt2t_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m                          \u001b[0;34m\"model evaluation. Assuming ValidationMonitor present \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                          \"in train_hooks.\")\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_steps)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         max_steps=max_steps or self._train_spec.max_steps)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2,16,304,304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node transformer/parallel_0_5/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1468) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node transformer/parallel_0_5/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/dot_product_attention/Max (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1153) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-c4d421628be9>\", line 26, in <module>\n    t2t_model.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1154, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 392, in model_fn\n    body_out = self.body(transformed_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\", line 210, in body\n    losses=losses)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\", line 161, in decode\n    losses=losses)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\", line 1316, in transformer_decoder\n    vars_3d=hparams.get(\"attention_variables_3d\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py\", line 3467, in multihead_attention\n    dropout_broadcast_dims=dropout_broadcast_dims)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py\", line 1468, in dot_product_attention\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2224, in softmax\n    return _softmax(logits, gen_nn_ops.softmax, axis, name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2157, in _softmax\n    return compute_op(logits, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7785, in softmax\n    \"Softmax\", logits=logits, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2,16,304,304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node transformer/parallel_0_5/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1468) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node transformer/parallel_0_5/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/dot_product_attention/Max (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_attention.py:1153) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# create run config\n",
    "t2t_problem = problem.onlinereview('onlinereview')\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=1000,\n",
    "    )\n",
    "\n",
    "t2t_model = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, \n",
    "        data_dir='./data', \n",
    "        train_steps=100,\n",
    "        eval_steps=100,\n",
    "        min_eval_frequency=1000,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model.train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multiproblem_max_target_length': -1, 'scheduled_sampling_gold_mixin_prob': 0.5, 'scheduled_sampling_prob': 0.0, 'activation_dtype': 'float32', 'optimizer_adafactor_memory_exponent': 0.8, 'optimizer_adafactor_factored': True, 'attention_value_channels': 0, 'optimizer_adafactor_beta2': 0.999, 'tpu_enable_host_call': False, 'learning_rate': 0.1, 'symbol_modality_skip_top': False, 'max_relative_position': 0, 'multiproblem_reweight_label_loss': False, 'optimizer_adam_epsilon': 1e-09, 'optimizer_zero_grads': False, 'eval_run_autoregressive': False, 'modality': {}, 'pretrained_model_dir': '', 'parameter_attention_value_channels': 0, 'filter_size': 2048, 'optimizer_adam_beta1': 0.9, 'optimizer_adafactor_clipping_threshold': 1.0, 'multiproblem_schedule_max_examples': 10000000.0, 'warm_start_from_second': '', 'learning_rate_decay_staircase': False, 'length_bucket_step': 1.1, 'optimizer_adafactor_beta1': 0.0, 'multiproblem_target_eval_only': False, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'use_fixed_batch_size': False, 'layer_prepostprocess_dropout_broadcast_dims': '', 'attention_variables_3d': False, 'sampling_temp': 1.0, 'pad_batch': False, 'summarize_vars': False, 'grad_noise_scale': 0.0, 'force_full_predict': False, 'attention_key_channels': 0, 'symbol_modality_num_shards': 16, 'norm_epsilon': 1e-06, 'shared_embedding_and_softmax_weights': True, 'num_encoder_layers': 2, 'min_length_bucket': 8, 'video_num_target_frames': 1, 'overload_eval_metric_name': '', 'learning_rate_warmup_steps': 8000, 'initializer_gain': 1.0, 'learning_rate_schedule': 'legacy', 'optimizer': 'Adam', 'batch_size': 1024, 'layer_prepostprocess_dropout': 0.1, 'add_relative_to_values': False, 'multiproblem_label_weight': 0.5, 'learning_rate_decay_rate': 1.0, 'multiply_embedding_mode': 'sqrt_depth', 'layer_postprocess_sequence': 'da', 'num_decoder_layers': 2, 'clip_grad_norm': 0.0, 'ffn_layer': 'dense_relu_dense', 'prepend_mode': 'prepend_inputs_masked_attention', 'norm_type': 'layer', 'scheduled_sampling_warmup_steps': 50000, 'vocab_divisor': 1, 'moe_loss_coef': 0.001, 'multiproblem_fixed_train_length': -1, 'multiproblem_vocab_size': -1, 'mlperf_mode': False, 'num_heads': 8, 'kernel_height': 3, 'learning_rate_cosine_cycle_steps': 250000, 'optimizer_adam_beta2': 0.98, 'pos': 'timing', 'video_num_input_frames': 1, 'weight_dtype': 'float32', 'factored_logits': False, 'layer_preprocess_sequence': 'n', 'dropout': 0.2, 'learning_rate_constant': 1.0, 'moe_k': 2, 'no_data_parallelism': False, 'sampling_method': 'argmax', 'proximity_bias': False, 'eval_drop_long_sequences': False, 'attention_dropout_broadcast_dims': '', 'nbr_decoder_problems': 1, 'label_smoothing': 0.1, 'symbol_dropout': 0.0, 'moe_overhead_eval': 2.0, 'moe_num_experts': 16, 'causal_decoder_self_attention': True, 'hidden_size': 512, 'multiproblem_mixing_schedule': 'constant', 'daisy_chain_variables': True, 'shared_embedding': False, 'use_pad_remover': True, 'max_input_seq_length': 1024, 'multiproblem_schedule_threshold': 0.5, 'max_length': 0, 'split_to_length': 0, 'optimizer_momentum_nesterov': False, 'conv_first_kernel': 3, 'weight_decay': 0.0, 'learning_rate_decay_scheme': 'noam', 'use_target_space_embedding': True, 'parameter_attention_key_channels': 0, 'self_attention_type': 'dot_product', 'relu_dropout': 0.1, 'heads_share_relative_embedding': False, 'attention_dropout': 0.1, 'optimizer_adafactor_decay_type': 'pow', 'multiproblem_max_input_length': -1, 'learning_rate_decay_steps': 5000, 'compress_steps': 0, 'unidirectional_encoder': False, 'moe_overhead_train': 1.0, 'learning_rate_minimum': None, 'max_target_seq_length': 0, 'optimizer_multistep_accumulate_steps': None, 'min_length': 0, 'initializer': 'uniform_unit_scaling', 'batch_shuffle_size': 512, 'multiproblem_per_task_threshold': '', 'summarize_grads': False, 'relu_dropout_broadcast_dims': '', 'kernel_width': 1, 'optimizer_momentum_momentum': 0.9, 'weight_noise': 0.0, 'num_hidden_layers': 6, 'moe_hidden_sizes': '2048'}\n",
      "{'decode_in_memory': False, 'frames_per_second': 10, 'num_samples': -1, 'decode_timeout_mins': 240, 'shards_start_offset': 0, 'block_size': 0, 'display_decoded_images': False, 'mlperf_threshold': 25.0, 'shard_google_format': False, 'save_images': False, 'vgg_ckpt_path': '', 'extra_length': 100, 'multiproblem_task_id': -1, 'mlperf_success': False, 'mlperf_decode_step': 0.0, 'alpha': 0.6, 'max_display_decodes': 5, 'summaries_log_dir': 'decode', 'return_beams': False, 'identity_output': False, 'num_decodes': 1, 'batch_size': 0, 'border_percent': 2, 'delimiter': '\\n', 'shards': 1, 'decode_to_file': None, 'shard_id': 0, 'guess_and_check_top_k': 0, 'max_display_outputs': 10, 'beam_size': 4, 'eos_penalty': 0.0, 'write_beam_scores': False, 'max_input_size': -1, 'log_results': True, 'skip_eos_postprocess': False, 'force_decode_length': False, 'guess_and_check_epsilon': -1}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_task_type': None, '_model_dir': 'model_files_1024_new', '_eval_distribute': None, '_keep_checkpoint_max': 20, '_train_distribute': None, '_num_worker_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_environment': 'local', '_save_summary_steps': 100, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4a18ea40f0>, 't2t_device_info': {'num_async_replicas': 1}, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_protocol': None, '_save_checkpoints_secs': None, '_is_chief': True, '_save_checkpoints_steps': 1000, 'use_tpu': False, '_evaluation_master': '', 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f4a18ea4128>, '_device_fn': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f4a19e416a8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4a18f65fd0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4a18ea4048>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4a19fbd978>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4a19fbd978>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 35227136\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:235: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:33:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:34:43\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.009802398, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.038883306, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.19388868\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: model_files_1024_new/model.ckpt-1000\n",
      "INFO:tensorflow:Validation (step 1001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.038883306, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.19388868, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.009802398, global_step = 1000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:loss = 5.5929694, step = 1000\n",
      "INFO:tensorflow:global_step/sec: 1.27432\n",
      "INFO:tensorflow:loss = 5.3400426, step = 1100 (17.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25685\n",
      "INFO:tensorflow:loss = 5.7044735, step = 1200 (15.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.9965\n",
      "INFO:tensorflow:loss = 5.83008, step = 1300 (16.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24693\n",
      "INFO:tensorflow:loss = 4.988793, step = 1400 (16.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08226\n",
      "INFO:tensorflow:loss = 5.3543468, step = 1500 (16.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32493\n",
      "INFO:tensorflow:loss = 5.0353565, step = 1600 (15.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26311\n",
      "INFO:tensorflow:loss = 5.359641, step = 1700 (15.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18152\n",
      "INFO:tensorflow:loss = 6.078044, step = 1800 (16.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21599\n",
      "INFO:tensorflow:loss = 5.546355, step = 1900 (16.086 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.66706\n",
      "INFO:tensorflow:loss = 5.2259393, step = 2000 (21.427 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:37:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:38:21\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.014330758, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.04895454, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.21196455\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_files_1024_new/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.04895454, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.21196455, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.014330758, global_step = 2000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.52168\n",
      "INFO:tensorflow:loss = 5.2416167, step = 2100 (65.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15454\n",
      "INFO:tensorflow:loss = 5.2994895, step = 2200 (16.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18607\n",
      "INFO:tensorflow:loss = 5.188624, step = 2300 (16.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13219\n",
      "INFO:tensorflow:loss = 5.5219355, step = 2400 (16.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08551\n",
      "INFO:tensorflow:loss = 5.3464127, step = 2500 (16.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26083\n",
      "INFO:tensorflow:loss = 5.45347, step = 2600 (15.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21512\n",
      "INFO:tensorflow:loss = 5.498091, step = 2700 (16.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21946\n",
      "INFO:tensorflow:loss = 4.6352806, step = 2800 (16.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13501\n",
      "INFO:tensorflow:loss = 5.5721226, step = 2900 (16.302 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74611\n",
      "INFO:tensorflow:loss = 5.43461, step = 3000 (21.069 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:41:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:41:57\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.04013329, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.100136004, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.2920968\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: model_files_1024_new/model.ckpt-3000\n",
      "INFO:tensorflow:Validation (step 3001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.100136004, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.2920968, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.04013329, global_step = 3000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.52757\n",
      "INFO:tensorflow:loss = 4.6846185, step = 3100 (65.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2607\n",
      "INFO:tensorflow:loss = 3.5225728, step = 3200 (15.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19792\n",
      "INFO:tensorflow:loss = 5.1061497, step = 3300 (16.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21168\n",
      "INFO:tensorflow:loss = 4.2285895, step = 3400 (16.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2402\n",
      "INFO:tensorflow:loss = 4.631033, step = 3500 (16.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21614\n",
      "INFO:tensorflow:loss = 4.881013, step = 3600 (16.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28604\n",
      "INFO:tensorflow:loss = 4.268908, step = 3700 (15.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.30415\n",
      "INFO:tensorflow:loss = 5.10923, step = 3800 (15.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.35578\n",
      "INFO:tensorflow:loss = 4.423191, step = 3900 (15.735 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.80029\n",
      "INFO:tensorflow:loss = 2.0238767, step = 4000 (20.830 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:44:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:45:32\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.3576438, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.43429986, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.6159911\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_files_1024_new/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.43429986, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.6159911, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.3576438, global_step = 4000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.51275\n",
      "INFO:tensorflow:loss = 3.862774, step = 4100 (66.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23668\n",
      "INFO:tensorflow:loss = 3.3272078, step = 4200 (16.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18038\n",
      "INFO:tensorflow:loss = 3.968001, step = 4300 (16.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13227\n",
      "INFO:tensorflow:loss = 3.0602453, step = 4400 (16.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00341\n",
      "INFO:tensorflow:loss = 3.1616337, step = 4500 (16.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18409\n",
      "INFO:tensorflow:loss = 3.1475081, step = 4600 (16.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16217\n",
      "INFO:tensorflow:loss = 2.1599321, step = 4700 (16.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19032\n",
      "INFO:tensorflow:loss = 2.301388, step = 4800 (16.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18399\n",
      "INFO:tensorflow:loss = 2.15612, step = 4900 (16.172 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.79046\n",
      "INFO:tensorflow:loss = 0.6801776, step = 5000 (20.873 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:48:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:49:08\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.71043336, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.7586086, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.84689957\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: model_files_1024_new/model.ckpt-5000\n",
      "INFO:tensorflow:Validation (step 5001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.7586086, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.84689957, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.71043336, global_step = 5000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.52935\n",
      "INFO:tensorflow:loss = 1.9056311, step = 5100 (65.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21187\n",
      "INFO:tensorflow:loss = 3.0489168, step = 5200 (16.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17649\n",
      "INFO:tensorflow:loss = 2.3607862, step = 5300 (16.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22698\n",
      "INFO:tensorflow:loss = 1.0211226, step = 5400 (16.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15929\n",
      "INFO:tensorflow:loss = 1.4404324, step = 5500 (16.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18763\n",
      "INFO:tensorflow:loss = 0.9075937, step = 5600 (16.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11715\n",
      "INFO:tensorflow:loss = 0.99149984, step = 5700 (16.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21831\n",
      "INFO:tensorflow:loss = 1.6137884, step = 5800 (16.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15241\n",
      "INFO:tensorflow:loss = 1.2691858, step = 5900 (16.254 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.73564\n",
      "INFO:tensorflow:loss = 0.98760325, step = 6000 (21.115 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:52:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:52:45\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.7976388, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8318135, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.89388746\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_files_1024_new/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8318135, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.89388746, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.7976388, global_step = 6000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.51865\n",
      "INFO:tensorflow:loss = 0.79869825, step = 6100 (65.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12468\n",
      "INFO:tensorflow:loss = 1.5822132, step = 6200 (16.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1785\n",
      "INFO:tensorflow:loss = 0.80756104, step = 6300 (16.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09786\n",
      "INFO:tensorflow:loss = 0.6170034, step = 6400 (16.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06305\n",
      "INFO:tensorflow:loss = 1.6082532, step = 6500 (16.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24205\n",
      "INFO:tensorflow:loss = 0.6022285, step = 6600 (16.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24694\n",
      "INFO:tensorflow:loss = 0.8777546, step = 6700 (16.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13929\n",
      "INFO:tensorflow:loss = 0.49665478, step = 6800 (16.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16617\n",
      "INFO:tensorflow:loss = 0.7859491, step = 6900 (16.218 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.70293\n",
      "INFO:tensorflow:loss = 0.8629087, step = 7000 (21.263 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:55:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:56:21\n",
      "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.801055, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8339656, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.89658034\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: model_files_1024_new/model.ckpt-7000\n",
      "INFO:tensorflow:Validation (step 7001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8339656, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.89658034, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.801055, global_step = 7000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.52392\n",
      "INFO:tensorflow:loss = 0.71836436, step = 7100 (65.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1522\n",
      "INFO:tensorflow:loss = 1.4844846, step = 7200 (16.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18246\n",
      "INFO:tensorflow:loss = 0.59734726, step = 7300 (16.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28658\n",
      "INFO:tensorflow:loss = 0.8761729, step = 7400 (15.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.94459\n",
      "INFO:tensorflow:loss = 0.9262199, step = 7500 (16.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19535\n",
      "INFO:tensorflow:loss = 0.96947, step = 7600 (16.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22585\n",
      "INFO:tensorflow:loss = 1.0122808, step = 7700 (16.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02705\n",
      "INFO:tensorflow:loss = 0.4229706, step = 7800 (16.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.137\n",
      "INFO:tensorflow:loss = 0.5109299, step = 7900 (16.295 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.75951\n",
      "INFO:tensorflow:loss = 0.63911486, step = 8000 (21.011 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T08:59:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-08:59:58\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.81107354, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.84326226, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.90186983\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_files_1024_new/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.84326226, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.90186983, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.81107354, global_step = 8000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.52166\n",
      "INFO:tensorflow:loss = 0.46211544, step = 8100 (65.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12604\n",
      "INFO:tensorflow:loss = 0.7317359, step = 8200 (16.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16303\n",
      "INFO:tensorflow:loss = 0.48001936, step = 8300 (16.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2902\n",
      "INFO:tensorflow:loss = 0.504865, step = 8400 (15.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25946\n",
      "INFO:tensorflow:loss = 0.31936038, step = 8500 (15.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2332\n",
      "INFO:tensorflow:loss = 0.42050305, step = 8600 (16.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23977\n",
      "INFO:tensorflow:loss = 0.39099145, step = 8700 (16.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.113\n",
      "INFO:tensorflow:loss = 1.028965, step = 8800 (16.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1704\n",
      "INFO:tensorflow:loss = 0.45112804, step = 8900 (16.208 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.75268\n",
      "INFO:tensorflow:loss = 1.2595764, step = 9000 (21.040 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T09:02:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-09:03:34\n",
      "INFO:tensorflow:Saving dict for global step 9000: global_step = 9000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.81881636, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8491219, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9055767\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: model_files_1024_new/model.ckpt-9000\n",
      "INFO:tensorflow:Validation (step 9001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8491219, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9055767, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.81881636, global_step = 9000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.53837\n",
      "INFO:tensorflow:loss = 0.47228426, step = 9100 (65.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21911\n",
      "INFO:tensorflow:loss = 0.8621632, step = 9200 (16.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27219\n",
      "INFO:tensorflow:loss = 0.5037748, step = 9300 (15.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2126\n",
      "INFO:tensorflow:loss = 0.5081175, step = 9400 (16.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20454\n",
      "INFO:tensorflow:loss = 0.47509927, step = 9500 (16.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12891\n",
      "INFO:tensorflow:loss = 0.45262185, step = 9600 (16.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20516\n",
      "INFO:tensorflow:loss = 0.92212826, step = 9700 (16.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14134\n",
      "INFO:tensorflow:loss = 0.3887284, step = 9800 (16.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15931\n",
      "INFO:tensorflow:loss = 0.69549876, step = 9900 (16.236 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_files_1024_new/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.79391\n",
      "INFO:tensorflow:loss = 0.57596546, step = 10000 (20.860 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-30T09:06:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_1024_new/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-30-09:07:09\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8233811, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8527083, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9078914\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_files_1024_new/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10001): metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8527083, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9078914, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8233811, global_step = 10000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0\n",
      "INFO:tensorflow:global_step/sec: 1.53641\n",
      "INFO:tensorflow:loss = 0.992347, step = 10100 (65.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1265\n",
      "INFO:tensorflow:loss = 0.57015944, step = 10200 (16.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22051\n",
      "INFO:tensorflow:loss = 0.667021, step = 10300 (16.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19464\n",
      "INFO:tensorflow:loss = 1.2870171, step = 10400 (16.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18348\n",
      "INFO:tensorflow:loss = 1.119579, step = 10500 (16.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27257\n",
      "INFO:tensorflow:loss = 0.6235132, step = 10600 (15.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28284\n",
      "INFO:tensorflow:loss = 0.48513666, step = 10700 (15.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.30776\n",
      "INFO:tensorflow:loss = 0.5003654, step = 10800 (15.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04067\n",
      "INFO:tensorflow:loss = 0.6155879, step = 10900 (16.556 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3bf41b078b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mt2t_model_1024_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# running time check (running on 1GPU server)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m                          \u001b[0;34m\"model evaluation. Assuming ValidationMonitor present \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                          \"in train_hooks.\")\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_steps)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         max_steps=max_steps or self._train_spec.max_steps)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# select the transformer model\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding, metrics\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_1024_new'\n",
    "\n",
    "# Define hparams\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "# hparams.num_encoder_layers = 2\n",
    "hparams.num_hidden_layers = 6\n",
    "# hparams.num_decoder_layers = 2 \n",
    "hparams.dropout =0.2\n",
    "hparams.max_input_seq_length = 1024\n",
    "hparams.shared_embedding_and_softmax_weights = False ###????\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = False\n",
    "# decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "# create run config\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=1000,\n",
    "    )\n",
    "# t2t_problem.eval_metrics()\n",
    "\n",
    "t2t_model_1024_new = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, \n",
    "        data_dir='./data', \n",
    "        train_steps=40001,\n",
    "        eval_steps=100,\n",
    "        min_eval_frequency=1000,\n",
    "        eval_use_test_set=True\n",
    "    )\n",
    "\n",
    "hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_1024_new.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_adam_beta2': 0.98, 'factored_logits': False, 'learning_rate_decay_scheme': 'noam', 'scheduled_sampling_warmup_steps': 50000, 'learning_rate_decay_rate': 1.0, 'heads_share_relative_embedding': False, 'overload_eval_metric_name': '', 'prepend_mode': 'prepend_inputs_masked_attention', 'initializer_gain': 1.0, 'learning_rate_warmup_steps': 8000, 'tpu_enable_host_call': False, 'weight_dtype': 'float32', 'optimizer_adafactor_factored': True, 'ffn_layer': 'dense_relu_dense', 'summarize_vars': False, 'force_full_predict': False, 'multiproblem_mixing_schedule': 'constant', 'num_encoder_layers': 2, 'filter_size': 2048, 'min_length': 0, 'activation_dtype': 'float32', 'dropout': 0.2, 'learning_rate_minimum': None, 'moe_overhead_eval': 2.0, 'label_smoothing': 0.1, 'learning_rate_decay_staircase': False, 'optimizer_adafactor_memory_exponent': 0.8, 'optimizer_adafactor_beta1': 0.0, 'multiproblem_per_task_threshold': '', 'multiproblem_fixed_train_length': -1, 'optimizer_adafactor_clipping_threshold': 1.0, 'self_attention_type': 'dot_product', 'scheduled_sampling_prob': 0.0, 'use_pad_remover': True, 'hidden_size': 512, 'num_heads': 8, 'moe_loss_coef': 0.001, 'max_relative_position': 0, 'optimizer_adam_beta1': 0.9, 'multiproblem_reweight_label_loss': False, 'batch_shuffle_size': 512, 'add_relative_to_values': False, 'eval_run_autoregressive': False, 'learning_rate': 0.1, 'relu_dropout_broadcast_dims': '', 'moe_hidden_sizes': '2048', 'learning_rate_decay_steps': 5000, 'compress_steps': 0, 'norm_epsilon': 1e-06, 'layer_prepostprocess_dropout': 0.1, 'moe_k': 2, 'kernel_height': 3, 'layer_postprocess_sequence': 'da', 'optimizer_adafactor_decay_type': 'pow', 'weight_decay': 0.0, 'parameter_attention_key_channels': 0, 'attention_variables_3d': False, 'daisy_chain_variables': True, 'optimizer_adam_epsilon': 1e-09, 'symbol_modality_skip_top': False, 'sampling_method': 'argmax', 'optimizer_momentum_nesterov': False, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'attention_dropout_broadcast_dims': '', 'initializer': 'uniform_unit_scaling', 'conv_first_kernel': 3, 'min_length_bucket': 8, 'moe_num_experts': 16, 'multiproblem_target_eval_only': False, 'mlperf_mode': False, 'batch_size': 1024, 'modality': {}, 'optimizer_zero_grads': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'optimizer_momentum_momentum': 0.9, 'multiply_embedding_mode': 'sqrt_depth', 'use_fixed_batch_size': False, 'eval_drop_long_sequences': False, 'warm_start_from_second': '', 'video_num_target_frames': 1, 'clip_grad_norm': 0.0, 'multiproblem_vocab_size': -1, 'max_length': 0, 'pretrained_model_dir': '', 'no_data_parallelism': False, 'attention_dropout': 0.1, 'split_to_length': 0, 'max_input_seq_length': 1024, 'max_target_seq_length': 0, 'parameter_attention_value_channels': 0, 'grad_noise_scale': 0.0, 'length_bucket_step': 1.1, 'optimizer_adafactor_beta2': 0.999, 'learning_rate_constant': 1.0, 'optimizer': 'Adam', 'video_num_input_frames': 1, 'learning_rate_cosine_cycle_steps': 250000, 'attention_key_channels': 0, 'shared_embedding': False, 'multiproblem_label_weight': 0.5, 'optimizer_multistep_accumulate_steps': None, 'unidirectional_encoder': False, 'nbr_decoder_problems': 1, 'shared_embedding_and_softmax_weights': True, 'relu_dropout': 0.1, 'summarize_grads': False, 'multiproblem_max_input_length': -1, 'norm_type': 'layer', 'symbol_dropout': 0.0, 'pad_batch': False, 'sampling_temp': 1.0, 'multiproblem_schedule_threshold': 0.5, 'attention_value_channels': 0, 'use_target_space_embedding': True, 'layer_preprocess_sequence': 'n', 'weight_noise': 0.0, 'causal_decoder_self_attention': True, 'num_hidden_layers': 6, 'layer_prepostprocess_dropout_broadcast_dims': '', 'multiproblem_schedule_max_examples': 10000000.0, 'learning_rate_schedule': 'legacy', 'symbol_modality_num_shards': 16, 'vocab_divisor': 1, 'num_decoder_layers': 2, 'pos': 'timing', 'proximity_bias': False, 'kernel_width': 1, 'moe_overhead_train': 1.0, 'multiproblem_max_target_length': -1}\n",
      "{'num_samples': -1, 'write_beam_scores': False, 'log_results': True, 'return_beams': True, 'multiproblem_task_id': -1, 'batch_size': 0, 'identity_output': False, 'decode_in_memory': False, 'mlperf_decode_step': 0.0, 'shards': 1, 'max_input_size': -1, 'shard_id': 0, 'frames_per_second': 10, 'mlperf_success': False, 'force_decode_length': False, 'guess_and_check_epsilon': -1, 'display_decoded_images': False, 'eos_penalty': 0.0, 'extra_length': 100, 'mlperf_threshold': 25.0, 'vgg_ckpt_path': '', 'delimiter': '\\n', 'decode_to_file': None, 'block_size': 0, 'decode_timeout_mins': 240, 'skip_eos_postprocess': False, 'shards_start_offset': 0, 'guess_and_check_top_k': 0, 'summaries_log_dir': 'decode', 'border_percent': 2, 'max_display_outputs': 10, 'num_decodes': 1, 'save_images': False, 'beam_size': 4, 'max_display_decodes': 5, 'shard_google_format': False, 'alpha': 0.6}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_protocol': None, '_save_checkpoints_steps': 1000, '_master': '', '_device_fn': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_secs': None, '_save_summary_steps': 100, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", 'use_tpu': False, '_keep_checkpoint_max': 20, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", 't2t_device_info': {'num_async_replicas': 1}, '_task_type': None, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6a860207f0>, '_num_worker_replicas': 0, '_eval_distribute': None, '_is_chief': True, '_tf_random_seed': None, '_model_dir': 'model_files_512', '_task_id': 0, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_train_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f6a86020908>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f6a7f6382f0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f6cf91f1cc0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f6cf91f1cf8>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f6cfa244b70>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f6cfa244b70>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 35396096\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:loss = 11.188004, step = 0\n",
      "INFO:tensorflow:global_step/sec: 5.50608\n",
      "INFO:tensorflow:loss = 9.417504, step = 100 (18.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03151\n",
      "INFO:tensorflow:loss = 8.071609, step = 200 (16.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18876\n",
      "INFO:tensorflow:loss = 7.0966353, step = 300 (16.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21046\n",
      "INFO:tensorflow:loss = 6.769985, step = 400 (16.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13414\n",
      "INFO:tensorflow:loss = 6.444959, step = 500 (16.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12722\n",
      "INFO:tensorflow:loss = 6.295968, step = 600 (16.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23412\n",
      "INFO:tensorflow:loss = 5.855097, step = 700 (16.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20503\n",
      "INFO:tensorflow:loss = 5.6549077, step = 800 (16.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98603\n",
      "INFO:tensorflow:loss = 5.6312494, step = 900 (16.706 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.83434\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T18:41:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-18:42:40\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.009154438, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.034609586, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.18910904\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: model_files_512/model.ckpt-1000\n",
      "INFO:tensorflow:Validation (step 1000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.18910904, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.009154438, global_step = 1000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.034609586\n",
      "INFO:tensorflow:loss = 5.3682027, step = 1000 (72.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48574\n",
      "INFO:tensorflow:loss = 5.569435, step = 1100 (15.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14981\n",
      "INFO:tensorflow:loss = 6.656428, step = 1200 (16.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20057\n",
      "INFO:tensorflow:loss = 5.443648, step = 1300 (16.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08115\n",
      "INFO:tensorflow:loss = 5.294071, step = 1400 (16.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16172\n",
      "INFO:tensorflow:loss = 5.2108984, step = 1500 (16.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11095\n",
      "INFO:tensorflow:loss = 5.327215, step = 1600 (16.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17923\n",
      "INFO:tensorflow:loss = 5.0287323, step = 1700 (16.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14135\n",
      "INFO:tensorflow:loss = 5.097176, step = 1800 (16.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1326\n",
      "INFO:tensorflow:loss = 5.4438596, step = 1900 (16.308 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82541\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T18:45:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-18:46:17\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.015651658, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.05430443, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.21704872\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_files_512/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.21704872, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.015651658, global_step = 2000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.05430443\n",
      "INFO:tensorflow:loss = 5.049559, step = 2000 (70.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50929\n",
      "INFO:tensorflow:loss = 5.305725, step = 2100 (16.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18959\n",
      "INFO:tensorflow:loss = 6.0472326, step = 2200 (16.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14948\n",
      "INFO:tensorflow:loss = 5.6003504, step = 2300 (16.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11\n",
      "INFO:tensorflow:loss = 5.414893, step = 2400 (16.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08238\n",
      "INFO:tensorflow:loss = 4.9564767, step = 2500 (16.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.94978\n",
      "INFO:tensorflow:loss = 5.088769, step = 2600 (16.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11623\n",
      "INFO:tensorflow:loss = 5.4254327, step = 2700 (16.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11163\n",
      "INFO:tensorflow:loss = 5.488344, step = 2800 (16.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08995\n",
      "INFO:tensorflow:loss = 4.7447, step = 2900 (16.419 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.88357\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T18:49:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-18:49:56\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.03498712, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.09164196, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.27804157\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: model_files_512/model.ckpt-3000\n",
      "INFO:tensorflow:Validation (step 3000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.27804157, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.03498712, global_step = 3000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.09164196\n",
      "INFO:tensorflow:loss = 4.804373, step = 3000 (71.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49793\n",
      "INFO:tensorflow:loss = 5.3931217, step = 3100 (16.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23556\n",
      "INFO:tensorflow:loss = 3.845401, step = 3200 (16.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0788\n",
      "INFO:tensorflow:loss = 4.166145, step = 3300 (16.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20164\n",
      "INFO:tensorflow:loss = 5.213226, step = 3400 (16.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.96068\n",
      "INFO:tensorflow:loss = 4.9310665, step = 3500 (16.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12713\n",
      "INFO:tensorflow:loss = 5.0179267, step = 3600 (16.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12327\n",
      "INFO:tensorflow:loss = 3.9879422, step = 3700 (16.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27568\n",
      "INFO:tensorflow:loss = 4.3836412, step = 3800 (15.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25649\n",
      "INFO:tensorflow:loss = 4.1205654, step = 3900 (15.984 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.81554\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T18:52:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-18:53:31\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.2843396, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.35785714, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.54363066\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_files_512/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.54363066, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.2843396, global_step = 4000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.35785714\n",
      "INFO:tensorflow:loss = 2.7748125, step = 4000 (69.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53383\n",
      "INFO:tensorflow:loss = 2.6566598, step = 4100 (16.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97397\n",
      "INFO:tensorflow:loss = 5.0122824, step = 4200 (16.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09866\n",
      "INFO:tensorflow:loss = 2.892678, step = 4300 (16.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14745\n",
      "INFO:tensorflow:loss = 1.8693929, step = 4400 (16.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1717\n",
      "INFO:tensorflow:loss = 1.999602, step = 4500 (16.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00586\n",
      "INFO:tensorflow:loss = 2.2342625, step = 4600 (16.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12982\n",
      "INFO:tensorflow:loss = 2.0586631, step = 4700 (16.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23983\n",
      "INFO:tensorflow:loss = 2.1266181, step = 4800 (16.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.33754\n",
      "INFO:tensorflow:loss = 1.6555109, step = 4900 (15.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.78305\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T18:56:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-18:57:20\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.68996066, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.7390207, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8436814\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: model_files_512/model.ckpt-5000\n",
      "INFO:tensorflow:Validation (step 5000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8436814, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.68996066, global_step = 5000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.7390207\n",
      "INFO:tensorflow:loss = 1.2797395, step = 5000 (81.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30223\n",
      "INFO:tensorflow:loss = 1.4455723, step = 5100 (15.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08866\n",
      "INFO:tensorflow:loss = 0.92230254, step = 5200 (16.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28368\n",
      "INFO:tensorflow:loss = 2.2984579, step = 5300 (15.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12049\n",
      "INFO:tensorflow:loss = 1.3208907, step = 5400 (16.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16575\n",
      "INFO:tensorflow:loss = 0.4753683, step = 5500 (16.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23993\n",
      "INFO:tensorflow:loss = 0.7402669, step = 5600 (16.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06914\n",
      "INFO:tensorflow:loss = 1.990075, step = 5700 (16.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24898\n",
      "INFO:tensorflow:loss = 1.9609085, step = 5800 (16.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21343\n",
      "INFO:tensorflow:loss = 1.8320521, step = 5900 (16.095 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.85828\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:00:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:01:06\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.7842075, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8197465, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8892753\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_files_512/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8892753, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.7842075, global_step = 6000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8197465\n",
      "INFO:tensorflow:loss = 1.6303915, step = 6000 (80.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31179\n",
      "INFO:tensorflow:loss = 1.2131208, step = 6100 (16.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18703\n",
      "INFO:tensorflow:loss = 0.7901786, step = 6200 (16.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.93617\n",
      "INFO:tensorflow:loss = 2.5102594, step = 6300 (16.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.226\n",
      "INFO:tensorflow:loss = 1.0100976, step = 6400 (16.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24589\n",
      "INFO:tensorflow:loss = 0.74231106, step = 6500 (16.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32372\n",
      "INFO:tensorflow:loss = 0.6210118, step = 6600 (15.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0277\n",
      "INFO:tensorflow:loss = 1.1490206, step = 6700 (16.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08831\n",
      "INFO:tensorflow:loss = 0.9116075, step = 6800 (16.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1246\n",
      "INFO:tensorflow:loss = 0.46284065, step = 6900 (16.327 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.7558\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:03:58Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:04:52\n",
      "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8112599, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8425168, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.903453\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: model_files_512/model.ckpt-7000\n",
      "INFO:tensorflow:Validation (step 7000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.903453, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8112599, global_step = 7000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8425168\n",
      "INFO:tensorflow:loss = 1.9464301, step = 7000 (80.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31975\n",
      "INFO:tensorflow:loss = 0.93349475, step = 7100 (16.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17908\n",
      "INFO:tensorflow:loss = 2.454884, step = 7200 (16.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15532\n",
      "INFO:tensorflow:loss = 0.9946809, step = 7300 (16.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20483\n",
      "INFO:tensorflow:loss = 1.0817022, step = 7400 (16.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08948\n",
      "INFO:tensorflow:loss = 0.35040817, step = 7500 (16.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19814\n",
      "INFO:tensorflow:loss = 0.94667363, step = 7600 (16.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05466\n",
      "INFO:tensorflow:loss = 0.954506, step = 7700 (16.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14858\n",
      "INFO:tensorflow:loss = 0.56642514, step = 7800 (16.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24946\n",
      "INFO:tensorflow:loss = 1.4345497, step = 7900 (16.003 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74311\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:07:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:08:41\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8202622, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.85035205, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9086603\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_files_512/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9086603, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8202622, global_step = 8000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.85035205\n",
      "INFO:tensorflow:loss = 0.672768, step = 8000 (81.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30062\n",
      "INFO:tensorflow:loss = 0.7827652, step = 8100 (16.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17517\n",
      "INFO:tensorflow:loss = 1.9076086, step = 8200 (16.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09674\n",
      "INFO:tensorflow:loss = 0.9869346, step = 8300 (16.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15071\n",
      "INFO:tensorflow:loss = 0.67124474, step = 8400 (16.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.30786\n",
      "INFO:tensorflow:loss = 0.5455641, step = 8500 (15.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.96916\n",
      "INFO:tensorflow:loss = 0.87521887, step = 8600 (16.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17999\n",
      "INFO:tensorflow:loss = 0.38633466, step = 8700 (16.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32111\n",
      "INFO:tensorflow:loss = 1.3075976, step = 8800 (15.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06212\n",
      "INFO:tensorflow:loss = 1.8117334, step = 8900 (16.497 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.84932\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:11:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:12:28\n",
      "INFO:tensorflow:Saving dict for global step 9000: global_step = 9000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.82602805, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8545259, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9113162\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: model_files_512/model.ckpt-9000\n",
      "INFO:tensorflow:Validation (step 9000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9113162, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.82602805, global_step = 9000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8545259\n",
      "INFO:tensorflow:loss = 0.899739, step = 9000 (81.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.29639\n",
      "INFO:tensorflow:loss = 0.38430604, step = 9100 (16.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09655\n",
      "INFO:tensorflow:loss = 0.5089821, step = 9200 (16.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10417\n",
      "INFO:tensorflow:loss = 1.9252772, step = 9300 (16.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15608\n",
      "INFO:tensorflow:loss = 2.5953863, step = 9400 (16.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04813\n",
      "INFO:tensorflow:loss = 1.2034801, step = 9500 (16.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1851\n",
      "INFO:tensorflow:loss = 1.1590621, step = 9600 (16.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17459\n",
      "INFO:tensorflow:loss = 0.55560035, step = 9700 (16.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0314\n",
      "INFO:tensorflow:loss = 0.99056035, step = 9800 (16.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03853\n",
      "INFO:tensorflow:loss = 0.3213455, step = 9900 (16.560 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.85865\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:15:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:16:16\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8274401, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8556646, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91200083\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_files_512/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91200083, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8274401, global_step = 10000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8556646\n",
      "INFO:tensorflow:loss = 0.7843789, step = 10000 (80.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31464\n",
      "INFO:tensorflow:loss = 0.47727755, step = 10100 (16.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08299\n",
      "INFO:tensorflow:loss = 1.3708233, step = 10200 (16.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19469\n",
      "INFO:tensorflow:loss = 0.96136236, step = 10300 (16.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22675\n",
      "INFO:tensorflow:loss = 2.9817293, step = 10400 (16.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24404\n",
      "INFO:tensorflow:loss = 0.38403538, step = 10500 (16.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22774\n",
      "INFO:tensorflow:loss = 0.4465174, step = 10600 (16.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1967\n",
      "INFO:tensorflow:loss = 0.86937964, step = 10700 (16.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1167\n",
      "INFO:tensorflow:loss = 1.8274924, step = 10800 (16.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14863\n",
      "INFO:tensorflow:loss = 0.5315791, step = 10900 (16.263 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.80593\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:19:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-11000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:20:02\n",
      "INFO:tensorflow:Saving dict for global step 11000: global_step = 11000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8325478, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8597815, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9146664\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11000: model_files_512/model.ckpt-11000\n",
      "INFO:tensorflow:Validation (step 11000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9146664, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8325478, global_step = 11000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8597815\n",
      "INFO:tensorflow:loss = 0.8598182, step = 11000 (80.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32577\n",
      "INFO:tensorflow:loss = 0.69810766, step = 11100 (15.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07042\n",
      "INFO:tensorflow:loss = 0.63903385, step = 11200 (16.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.31629\n",
      "INFO:tensorflow:loss = 0.69567996, step = 11300 (15.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16874\n",
      "INFO:tensorflow:loss = 0.54967445, step = 11400 (16.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19174\n",
      "INFO:tensorflow:loss = 0.5273458, step = 11500 (16.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22482\n",
      "INFO:tensorflow:loss = 1.2710291, step = 11600 (16.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07216\n",
      "INFO:tensorflow:loss = 0.82229024, step = 11700 (16.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13566\n",
      "INFO:tensorflow:loss = 0.6811816, step = 11800 (16.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16282\n",
      "INFO:tensorflow:loss = 1.0367739, step = 11900 (16.227 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.87356\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:22:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:23:48\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83351606, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.86079323, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91497207\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_files_512/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91497207, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83351606, global_step = 12000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.86079323\n",
      "INFO:tensorflow:loss = 0.51819944, step = 12000 (79.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31789\n",
      "INFO:tensorflow:loss = 1.7449539, step = 12100 (16.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18054\n",
      "INFO:tensorflow:loss = 0.46292466, step = 12200 (16.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22324\n",
      "INFO:tensorflow:loss = 0.60913044, step = 12300 (16.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13763\n",
      "INFO:tensorflow:loss = 0.93174094, step = 12400 (16.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23409\n",
      "INFO:tensorflow:loss = 0.347221, step = 12500 (16.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07794\n",
      "INFO:tensorflow:loss = 0.47936198, step = 12600 (16.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1475\n",
      "INFO:tensorflow:loss = 0.9592645, step = 12700 (16.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1725\n",
      "INFO:tensorflow:loss = 0.39605036, step = 12800 (16.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1664\n",
      "INFO:tensorflow:loss = 1.1406251, step = 12900 (16.218 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.72941\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:26:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-13000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:27:35\n",
      "INFO:tensorflow:Saving dict for global step 13000: global_step = 13000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83531564, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8617865, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9160164\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13000: model_files_512/model.ckpt-13000\n",
      "INFO:tensorflow:Validation (step 13000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9160164, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83531564, global_step = 13000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8617865\n",
      "INFO:tensorflow:loss = 0.9722158, step = 13000 (81.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30703\n",
      "INFO:tensorflow:loss = 0.93614775, step = 13100 (16.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08136\n",
      "INFO:tensorflow:loss = 0.48981953, step = 13200 (16.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.37547\n",
      "INFO:tensorflow:loss = 0.43803176, step = 13300 (15.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15532\n",
      "INFO:tensorflow:loss = 0.9945875, step = 13400 (16.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12404\n",
      "INFO:tensorflow:loss = 0.6810494, step = 13500 (16.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99227\n",
      "INFO:tensorflow:loss = 0.6106798, step = 13600 (16.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18816\n",
      "INFO:tensorflow:loss = 0.62258023, step = 13700 (16.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04455\n",
      "INFO:tensorflow:loss = 0.4573861, step = 13800 (16.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12806\n",
      "INFO:tensorflow:loss = 0.75182503, step = 13900 (16.320 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.80482\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:30:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:31:21\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8354065, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.86280596, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9159263\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_files_512/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9159263, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8354065, global_step = 14000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.86280596\n",
      "INFO:tensorflow:loss = 0.59684175, step = 14000 (79.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34386\n",
      "INFO:tensorflow:loss = 0.47864765, step = 14100 (16.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12832\n",
      "INFO:tensorflow:loss = 0.7382494, step = 14200 (16.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2309\n",
      "INFO:tensorflow:loss = 0.5400913, step = 14300 (16.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06001\n",
      "INFO:tensorflow:loss = 0.52498066, step = 14400 (16.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04541\n",
      "INFO:tensorflow:loss = 0.7009253, step = 14500 (16.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1152\n",
      "INFO:tensorflow:loss = 0.5925465, step = 14600 (16.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05551\n",
      "INFO:tensorflow:loss = 0.6356147, step = 14700 (16.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16758\n",
      "INFO:tensorflow:loss = 0.58783233, step = 14800 (16.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14014\n",
      "INFO:tensorflow:loss = 0.9463925, step = 14900 (16.288 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.72652\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:34:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:35:09\n",
      "INFO:tensorflow:Saving dict for global step 15000: global_step = 15000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83825797, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.864836, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91765845\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: model_files_512/model.ckpt-15000\n",
      "INFO:tensorflow:Validation (step 15000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91765845, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83825797, global_step = 15000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.864836\n",
      "INFO:tensorflow:loss = 0.6938405, step = 15000 (81.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30527\n",
      "INFO:tensorflow:loss = 0.40240604, step = 15100 (16.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13153\n",
      "INFO:tensorflow:loss = 0.9603808, step = 15200 (16.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08777\n",
      "INFO:tensorflow:loss = 0.6455775, step = 15300 (16.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1937\n",
      "INFO:tensorflow:loss = 0.5808435, step = 15400 (16.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10368\n",
      "INFO:tensorflow:loss = 0.9973065, step = 15500 (16.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08408\n",
      "INFO:tensorflow:loss = 0.3911983, step = 15600 (16.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22687\n",
      "INFO:tensorflow:loss = 0.6794496, step = 15700 (16.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.3027\n",
      "INFO:tensorflow:loss = 0.4234854, step = 15800 (15.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09833\n",
      "INFO:tensorflow:loss = 0.59748185, step = 15900 (16.398 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.84118\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:38:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:38:56\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.84222007, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8685908, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.919493\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_files_512/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.919493, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.84222007, global_step = 16000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8685908\n",
      "INFO:tensorflow:loss = 0.33533674, step = 16000 (80.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30684\n",
      "INFO:tensorflow:loss = 0.71549845, step = 16100 (16.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04869\n",
      "INFO:tensorflow:loss = 0.3192965, step = 16200 (16.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25014\n",
      "INFO:tensorflow:loss = 0.44336313, step = 16300 (16.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02841\n",
      "INFO:tensorflow:loss = 0.5190988, step = 16400 (16.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12244\n",
      "INFO:tensorflow:loss = 0.40819782, step = 16500 (16.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05194\n",
      "INFO:tensorflow:loss = 0.770108, step = 16600 (16.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0963\n",
      "INFO:tensorflow:loss = 0.62835056, step = 16700 (16.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10199\n",
      "INFO:tensorflow:loss = 0.47787943, step = 16800 (16.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04092\n",
      "INFO:tensorflow:loss = 0.3632794, step = 16900 (16.555 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.80353\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:41:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-17000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:42:35\n",
      "INFO:tensorflow:Saving dict for global step 17000: global_step = 17000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8451934, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8709208, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9210688\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 17000: model_files_512/model.ckpt-17000\n",
      "INFO:tensorflow:Validation (step 17000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9210688, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8451934, global_step = 17000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8709208\n",
      "INFO:tensorflow:loss = 0.37602577, step = 17000 (70.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50869\n",
      "INFO:tensorflow:loss = 0.45434862, step = 17100 (16.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03455\n",
      "INFO:tensorflow:loss = 0.5321552, step = 17200 (16.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13222\n",
      "INFO:tensorflow:loss = 0.6098209, step = 17300 (16.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1493\n",
      "INFO:tensorflow:loss = 0.5565097, step = 17400 (16.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11667\n",
      "INFO:tensorflow:loss = 0.3910312, step = 17500 (16.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24819\n",
      "INFO:tensorflow:loss = 0.42952564, step = 17600 (16.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99324\n",
      "INFO:tensorflow:loss = 0.6581071, step = 17700 (16.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19432\n",
      "INFO:tensorflow:loss = 0.4522783, step = 17800 (16.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10438\n",
      "INFO:tensorflow:loss = 0.581995, step = 17900 (16.383 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.8192\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:45:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:46:16\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8457574, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8717032, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92097044\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_files_512/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92097044, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8457574, global_step = 18000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8717032\n",
      "INFO:tensorflow:loss = 0.33246905, step = 18000 (74.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42863\n",
      "INFO:tensorflow:loss = 0.396295, step = 18100 (16.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21218\n",
      "INFO:tensorflow:loss = 1.3850516, step = 18200 (16.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05448\n",
      "INFO:tensorflow:loss = 0.84849876, step = 18300 (16.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12197\n",
      "INFO:tensorflow:loss = 1.5401795, step = 18400 (16.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11062\n",
      "INFO:tensorflow:loss = 0.45171535, step = 18500 (16.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97594\n",
      "INFO:tensorflow:loss = 0.28649798, step = 18600 (16.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21059\n",
      "INFO:tensorflow:loss = 0.3923467, step = 18700 (16.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11451\n",
      "INFO:tensorflow:loss = 0.5569443, step = 18800 (16.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2019\n",
      "INFO:tensorflow:loss = 0.6694445, step = 18900 (16.125 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.79824\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:49:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-19000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:50:03\n",
      "INFO:tensorflow:Saving dict for global step 19000: global_step = 19000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8531505, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8777878, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92498034\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19000: model_files_512/model.ckpt-19000\n",
      "INFO:tensorflow:Validation (step 19000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92498034, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8531505, global_step = 19000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8777878\n",
      "INFO:tensorflow:loss = 0.48309606, step = 19000 (79.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33869\n",
      "INFO:tensorflow:loss = 0.9287768, step = 19100 (15.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10479\n",
      "INFO:tensorflow:loss = 1.9104034, step = 19200 (16.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10303\n",
      "INFO:tensorflow:loss = 0.56748366, step = 19300 (16.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19602\n",
      "INFO:tensorflow:loss = 0.7349394, step = 19400 (16.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09015\n",
      "INFO:tensorflow:loss = 0.39149308, step = 19500 (16.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22282\n",
      "INFO:tensorflow:loss = 0.5104129, step = 19600 (16.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14038\n",
      "INFO:tensorflow:loss = 0.53139794, step = 19700 (16.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01449\n",
      "INFO:tensorflow:loss = 1.3075162, step = 19800 (16.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18494\n",
      "INFO:tensorflow:loss = 0.545756, step = 19900 (16.169 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74058\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:52:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:53:48\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8526274, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.87678456, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92459834\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_files_512/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92459834, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8526274, global_step = 20000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.87678456\n",
      "INFO:tensorflow:loss = 1.1023749, step = 20000 (78.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36521\n",
      "INFO:tensorflow:loss = 0.63180405, step = 20100 (15.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07179\n",
      "INFO:tensorflow:loss = 0.93995833, step = 20200 (16.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17399\n",
      "INFO:tensorflow:loss = 0.48317975, step = 20300 (16.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23031\n",
      "INFO:tensorflow:loss = 0.5112417, step = 20400 (16.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11626\n",
      "INFO:tensorflow:loss = 0.505206, step = 20500 (16.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12775\n",
      "INFO:tensorflow:loss = 0.5134162, step = 20600 (16.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07357\n",
      "INFO:tensorflow:loss = 0.82436097, step = 20700 (16.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20766\n",
      "INFO:tensorflow:loss = 1.0385889, step = 20800 (16.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1827\n",
      "INFO:tensorflow:loss = 0.6467402, step = 20900 (16.173 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.80378\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T19:56:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-21000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-19:57:25\n",
      "INFO:tensorflow:Saving dict for global step 21000: global_step = 21000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8552105, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88000506, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92596537\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21000: model_files_512/model.ckpt-21000\n",
      "INFO:tensorflow:Validation (step 21000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92596537, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8552105, global_step = 21000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88000506\n",
      "INFO:tensorflow:loss = 0.41846594, step = 21000 (71.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50454\n",
      "INFO:tensorflow:loss = 1.2956603, step = 21100 (15.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05889\n",
      "INFO:tensorflow:loss = 0.73170125, step = 21200 (16.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12275\n",
      "INFO:tensorflow:loss = 0.48151213, step = 21300 (16.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13763\n",
      "INFO:tensorflow:loss = 0.36150405, step = 21400 (16.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26198\n",
      "INFO:tensorflow:loss = 0.53058743, step = 21500 (15.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12936\n",
      "INFO:tensorflow:loss = 0.47570184, step = 21600 (16.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04688\n",
      "INFO:tensorflow:loss = 0.8876872, step = 21700 (16.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02257\n",
      "INFO:tensorflow:loss = 0.47631437, step = 21800 (16.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09979\n",
      "INFO:tensorflow:loss = 0.647958, step = 21900 (16.396 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82517\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:00:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:01:04\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8548829, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.87965417, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9253332\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_files_512/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9253332, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8548829, global_step = 22000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.87965417\n",
      "INFO:tensorflow:loss = 0.34263316, step = 22000 (71.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49304\n",
      "INFO:tensorflow:loss = 0.51967514, step = 22100 (15.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95335\n",
      "INFO:tensorflow:loss = 0.6182869, step = 22200 (16.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14436\n",
      "INFO:tensorflow:loss = 0.48633355, step = 22300 (16.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11703\n",
      "INFO:tensorflow:loss = 0.3420017, step = 22400 (16.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21019\n",
      "INFO:tensorflow:loss = 0.38368738, step = 22500 (16.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23126\n",
      "INFO:tensorflow:loss = 0.31427363, step = 22600 (16.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09851\n",
      "INFO:tensorflow:loss = 0.6861754, step = 22700 (16.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23254\n",
      "INFO:tensorflow:loss = 0.65999717, step = 22800 (16.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15325\n",
      "INFO:tensorflow:loss = 0.38097772, step = 22900 (16.252 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.86716\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:03:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-23000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:04:51\n",
      "INFO:tensorflow:Saving dict for global step 23000: global_step = 23000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8560325, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8821578, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92609006\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 23000: model_files_512/model.ckpt-23000\n",
      "INFO:tensorflow:Validation (step 23000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92609006, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8560325, global_step = 23000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8821578\n",
      "INFO:tensorflow:loss = 0.7034879, step = 23000 (80.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30295\n",
      "INFO:tensorflow:loss = 0.2594557, step = 23100 (16.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06232\n",
      "INFO:tensorflow:loss = 0.4951353, step = 23200 (16.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21639\n",
      "INFO:tensorflow:loss = 0.78668815, step = 23300 (16.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.30406\n",
      "INFO:tensorflow:loss = 0.3700105, step = 23400 (15.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11353\n",
      "INFO:tensorflow:loss = 0.30613533, step = 23500 (16.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08675\n",
      "INFO:tensorflow:loss = 0.488274, step = 23600 (16.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11665\n",
      "INFO:tensorflow:loss = 1.0151831, step = 23700 (16.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98985\n",
      "INFO:tensorflow:loss = 0.56486106, step = 23800 (16.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24495\n",
      "INFO:tensorflow:loss = 0.5784084, step = 23900 (16.013 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.70418\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:07:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:08:36\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8604823, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.884322, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9281182\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_files_512/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9281182, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8604823, global_step = 24000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.884322\n",
      "INFO:tensorflow:loss = 0.52456766, step = 24000 (78.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36253\n",
      "INFO:tensorflow:loss = 0.459747, step = 24100 (16.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26774\n",
      "INFO:tensorflow:loss = 0.35256034, step = 24200 (15.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05544\n",
      "INFO:tensorflow:loss = 0.51712316, step = 24300 (16.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13682\n",
      "INFO:tensorflow:loss = 0.5969344, step = 24400 (16.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17694\n",
      "INFO:tensorflow:loss = 1.1771326, step = 24500 (16.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11856\n",
      "INFO:tensorflow:loss = 0.48680818, step = 24600 (16.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13439\n",
      "INFO:tensorflow:loss = 0.42708644, step = 24700 (16.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.31277\n",
      "INFO:tensorflow:loss = 0.50053406, step = 24800 (15.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1659\n",
      "INFO:tensorflow:loss = 0.2894309, step = 24900 (16.219 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.75882\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:11:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:12:20\n",
      "INFO:tensorflow:Saving dict for global step 25000: global_step = 25000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8607327, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88533914, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9287359\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25000: model_files_512/model.ckpt-25000\n",
      "INFO:tensorflow:Validation (step 25000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9287359, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8607327, global_step = 25000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88533914\n",
      "INFO:tensorflow:loss = 1.0006167, step = 25000 (78.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36501\n",
      "INFO:tensorflow:loss = 0.93713635, step = 25100 (16.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.34791\n",
      "INFO:tensorflow:loss = 0.47348025, step = 25200 (15.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02453\n",
      "INFO:tensorflow:loss = 1.1481563, step = 25300 (16.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16359\n",
      "INFO:tensorflow:loss = 2.0810077, step = 25400 (16.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20842\n",
      "INFO:tensorflow:loss = 0.5870524, step = 25500 (16.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12322\n",
      "INFO:tensorflow:loss = 0.44545683, step = 25600 (16.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99918\n",
      "INFO:tensorflow:loss = 0.51712036, step = 25700 (16.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26627\n",
      "INFO:tensorflow:loss = 0.51400834, step = 25800 (15.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08378\n",
      "INFO:tensorflow:loss = 0.5933226, step = 25900 (16.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.84378\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:15:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:16:10\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8653588, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.889487, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9308275\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_files_512/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9308275, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8653588, global_step = 26000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.889487\n",
      "INFO:tensorflow:loss = 0.6029047, step = 26000 (84.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.24822\n",
      "INFO:tensorflow:loss = 1.0514318, step = 26100 (16.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10309\n",
      "INFO:tensorflow:loss = 0.6445008, step = 26200 (16.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.30476\n",
      "INFO:tensorflow:loss = 0.38759953, step = 26300 (15.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29839\n",
      "INFO:tensorflow:loss = 0.45985797, step = 26400 (15.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02486\n",
      "INFO:tensorflow:loss = 0.45412108, step = 26500 (16.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.96595\n",
      "INFO:tensorflow:loss = 1.0696698, step = 26600 (16.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07996\n",
      "INFO:tensorflow:loss = 0.31634098, step = 26700 (16.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14218\n",
      "INFO:tensorflow:loss = 0.3325555, step = 26800 (16.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23759\n",
      "INFO:tensorflow:loss = 0.51879, step = 26900 (16.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.85301\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:19:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-27000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:19:53\n",
      "INFO:tensorflow:Saving dict for global step 27000: global_step = 27000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8663597, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.890561, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9312692\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 27000: model_files_512/model.ckpt-27000\n",
      "INFO:tensorflow:Validation (step 27000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9312692, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8663597, global_step = 27000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.890561\n",
      "INFO:tensorflow:loss = 0.35750577, step = 27000 (75.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40548\n",
      "INFO:tensorflow:loss = 1.1204128, step = 27100 (16.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17921\n",
      "INFO:tensorflow:loss = 0.43652964, step = 27200 (16.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18737\n",
      "INFO:tensorflow:loss = 0.6125087, step = 27300 (16.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18155\n",
      "INFO:tensorflow:loss = 0.524702, step = 27400 (16.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13611\n",
      "INFO:tensorflow:loss = 0.47333944, step = 27500 (16.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11747\n",
      "INFO:tensorflow:loss = 0.8301597, step = 27600 (16.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0183\n",
      "INFO:tensorflow:loss = 0.50787884, step = 27700 (16.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.86806\n",
      "INFO:tensorflow:loss = 0.7051478, step = 27800 (17.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16227\n",
      "INFO:tensorflow:loss = 0.41326535, step = 27900 (16.228 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.69745\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:22:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:23:31\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87309295, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8955069, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9345491\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_files_512/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9345491, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87309295, global_step = 28000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8955069\n",
      "INFO:tensorflow:loss = 0.28002554, step = 28000 (70.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52444\n",
      "INFO:tensorflow:loss = 0.55577904, step = 28100 (16.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2126\n",
      "INFO:tensorflow:loss = 0.32335073, step = 28200 (16.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18616\n",
      "INFO:tensorflow:loss = 0.35816297, step = 28300 (16.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02242\n",
      "INFO:tensorflow:loss = 0.55104643, step = 28400 (16.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08197\n",
      "INFO:tensorflow:loss = 0.44189978, step = 28500 (16.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13619\n",
      "INFO:tensorflow:loss = 0.4161089, step = 28600 (16.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1351\n",
      "INFO:tensorflow:loss = 1.1045519, step = 28700 (16.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.30205\n",
      "INFO:tensorflow:loss = 0.3502217, step = 28800 (15.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08472\n",
      "INFO:tensorflow:loss = 0.52930915, step = 28900 (16.437 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82853\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:26:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-29000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:27:08\n",
      "INFO:tensorflow:Saving dict for global step 29000: global_step = 29000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86757827, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89131516, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93187064\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 29000: model_files_512/model.ckpt-29000\n",
      "INFO:tensorflow:Validation (step 29000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93187064, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86757827, global_step = 29000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89131516\n",
      "INFO:tensorflow:loss = 1.333082, step = 29000 (70.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53124\n",
      "INFO:tensorflow:loss = 0.46169782, step = 29100 (15.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19707\n",
      "INFO:tensorflow:loss = 0.48680475, step = 29200 (16.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.35686\n",
      "INFO:tensorflow:loss = 0.6984028, step = 29300 (15.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16239\n",
      "INFO:tensorflow:loss = 0.55281806, step = 29400 (16.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00467\n",
      "INFO:tensorflow:loss = 0.31802803, step = 29500 (16.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19521\n",
      "INFO:tensorflow:loss = 0.39121678, step = 29600 (16.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.028\n",
      "INFO:tensorflow:loss = 0.64640784, step = 29700 (16.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10035\n",
      "INFO:tensorflow:loss = 0.8134623, step = 29800 (16.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08162\n",
      "INFO:tensorflow:loss = 0.62503785, step = 29900 (16.445 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.85235\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:29:59Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:30:47\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8712623, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89491004, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9335922\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_files_512/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9335922, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8712623, global_step = 30000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89491004\n",
      "INFO:tensorflow:loss = 0.83046556, step = 30000 (73.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43614\n",
      "INFO:tensorflow:loss = 0.28946584, step = 30100 (16.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06345\n",
      "INFO:tensorflow:loss = 0.40859678, step = 30200 (16.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15587\n",
      "INFO:tensorflow:loss = 0.42098874, step = 30300 (16.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11056\n",
      "INFO:tensorflow:loss = 0.3456241, step = 30400 (16.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27357\n",
      "INFO:tensorflow:loss = 0.3068649, step = 30500 (15.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09151\n",
      "INFO:tensorflow:loss = 0.24920756, step = 30600 (16.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03302\n",
      "INFO:tensorflow:loss = 0.70107836, step = 30700 (16.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22958\n",
      "INFO:tensorflow:loss = 0.29256448, step = 30800 (16.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98222\n",
      "INFO:tensorflow:loss = 1.1187567, step = 30900 (16.717 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.79954\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:33:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-31000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:34:35\n",
      "INFO:tensorflow:Saving dict for global step 31000: global_step = 31000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8713228, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.895217, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93386424\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 31000: model_files_512/model.ckpt-31000\n",
      "INFO:tensorflow:Validation (step 31000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93386424, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8713228, global_step = 31000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.895217\n",
      "INFO:tensorflow:loss = 0.24122626, step = 31000 (80.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31545\n",
      "INFO:tensorflow:loss = 0.2968919, step = 31100 (16.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21949\n",
      "INFO:tensorflow:loss = 0.343622, step = 31200 (16.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05159\n",
      "INFO:tensorflow:loss = 0.57776815, step = 31300 (16.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2177\n",
      "INFO:tensorflow:loss = 0.42677754, step = 31400 (16.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03815\n",
      "INFO:tensorflow:loss = 0.39111057, step = 31500 (16.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22886\n",
      "INFO:tensorflow:loss = 0.71196437, step = 31600 (16.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09867\n",
      "INFO:tensorflow:loss = 0.35746902, step = 31700 (16.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10965\n",
      "INFO:tensorflow:loss = 0.8104865, step = 31800 (16.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13544\n",
      "INFO:tensorflow:loss = 0.6746775, step = 31900 (16.299 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82248\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:37:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:38:20\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87835413, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.9004658, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.937289\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_files_512/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.937289, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87835413, global_step = 32000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.9004658\n",
      "INFO:tensorflow:loss = 0.3989464, step = 32000 (77.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36301\n",
      "INFO:tensorflow:loss = 0.50557846, step = 32100 (16.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04534\n",
      "INFO:tensorflow:loss = 0.5898706, step = 32200 (16.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11168\n",
      "INFO:tensorflow:loss = 0.8621374, step = 32300 (16.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1124\n",
      "INFO:tensorflow:loss = 1.113974, step = 32400 (16.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23784\n",
      "INFO:tensorflow:loss = 0.79301333, step = 32500 (16.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0779\n",
      "INFO:tensorflow:loss = 0.33200404, step = 32600 (16.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05375\n",
      "INFO:tensorflow:loss = 0.8200127, step = 32700 (16.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14966\n",
      "INFO:tensorflow:loss = 0.57549083, step = 32800 (16.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13878\n",
      "INFO:tensorflow:loss = 0.38125548, step = 32900 (16.290 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74004\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:41:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-33000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:42:13\n",
      "INFO:tensorflow:Saving dict for global step 33000: global_step = 33000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8748051, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.897685, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9354257\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 33000: model_files_512/model.ckpt-33000\n",
      "INFO:tensorflow:Validation (step 33000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9354257, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8748051, global_step = 33000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.897685\n",
      "INFO:tensorflow:loss = 2.0691614, step = 33000 (86.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.2319\n",
      "INFO:tensorflow:loss = 0.5368506, step = 33100 (16.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27077\n",
      "INFO:tensorflow:loss = 0.3349476, step = 33200 (15.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14732\n",
      "INFO:tensorflow:loss = 0.41215545, step = 33300 (16.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09317\n",
      "INFO:tensorflow:loss = 0.53667647, step = 33400 (16.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2557\n",
      "INFO:tensorflow:loss = 1.7992646, step = 33500 (15.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11979\n",
      "INFO:tensorflow:loss = 1.2625663, step = 33600 (16.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19288\n",
      "INFO:tensorflow:loss = 0.31770352, step = 33700 (16.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24462\n",
      "INFO:tensorflow:loss = 0.7451619, step = 33800 (16.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99667\n",
      "INFO:tensorflow:loss = 0.55932766, step = 33900 (16.676 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.75309\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:45:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:46:03\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87488484, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89767325, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9357678\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_files_512/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9357678, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87488484, global_step = 34000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89767325\n",
      "INFO:tensorflow:loss = 0.5070703, step = 34000 (83.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.2647\n",
      "INFO:tensorflow:loss = 0.39758217, step = 34100 (16.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15352\n",
      "INFO:tensorflow:loss = 0.69822556, step = 34200 (16.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03558\n",
      "INFO:tensorflow:loss = 0.33027464, step = 34300 (16.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07046\n",
      "INFO:tensorflow:loss = 0.5110447, step = 34400 (16.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15159\n",
      "INFO:tensorflow:loss = 0.5556421, step = 34500 (16.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14255\n",
      "INFO:tensorflow:loss = 0.8490066, step = 34600 (16.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12675\n",
      "INFO:tensorflow:loss = 0.50468546, step = 34700 (16.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20322\n",
      "INFO:tensorflow:loss = 0.53496414, step = 34800 (16.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13218\n",
      "INFO:tensorflow:loss = 0.30539384, step = 34900 (16.309 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.84412\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:48:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-35000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:49:50\n",
      "INFO:tensorflow:Saving dict for global step 35000: global_step = 35000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87079513, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89493823, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.933787\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: model_files_512/model.ckpt-35000\n",
      "INFO:tensorflow:Validation (step 35000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.933787, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87079513, global_step = 35000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89493823\n",
      "INFO:tensorflow:loss = 0.28272817, step = 35000 (80.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30458\n",
      "INFO:tensorflow:loss = 0.41248888, step = 35100 (16.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09047\n",
      "INFO:tensorflow:loss = 0.4404698, step = 35200 (16.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06442\n",
      "INFO:tensorflow:loss = 0.31303245, step = 35300 (16.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08952\n",
      "INFO:tensorflow:loss = 0.4384096, step = 35400 (16.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11479\n",
      "INFO:tensorflow:loss = 0.40756363, step = 35500 (16.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21925\n",
      "INFO:tensorflow:loss = 0.30194855, step = 35600 (16.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19194\n",
      "INFO:tensorflow:loss = 0.42254907, step = 35700 (16.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15075\n",
      "INFO:tensorflow:loss = 0.27713513, step = 35800 (16.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09142\n",
      "INFO:tensorflow:loss = 0.4396537, step = 35900 (16.418 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.80484\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:52:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:53:42\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87642515, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89973456, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93643034\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_files_512/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93643034, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87642515, global_step = 36000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89973456\n",
      "INFO:tensorflow:loss = 0.29316887, step = 36000 (84.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.24713\n",
      "INFO:tensorflow:loss = 0.57830924, step = 36100 (16.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08863\n",
      "INFO:tensorflow:loss = 0.4905576, step = 36200 (16.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26753\n",
      "INFO:tensorflow:loss = 0.7448426, step = 36300 (15.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04966\n",
      "INFO:tensorflow:loss = 0.4310071, step = 36400 (16.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13248\n",
      "INFO:tensorflow:loss = 0.6192246, step = 36500 (16.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08457\n",
      "INFO:tensorflow:loss = 0.3214038, step = 36600 (16.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18444\n",
      "INFO:tensorflow:loss = 0.45348802, step = 36700 (16.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17563\n",
      "INFO:tensorflow:loss = 1.3005015, step = 36800 (16.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18384\n",
      "INFO:tensorflow:loss = 0.5003378, step = 36900 (16.170 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.91287\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T20:56:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-37000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-20:57:21\n",
      "INFO:tensorflow:Saving dict for global step 37000: global_step = 37000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8738204, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8963937, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93501395\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 37000: model_files_512/model.ckpt-37000\n",
      "INFO:tensorflow:Validation (step 37000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93501395, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8738204, global_step = 37000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8963937\n",
      "INFO:tensorflow:loss = 0.35245925, step = 37000 (72.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46201\n",
      "INFO:tensorflow:loss = 0.41456798, step = 37100 (16.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24469\n",
      "INFO:tensorflow:loss = 0.45640153, step = 37200 (16.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06907\n",
      "INFO:tensorflow:loss = 0.7145841, step = 37300 (16.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19335\n",
      "INFO:tensorflow:loss = 0.41188666, step = 37400 (16.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18779\n",
      "INFO:tensorflow:loss = 0.3066335, step = 37500 (16.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10799\n",
      "INFO:tensorflow:loss = 0.43441084, step = 37600 (16.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14713\n",
      "INFO:tensorflow:loss = 0.7409263, step = 37700 (16.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05903\n",
      "INFO:tensorflow:loss = 0.34283325, step = 37800 (16.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95522\n",
      "INFO:tensorflow:loss = 0.45229325, step = 37900 (16.797 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74184\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:00:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:01:03\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8771212, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8990377, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93646836\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_files_512/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93646836, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8771212, global_step = 38000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8990377\n",
      "INFO:tensorflow:loss = 0.8423682, step = 38000 (75.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42743\n",
      "INFO:tensorflow:loss = 0.6278523, step = 38100 (15.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14864\n",
      "INFO:tensorflow:loss = 0.41993842, step = 38200 (16.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20334\n",
      "INFO:tensorflow:loss = 0.6937829, step = 38300 (16.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10944\n",
      "INFO:tensorflow:loss = 0.3368455, step = 38400 (16.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10537\n",
      "INFO:tensorflow:loss = 0.9036839, step = 38500 (16.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17359\n",
      "INFO:tensorflow:loss = 0.43370652, step = 38600 (16.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21784\n",
      "INFO:tensorflow:loss = 0.612415, step = 38700 (16.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08832\n",
      "INFO:tensorflow:loss = 0.4907272, step = 38800 (16.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16512\n",
      "INFO:tensorflow:loss = 0.49310175, step = 38900 (16.220 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74447\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:03:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-39000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:04:51\n",
      "INFO:tensorflow:Saving dict for global step 39000: global_step = 39000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8762022, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89927393, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9359851\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 39000: model_files_512/model.ckpt-39000\n",
      "INFO:tensorflow:Validation (step 39000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9359851, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8762022, global_step = 39000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89927393\n",
      "INFO:tensorflow:loss = 0.8247489, step = 39000 (81.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30093\n",
      "INFO:tensorflow:loss = 0.95924103, step = 39100 (16.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.31277\n",
      "INFO:tensorflow:loss = 0.41418478, step = 39200 (15.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12859\n",
      "INFO:tensorflow:loss = 2.079776, step = 39300 (16.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20531\n",
      "INFO:tensorflow:loss = 0.33002454, step = 39400 (16.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19455\n",
      "INFO:tensorflow:loss = 0.30188194, step = 39500 (16.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18098\n",
      "INFO:tensorflow:loss = 0.53001994, step = 39600 (16.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21367\n",
      "INFO:tensorflow:loss = 0.43520027, step = 39700 (16.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14033\n",
      "INFO:tensorflow:loss = 0.49889603, step = 39800 (16.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25816\n",
      "INFO:tensorflow:loss = 0.3706635, step = 39900 (15.980 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.84143\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:07:41Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_512/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:08:38\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8718006, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8956373, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9337516\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: model_files_512/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9337516, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8718006, global_step = 40000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8956373\n",
      "INFO:tensorflow:loss = 0.7769466, step = 40000 (81.708 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_512/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7769466.\n",
      "Time: 9010.76 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding, metrics\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_512'\n",
    "\n",
    "# Define hparams\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "hparams.num_encoder_layers = 2\n",
    "hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 2 \n",
    "hparams.dropout =0.2\n",
    "hparams.max_input_seq_length = \n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams =True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "# create run config\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=1000,\n",
    "    )\n",
    "# t2t_problem.eval_metrics()\n",
    "\n",
    "t2t_model_512 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, \n",
    "        data_dir='./data', \n",
    "        train_steps=40001,\n",
    "        eval_steps=100,\n",
    "        min_eval_frequency=1000,\n",
    "    )\n",
    "\n",
    "hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_512.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_adam_beta2': 0.98, 'factored_logits': False, 'learning_rate_decay_scheme': 'noam', 'scheduled_sampling_warmup_steps': 50000, 'learning_rate_decay_rate': 1.0, 'heads_share_relative_embedding': False, 'overload_eval_metric_name': '', 'prepend_mode': 'prepend_inputs_masked_attention', 'initializer_gain': 1.0, 'learning_rate_warmup_steps': 8000, 'tpu_enable_host_call': False, 'weight_dtype': 'float32', 'optimizer_adafactor_factored': True, 'ffn_layer': 'dense_relu_dense', 'summarize_vars': False, 'force_full_predict': False, 'multiproblem_mixing_schedule': 'constant', 'num_encoder_layers': 2, 'filter_size': 2048, 'min_length': 0, 'activation_dtype': 'float32', 'dropout': 0.2, 'learning_rate_minimum': None, 'moe_overhead_eval': 2.0, 'label_smoothing': 0.1, 'learning_rate_decay_staircase': False, 'optimizer_adafactor_memory_exponent': 0.8, 'optimizer_adafactor_beta1': 0.0, 'multiproblem_per_task_threshold': '', 'multiproblem_fixed_train_length': -1, 'optimizer_adafactor_clipping_threshold': 1.0, 'self_attention_type': 'dot_product', 'scheduled_sampling_prob': 0.0, 'use_pad_remover': True, 'hidden_size': 512, 'num_heads': 8, 'moe_loss_coef': 0.001, 'max_relative_position': 0, 'optimizer_adam_beta1': 0.9, 'multiproblem_reweight_label_loss': False, 'batch_shuffle_size': 512, 'add_relative_to_values': False, 'eval_run_autoregressive': False, 'learning_rate': 0.1, 'relu_dropout_broadcast_dims': '', 'moe_hidden_sizes': '2048', 'learning_rate_decay_steps': 5000, 'compress_steps': 0, 'norm_epsilon': 1e-06, 'layer_prepostprocess_dropout': 0.1, 'moe_k': 2, 'kernel_height': 3, 'layer_postprocess_sequence': 'da', 'optimizer_adafactor_decay_type': 'pow', 'weight_decay': 0.0, 'parameter_attention_key_channels': 0, 'attention_variables_3d': False, 'daisy_chain_variables': True, 'optimizer_adam_epsilon': 1e-09, 'symbol_modality_skip_top': False, 'sampling_method': 'argmax', 'optimizer_momentum_nesterov': False, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'attention_dropout_broadcast_dims': '', 'initializer': 'uniform_unit_scaling', 'conv_first_kernel': 3, 'min_length_bucket': 8, 'moe_num_experts': 16, 'multiproblem_target_eval_only': False, 'mlperf_mode': False, 'batch_size': 1024, 'modality': {}, 'optimizer_zero_grads': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'optimizer_momentum_momentum': 0.9, 'multiply_embedding_mode': 'sqrt_depth', 'use_fixed_batch_size': False, 'eval_drop_long_sequences': False, 'warm_start_from_second': '', 'video_num_target_frames': 1, 'clip_grad_norm': 0.0, 'multiproblem_vocab_size': -1, 'max_length': 0, 'pretrained_model_dir': '', 'no_data_parallelism': False, 'attention_dropout': 0.1, 'split_to_length': 0, 'max_input_seq_length': 1024, 'max_target_seq_length': 0, 'parameter_attention_value_channels': 0, 'grad_noise_scale': 0.0, 'length_bucket_step': 1.1, 'optimizer_adafactor_beta2': 0.999, 'learning_rate_constant': 1.0, 'optimizer': 'Adam', 'video_num_input_frames': 1, 'learning_rate_cosine_cycle_steps': 250000, 'attention_key_channels': 0, 'shared_embedding': False, 'multiproblem_label_weight': 0.5, 'optimizer_multistep_accumulate_steps': None, 'unidirectional_encoder': False, 'nbr_decoder_problems': 1, 'shared_embedding_and_softmax_weights': True, 'relu_dropout': 0.1, 'summarize_grads': False, 'multiproblem_max_input_length': -1, 'norm_type': 'layer', 'symbol_dropout': 0.0, 'pad_batch': False, 'sampling_temp': 1.0, 'multiproblem_schedule_threshold': 0.5, 'attention_value_channels': 0, 'use_target_space_embedding': True, 'layer_preprocess_sequence': 'n', 'weight_noise': 0.0, 'causal_decoder_self_attention': True, 'num_hidden_layers': 6, 'layer_prepostprocess_dropout_broadcast_dims': '', 'multiproblem_schedule_max_examples': 10000000.0, 'learning_rate_schedule': 'legacy', 'symbol_modality_num_shards': 16, 'vocab_divisor': 1, 'num_decoder_layers': 2, 'pos': 'timing', 'proximity_bias': False, 'kernel_width': 1, 'moe_overhead_train': 1.0, 'multiproblem_max_target_length': -1}\n",
      "{'num_samples': -1, 'write_beam_scores': False, 'log_results': True, 'return_beams': True, 'multiproblem_task_id': -1, 'batch_size': 0, 'identity_output': False, 'decode_in_memory': False, 'mlperf_decode_step': 0.0, 'shards': 1, 'max_input_size': -1, 'shard_id': 0, 'frames_per_second': 10, 'mlperf_success': False, 'force_decode_length': False, 'guess_and_check_epsilon': -1, 'display_decoded_images': False, 'eos_penalty': 0.0, 'extra_length': 100, 'mlperf_threshold': 25.0, 'vgg_ckpt_path': '', 'delimiter': '\\n', 'decode_to_file': None, 'block_size': 0, 'decode_timeout_mins': 240, 'skip_eos_postprocess': False, 'shards_start_offset': 0, 'guess_and_check_top_k': 0, 'summaries_log_dir': 'decode', 'border_percent': 2, 'max_display_outputs': 10, 'num_decodes': 1, 'save_images': False, 'beam_size': 4, 'max_display_decodes': 5, 'shard_google_format': False, 'alpha': 0.6}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_protocol': None, '_save_checkpoints_steps': 1000, '_master': '', '_device_fn': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_secs': None, '_save_summary_steps': 100, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", 'use_tpu': False, '_keep_checkpoint_max': 20, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", 't2t_device_info': {'num_async_replicas': 1}, '_task_type': None, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6a78d34da0>, '_num_worker_replicas': 0, '_eval_distribute': None, '_is_chief': True, '_tf_random_seed': None, '_model_dir': 'model_files_256', '_task_id': 0, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_train_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f6a72653cf8>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f6a71d8a378>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f6cf91f1cc0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f6cf91f1cf8>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f6cfa244b70>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f6cfa244b70>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 35396096\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:loss = 10.968329, step = 0\n",
      "INFO:tensorflow:global_step/sec: 5.51456\n",
      "INFO:tensorflow:loss = 9.443371, step = 100 (18.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10584\n",
      "INFO:tensorflow:loss = 8.01007, step = 200 (16.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13299\n",
      "INFO:tensorflow:loss = 7.0976048, step = 300 (16.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26872\n",
      "INFO:tensorflow:loss = 6.5317473, step = 400 (15.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25614\n",
      "INFO:tensorflow:loss = 6.064748, step = 500 (15.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15156\n",
      "INFO:tensorflow:loss = 6.1698384, step = 600 (16.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10149\n",
      "INFO:tensorflow:loss = 5.9234796, step = 700 (16.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.92893\n",
      "INFO:tensorflow:loss = 6.149897, step = 800 (16.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08012\n",
      "INFO:tensorflow:loss = 6.0633597, step = 900 (16.447 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74762\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:12:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:12:56\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.011570761, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.04138874, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.2054125\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: model_files_256/model.ckpt-1000\n",
      "INFO:tensorflow:Validation (step 1000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.2054125, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.011570761, global_step = 1000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.04138874\n",
      "INFO:tensorflow:loss = 5.936882, step = 1000 (78.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34873\n",
      "INFO:tensorflow:loss = 6.4960904, step = 1100 (16.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24385\n",
      "INFO:tensorflow:loss = 5.539308, step = 1200 (16.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07908\n",
      "INFO:tensorflow:loss = 5.15049, step = 1300 (16.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00903\n",
      "INFO:tensorflow:loss = 5.369429, step = 1400 (16.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21795\n",
      "INFO:tensorflow:loss = 5.5679774, step = 1500 (16.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18475\n",
      "INFO:tensorflow:loss = 6.1002665, step = 1600 (16.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09708\n",
      "INFO:tensorflow:loss = 5.145973, step = 1700 (16.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.92419\n",
      "INFO:tensorflow:loss = 5.982272, step = 1800 (16.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05379\n",
      "INFO:tensorflow:loss = 4.8232465, step = 1900 (16.519 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82814\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:15:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:16:43\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.013828904, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.04861457, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.20823982\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_files_256/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.20823982, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.013828904, global_step = 2000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.04861457\n",
      "INFO:tensorflow:loss = 4.8830748, step = 2000 (79.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33637\n",
      "INFO:tensorflow:loss = 6.1530643, step = 2100 (16.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16278\n",
      "INFO:tensorflow:loss = 5.302291, step = 2200 (16.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28509\n",
      "INFO:tensorflow:loss = 5.457295, step = 2300 (15.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01827\n",
      "INFO:tensorflow:loss = 5.5816035, step = 2400 (16.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04399\n",
      "INFO:tensorflow:loss = 7.353746, step = 2500 (16.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25903\n",
      "INFO:tensorflow:loss = 5.567578, step = 2600 (15.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14244\n",
      "INFO:tensorflow:loss = 6.394186, step = 2700 (16.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0953\n",
      "INFO:tensorflow:loss = 5.2940392, step = 2800 (16.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07671\n",
      "INFO:tensorflow:loss = 4.842325, step = 2900 (16.456 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.83522\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:19:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:20:31\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.025553888, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.07700053, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.25516623\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: model_files_256/model.ckpt-3000\n",
      "INFO:tensorflow:Validation (step 3000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.25516623, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.025553888, global_step = 3000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.07700053\n",
      "INFO:tensorflow:loss = 5.0348487, step = 3000 (81.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30729\n",
      "INFO:tensorflow:loss = 4.6017914, step = 3100 (16.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01047\n",
      "INFO:tensorflow:loss = 5.406023, step = 3200 (16.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07884\n",
      "INFO:tensorflow:loss = 4.586055, step = 3300 (16.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18798\n",
      "INFO:tensorflow:loss = 4.952958, step = 3400 (16.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02301\n",
      "INFO:tensorflow:loss = 5.5313134, step = 3500 (16.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19235\n",
      "INFO:tensorflow:loss = 4.173597, step = 3600 (16.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19786\n",
      "INFO:tensorflow:loss = 5.5594306, step = 3700 (16.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29067\n",
      "INFO:tensorflow:loss = 5.0909066, step = 3800 (15.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09032\n",
      "INFO:tensorflow:loss = 3.53989, step = 3900 (16.419 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.70923\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:23:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:24:18\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.17486005, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.24709788, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.44528222\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_files_256/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.44528222, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.17486005, global_step = 4000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.24709788\n",
      "INFO:tensorflow:loss = 4.7339163, step = 4000 (80.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32578\n",
      "INFO:tensorflow:loss = 3.208513, step = 4100 (16.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14769\n",
      "INFO:tensorflow:loss = 3.875027, step = 4200 (16.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06605\n",
      "INFO:tensorflow:loss = 2.5145457, step = 4300 (16.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95052\n",
      "INFO:tensorflow:loss = 4.12553, step = 4400 (16.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1108\n",
      "INFO:tensorflow:loss = 3.3328676, step = 4500 (16.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2586\n",
      "INFO:tensorflow:loss = 3.541085, step = 4600 (15.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13304\n",
      "INFO:tensorflow:loss = 2.8477767, step = 4700 (16.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.33017\n",
      "INFO:tensorflow:loss = 2.2047968, step = 4800 (15.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13066\n",
      "INFO:tensorflow:loss = 2.202257, step = 4900 (16.312 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74647\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:27:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:28:05\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.5303322, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.59500146, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.7399334\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: model_files_256/model.ckpt-5000\n",
      "INFO:tensorflow:Validation (step 5000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.7399334, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.5303322, global_step = 5000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.59500146\n",
      "INFO:tensorflow:loss = 1.0344819, step = 5000 (80.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32249\n",
      "INFO:tensorflow:loss = 3.2302287, step = 5100 (16.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1637\n",
      "INFO:tensorflow:loss = 2.3476474, step = 5200 (16.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22849\n",
      "INFO:tensorflow:loss = 2.2427795, step = 5300 (16.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16499\n",
      "INFO:tensorflow:loss = 1.6419603, step = 5400 (16.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26569\n",
      "INFO:tensorflow:loss = 0.7040206, step = 5500 (15.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12663\n",
      "INFO:tensorflow:loss = 2.540364, step = 5600 (16.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24083\n",
      "INFO:tensorflow:loss = 1.0883138, step = 5700 (16.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.134\n",
      "INFO:tensorflow:loss = 0.7280119, step = 5800 (16.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20637\n",
      "INFO:tensorflow:loss = 1.5487221, step = 5900 (16.114 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82302\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:30:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:31:50\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.74797744, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.7887391, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8700415\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_files_256/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8700415, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.74797744, global_step = 6000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.7887391\n",
      "INFO:tensorflow:loss = 0.98544395, step = 6000 (79.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34004\n",
      "INFO:tensorflow:loss = 0.52160513, step = 6100 (16.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16018\n",
      "INFO:tensorflow:loss = 1.0934758, step = 6200 (16.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04042\n",
      "INFO:tensorflow:loss = 0.5114796, step = 6300 (16.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07247\n",
      "INFO:tensorflow:loss = 1.1941466, step = 6400 (16.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14181\n",
      "INFO:tensorflow:loss = 1.288561, step = 6500 (16.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20184\n",
      "INFO:tensorflow:loss = 0.68331045, step = 6600 (16.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.94901\n",
      "INFO:tensorflow:loss = 0.62597454, step = 6700 (16.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16817\n",
      "INFO:tensorflow:loss = 0.9432418, step = 6800 (16.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32836\n",
      "INFO:tensorflow:loss = 0.5873552, step = 6900 (15.802 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.81413\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:34:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:35:32\n",
      "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.80329704, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8341727, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8986853\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: model_files_256/model.ckpt-7000\n",
      "INFO:tensorflow:Validation (step 7000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.8986853, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.80329704, global_step = 7000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8341727\n",
      "INFO:tensorflow:loss = 0.911887, step = 7000 (75.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39973\n",
      "INFO:tensorflow:loss = 0.7757481, step = 7100 (16.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15278\n",
      "INFO:tensorflow:loss = 0.82203794, step = 7200 (16.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18571\n",
      "INFO:tensorflow:loss = 0.49003515, step = 7300 (16.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06928\n",
      "INFO:tensorflow:loss = 1.0135494, step = 7400 (16.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17994\n",
      "INFO:tensorflow:loss = 0.7886244, step = 7500 (16.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04315\n",
      "INFO:tensorflow:loss = 1.4199961, step = 7600 (16.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0333\n",
      "INFO:tensorflow:loss = 1.1333232, step = 7700 (16.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18322\n",
      "INFO:tensorflow:loss = 1.0419216, step = 7800 (16.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09548\n",
      "INFO:tensorflow:loss = 0.7108614, step = 7900 (16.406 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.78073\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:38:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:39:10\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8090208, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.83989775, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9024666\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_files_256/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9024666, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8090208, global_step = 8000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.83989775\n",
      "INFO:tensorflow:loss = 1.1828407, step = 8000 (70.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51601\n",
      "INFO:tensorflow:loss = 0.68412733, step = 8100 (16.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21505\n",
      "INFO:tensorflow:loss = 0.3065997, step = 8200 (16.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12075\n",
      "INFO:tensorflow:loss = 0.7603369, step = 8300 (16.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15245\n",
      "INFO:tensorflow:loss = 0.6246629, step = 8400 (16.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19579\n",
      "INFO:tensorflow:loss = 0.53451514, step = 8500 (16.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16071\n",
      "INFO:tensorflow:loss = 1.1555638, step = 8600 (16.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06256\n",
      "INFO:tensorflow:loss = 0.9322605, step = 8700 (16.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14033\n",
      "INFO:tensorflow:loss = 0.8601206, step = 8800 (16.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20426\n",
      "INFO:tensorflow:loss = 0.7801672, step = 8900 (16.118 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.87539\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:42:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:42:46\n",
      "INFO:tensorflow:Saving dict for global step 9000: global_step = 9000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.81917113, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.84880847, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.90727335\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: model_files_256/model.ckpt-9000\n",
      "INFO:tensorflow:Validation (step 9000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.90727335, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.81917113, global_step = 9000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.84880847\n",
      "INFO:tensorflow:loss = 1.650946, step = 9000 (69.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52584\n",
      "INFO:tensorflow:loss = 1.0807112, step = 9100 (16.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22184\n",
      "INFO:tensorflow:loss = 0.50009567, step = 9200 (16.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2745\n",
      "INFO:tensorflow:loss = 0.61511135, step = 9300 (15.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02377\n",
      "INFO:tensorflow:loss = 1.0570127, step = 9400 (16.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18844\n",
      "INFO:tensorflow:loss = 0.8575622, step = 9500 (16.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13837\n",
      "INFO:tensorflow:loss = 1.1622156, step = 9600 (16.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16889\n",
      "INFO:tensorflow:loss = 0.44686842, step = 9700 (16.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27768\n",
      "INFO:tensorflow:loss = 0.5938179, step = 9800 (15.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06577\n",
      "INFO:tensorflow:loss = 0.58969414, step = 9900 (16.487 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.87173\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:45:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:46:32\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8258403, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.85427004, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91099167\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_files_256/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91099167, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8258403, global_step = 10000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.85427004\n",
      "INFO:tensorflow:loss = 0.73481894, step = 10000 (80.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31926\n",
      "INFO:tensorflow:loss = 0.6199034, step = 10100 (16.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29494\n",
      "INFO:tensorflow:loss = 0.4755533, step = 10200 (15.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16836\n",
      "INFO:tensorflow:loss = 1.2097886, step = 10300 (16.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13049\n",
      "INFO:tensorflow:loss = 2.6021001, step = 10400 (16.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26154\n",
      "INFO:tensorflow:loss = 0.746244, step = 10500 (15.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06336\n",
      "INFO:tensorflow:loss = 0.52882665, step = 10600 (16.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13464\n",
      "INFO:tensorflow:loss = 0.74039054, step = 10700 (16.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09104\n",
      "INFO:tensorflow:loss = 0.70920557, step = 10800 (16.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06902\n",
      "INFO:tensorflow:loss = 1.2201713, step = 10900 (16.477 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74872\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:49:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-11000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:50:17\n",
      "INFO:tensorflow:Saving dict for global step 11000: global_step = 11000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8288981, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8564051, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.912696\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11000: model_files_256/model.ckpt-11000\n",
      "INFO:tensorflow:Validation (step 11000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.912696, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8288981, global_step = 11000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8564051\n",
      "INFO:tensorflow:loss = 1.428618, step = 11000 (79.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34603\n",
      "INFO:tensorflow:loss = 0.30047718, step = 11100 (16.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15945\n",
      "INFO:tensorflow:loss = 0.8546949, step = 11200 (16.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97451\n",
      "INFO:tensorflow:loss = 0.7220972, step = 11300 (16.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20573\n",
      "INFO:tensorflow:loss = 0.5143913, step = 11400 (16.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1817\n",
      "INFO:tensorflow:loss = 0.8253355, step = 11500 (16.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22563\n",
      "INFO:tensorflow:loss = 0.93481976, step = 11600 (16.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15881\n",
      "INFO:tensorflow:loss = 0.56133497, step = 11700 (16.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14809\n",
      "INFO:tensorflow:loss = 0.5333587, step = 11800 (16.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.30659\n",
      "INFO:tensorflow:loss = 0.5248484, step = 11900 (15.857 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.68163\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:53:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:54:05\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83519506, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8613535, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9155432\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_files_256/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9155432, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83519506, global_step = 12000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8613535\n",
      "INFO:tensorflow:loss = 0.36036858, step = 12000 (81.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31118\n",
      "INFO:tensorflow:loss = 1.1533128, step = 12100 (16.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09288\n",
      "INFO:tensorflow:loss = 0.41368106, step = 12200 (16.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13589\n",
      "INFO:tensorflow:loss = 0.4587094, step = 12300 (16.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04048\n",
      "INFO:tensorflow:loss = 1.0002248, step = 12400 (16.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05155\n",
      "INFO:tensorflow:loss = 0.45891175, step = 12500 (16.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29869\n",
      "INFO:tensorflow:loss = 0.69365174, step = 12600 (15.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16053\n",
      "INFO:tensorflow:loss = 0.872337, step = 12700 (16.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.9583\n",
      "INFO:tensorflow:loss = 0.81667686, step = 12800 (16.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11935\n",
      "INFO:tensorflow:loss = 0.30306754, step = 12900 (16.341 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.85093\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T21:56:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-13000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-21:57:52\n",
      "INFO:tensorflow:Saving dict for global step 13000: global_step = 13000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83549166, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8625305, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9162902\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13000: model_files_256/model.ckpt-13000\n",
      "INFO:tensorflow:Validation (step 13000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9162902, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.83549166, global_step = 13000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8625305\n",
      "INFO:tensorflow:loss = 0.7462718, step = 13000 (79.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33897\n",
      "INFO:tensorflow:loss = 0.5451227, step = 13100 (15.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21826\n",
      "INFO:tensorflow:loss = 0.7449849, step = 13200 (16.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07326\n",
      "INFO:tensorflow:loss = 1.000266, step = 13300 (16.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15201\n",
      "INFO:tensorflow:loss = 0.87727356, step = 13400 (16.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16115\n",
      "INFO:tensorflow:loss = 0.80288947, step = 13500 (16.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22768\n",
      "INFO:tensorflow:loss = 0.58578, step = 13600 (16.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02809\n",
      "INFO:tensorflow:loss = 0.49848074, step = 13700 (16.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22475\n",
      "INFO:tensorflow:loss = 1.4391577, step = 13800 (16.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13938\n",
      "INFO:tensorflow:loss = 0.6524081, step = 13900 (16.290 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.8104\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:00:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:01:39\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.84043276, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.86631036, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9185752\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_files_256/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9185752, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.84043276, global_step = 14000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.86631036\n",
      "INFO:tensorflow:loss = 1.2734524, step = 14000 (81.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30179\n",
      "INFO:tensorflow:loss = 0.7946648, step = 14100 (16.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11201\n",
      "INFO:tensorflow:loss = 0.5656597, step = 14200 (16.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04456\n",
      "INFO:tensorflow:loss = 0.93651223, step = 14300 (16.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10531\n",
      "INFO:tensorflow:loss = 0.8217149, step = 14400 (16.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18326\n",
      "INFO:tensorflow:loss = 0.42504215, step = 14500 (16.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23089\n",
      "INFO:tensorflow:loss = 0.89641786, step = 14600 (16.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08857\n",
      "INFO:tensorflow:loss = 0.7823849, step = 14700 (16.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17906\n",
      "INFO:tensorflow:loss = 0.60938764, step = 14800 (16.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19586\n",
      "INFO:tensorflow:loss = 1.5064338, step = 14900 (16.140 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.84308\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:04:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:05:25\n",
      "INFO:tensorflow:Saving dict for global step 15000: global_step = 15000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8384805, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8647878, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91732216\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: model_files_256/model.ckpt-15000\n",
      "INFO:tensorflow:Validation (step 15000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91732216, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8384805, global_step = 15000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8647878\n",
      "INFO:tensorflow:loss = 0.94828165, step = 15000 (79.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32601\n",
      "INFO:tensorflow:loss = 0.52952266, step = 15100 (16.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20491\n",
      "INFO:tensorflow:loss = 0.76523286, step = 15200 (16.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23162\n",
      "INFO:tensorflow:loss = 0.69515586, step = 15300 (16.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14456\n",
      "INFO:tensorflow:loss = 1.037131, step = 15400 (16.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15208\n",
      "INFO:tensorflow:loss = 0.55222553, step = 15500 (16.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10097\n",
      "INFO:tensorflow:loss = 0.7698487, step = 15600 (16.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22507\n",
      "INFO:tensorflow:loss = 0.41252747, step = 15700 (16.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16484\n",
      "INFO:tensorflow:loss = 0.40806437, step = 15800 (16.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05176\n",
      "INFO:tensorflow:loss = 1.0428104, step = 15900 (16.526 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.80315\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:08:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:09:12\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.84131706, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8676474, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91853356\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_files_256/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.91853356, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.84131706, global_step = 16000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8676474\n",
      "INFO:tensorflow:loss = 1.1250068, step = 16000 (81.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30923\n",
      "INFO:tensorflow:loss = 0.5987373, step = 16100 (16.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14381\n",
      "INFO:tensorflow:loss = 0.5156859, step = 16200 (16.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16284\n",
      "INFO:tensorflow:loss = 0.6327958, step = 16300 (16.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23811\n",
      "INFO:tensorflow:loss = 0.5827895, step = 16400 (16.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99827\n",
      "INFO:tensorflow:loss = 0.3664346, step = 16500 (16.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18082\n",
      "INFO:tensorflow:loss = 2.5294805, step = 16600 (16.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11785\n",
      "INFO:tensorflow:loss = 0.4958664, step = 16700 (16.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01351\n",
      "INFO:tensorflow:loss = 0.6724258, step = 16800 (16.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13001\n",
      "INFO:tensorflow:loss = 0.43164423, step = 16900 (16.314 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.8776\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:12:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-17000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:12:59\n",
      "INFO:tensorflow:Saving dict for global step 17000: global_step = 17000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8489428, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.87362725, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9219731\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 17000: model_files_256/model.ckpt-17000\n",
      "INFO:tensorflow:Validation (step 17000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9219731, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8489428, global_step = 17000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.87362725\n",
      "INFO:tensorflow:loss = 0.43708038, step = 17000 (79.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32229\n",
      "INFO:tensorflow:loss = 0.60490286, step = 17100 (16.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13509\n",
      "INFO:tensorflow:loss = 0.29529405, step = 17200 (16.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15916\n",
      "INFO:tensorflow:loss = 0.70260537, step = 17300 (16.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13418\n",
      "INFO:tensorflow:loss = 1.2057779, step = 17400 (16.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12656\n",
      "INFO:tensorflow:loss = 0.4826643, step = 17500 (16.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0828\n",
      "INFO:tensorflow:loss = 0.41148627, step = 17600 (16.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10619\n",
      "INFO:tensorflow:loss = 0.6250245, step = 17700 (16.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11062\n",
      "INFO:tensorflow:loss = 0.30972394, step = 17800 (16.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04009\n",
      "INFO:tensorflow:loss = 0.3164002, step = 17900 (16.557 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82678\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:15:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:16:48\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8470884, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8721573, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92165124\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_files_256/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92165124, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8470884, global_step = 18000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8721573\n",
      "INFO:tensorflow:loss = 0.3408032, step = 18000 (82.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.28362\n",
      "INFO:tensorflow:loss = 0.7076601, step = 18100 (16.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2801\n",
      "INFO:tensorflow:loss = 0.6930605, step = 18200 (15.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11855\n",
      "INFO:tensorflow:loss = 1.0384836, step = 18300 (16.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11736\n",
      "INFO:tensorflow:loss = 0.78187984, step = 18400 (16.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08635\n",
      "INFO:tensorflow:loss = 0.5649043, step = 18500 (16.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22361\n",
      "INFO:tensorflow:loss = 0.53779215, step = 18600 (16.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10956\n",
      "INFO:tensorflow:loss = 0.60322237, step = 18700 (16.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12152\n",
      "INFO:tensorflow:loss = 0.6604635, step = 18800 (16.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09066\n",
      "INFO:tensorflow:loss = 1.2243426, step = 18900 (16.419 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.84773\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:19:41Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-19000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:20:35\n",
      "INFO:tensorflow:Saving dict for global step 19000: global_step = 19000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8478936, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8732024, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9221554\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19000: model_files_256/model.ckpt-19000\n",
      "INFO:tensorflow:Validation (step 19000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9221554, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8478936, global_step = 19000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8732024\n",
      "INFO:tensorflow:loss = 0.42122108, step = 19000 (80.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31735\n",
      "INFO:tensorflow:loss = 0.38579544, step = 19100 (16.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14916\n",
      "INFO:tensorflow:loss = 0.45836297, step = 19200 (16.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04669\n",
      "INFO:tensorflow:loss = 0.43171468, step = 19300 (16.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04541\n",
      "INFO:tensorflow:loss = 1.7322896, step = 19400 (16.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21126\n",
      "INFO:tensorflow:loss = 1.0424479, step = 19500 (16.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25426\n",
      "INFO:tensorflow:loss = 0.47323593, step = 19600 (15.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02517\n",
      "INFO:tensorflow:loss = 0.7737018, step = 19700 (16.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11847\n",
      "INFO:tensorflow:loss = 0.25078633, step = 19800 (16.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16503\n",
      "INFO:tensorflow:loss = 0.44765276, step = 19900 (16.221 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.77028\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:23:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:24:22\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85141027, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8762909, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92398226\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_files_256/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92398226, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85141027, global_step = 20000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8762909\n",
      "INFO:tensorflow:loss = 0.45597404, step = 20000 (79.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32474\n",
      "INFO:tensorflow:loss = 0.40744868, step = 20100 (16.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26651\n",
      "INFO:tensorflow:loss = 0.43921477, step = 20200 (15.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01327\n",
      "INFO:tensorflow:loss = 0.910875, step = 20300 (16.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16749\n",
      "INFO:tensorflow:loss = 0.65741056, step = 20400 (16.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18785\n",
      "INFO:tensorflow:loss = 0.36661017, step = 20500 (16.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12197\n",
      "INFO:tensorflow:loss = 1.0535973, step = 20600 (16.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14291\n",
      "INFO:tensorflow:loss = 0.6272608, step = 20700 (16.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27019\n",
      "INFO:tensorflow:loss = 0.53500897, step = 20800 (15.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11628\n",
      "INFO:tensorflow:loss = 0.37050423, step = 20900 (16.350 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.72445\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:27:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-21000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:28:12\n",
      "INFO:tensorflow:Saving dict for global step 21000: global_step = 21000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8524716, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8778, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92444575\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21000: model_files_256/model.ckpt-21000\n",
      "INFO:tensorflow:Validation (step 21000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92444575, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8524716, global_step = 21000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8778\n",
      "INFO:tensorflow:loss = 0.34090638, step = 21000 (83.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.28549\n",
      "INFO:tensorflow:loss = 0.5338899, step = 21100 (15.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1634\n",
      "INFO:tensorflow:loss = 0.49355763, step = 21200 (16.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1454\n",
      "INFO:tensorflow:loss = 0.45128196, step = 21300 (16.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10799\n",
      "INFO:tensorflow:loss = 0.45253384, step = 21400 (16.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17332\n",
      "INFO:tensorflow:loss = 0.5617985, step = 21500 (16.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04553\n",
      "INFO:tensorflow:loss = 1.2937112, step = 21600 (16.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09682\n",
      "INFO:tensorflow:loss = 0.47191176, step = 21700 (16.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02083\n",
      "INFO:tensorflow:loss = 0.5680348, step = 21800 (16.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08936\n",
      "INFO:tensorflow:loss = 1.223682, step = 21900 (16.424 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.8268\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:31:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:31:58\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85632443, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88075554, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92627335\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_files_256/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92627335, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85632443, global_step = 22000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88075554\n",
      "INFO:tensorflow:loss = 0.8641356, step = 22000 (79.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33447\n",
      "INFO:tensorflow:loss = 1.1738335, step = 22100 (16.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05974\n",
      "INFO:tensorflow:loss = 1.0230035, step = 22200 (16.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97039\n",
      "INFO:tensorflow:loss = 0.47912797, step = 22300 (16.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05626\n",
      "INFO:tensorflow:loss = 0.41963425, step = 22400 (16.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2096\n",
      "INFO:tensorflow:loss = 0.3126225, step = 22500 (16.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10275\n",
      "INFO:tensorflow:loss = 1.0203032, step = 22600 (16.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1094\n",
      "INFO:tensorflow:loss = 0.45978132, step = 22700 (16.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0871\n",
      "INFO:tensorflow:loss = 0.37171537, step = 22800 (16.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97119\n",
      "INFO:tensorflow:loss = 0.75161374, step = 22900 (16.749 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.79853\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:34:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-23000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:35:45\n",
      "INFO:tensorflow:Saving dict for global step 23000: global_step = 23000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85864663, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88299423, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9278161\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 23000: model_files_256/model.ckpt-23000\n",
      "INFO:tensorflow:Validation (step 23000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9278161, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85864663, global_step = 23000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88299423\n",
      "INFO:tensorflow:loss = 0.49335718, step = 23000 (79.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34445\n",
      "INFO:tensorflow:loss = 0.758916, step = 23100 (16.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19312\n",
      "INFO:tensorflow:loss = 0.522458, step = 23200 (16.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24246\n",
      "INFO:tensorflow:loss = 0.50905627, step = 23300 (16.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10959\n",
      "INFO:tensorflow:loss = 0.8779343, step = 23400 (16.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06961\n",
      "INFO:tensorflow:loss = 0.55058604, step = 23500 (16.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1438\n",
      "INFO:tensorflow:loss = 0.5174455, step = 23600 (16.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13262\n",
      "INFO:tensorflow:loss = 0.7248505, step = 23700 (16.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0845\n",
      "INFO:tensorflow:loss = 0.61099064, step = 23800 (16.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10813\n",
      "INFO:tensorflow:loss = 0.7056555, step = 23900 (16.373 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.78829\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:38:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:39:31\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85847574, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88290155, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9269892\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_files_256/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9269892, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.85847574, global_step = 24000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88290155\n",
      "INFO:tensorflow:loss = 0.39246565, step = 24000 (79.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33042\n",
      "INFO:tensorflow:loss = 0.3239413, step = 24100 (16.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18898\n",
      "INFO:tensorflow:loss = 0.42559245, step = 24200 (16.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.93484\n",
      "INFO:tensorflow:loss = 0.37052578, step = 24300 (16.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14348\n",
      "INFO:tensorflow:loss = 0.7503936, step = 24400 (16.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03583\n",
      "INFO:tensorflow:loss = 0.59717876, step = 24500 (16.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22473\n",
      "INFO:tensorflow:loss = 0.46455938, step = 24600 (16.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2472\n",
      "INFO:tensorflow:loss = 0.7584337, step = 24700 (16.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15215\n",
      "INFO:tensorflow:loss = 0.6505693, step = 24800 (16.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11977\n",
      "INFO:tensorflow:loss = 0.35522005, step = 24900 (16.340 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.75771\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:42:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:43:21\n",
      "INFO:tensorflow:Saving dict for global step 25000: global_step = 25000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86099875, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88498276, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92809874\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25000: model_files_256/model.ckpt-25000\n",
      "INFO:tensorflow:Validation (step 25000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92809874, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86099875, global_step = 25000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88498276\n",
      "INFO:tensorflow:loss = 0.72859055, step = 25000 (83.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.27058\n",
      "INFO:tensorflow:loss = 0.29915878, step = 25100 (16.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06611\n",
      "INFO:tensorflow:loss = 0.29535353, step = 25200 (16.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1845\n",
      "INFO:tensorflow:loss = 0.6557297, step = 25300 (16.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0726\n",
      "INFO:tensorflow:loss = 0.74680924, step = 25400 (16.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13337\n",
      "INFO:tensorflow:loss = 0.3792222, step = 25500 (16.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05115\n",
      "INFO:tensorflow:loss = 0.9551791, step = 25600 (16.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10131\n",
      "INFO:tensorflow:loss = 0.7991468, step = 25700 (16.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14323\n",
      "INFO:tensorflow:loss = 0.6185497, step = 25800 (16.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17438\n",
      "INFO:tensorflow:loss = 0.71602714, step = 25900 (16.199 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.81148\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:46:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:47:12\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8608117, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.885171, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9283345\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_files_256/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9283345, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8608117, global_step = 26000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.885171\n",
      "INFO:tensorflow:loss = 0.23638785, step = 26000 (83.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.26305\n",
      "INFO:tensorflow:loss = 0.66068697, step = 26100 (16.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11791\n",
      "INFO:tensorflow:loss = 0.58586776, step = 26200 (16.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12824\n",
      "INFO:tensorflow:loss = 0.87100434, step = 26300 (16.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16454\n",
      "INFO:tensorflow:loss = 0.6837137, step = 26400 (16.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2768\n",
      "INFO:tensorflow:loss = 0.20534158, step = 26500 (15.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15237\n",
      "INFO:tensorflow:loss = 0.63551325, step = 26600 (16.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19927\n",
      "INFO:tensorflow:loss = 0.5955504, step = 26700 (16.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0979\n",
      "INFO:tensorflow:loss = 0.6867505, step = 26800 (16.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12959\n",
      "INFO:tensorflow:loss = 0.6330765, step = 26900 (16.316 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.79191\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:50:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-27000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:51:04\n",
      "INFO:tensorflow:Saving dict for global step 27000: global_step = 27000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8623145, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88660944, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92904735\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 27000: model_files_256/model.ckpt-27000\n",
      "INFO:tensorflow:Validation (step 27000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.92904735, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8623145, global_step = 27000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.88660944\n",
      "INFO:tensorflow:loss = 0.4129289, step = 27000 (85.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.243\n",
      "INFO:tensorflow:loss = 0.5329552, step = 27100 (15.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14983\n",
      "INFO:tensorflow:loss = 0.40565443, step = 27200 (16.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08635\n",
      "INFO:tensorflow:loss = 0.5109409, step = 27300 (16.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25413\n",
      "INFO:tensorflow:loss = 0.43365514, step = 27400 (15.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10531\n",
      "INFO:tensorflow:loss = 0.7143355, step = 27500 (16.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20414\n",
      "INFO:tensorflow:loss = 0.25231212, step = 27600 (16.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10497\n",
      "INFO:tensorflow:loss = 0.27469975, step = 27700 (16.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18886\n",
      "INFO:tensorflow:loss = 0.7285396, step = 27800 (16.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1467\n",
      "INFO:tensorflow:loss = 1.2492394, step = 27900 (16.274 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.88398\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:53:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:54:51\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8645523, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8893302, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9303299\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_files_256/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9303299, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8645523, global_step = 28000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8893302\n",
      "INFO:tensorflow:loss = 2.6781592, step = 28000 (81.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.29924\n",
      "INFO:tensorflow:loss = 0.6409651, step = 28100 (16.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98688\n",
      "INFO:tensorflow:loss = 0.39420497, step = 28200 (16.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00972\n",
      "INFO:tensorflow:loss = 0.60268086, step = 28300 (16.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98625\n",
      "INFO:tensorflow:loss = 1.6846135, step = 28400 (16.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1971\n",
      "INFO:tensorflow:loss = 0.31524864, step = 28500 (16.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12197\n",
      "INFO:tensorflow:loss = 0.9668622, step = 28600 (16.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09916\n",
      "INFO:tensorflow:loss = 0.69806755, step = 28700 (16.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10205\n",
      "INFO:tensorflow:loss = 0.45581648, step = 28800 (16.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10535\n",
      "INFO:tensorflow:loss = 0.26135895, step = 28900 (16.380 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.73832\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T22:57:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-29000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-22:58:42\n",
      "INFO:tensorflow:Saving dict for global step 29000: global_step = 29000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8730457, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8956802, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9341762\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 29000: model_files_256/model.ckpt-29000\n",
      "INFO:tensorflow:Validation (step 29000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9341762, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8730457, global_step = 29000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8956802\n",
      "INFO:tensorflow:loss = 0.4861914, step = 29000 (82.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.28011\n",
      "INFO:tensorflow:loss = 0.5850555, step = 29100 (16.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28387\n",
      "INFO:tensorflow:loss = 0.6443725, step = 29200 (15.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2051\n",
      "INFO:tensorflow:loss = 0.4936353, step = 29300 (16.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0452\n",
      "INFO:tensorflow:loss = 0.26884887, step = 29400 (16.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08588\n",
      "INFO:tensorflow:loss = 0.6706285, step = 29500 (16.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14609\n",
      "INFO:tensorflow:loss = 0.6494814, step = 29600 (16.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09763\n",
      "INFO:tensorflow:loss = 0.42468295, step = 29700 (16.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17802\n",
      "INFO:tensorflow:loss = 0.38981408, step = 29800 (16.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1906\n",
      "INFO:tensorflow:loss = 0.5509294, step = 29900 (16.156 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82836\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:01:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:02:34\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86675555, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89096975, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93105483\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_files_256/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93105483, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86675555, global_step = 30000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89096975\n",
      "INFO:tensorflow:loss = 0.52758366, step = 30000 (85.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.23063\n",
      "INFO:tensorflow:loss = 0.39986485, step = 30100 (16.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08105\n",
      "INFO:tensorflow:loss = 0.70295024, step = 30200 (16.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18482\n",
      "INFO:tensorflow:loss = 0.41754308, step = 30300 (16.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16338\n",
      "INFO:tensorflow:loss = 0.3490227, step = 30400 (16.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27589\n",
      "INFO:tensorflow:loss = 0.26472375, step = 30500 (15.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08657\n",
      "INFO:tensorflow:loss = 0.43958503, step = 30600 (16.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02445\n",
      "INFO:tensorflow:loss = 0.40346065, step = 30700 (16.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20576\n",
      "INFO:tensorflow:loss = 0.39007983, step = 30800 (16.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01684\n",
      "INFO:tensorflow:loss = 0.31746316, step = 30900 (16.620 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.82046\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:05:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-31000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:06:24\n",
      "INFO:tensorflow:Saving dict for global step 31000: global_step = 31000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87224936, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.895058, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93411475\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 31000: model_files_256/model.ckpt-31000\n",
      "INFO:tensorflow:Validation (step 31000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93411475, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87224936, global_step = 31000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.895058\n",
      "INFO:tensorflow:loss = 0.44064415, step = 31000 (83.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.26281\n",
      "INFO:tensorflow:loss = 0.43008384, step = 31100 (16.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99781\n",
      "INFO:tensorflow:loss = 1.1262114, step = 31200 (16.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1818\n",
      "INFO:tensorflow:loss = 0.8848594, step = 31300 (16.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06636\n",
      "INFO:tensorflow:loss = 0.57149357, step = 31400 (16.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.34445\n",
      "INFO:tensorflow:loss = 0.5626638, step = 31500 (15.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12578\n",
      "INFO:tensorflow:loss = 0.55683833, step = 31600 (16.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16752\n",
      "INFO:tensorflow:loss = 1.0031306, step = 31700 (16.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97239\n",
      "INFO:tensorflow:loss = 0.4179067, step = 31800 (16.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26461\n",
      "INFO:tensorflow:loss = 0.5844869, step = 31900 (15.964 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.81023\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:09:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:10:04\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8686631, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89161, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.932182\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_files_256/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.932182, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8686631, global_step = 32000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89161\n",
      "INFO:tensorflow:loss = 0.28221878, step = 32000 (73.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45856\n",
      "INFO:tensorflow:loss = 0.5897458, step = 32100 (16.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05952\n",
      "INFO:tensorflow:loss = 0.55445117, step = 32200 (16.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14611\n",
      "INFO:tensorflow:loss = 0.21732822, step = 32300 (16.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17924\n",
      "INFO:tensorflow:loss = 0.6751761, step = 32400 (16.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14595\n",
      "INFO:tensorflow:loss = 0.5681276, step = 32500 (16.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09823\n",
      "INFO:tensorflow:loss = 0.7325159, step = 32600 (16.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21409\n",
      "INFO:tensorflow:loss = 0.4728026, step = 32700 (16.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14945\n",
      "INFO:tensorflow:loss = 0.36966947, step = 32800 (16.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04741\n",
      "INFO:tensorflow:loss = 0.3680505, step = 32900 (16.536 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.81423\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:12:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-33000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:13:43\n",
      "INFO:tensorflow:Saving dict for global step 33000: global_step = 33000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8730246, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8957084, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93434197\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 33000: model_files_256/model.ckpt-33000\n",
      "INFO:tensorflow:Validation (step 33000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93434197, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8730246, global_step = 33000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8957084\n",
      "INFO:tensorflow:loss = 0.43188745, step = 33000 (71.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47621\n",
      "INFO:tensorflow:loss = 0.6390657, step = 33100 (16.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1089\n",
      "INFO:tensorflow:loss = 0.6981484, step = 33200 (16.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19643\n",
      "INFO:tensorflow:loss = 1.1194698, step = 33300 (16.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.2545\n",
      "INFO:tensorflow:loss = 0.3808858, step = 33400 (15.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11414\n",
      "INFO:tensorflow:loss = 0.30434763, step = 33500 (16.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22264\n",
      "INFO:tensorflow:loss = 0.3606253, step = 33600 (16.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13298\n",
      "INFO:tensorflow:loss = 1.1398512, step = 33700 (16.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20205\n",
      "INFO:tensorflow:loss = 0.6230494, step = 33800 (16.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.34407\n",
      "INFO:tensorflow:loss = 0.44347838, step = 33900 (15.763 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.78554\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:16:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:17:21\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8716265, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8952049, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93375456\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_files_256/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93375456, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8716265, global_step = 34000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8952049\n",
      "INFO:tensorflow:loss = 0.35348612, step = 34000 (72.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46126\n",
      "INFO:tensorflow:loss = 0.74035037, step = 34100 (16.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20032\n",
      "INFO:tensorflow:loss = 0.39327574, step = 34200 (16.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14714\n",
      "INFO:tensorflow:loss = 0.9422232, step = 34300 (16.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20337\n",
      "INFO:tensorflow:loss = 0.88077426, step = 34400 (16.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06465\n",
      "INFO:tensorflow:loss = 0.43655336, step = 34500 (16.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25204\n",
      "INFO:tensorflow:loss = 0.8635664, step = 34600 (15.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11824\n",
      "INFO:tensorflow:loss = 0.2767884, step = 34700 (16.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11848\n",
      "INFO:tensorflow:loss = 0.40047505, step = 34800 (16.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21163\n",
      "INFO:tensorflow:loss = 0.39717916, step = 34900 (16.099 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.77952\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:20:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-35000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:21:01\n",
      "INFO:tensorflow:Saving dict for global step 35000: global_step = 35000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86901236, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8937135, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.932549\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: model_files_256/model.ckpt-35000\n",
      "INFO:tensorflow:Validation (step 35000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.932549, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.86901236, global_step = 35000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8937135\n",
      "INFO:tensorflow:loss = 0.33896163, step = 35000 (73.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43944\n",
      "INFO:tensorflow:loss = 0.45310426, step = 35100 (16.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10603\n",
      "INFO:tensorflow:loss = 0.6546859, step = 35200 (16.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02676\n",
      "INFO:tensorflow:loss = 0.33776626, step = 35300 (16.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18148\n",
      "INFO:tensorflow:loss = 0.75330496, step = 35400 (16.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07676\n",
      "INFO:tensorflow:loss = 0.7489877, step = 35500 (16.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07832\n",
      "INFO:tensorflow:loss = 0.50720537, step = 35600 (16.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.12077\n",
      "INFO:tensorflow:loss = 0.8741146, step = 35700 (16.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29085\n",
      "INFO:tensorflow:loss = 0.4301806, step = 35800 (15.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23743\n",
      "INFO:tensorflow:loss = 0.7178202, step = 35900 (16.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.8846\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:23:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:24:39\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87145334, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8946035, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9336257\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_files_256/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9336257, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87145334, global_step = 36000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.8946035\n",
      "INFO:tensorflow:loss = 0.38573962, step = 36000 (71.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49182\n",
      "INFO:tensorflow:loss = 0.42233452, step = 36100 (16.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14704\n",
      "INFO:tensorflow:loss = 0.46613184, step = 36200 (16.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00541\n",
      "INFO:tensorflow:loss = 0.27520132, step = 36300 (16.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18468\n",
      "INFO:tensorflow:loss = 0.8177683, step = 36400 (16.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23173\n",
      "INFO:tensorflow:loss = 0.4571741, step = 36500 (16.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03941\n",
      "INFO:tensorflow:loss = 0.40566015, step = 36600 (16.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06549\n",
      "INFO:tensorflow:loss = 0.79794776, step = 36700 (16.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16117\n",
      "INFO:tensorflow:loss = 0.5638905, step = 36800 (16.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08225\n",
      "INFO:tensorflow:loss = 0.33491823, step = 36900 (16.441 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.85251\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:27:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-37000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:28:21\n",
      "INFO:tensorflow:Saving dict for global step 37000: global_step = 37000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87463874, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89752007, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93533087\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 37000: model_files_256/model.ckpt-37000\n",
      "INFO:tensorflow:Validation (step 37000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.93533087, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.87463874, global_step = 37000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89752007\n",
      "INFO:tensorflow:loss = 0.57222784, step = 37000 (74.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42989\n",
      "INFO:tensorflow:loss = 0.24970509, step = 37100 (16.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32054\n",
      "INFO:tensorflow:loss = 0.463298, step = 37200 (15.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08773\n",
      "INFO:tensorflow:loss = 1.0319064, step = 37300 (16.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0684\n",
      "INFO:tensorflow:loss = 0.42222202, step = 37400 (16.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18998\n",
      "INFO:tensorflow:loss = 0.21513675, step = 37500 (16.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10001\n",
      "INFO:tensorflow:loss = 0.721313, step = 37600 (16.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.19049\n",
      "INFO:tensorflow:loss = 0.32439488, step = 37700 (16.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21146\n",
      "INFO:tensorflow:loss = 0.4697201, step = 37800 (16.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.06303\n",
      "INFO:tensorflow:loss = 0.31501937, step = 37900 (16.494 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.74621\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:31:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:32:00\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.88110083, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.90256613, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9381005\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_files_256/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9381005, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.88110083, global_step = 38000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.90256613\n",
      "INFO:tensorflow:loss = 0.68991774, step = 38000 (72.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47862\n",
      "INFO:tensorflow:loss = 0.6393878, step = 38100 (16.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16892\n",
      "INFO:tensorflow:loss = 0.38378918, step = 38200 (16.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08502\n",
      "INFO:tensorflow:loss = 0.7237874, step = 38300 (16.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13437\n",
      "INFO:tensorflow:loss = 0.5918638, step = 38400 (16.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03327\n",
      "INFO:tensorflow:loss = 0.51629406, step = 38500 (16.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98658\n",
      "INFO:tensorflow:loss = 0.5846859, step = 38600 (16.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18069\n",
      "INFO:tensorflow:loss = 0.46257043, step = 38700 (16.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0214\n",
      "INFO:tensorflow:loss = 0.39234135, step = 38800 (16.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13405\n",
      "INFO:tensorflow:loss = 0.21919136, step = 38900 (16.302 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.73956\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:34:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-39000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:35:44\n",
      "INFO:tensorflow:Saving dict for global step 39000: global_step = 39000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.879995, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.9018076, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9375499\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 39000: model_files_256/model.ckpt-39000\n",
      "INFO:tensorflow:Validation (step 39000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9375499, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.879995, global_step = 39000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.9018076\n",
      "INFO:tensorflow:loss = 0.65576017, step = 39000 (77.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38639\n",
      "INFO:tensorflow:loss = 0.53129774, step = 39100 (15.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03642\n",
      "INFO:tensorflow:loss = 0.6735251, step = 39200 (16.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17506\n",
      "INFO:tensorflow:loss = 0.8573323, step = 39300 (16.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18605\n",
      "INFO:tensorflow:loss = 0.56140167, step = 39400 (16.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.10111\n",
      "INFO:tensorflow:loss = 0.49515107, step = 39500 (16.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14182\n",
      "INFO:tensorflow:loss = 0.4532116, step = 39600 (16.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26092\n",
      "INFO:tensorflow:loss = 0.6998336, step = 39700 (15.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.35582\n",
      "INFO:tensorflow:loss = 0.73114395, step = 39800 (15.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13677\n",
      "INFO:tensorflow:loss = 0.53279704, step = 39900 (16.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.77964\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd_new-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T23:38:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-23:39:34\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8760877, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89846396, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9359028\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: model_files_256/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40000): metrics-online_revew_project_usyd_new_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_L_fscore = 0.9359028, metrics-online_revew_project_usyd_new_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_new_rev/targets/approx_bleu_score = 0.8760877, global_step = 40000, metrics-online_revew_project_usyd_new_rev/targets/neg_log_perplexity = 0.0, loss = 0.0, metrics-online_revew_project_usyd_new_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_new_rev/targets/rouge_2_fscore = 0.89846396\n",
      "INFO:tensorflow:loss = 0.3664246, step = 40000 (84.520 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3664246.\n",
      "Time: 9056.94 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding, metrics\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "# Define hparams\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "hparams.num_encoder_layers = 2\n",
    "hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 2 \n",
    "hparams.dropout =0.2\n",
    "hparams.max_input_seq_length = \n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams =True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "# create run config\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=1000,\n",
    "    )\n",
    "# t2t_problem.eval_metrics()\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, \n",
    "        data_dir='./data', \n",
    "        train_steps=40001,\n",
    "        eval_steps=100,\n",
    "        min_eval_frequency=1000,\n",
    "    )\n",
    "\n",
    "hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- ###########-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "import generate_problem # self-defined 'generate_problem.py' file in the same folder.\n",
    "\n",
    "# define the directory for generated data\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' # Where data files from internet stored\n",
    "DATA_LOC = './data' # Where pre-prcessed data is stored\n",
    "\n",
    "# Generated training data\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada58>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada90>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.utils import decoding\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "\n",
    "decode_to_file = 'decoding_result'\n",
    "output_dir = './'\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('activation_dtype', 'float32'), ('add_relative_to_values', False), ('attention_dropout', 0.1), ('attention_dropout_broadcast_dims', ''), ('attention_key_channels', 0), ('attention_value_channels', 0), ('attention_variables_3d', False), ('batch_shuffle_size', 512), ('batch_size', 4096), ('causal_decoder_self_attention', True), ('clip_grad_norm', 0.0), ('compress_steps', 0), ('conv_first_kernel', 3), ('daisy_chain_variables', True), ('data_dir', './data'), ('dropout', 0.2), ('eval_drop_long_sequences', False), ('eval_run_autoregressive', False), ('factored_logits', False), ('ffn_layer', 'dense_relu_dense'), ('filter_size', 2048), ('force_full_predict', False), ('grad_noise_scale', 0.0), ('heads_share_relative_embedding', False), ('hidden_size', 512), ('initializer', 'uniform_unit_scaling'), ('initializer_gain', 1.0), ('kernel_height', 3), ('kernel_width', 1), ('label_smoothing', 0.1), ('layer_postprocess_sequence', 'da'), ('layer_prepostprocess_dropout', 0.1), ('layer_prepostprocess_dropout_broadcast_dims', ''), ('layer_preprocess_sequence', 'n'), ('learning_rate', 0.2), ('learning_rate_constant', 1.0), ('learning_rate_cosine_cycle_steps', 250000), ('learning_rate_decay_rate', 1.0), ('learning_rate_decay_scheme', 'noam'), ('learning_rate_decay_staircase', False), ('learning_rate_decay_steps', 5000), ('learning_rate_minimum', None), ('learning_rate_schedule', 'legacy'), ('learning_rate_warmup_steps', 8000), ('length_bucket_step', 1.1), ('max_input_seq_length', 0), ('max_length', 0), ('max_relative_position', 0), ('max_target_seq_length', 0), ('min_length', 0), ('min_length_bucket', 8), ('mlperf_mode', False), ('modality', {}), ('moe_hidden_sizes', '2048'), ('moe_k', 2), ('moe_loss_coef', 0.001), ('moe_num_experts', 16), ('moe_overhead_eval', 2.0), ('moe_overhead_train', 1.0), ('multiply_embedding_mode', 'sqrt_depth'), ('multiproblem_fixed_train_length', -1), ('multiproblem_label_weight', 0.5), ('multiproblem_max_input_length', -1), ('multiproblem_max_target_length', -1), ('multiproblem_mixing_schedule', 'constant'), ('multiproblem_per_task_threshold', ''), ('multiproblem_reweight_label_loss', False), ('multiproblem_schedule_max_examples', 10000000.0), ('multiproblem_schedule_threshold', 0.5), ('multiproblem_target_eval_only', False), ('multiproblem_vocab_size', -1), ('nbr_decoder_problems', 1), ('no_data_parallelism', False), ('norm_epsilon', 1e-06), ('norm_type', 'layer'), ('num_decoder_layers', 0), ('num_encoder_layers', 0), ('num_heads', 8), ('num_hidden_layers', 6), ('optimizer', 'Adam'), ('optimizer_adafactor_beta1', 0.0), ('optimizer_adafactor_beta2', 0.999), ('optimizer_adafactor_clipping_threshold', 1.0), ('optimizer_adafactor_decay_type', 'pow'), ('optimizer_adafactor_factored', True), ('optimizer_adafactor_memory_exponent', 0.8), ('optimizer_adafactor_multiply_by_parameter_scale', True), ('optimizer_adam_beta1', 0.9), ('optimizer_adam_beta2', 0.98), ('optimizer_adam_epsilon', 1e-09), ('optimizer_momentum_momentum', 0.9), ('optimizer_momentum_nesterov', False), ('optimizer_multistep_accumulate_steps', None), ('optimizer_zero_grads', False), ('overload_eval_metric_name', ''), ('pad_batch', False), ('parameter_attention_key_channels', 0), ('parameter_attention_value_channels', 0), ('pos', 'timing'), ('prepend_mode', 'prepend_inputs_masked_attention'), ('pretrained_model_dir', ''), ('proximity_bias', False), ('relu_dropout', 0.1), ('relu_dropout_broadcast_dims', ''), ('sampling_method', 'argmax'), ('sampling_temp', 1.0), ('scheduled_sampling_gold_mixin_prob', 0.5), ('scheduled_sampling_prob', 0.0), ('scheduled_sampling_warmup_steps', 50000), ('self_attention_type', 'dot_product'), ('shared_embedding', False), ('shared_embedding_and_softmax_weights', True), ('split_to_length', 0), ('summarize_grads', False), ('summarize_vars', False), ('symbol_dropout', 0.0), ('symbol_modality_num_shards', 16), ('symbol_modality_skip_top', False), ('tpu_enable_host_call', False), ('unidirectional_encoder', False), ('use_fixed_batch_size', False), ('use_pad_remover', True), ('use_target_space_embedding', True), ('video_num_input_frames', 1), ('video_num_target_frames', 1), ('vocab_divisor', 1), ('warm_start_from_second', ''), ('weight_decay', 0.0), ('weight_dtype', 'float32'), ('weight_noise', 0.0)])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_master': '', 't2t_device_info': {'num_async_replicas': 1}, '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f585c98e470>, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_num_worker_replicas': 0, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_environment': 'local', '_is_chief': True, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f585c98e668>, '_protocol': None, 'use_tpu': False, '_keep_checkpoint_max': 20, '_evaluation_master': '', '_tf_random_seed': None, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_train_distribute': None, '_task_id': 0, '_model_dir': 'model_files_256', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_steps': 1000, '_task_type': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f585cea8598>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "# t2t_trainer\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n",
    "# BEAM_SIZE=4\n",
    "# ALPHA=0.6\n",
    "\n",
    "# data_dir=DATA_LOC\n",
    "# problem = t2t_problem\n",
    "# model = MODEL\n",
    "# hparams_set = HPARAMS\n",
    "# output_dir = TRAIN_DIR\n",
    "\n",
    "# decode_to_file = 'decode_from_file'\n",
    "#########\n",
    "t2t_problem.get_hparams().was_reversed =False\n",
    "####\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "\n",
    "####\n",
    "# hparams = registry.hparams('transformer_base_single_gpu')\n",
    "# hparams.add_hparam(\"data_dir\", DATA_LOC)\n",
    "# t2t_problem.get_hparams().was_reversed =False\n",
    "# hparams = t2t_problem.get_hparams(hparams)\n",
    "# hparams\n",
    "######\n",
    "\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada58>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada90>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f597c0ba2e8>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f597c0ba320>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f599c039e48>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f599c039e48>}), ('was_copy', False), ('was_reversed', True)])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2t_problem.get_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_feature_encoders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-f3287950e6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_feature_encoders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_feature_encoders' is not defined"
     ]
    }
   ],
   "source": [
    "get_feature_encoders(DATA_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'t2t_device_info': {'num_async_replicas': 1}, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, 'use_tpu': False, '_num_worker_replicas': 0, '_device_fn': None, '_train_distribute': None, '_task_id': 0, '_tf_random_seed': None, '_save_checkpoints_secs': None, '_evaluation_master': '', '_model_dir': 'model_files_1024_new', '_task_type': None, '_save_checkpoints_steps': 1000, '_environment': 'local', '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7ff4c7ba6a20>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff4c7ba6cf8>, '_save_summary_steps': 100, '_protocol': None, '_eval_distribute': None, '_log_step_count_steps': 100, '_master': ''}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7ff54a7567b8>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024_new/\") #model.ckpt\n",
    "TRAIN_DIR = 'model_files_1024_new'\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4a18f65fd0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4a18ea4048>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4a19fbd978>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4a19fbd978>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'t2t_device_info': {'num_async_replicas': 1}, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, 'use_tpu': False, '_num_worker_replicas': 0, '_device_fn': None, '_train_distribute': None, '_task_id': 0, '_tf_random_seed': None, '_save_checkpoints_secs': None, '_evaluation_master': '', '_model_dir': 'model_files_full_new', '_task_type': None, '_save_checkpoints_steps': 1000, '_environment': 'local', '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7ff4c7ba6a90>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff4c7ba6a58>, '_save_summary_steps': 100, '_protocol': None, '_eval_distribute': None, '_log_step_count_steps': 100, '_master': ''}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7ff54a756c80>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint(\"model_files_full_new\")\n",
    "ckpt_path #= './model_files_1024/model.ckpt-22000'\n",
    "\n",
    "TRAIN_DIR = 'model_files_full_new'\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HParams' object has no attribute 'problem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f8f638b8fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_interactively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_interactively\u001b[0;34m(estimator, hparams, decode_hp, checkpoint_path)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0;34m\"\"\"Interactive decoding.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mis_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m   is_text2class = isinstance(hparams.problem,\n\u001b[1;32m    580\u001b[0m                              text_problems.Text2ClassProblem)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HParams' object has no attribute 'problem'"
     ]
    }
   ],
   "source": [
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "review2 = '''\n",
    "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
    "'''\n",
    "s2 = '''\n",
    "happy with purchase even though it came a lot later than expected.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infer'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.estimator.ModeKeys.PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/modalities.py:114: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py:621: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:1037: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "inputs = review2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "model_decoder = registry.model(MODEL)(hparams, Modes.EVAL)\n",
    "\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "encoded_inputs = encode(inputs)\n",
    "with tfe.restore_variables_on_create(ckpt_path):\n",
    "    model_output = model_decoder.infer(encoded_inputs)[\"outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "  \"shard\": decode_hp.shards,\n",
    "  \"dataset_split\": None,\n",
    "  \"max_records\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decoder = registry.model(MODEL)(hparams, Modes.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_input_fn = t2t_problem.make_estimator_input_fn(\n",
    "    tf.estimator.ModeKeys.PREDICT, hparams, dataset_kwargs=dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_input_fn = t2t_problem.make_estimator_input_fn(\n",
    "    Modes.PREDICT, hparams, dataset_kwargs=dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'input_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e77265129b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 checkpoint_path=ckpt_path)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_once\u001b[0;34m(estimator, problem_name, hparams, infer_input_fn, decode_hp, decode_to_file, output_dir, log_results, checkpoint_path)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;31m# Get the predictions as an iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   predictions = estimator.predict(infer_input_fn,\n\u001b[0;32m--> 253\u001b[0;31m                                   checkpoint_path=checkpoint_path)\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'input_fn'"
     ]
    }
   ],
   "source": [
    "# infer_input_fn = model_output\n",
    "\n",
    "decoding.decode_once(estimator,\n",
    "                t2t_problem,\n",
    "                hparams,\n",
    "                infer_input_fn,\n",
    "                decode_hp,\n",
    "                decode_to_file,\n",
    "                output_dir,\n",
    "                log_results=True,\n",
    "                checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  Args:\n",
    "    estimator: tf.estimator.Estimator instance. Used to generate encoded\n",
    "      predictions.\n",
    "    problem_name: str. Name of problem.\n",
    "    hparams: HParams instance. HParams for model training.\n",
    "    infer_input_fn: zero-arg function. Input function for estimator.\n",
    "    decode_hp: HParams instance. See decode_hparams() above.\n",
    "    decode_to_file: str. Prefix for filenames. Used to generated filenames to\n",
    "      which decoded predictions are written.\n",
    "    output_dir: str. Output directory. Only used for writing images.\n",
    "    log_results: bool. If False, return encoded predictions without any\n",
    "      further processing.\n",
    "    checkpoint_path: str. Path to load model checkpoint from. If unspecified,\n",
    "      Estimator's default is used.\n",
    "  Returns:\n",
    "    If decode_hp.decode_in_memory is True:\n",
    "      List of dicts, one per example. Values are either numpy arrays or decoded\n",
    "      strings.\n",
    "    If decode_hp.decode_in_memory is False:\n",
    "      An empty list.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fdd24ae2080>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_task_type': None, '_train_distribute': None, '_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", 't2t_device_info': {'num_async_replicas': 1}, '_device_fn': None, '_evaluation_master': '', '_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdd24ae20b8>, '_protocol': None, '_environment': 'local', '_model_dir': 'model_files_256', '_num_worker_replicas': 0, 'use_tpu': False, '_tf_random_seed': None, '_save_checkpoints_steps': 1000, '_task_id': 0, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fdd25abe840>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64797184\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40001\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-28T14:02:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-28-14:03:25\n",
      "INFO:tensorflow:Saving dict for global step 40001: global_step = 40001, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89221823, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91662514, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93793267\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40001: model_files_256/model.ckpt-40001\n",
      "INFO:tensorflow:Validation (step 40002): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, global_step = 40001, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89221823, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91662514, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93793267\n",
      "INFO:tensorflow:loss = 0.39651114, step = 40001\n",
      "INFO:tensorflow:global_step/sec: 0.873113\n",
      "INFO:tensorflow:loss = 0.42706436, step = 40101 (38.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01556\n",
      "INFO:tensorflow:loss = 0.28093913, step = 40201 (33.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00659\n",
      "INFO:tensorflow:loss = 0.5703713, step = 40301 (33.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00643\n",
      "INFO:tensorflow:loss = 0.524451, step = 40401 (33.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07053\n",
      "INFO:tensorflow:loss = 0.32810357, step = 40501 (32.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03513\n",
      "INFO:tensorflow:loss = 0.55903786, step = 40601 (32.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03153\n",
      "INFO:tensorflow:loss = 0.14611869, step = 40701 (32.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02187\n",
      "INFO:tensorflow:loss = 0.41055575, step = 40801 (33.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04566\n",
      "INFO:tensorflow:loss = 0.38706577, step = 40901 (32.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into model_files_256/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 2.3757\n",
      "INFO:tensorflow:loss = 0.26943615, step = 41001 (42.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00123\n",
      "INFO:tensorflow:loss = 0.42616627, step = 41101 (33.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00059\n",
      "INFO:tensorflow:loss = 0.36144212, step = 41201 (33.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02449\n",
      "INFO:tensorflow:loss = 0.40964493, step = 41301 (33.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02828\n",
      "INFO:tensorflow:loss = 0.28787893, step = 41401 (33.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03015\n",
      "INFO:tensorflow:loss = 0.24273534, step = 41501 (33.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02748\n",
      "INFO:tensorflow:loss = 0.2890115, step = 41601 (33.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.023\n",
      "INFO:tensorflow:loss = 0.60741675, step = 41701 (33.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03995\n",
      "INFO:tensorflow:loss = 0.7905096, step = 41801 (32.894 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b6844955f7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mt2t_model_256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# running time check (running on 1GPU server)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_eval_and_decode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m           hooks=self._train_spec.hooks)\n\u001b[0m\u001b[1;32m    473\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_eval_dir_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m       self._estimator.evaluate(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# select the transformer model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 \n",
    "hparams.learning_rate = 0.2 # default 0.2\n",
    "hparams.num_encoder_layers = 6 # default 0\n",
    "hparams.num_decoder_layers = 6 # default 0\n",
    "hparams.max_input_seq_length = 256\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, #PROBLEM,\n",
    "        data_dir='./data', \n",
    "        train_steps=40001, \n",
    "        eval_steps=200 \n",
    "    )\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_eval_and_decode()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensor2tensor.bin import t2t_decoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS \\\n",
    "  --output_dir=$TRAIN_DIR \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --decode_from_file=$DECODE_FILE \\\n",
    "  --decode_to_file=translation.en\n",
    "\n",
    "def main(argv):\n",
    "    t2t_decoder.main(argv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import generate_problem\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' \n",
    "DATA_LOC = './data' \n",
    "\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) \n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_2014'\n",
    "\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registry.model(MODEL)(hparams, Modes.PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_files_1024/model.ckpt-40001'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWS: \n",
      "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
      "\n",
      "PRED_SUMMARY: read 10; i the the did not get the item i ordered.  when its company they got back with me me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase the has 10;\n",
      "GOLD_SUMMARY: \n",
      "happy with purchase even though it came a lot later than expected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review1 = '''\n",
    "we have many of the old , old issue but the number had depleted there were not enough books to allow us to use them regularly with the additional supply the books will be used more often they are a good old standby for gospel singing\n",
    "'''\n",
    "review2 = '''\n",
    "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
    "'''\n",
    "s2 = '''\n",
    "happy with purchase even though it came a lot later than expected.\n",
    "'''\n",
    "\n",
    "summary = summarize(review2)\n",
    "\n",
    "print(\"REVIEWS: %s\" % review2)\n",
    "print(\"PRED_SUMMARY: %s\" % summary)\n",
    "print(\"GOLD_SUMMARY: %s\" % s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
