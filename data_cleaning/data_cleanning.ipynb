{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
    "                \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "                \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
    "                \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
    "                \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "                \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
    "                \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
    "                \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
    "                \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
    "                \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
    "                \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
    "                \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
    "                \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "                \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "# Expand common English contractions\n",
    "def expand_contractions(text):\n",
    "  \n",
    "    compiled = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
    "    def replace(contraction):\n",
    "        return contractions[contraction.group(0)]\n",
    "    expanded = compiled.sub(replace, text)\n",
    "    \n",
    "    return expanded\n",
    "\n",
    "# Clean the data\n",
    "def cleaning_data(text):\n",
    "    text = text.lower() # decapitalisation\n",
    "    text = expand_contractions(text) # expand contractions\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!\\,\\:\\;]','', text) # remove special characters and punctuations\n",
    "#     text = re.sub('\\d', '', text) # remove digits\n",
    "    \n",
    "    return text\n",
    "\n",
    "# # Tokenization\n",
    "# tokenizer = TweetTokenizer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "# running time calculation\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "\n",
    "data_file = '../../data/reviews.json.gz'\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)       \n",
    "\n",
    "for data in parse(path):\n",
    "    # cleaning the data\n",
    "    review = cleaning_data(data['review'])\n",
    "    summary = cleaning_data(data['summary'])\n",
    "\n",
    "    reviews.append({'review': review, 'summary': summary}) \n",
    "        \n",
    "json_str = json.dumps(reviews) + \"\\n\"              \n",
    "json_bytes = json_str.encode('utf-8')          \n",
    "\n",
    "with gzip.GzipFile(\"../../data/reviews_cleaned.json.gz\", 'w') as f:  \n",
    "    f.write(json_bytes)     \n",
    "    \n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are not qualified, i cannot do it man ! can you  under  stand...me? ;dkf  fll\n"
     ]
    }
   ],
   "source": [
    "# # test\n",
    "# cleaned = cleaning_data(\"You're not qualified, I can't do it man ! Can you % under -=- stand...me? '';dkf @# fll\")\n",
    "# print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'qualified',\n",
       " ',',\n",
       " 'i',\n",
       " 'cannot',\n",
       " 'do',\n",
       " 'it',\n",
       " 'man',\n",
       " '!',\n",
       " 'can',\n",
       " 'you',\n",
       " 'under',\n",
       " 'stand',\n",
       " '...',\n",
       " 'me',\n",
       " '?',\n",
       " ';d',\n",
       " 'kf',\n",
       " 'fll']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.tokenize import TweetTokenizer\n",
    "# tokenizer = TweetTokenizer() \n",
    "# tokenizer.tokenize(cleaned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
