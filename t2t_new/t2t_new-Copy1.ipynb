{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_v3 Max length variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable TF Eager execution at the beginning  ==> for decoder later\n",
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate t2t data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviews that the summary contains exactly same sentences with review text are dropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Importing user module train from path /tf/jupyter-code/code/t2t_new\n",
      "INFO:tensorflow:Generating problems:\n",
      "    onlinereview:\n",
      "      * onlinereview\n",
      "INFO:tensorflow:Generating data for onlinereview.\n",
      "INFO:tensorflow:Generating vocab file: ./data/vocab.onlinereview.32768.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.12965989112854004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.26036643981933594 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5206942558288574 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9959280490875244 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0407860279083252 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 153103\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [tracklocked] took 0.13071799278259277 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [photodiscoloration] took 0.2608821392059326 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5500085353851318 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 57272\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [keeler9670] took 0.1308445930480957 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [iwouldliketoreviewthelepanupgradeprocedureon] took 0.26286983489990234 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5063157081604004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58117\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [9781589804715successful] took 0.1309354305267334 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [playplaypen] took 0.26076388359069824 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49381351470947266 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58059\n",
      "INFO:tensorflow:Trying min_count 750\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.1307694911956787 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2609367370605469 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5211169719696045 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9982104301452637 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0427327156066895 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 122366\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [woodorhightemperaturesiliconetools] took 0.1304328441619873 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [mphkph] took 0.260941743850708 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5528564453125 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 45993\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [distressmussomatization] took 0.13041400909423828 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [mg21035sr61035] took 0.2608020305633545 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.48694419860839844 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [emancipationonward] took 0.520841121673584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 46746\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [212fdisplay] took 0.1303555965423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [newcastleupontyne] took 0.26249170303344727 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5042061805725098 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [comwattslfpbav666adaptvalvecompressiondpb004vt4zi4refsr] took 0.520988941192627 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 46687\n",
      "INFO:tensorflow:Trying min_count 875\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13022255897521973 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2608470916748047 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5212345123291016 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9987821578979492 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0432980060577393 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 112348\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [,,,,,,,,,,,, , , , , , . .  . . .  .. . . .  ..  . . . .  .  .. ,, ,...... ...  ,,.. .. .. ..  ,,.. .. .. ..] took 0.13115739822387695 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [depinnedswapped] took 0.2604541778564453 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5630483627319336 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 42333\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [levelground] took 0.13036227226257324 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [otherwisewonderful] took 0.26075005531311035 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49868202209472656 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [p115117consciousness] took 0.521615743637085 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 43036\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [9780471460053] took 0.1301271915435791 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [w1additivity] took 0.2610206604003906 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5148520469665527 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [casualthe] took 0.5203678607940674 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 42970\n",
      "INFO:tensorflow:Trying min_count 938\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13022637367248535 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2607700824737549 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.521214485168457 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.002939224243164 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0438389778137207 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 108170\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [ufothemed] took 0.13042712211608887 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [scapinooverture] took 0.26084375381469727 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5715944766998291 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40825\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [p51k] took 0.13043546676635742 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [claimmyth] took 0.26041197776794434 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49933290481567383 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [stirreth] took 0.5210912227630615 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41496\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [systemlogitech] took 0.1303560733795166 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [merciful3542god] took 0.260514497756958 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5221271514892578 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [musicborn] took 0.5209805965423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41430\n",
      "INFO:tensorflow:Trying min_count 969\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13022446632385254 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.26273083686828613 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5254840850830078 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9970543384552002 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0446727275848389 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 106207\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [differentscenarios] took 0.13006234169006348 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [sd425] took 0.26052260398864746 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5732643604278564 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40130\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [islandstellar] took 0.13069748878479004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [pricesoundutility] took 0.2606673240661621 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49613356590270996 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [infraredplates] took 0.5209789276123047 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40759\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [intercontinentalballisticmissile] took 0.13048815727233887 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [prealgebra] took 0.26034116744995117 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.520545244216919 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [snotnosebrat] took 0.5221157073974609 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40706\n",
      "INFO:tensorflow:Trying min_count 985\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13025546073913574 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2609562873840332 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5216953754425049 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9963455200195312 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0441772937774658 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 105224\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [fantasytechnosciencereligiosity] took 0.13046598434448242 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [clackclackclack] took 0.26054978370666504 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5711402893066406 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39795\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [comjfklbjchapterassassinationassassinationdp0982892004refsr] took 0.13054776191711426 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [goofingoffbeforetheshow] took 0.2604484558105469 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.496990442276001 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [superultrakawaiicutiekoochykoochybooboo] took 0.5207059383392334 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40406\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [0553275194] took 0.1302950382232666 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [40nice] took 0.2604823112487793 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5236611366271973 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [sneakerpumalink] took 0.5206971168518066 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40336\n",
      "INFO:tensorflow:Trying min_count 993\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13019609451293945 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2606379985809326 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5254948139190674 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9951467514038086 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.046219825744629 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104719\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [jordanoverall] took 0.1301441192626953 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [woodclickingtogether] took 0.260317325592041 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5697999000549316 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39626\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [countries04b] took 0.1303555965423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [oneononedekes] took 0.26029324531555176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49656248092651367 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [editiondirty] took 0.520923376083374 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40244\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [carnabeat] took 0.13040637969970703 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [weagreed] took 0.2604660987854004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5250394344329834 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [lovefurypassionenergy] took 0.5206625461578369 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40181\n",
      "INFO:tensorflow:Trying min_count 997\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13007664680480957 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.26024937629699707 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5207791328430176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9991931915283203 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0439879894256592 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104510\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [decoglow] took 0.13025188446044922 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [ckgauml] took 0.260256290435791 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5711197853088379 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39531\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [loosycounterclockwise] took 0.1303548812866211 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [soloveitchikian] took 0.2607574462890625 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.4952988624572754 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [cleaningvery] took 0.5211200714111328 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40183\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [tebaldibergonziserafin] took 0.13044142723083496 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [chocolatealmondraisin] took 0.2604985237121582 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5235962867736816 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [theirdedication] took 0.5206570625305176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40104\n",
      "INFO:tensorflow:Trying min_count 999\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.1304917335510254 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2608518600463867 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5213892459869385 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9980509281158447 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0436899662017822 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104395\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [workshoppresented] took 0.130462646484375 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [goodifnotamazing] took 0.26284146308898926 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.584650993347168 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39489\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [morala] took 0.13022804260253906 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [pateresquereflection] took 0.26068902015686035 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5085837841033936 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [coveredrobotsandmonsters] took 0.5210459232330322 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40135\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [np700z5as03us] took 0.13052845001220703 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [kxtg6324] took 0.26131439208984375 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5230984687805176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [cheapyweepy] took 0.5204038619995117 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40073\n",
      "INFO:tensorflow:Trying min_count 1000\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13012313842773438 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2607712745666504 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5216066837310791 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9996099472045898 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.044715404510498 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104338\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [arapeyev] took 0.13038992881774902 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [copbotsquot] took 0.2603592872619629 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5722789764404297 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39462\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [whathappenedtoeverybodyafterleavingschool] took 0.13036608695983887 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amiacute] took 0.2608222961425781 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.496596097946167 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [generallydirected] took 0.52158522605896 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40121\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [adjustmentsintegrates] took 0.1310727596282959 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [0x145a4810] took 0.2605752944946289 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5225009918212891 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [journeytothemotherland] took 0.5210280418395996 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40055\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n",
      "INFO:tensorflow:Generating case 3000000.\n",
      "INFO:tensorflow:Generating case 3100000.\n",
      "INFO:tensorflow:Generating case 3200000.\n",
      "INFO:tensorflow:Generating case 3300000.\n",
      "INFO:tensorflow:Generating case 3400000.\n",
      "INFO:tensorflow:Generating case 3500000.\n",
      "INFO:tensorflow:Generating case 3600000.\n",
      "INFO:tensorflow:Generated 3637767 Examples\n",
      "INFO:tensorflow:Found vocab file: ./data/vocab.onlinereview.32768.subwords\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n",
      "INFO:tensorflow:Generating case 3000000.\n",
      "INFO:tensorflow:Generating case 3100000.\n",
      "INFO:tensorflow:Generating case 3200000.\n",
      "INFO:tensorflow:Generating case 3300000.\n",
      "INFO:tensorflow:Generating case 3400000.\n",
      "INFO:tensorflow:Generating case 3500000.\n",
      "INFO:tensorflow:Generating case 3600000.\n",
      "INFO:tensorflow:Generated 3637767 Examples\n",
      "INFO:tensorflow:Found vocab file: ./data/vocab.onlinereview.32768.subwords\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n",
      "INFO:tensorflow:Generating case 3000000.\n",
      "INFO:tensorflow:Generating case 3100000.\n",
      "INFO:tensorflow:Generating case 3200000.\n",
      "INFO:tensorflow:Generating case 3300000.\n",
      "INFO:tensorflow:Generating case 3400000.\n",
      "INFO:tensorflow:Generating case 3500000.\n",
      "INFO:tensorflow:Generating case 3600000.\n",
      "INFO:tensorflow:Generated 3637767 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:467: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# DATA_DIR=./data\n",
    "# TMP_DIR=$DATA_DIR/tmp\n",
    "# rm -rf $DATA_DIR $TMP_DIR\n",
    "# mkdir -p $DATA_DIR $TMP_DIR\n",
    "# # Generate data\n",
    "# t2t-datagen \\\n",
    "#   --t2t_usr_dir=./train \\\n",
    "#   --problem=\"onlinereview\" \\\n",
    "#   --data_dir=$DATA_DIR \\\n",
    "#   --tmp_dir=$TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3637767 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Importing user module train from path /tf/jupyter-code/code/t2t/new\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_train_distribute': None, '_save_checkpoints_secs': None, 'use_tpu': False, '_task_id': 0, '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fcbfc3d15f8>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_device_fn': None, '_master': '', '_tf_random_seed': None, '_model_dir': './trained_model', '_is_chief': True, '_evaluation_master': '', '_task_type': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, '_protocol': None, 't2t_device_info': {'num_async_replicas': 1}, '_num_worker_replicas': 0, '_num_ps_replicas': 0, '_eval_distribute': None, '_save_checkpoints_steps': 1000, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbfc3d1630>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fcbfc408510>) includes params argument, but params are not passed to Estimator.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "INFO:tensorflow:Trainable Variables Total size: 1399808\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:19.673212: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-06-02 10:36:21.376349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-02 10:36:21.376871: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x80e2e30 executing computations on platform CUDA. Devices:\n",
      "2019-06-02 10:36:21.376886: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5\n",
      "2019-06-02 10:36:21.378531: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3407980000 Hz\n",
      "2019-06-02 10:36:21.378922: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x83ce4e0 executing computations on platform Host. Devices:\n",
      "2019-06-02 10:36:21.378965: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-02 10:36:21.379444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-06-02 10:36:21.379473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:21.380085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:21.380095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:21.380113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:21.380283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "2019-06-02 10:36:28.771530: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "2019-06-02 10:36:39.015856: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:101] Filling up shuffle buffer (this may take a while): 295 of 512\n",
      "2019-06-02 10:36:41.610738: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:140] Shuffle buffer filled.\n",
      "INFO:tensorflow:loss = 7.4019403, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./trained_model/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T10:36:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:50.269893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:50.269940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:50.269958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:50.269961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:50.270065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-10:36:52\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 8.828742, metrics-onlinereview/targets/accuracy = 0.00069252076, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.00069252076, metrics-onlinereview/targets/approx_bleu_score = 0.778015, metrics-onlinereview/targets/neg_log_perplexity = -8.803953, metrics-onlinereview/targets/rouge_2_fscore = 0.84111744, metrics-onlinereview/targets/rouge_L_fscore = 0.8062627\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Loss for final step: 7.4723377.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T10:36:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:57.293478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:57.293510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:57.293515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:57.293518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:57.293611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-10:36:59\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 8.828742, metrics-onlinereview/targets/accuracy = 0.00069252076, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.00069252076, metrics-onlinereview/targets/approx_bleu_score = 0.778015, metrics-onlinereview/targets/neg_log_perplexity = -8.803953, metrics-onlinereview/targets/rouge_2_fscore = 0.84111744, metrics-onlinereview/targets/rouge_L_fscore = 0.8062627\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# DATA_DIR=./data\n",
    "# OUTDIR=./trained_model\n",
    "# rm -rf $OUTDIR\n",
    "# t2t-trainer \\\n",
    "#   --data_dir=./data \\\n",
    "#   --t2t_usr_dir=./train \\\n",
    "#   --problem=\"onlinereview\" \\\n",
    "#   --model=transformer \\\n",
    "#   --hparams_set=onlinereviewhp \\\n",
    "#   --output_dir=$OUTDIR --job-dir=$OUTDIR --train_steps=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<train.problem.onlinereview at 0x7fd728362630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train import problem\n",
    "problem.onlinereview('onlinereview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import problems\n",
    "\n",
    "DATA_LOC = './data' \n",
    "t2t_problem = problems.problem('onlinereview')\n",
    "vocab_name = \"./data/vocab.onlinereview.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "#     print(\"inputs\",inputs)\n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "#         print(\"integers\", integers)\n",
    "#         print(\"targets\", encoders[\"targets\"])\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder at 0x7f33a7790160>,\n",
       " 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder at 0x7f33a7790160>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# ende_problem.generate_data(data_dir, tmp_dir)\n",
    "example = tfe.Iterator(t2t_problem.dataset(Modes.TRAIN, DATA_LOC)).next()\n",
    "inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
    "targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs, encoded:\n",
      "[168, 3, 2, 610, 253, 90, 9462, 11, 62, 13, 2, 766, 6, 458, 11, 12253, 7573, 6650, 87, 18, 110, 21, 776, 34, 204, 32, 3, 77, 83, 18, 718, 7, 143, 219, 11, 5, 175, 397, 241, 3, 23, 307, 461, 103, 15153, 11, 10, 672, 13, 75, 3, 11, 10, 1134, 3, 7, 37, 219, 11, 16, 13, 7, 25, 388, 2, 2698, 16, 2, 1114, 44, 15109, 258, 2, 2886, 21, 196, 310, 3, 24, 75, 24, 458, 11, 133, 8, 7, 702, 7, 143, 22, 71, 2, 892, 124, 8, 7, 103, 18, 931, 16, 3, 94, 2, 766, 87, 18, 110, 21, 776, 23, 7, 68, 3565, 16, 10, 18, 2, 180, 8, 7, 1614, 24934, 121, 2, 1313, 21, 2, 117, 310, 9, 11, 3, 36, 2, 595, 310, 3, 6, 116, 11, 79, 568, 32, 1600, 4, 22, 32, 4554, 509, 23, 3187, 7, 44, 222, 43, 5, 4295, 20, 5, 270, 16, 10, 39, 1442, 12, 4244, 1439, 3, 12, 9348, 28, 3, 59, 7, 103, 299, 872, 49, 160, 17, 32, 16, 10, 18, 13, 2, 624, 1007, 10, 89, 253, 19306, 8, 11, 10, 15780, 4, 132, 11, 842, 9, 1235, 2, 644, 9, 11, 7, 44, 352, 18, 1815, 27, 875, 121, 11, 3, 36, 1522, 1046, 38, 11, 10, 188, 6, 740, 54, 38, 7, 660, 13, 7, 44, 516, 11, 3, 23, 11, 25, 253, 563, 4, 11, 10, 18, 260, 2, 70, 8, 7, 2173, 2, 200, 25, 5, 587, 12, 16, 479, 13, 4490, 3, 7, 68, 188, 6, 293, 54, 164, 723, 150, 2, 270, 3011, 6, 2, 1549, 4, 52, 5, 15090, 1291, 17, 2, 624, 8, 7, 404, 7, 65, 1117, 2, 82, 515, 155, 7, 375, 14, 270, 13, 401, 16, 876, 276, 1244, 14, 17, 6051, 875, 99, 8, 17, 146, 3, 377, 11, 10, 56, 3, 23, 17, 875, 99, 3, 7, 68, 188, 20, 5, 175, 397, 17, 200, 3, 4, 32, 598, 397, 17, 4554, 78, 11, 103, 299, 2227, 124, 765, 59, 1807, 6, 2, 371, 989, 3, 94, 9, 2, 2357, 13, 1]\n",
      "Inputs, decoded:\n",
      "right, the title pretty much sums it up.the button to turn it onoffdim did not work on mine from day one, which does not mean i should give it a 1 star review, but nothing else could redeem it is value.well, it is bright, i will give it that.i was under the impression that the switch would toggle between the lighting on each side, as well as turn it off. i guess i should have read the description better. i could not test that, because the button did not work on mine but i am guessing that is not the case. i considered taping over the lights on the back side of it, or the front side, to make it only face one direction and have one brightness level but frankly i would feel like a fool with a light that is all covered in electrical tape, in uni, when i could probably spend about 5 for one that is not.the usb connection is also pretty sketchy. it is wobbly and while it sort of holds the weight of it i would rather not damage my laptop over it, or constantly wonder if it is going to fall out if i move.i would return it, but it was pretty cheap and it is not worth the time. i suppose the price was a plus in that sense.anyways, i am going to try out another brand where the light clips to the monitor and has a retractable cord for the usb. i wish i had noticed the other type before i purchased this light.hope that helps anyone considering this for purely laptop use. for books, maybe it is great, but for laptop use, i am going with a 1 star for price, and one extra star for brightness; it could probably serve better uses when attached to the battery pack, because of the output.\n",
      "------------------------------\n",
      "Targets, encoded:\n",
      "[766, 87, 18, 110, 29, 624, 1007, 10, 19306, 29, 1218, 519, 1]\n",
      "Targets, decoded:\n",
      "button did not work  usb connection is sketchy  annoying design\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Example inputs as int-tensor.\n",
    "print(\"Inputs, encoded:\")\n",
    "print(inputs)\n",
    "print(\"Inputs, decoded:\")\n",
    "# Example inputs as a sentence.\n",
    "print(decode(inputs))\n",
    "\n",
    "print(\"---\"*10)\n",
    "# Example targets as int-tensor.\n",
    "print(\"Targets, encoded:\")\n",
    "print(targets)\n",
    "# Example targets as a sentence.\n",
    "print(\"Targets, decoded:\")\n",
    "print(decode(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyper params and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multiproblem_mixing_schedule': 'constant', 'modality': {}, 'kernel_height': 3, 'initializer': 'uniform_unit_scaling', 'mlperf_mode': False, 'learning_rate_decay_scheme': 'noam', 'heads_share_relative_embedding': False, 'proximity_bias': False, 'multiproblem_schedule_max_examples': 10000000.0, 'kernel_width': 1, 'sampling_method': 'argmax', 'optimizer_momentum_nesterov': False, 'pad_batch': False, 'eval_drop_long_sequences': False, 'multiproblem_fixed_train_length': -1, 'shared_embedding': False, 'layer_prepostprocess_dropout': 0.1, 'learning_rate_minimum': None, 'max_input_seq_length': 0, 'multiproblem_schedule_threshold': 0.5, 'learning_rate_warmup_steps': 8000, 'hidden_size': 512, 'weight_dtype': 'float32', 'parameter_attention_key_channels': 0, 'factored_logits': False, 'optimizer_adam_epsilon': 1e-09, 'learning_rate_decay_staircase': False, 'multiproblem_max_target_length': -1, 'min_length_bucket': 8, 'causal_decoder_self_attention': True, 'summarize_grads': False, 'norm_epsilon': 1e-06, 'batch_shuffle_size': 512, 'prepend_mode': 'prepend_inputs_full_attention', 'symbol_dropout': 0.0, 'num_decoder_layers': 0, 'grad_noise_scale': 0.0, 'optimizer_zero_grads': False, 'overload_eval_metric_name': '', 'optimizer_adafactor_memory_exponent': 0.8, 'moe_k': 2, 'optimizer_adafactor_factored': True, 'shared_embedding_and_softmax_weights': True, 'pos': 'timing', 'optimizer_adafactor_clipping_threshold': 1.0, 'eval_run_autoregressive': False, 'optimizer_multistep_accumulate_steps': None, 'warm_start_from_second': '', 'compress_steps': 0, 'learning_rate': 0.1, 'learning_rate_decay_steps': 5000, 'optimizer_adafactor_beta2': 0.999, 'optimizer_momentum_momentum': 0.9, 'weight_noise': 0.0, 'optimizer_adafactor_beta1': 0.0, 'max_length': 0, 'multiproblem_per_task_threshold': '', 'summarize_vars': False, 'sampling_temp': 1.0, 'dropout': 0.2, 'moe_overhead_train': 1.0, 'use_pad_remover': True, 'daisy_chain_variables': True, 'split_to_length': 0, 'attention_variables_3d': False, 'ffn_layer': 'dense_relu_dense', 'length_bucket_step': 1.1, 'norm_type': 'layer', 'symbol_modality_skip_top': False, 'multiproblem_target_eval_only': False, 'optimizer_adam_beta2': 0.98, 'parameter_attention_value_channels': 0, 'multiproblem_max_input_length': -1, 'scheduled_sampling_warmup_steps': 50000, 'max_relative_position': 0, 'moe_hidden_sizes': '2048', 'num_hidden_layers': 6, 'activation_dtype': 'float32', 'optimizer_adam_beta1': 0.9, 'vocab_divisor': 1, 'relu_dropout': 0.1, 'optimizer_adafactor_decay_type': 'pow', 'initializer_gain': 1.0, 'multiproblem_label_weight': 0.5, 'multiproblem_reweight_label_loss': False, 'learning_rate_constant': 1.0, 'multiply_embedding_mode': 'sqrt_depth', 'no_data_parallelism': False, 'max_target_seq_length': 0, 'scheduled_sampling_gold_mixin_prob': 0.5, 'nbr_decoder_problems': 1, 'learning_rate_decay_rate': 1.0, 'moe_overhead_eval': 2.0, 'add_relative_to_values': False, 'symbol_modality_num_shards': 16, 'num_encoder_layers': 0, 'attention_dropout': 0.1, 'min_length': 0, 'layer_postprocess_sequence': 'da', 'video_num_input_frames': 1, 'num_heads': 8, 'learning_rate_schedule': 'legacy', 'use_target_space_embedding': True, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'unidirectional_encoder': False, 'self_attention_type': 'dot_product', 'scheduled_sampling_prob': 0.0, 'use_fixed_batch_size': False, 'multiproblem_vocab_size': -1, 'moe_num_experts': 16, 'video_num_target_frames': 1, 'pretrained_model_dir': '', 'attention_value_channels': 0, 'layer_prepostprocess_dropout_broadcast_dims': '', 'weight_decay': 0.0, 'layer_preprocess_sequence': 'n', 'label_smoothing': 0.1, 'tpu_enable_host_call': False, 'attention_dropout_broadcast_dims': '', 'clip_grad_norm': 0.0, 'conv_first_kernel': 3, 'batch_size': 2048, 'force_full_predict': False, 'moe_loss_coef': 0.001, 'filter_size': 2048, 'optimizer': 'Adam', 'relu_dropout_broadcast_dims': '', 'attention_key_channels': 0, 'learning_rate_cosine_cycle_steps': 250000}\n",
      "{'decode_timeout_mins': 240, 'max_display_decodes': 5, 'mlperf_threshold': 25.0, 'skip_eos_postprocess': False, 'shards_start_offset': 0, 'save_images': False, 'summaries_log_dir': 'decode', 'border_percent': 2, 'vgg_ckpt_path': '', 'write_beam_scores': False, 'force_decode_length': False, 'mlperf_decode_step': 0.0, 'mlperf_success': False, 'num_samples': -1, 'frames_per_second': 10, 'decode_in_memory': False, 'alpha': 0.6, 'batch_size': 0, 'display_decoded_images': False, 'delimiter': '\\n', 'log_results': True, 'extra_length': 100, 'beam_size': 4, 'num_decodes': 1, 'shard_google_format': False, 'return_beams': False, 'identity_output': False, 'multiproblem_task_id': -1, 'eos_penalty': 0.0, 'guess_and_check_top_k': 0, 'decode_to_file': None, 'max_input_size': -1, 'max_display_outputs': 10, 'block_size': 0, 'shards': 1, 'shard_id': 0, 'guess_and_check_epsilon': -1}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_file_v1', '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None, 'use_tpu': False, '_save_checkpoints_steps': 2000, '_tf_random_seed': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_task_id': 0, '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_device_fn': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_master': '', '_num_ps_replicas': 0, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc3d0664358>, '_evaluation_master': '', '_environment': 'local', '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc3d0664390>, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc2906206a8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc3d06641d0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc3d0664128>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc3e2d59da0>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc3e2d59da0>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-10000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T00:14:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-00:20:22\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 6.412321, metrics-onlinereview/targets/accuracy = 0.12671585, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.27117378, metrics-onlinereview/targets/approx_bleu_score = 0.005338237, metrics-onlinereview/targets/neg_log_perplexity = -6.333966, metrics-onlinereview/targets/rouge_2_fscore = 0.02271182, metrics-onlinereview/targets/rouge_L_fscore = 0.14463001\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_file_v1/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10001): loss = 6.412321, metrics-onlinereview/targets/neg_log_perplexity = -6.333966, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 10000, metrics-onlinereview/targets/approx_bleu_score = 0.005338237, metrics-onlinereview/targets/accuracy_top5 = 0.27117378, metrics-onlinereview/targets/rouge_2_fscore = 0.02271182, metrics-onlinereview/targets/accuracy = 0.12671585, metrics-onlinereview/targets/rouge_L_fscore = 0.14463001\n",
      "INFO:tensorflow:loss = 5.120249, step = 10000\n",
      "INFO:tensorflow:global_step/sec: 0.241603\n",
      "INFO:tensorflow:loss = 6.703458, step = 10100 (78.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35544\n",
      "INFO:tensorflow:loss = 7.366435, step = 10200 (73.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36362\n",
      "INFO:tensorflow:loss = 5.563476, step = 10300 (73.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39353\n",
      "INFO:tensorflow:loss = 5.3176966, step = 10400 (71.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3837\n",
      "INFO:tensorflow:loss = 6.8763413, step = 10500 (72.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37122\n",
      "INFO:tensorflow:loss = 5.392751, step = 10700 (72.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34143\n",
      "INFO:tensorflow:loss = 5.2732897, step = 10800 (74.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35263\n",
      "INFO:tensorflow:loss = 6.0564747, step = 10900 (73.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42216\n",
      "INFO:tensorflow:loss = 6.1092257, step = 11000 (70.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37922\n",
      "INFO:tensorflow:loss = 5.5613728, step = 11100 (72.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34684\n",
      "INFO:tensorflow:loss = 5.3524885, step = 11200 (74.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38949\n",
      "INFO:tensorflow:loss = 5.484736, step = 11300 (71.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39563\n",
      "INFO:tensorflow:loss = 6.137744, step = 11400 (71.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37134\n",
      "INFO:tensorflow:loss = 5.0498257, step = 11500 (72.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39739\n",
      "INFO:tensorflow:loss = 4.4332604, step = 11600 (71.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42005\n",
      "INFO:tensorflow:loss = 5.158435, step = 11700 (70.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35192\n",
      "INFO:tensorflow:loss = 5.388855, step = 11800 (73.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40613\n",
      "INFO:tensorflow:loss = 5.669346, step = 11900 (71.116 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.25337\n",
      "INFO:tensorflow:loss = 5.463659, step = 12000 (79.783 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T00:44:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-00:50:08\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 6.2296486, metrics-onlinereview/targets/accuracy = 0.13427958, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29218414, metrics-onlinereview/targets/approx_bleu_score = 0.006102796, metrics-onlinereview/targets/neg_log_perplexity = -6.1495867, metrics-onlinereview/targets/rouge_2_fscore = 0.0268439, metrics-onlinereview/targets/rouge_L_fscore = 0.14961135\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_file_v1/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12001): loss = 6.2296486, metrics-onlinereview/targets/neg_log_perplexity = -6.1495867, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 12000, metrics-onlinereview/targets/approx_bleu_score = 0.006102796, metrics-onlinereview/targets/accuracy_top5 = 0.29218414, metrics-onlinereview/targets/rouge_2_fscore = 0.0268439, metrics-onlinereview/targets/accuracy = 0.13427958, metrics-onlinereview/targets/rouge_L_fscore = 0.14961135\n",
      "INFO:tensorflow:global_step/sec: 0.254539\n",
      "INFO:tensorflow:loss = 7.703032, step = 12100 (392.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38398\n",
      "INFO:tensorflow:loss = 5.7119637, step = 12200 (72.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38839\n",
      "INFO:tensorflow:loss = 5.8248672, step = 12300 (72.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34955\n",
      "INFO:tensorflow:loss = 6.0224495, step = 12400 (74.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42102\n",
      "INFO:tensorflow:loss = 5.6915965, step = 12500 (70.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36861\n",
      "INFO:tensorflow:loss = 5.583126, step = 12600 (73.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40321\n",
      "INFO:tensorflow:loss = 5.2983193, step = 12700 (71.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41244\n",
      "INFO:tensorflow:loss = 4.967099, step = 12800 (70.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38973\n",
      "INFO:tensorflow:loss = 5.5804067, step = 12900 (71.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39699\n",
      "INFO:tensorflow:loss = 5.655112, step = 13000 (71.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.2932\n",
      "INFO:tensorflow:loss = 4.980192, step = 13100 (77.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38107\n",
      "INFO:tensorflow:loss = 5.8364787, step = 13200 (72.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31474\n",
      "INFO:tensorflow:loss = 5.646711, step = 13300 (76.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34159\n",
      "INFO:tensorflow:loss = 4.4810896, step = 13400 (74.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37446\n",
      "INFO:tensorflow:loss = 4.8372703, step = 13500 (72.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42784\n",
      "INFO:tensorflow:loss = 5.6893945, step = 13600 (70.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38935\n",
      "INFO:tensorflow:loss = 5.474726, step = 13700 (71.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42588\n",
      "INFO:tensorflow:loss = 5.0018225, step = 13800 (70.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40317\n",
      "INFO:tensorflow:loss = 5.3870554, step = 13900 (71.267 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.22511\n",
      "INFO:tensorflow:loss = 5.4713273, step = 14000 (81.625 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T01:14:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-01:20:41\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 6.1986637, metrics-onlinereview/targets/accuracy = 0.13890186, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29568586, metrics-onlinereview/targets/approx_bleu_score = 0.006955121, metrics-onlinereview/targets/neg_log_perplexity = -6.107355, metrics-onlinereview/targets/rouge_2_fscore = 0.031935383, metrics-onlinereview/targets/rouge_L_fscore = 0.16306564\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_file_v1/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14001): loss = 6.1986637, metrics-onlinereview/targets/neg_log_perplexity = -6.107355, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 14000, metrics-onlinereview/targets/approx_bleu_score = 0.006955121, metrics-onlinereview/targets/accuracy_top5 = 0.29568586, metrics-onlinereview/targets/rouge_2_fscore = 0.031935383, metrics-onlinereview/targets/accuracy = 0.13890186, metrics-onlinereview/targets/rouge_L_fscore = 0.16306564\n",
      "INFO:tensorflow:global_step/sec: 0.221965\n",
      "INFO:tensorflow:loss = 5.09781, step = 14100 (450.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41183\n",
      "INFO:tensorflow:loss = 5.7814507, step = 14200 (70.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40267\n",
      "INFO:tensorflow:loss = 5.5115695, step = 14300 (71.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38325\n",
      "INFO:tensorflow:loss = 6.2638474, step = 14400 (72.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40023\n",
      "INFO:tensorflow:loss = 5.2880054, step = 14500 (71.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38577\n",
      "INFO:tensorflow:loss = 5.4528985, step = 14600 (72.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38243\n",
      "INFO:tensorflow:loss = 5.2785335, step = 14700 (72.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3563\n",
      "INFO:tensorflow:loss = 6.168658, step = 14800 (73.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38571\n",
      "INFO:tensorflow:loss = 5.4518847, step = 14900 (72.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34722\n",
      "INFO:tensorflow:loss = 4.7924833, step = 15000 (74.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42398\n",
      "INFO:tensorflow:loss = 5.821923, step = 15100 (70.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43097\n",
      "INFO:tensorflow:loss = 5.2823687, step = 15200 (69.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41121\n",
      "INFO:tensorflow:loss = 5.3669825, step = 15300 (70.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43276\n",
      "INFO:tensorflow:loss = 5.4712934, step = 15400 (69.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37891\n",
      "INFO:tensorflow:loss = 6.114046, step = 15500 (72.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43626\n",
      "INFO:tensorflow:loss = 5.665798, step = 15600 (69.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35674\n",
      "INFO:tensorflow:loss = 5.1528397, step = 15700 (73.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3992\n",
      "INFO:tensorflow:loss = 4.8033023, step = 15800 (71.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39392\n",
      "INFO:tensorflow:loss = 5.376248, step = 15900 (71.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23269\n",
      "INFO:tensorflow:loss = 5.4503136, step = 16000 (81.122 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T01:44:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-01:51:06\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 6.1855373, metrics-onlinereview/targets/accuracy = 0.14310393, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29573256, metrics-onlinereview/targets/approx_bleu_score = 0.005000565, metrics-onlinereview/targets/neg_log_perplexity = -6.1081653, metrics-onlinereview/targets/rouge_2_fscore = 0.023418918, metrics-onlinereview/targets/rouge_L_fscore = 0.13549443\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_file_v1/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16001): loss = 6.1855373, metrics-onlinereview/targets/neg_log_perplexity = -6.1081653, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 16000, metrics-onlinereview/targets/approx_bleu_score = 0.005000565, metrics-onlinereview/targets/accuracy_top5 = 0.29573256, metrics-onlinereview/targets/rouge_2_fscore = 0.023418918, metrics-onlinereview/targets/accuracy = 0.14310393, metrics-onlinereview/targets/rouge_L_fscore = 0.13549443\n",
      "INFO:tensorflow:global_step/sec: 0.22069\n",
      "INFO:tensorflow:loss = 5.7777033, step = 16100 (453.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33832\n",
      "INFO:tensorflow:loss = 5.13559, step = 16200 (74.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4531\n",
      "INFO:tensorflow:loss = 5.1361694, step = 16300 (68.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38478\n",
      "INFO:tensorflow:loss = 4.768937, step = 16400 (72.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34028\n",
      "INFO:tensorflow:loss = 4.9504075, step = 16500 (74.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42701\n",
      "INFO:tensorflow:loss = 5.079594, step = 16600 (70.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38282\n",
      "INFO:tensorflow:loss = 5.4980626, step = 16700 (72.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32953\n",
      "INFO:tensorflow:loss = 6.4483724, step = 16800 (75.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39404\n",
      "INFO:tensorflow:loss = 5.6227775, step = 16900 (71.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43295\n",
      "INFO:tensorflow:loss = 5.1653366, step = 17000 (69.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37079\n",
      "INFO:tensorflow:loss = 5.0222545, step = 17100 (72.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43246\n",
      "INFO:tensorflow:loss = 5.546145, step = 17200 (69.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3964\n",
      "INFO:tensorflow:loss = 4.843791, step = 17300 (71.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37347\n",
      "INFO:tensorflow:loss = 5.1654162, step = 17400 (72.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38402\n",
      "INFO:tensorflow:loss = 5.1551876, step = 17700 (72.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40102\n",
      "INFO:tensorflow:loss = 5.038622, step = 17800 (71.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40092\n",
      "INFO:tensorflow:loss = 6.9584627, step = 17900 (71.397 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.17122\n",
      "INFO:tensorflow:loss = 5.470486, step = 18000 (85.366 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T02:15:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-02:21:19\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 6.152365, metrics-onlinereview/targets/accuracy = 0.14529835, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3023625, metrics-onlinereview/targets/approx_bleu_score = 0.0055779703, metrics-onlinereview/targets/neg_log_perplexity = -6.065924, metrics-onlinereview/targets/rouge_2_fscore = 0.025530465, metrics-onlinereview/targets/rouge_L_fscore = 0.14003389\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_file_v1/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18001): loss = 6.152365, metrics-onlinereview/targets/neg_log_perplexity = -6.065924, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 18000, metrics-onlinereview/targets/approx_bleu_score = 0.0055779703, metrics-onlinereview/targets/accuracy_top5 = 0.3023625, metrics-onlinereview/targets/rouge_2_fscore = 0.025530465, metrics-onlinereview/targets/accuracy = 0.14529835, metrics-onlinereview/targets/rouge_L_fscore = 0.14003389\n",
      "INFO:tensorflow:global_step/sec: 0.230865\n",
      "INFO:tensorflow:loss = 4.972527, step = 18100 (433.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36873\n",
      "INFO:tensorflow:loss = 5.535204, step = 18200 (73.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38562\n",
      "INFO:tensorflow:loss = 5.511552, step = 18300 (72.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37464\n",
      "INFO:tensorflow:loss = 5.049222, step = 18400 (72.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40801\n",
      "INFO:tensorflow:loss = 5.3231344, step = 18500 (71.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38276\n",
      "INFO:tensorflow:loss = 5.4581323, step = 18600 (72.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38813\n",
      "INFO:tensorflow:loss = 5.164748, step = 18700 (72.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40965\n",
      "INFO:tensorflow:loss = 5.849754, step = 18800 (70.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37796\n",
      "INFO:tensorflow:loss = 4.493865, step = 18900 (72.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3715\n",
      "INFO:tensorflow:loss = 4.662781, step = 19000 (72.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37602\n",
      "INFO:tensorflow:loss = 5.325846, step = 19100 (72.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37818\n",
      "INFO:tensorflow:loss = 4.891077, step = 19200 (72.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40349\n",
      "INFO:tensorflow:loss = 6.0415034, step = 19300 (71.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30536\n",
      "INFO:tensorflow:loss = 5.662205, step = 19400 (76.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40613\n",
      "INFO:tensorflow:loss = 5.260075, step = 19500 (71.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35825\n",
      "INFO:tensorflow:loss = 5.54129, step = 19600 (73.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38636\n",
      "INFO:tensorflow:loss = 4.887072, step = 19700 (72.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40704\n",
      "INFO:tensorflow:loss = 5.0438476, step = 19800 (71.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39573\n",
      "INFO:tensorflow:loss = 5.402284, step = 19900 (71.647 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23406\n",
      "INFO:tensorflow:loss = 5.527979, step = 20000 (81.032 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T02:45:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-02:51:52\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 6.118474, metrics-onlinereview/targets/accuracy = 0.14646558, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30535063, metrics-onlinereview/targets/approx_bleu_score = 0.006007597, metrics-onlinereview/targets/neg_log_perplexity = -6.0329967, metrics-onlinereview/targets/rouge_2_fscore = 0.026911188, metrics-onlinereview/targets/rouge_L_fscore = 0.14300902\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_file_v1/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20001): loss = 6.118474, metrics-onlinereview/targets/neg_log_perplexity = -6.0329967, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 20000, metrics-onlinereview/targets/approx_bleu_score = 0.006007597, metrics-onlinereview/targets/accuracy_top5 = 0.30535063, metrics-onlinereview/targets/rouge_2_fscore = 0.026911188, metrics-onlinereview/targets/accuracy = 0.14646558, metrics-onlinereview/targets/rouge_L_fscore = 0.14300902\n",
      "INFO:tensorflow:global_step/sec: 0.223464\n",
      "INFO:tensorflow:loss = 4.998704, step = 20100 (447.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.25673\n",
      "INFO:tensorflow:loss = 4.5544934, step = 20200 (79.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42415\n",
      "INFO:tensorflow:loss = 5.473774, step = 20300 (70.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36719\n",
      "INFO:tensorflow:loss = 5.4493146, step = 20400 (73.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35112\n",
      "INFO:tensorflow:loss = 5.4087353, step = 20500 (74.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32143\n",
      "INFO:tensorflow:loss = 7.0962443, step = 20600 (75.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36266\n",
      "INFO:tensorflow:loss = 4.876695, step = 20700 (73.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36535\n",
      "INFO:tensorflow:loss = 5.005794, step = 20800 (73.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35081\n",
      "INFO:tensorflow:loss = 4.8694625, step = 20900 (74.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33795\n",
      "INFO:tensorflow:loss = 4.791682, step = 21000 (74.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42733\n",
      "INFO:tensorflow:loss = 4.8101215, step = 21100 (70.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37701\n",
      "INFO:tensorflow:loss = 5.910554, step = 21200 (72.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34094\n",
      "INFO:tensorflow:loss = 5.157119, step = 21300 (74.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3832\n",
      "INFO:tensorflow:loss = 5.22992, step = 21400 (72.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41083\n",
      "INFO:tensorflow:loss = 4.1434183, step = 21500 (70.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38586\n",
      "INFO:tensorflow:loss = 5.755724, step = 21600 (72.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3265\n",
      "INFO:tensorflow:loss = 6.3688846, step = 21700 (75.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38579\n",
      "INFO:tensorflow:loss = 5.2625136, step = 21800 (72.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40742\n",
      "INFO:tensorflow:loss = 3.8090727, step = 21900 (71.065 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.2129\n",
      "INFO:tensorflow:loss = 4.888192, step = 22000 (82.440 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T03:16:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-03:22:20\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 6.113996, metrics-onlinereview/targets/accuracy = 0.14571856, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30572414, metrics-onlinereview/targets/approx_bleu_score = 0.005521014, metrics-onlinereview/targets/neg_log_perplexity = -6.0330853, metrics-onlinereview/targets/rouge_2_fscore = 0.02506089, metrics-onlinereview/targets/rouge_L_fscore = 0.14009188\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_file_v1/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22001): loss = 6.113996, metrics-onlinereview/targets/neg_log_perplexity = -6.0330853, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 22000, metrics-onlinereview/targets/approx_bleu_score = 0.005521014, metrics-onlinereview/targets/accuracy_top5 = 0.30572414, metrics-onlinereview/targets/rouge_2_fscore = 0.02506089, metrics-onlinereview/targets/accuracy = 0.14571856, metrics-onlinereview/targets/rouge_L_fscore = 0.14009188\n",
      "INFO:tensorflow:global_step/sec: 0.234584\n",
      "INFO:tensorflow:loss = 5.306472, step = 22100 (426.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35695\n",
      "INFO:tensorflow:loss = 5.8229303, step = 22200 (73.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.29992\n",
      "INFO:tensorflow:loss = 6.3522925, step = 22300 (76.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40813\n",
      "INFO:tensorflow:loss = 5.9316516, step = 22400 (71.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38268\n",
      "INFO:tensorflow:loss = 5.0413394, step = 22500 (72.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3854\n",
      "INFO:tensorflow:loss = 4.968439, step = 22600 (72.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3675\n",
      "INFO:tensorflow:loss = 5.720189, step = 22700 (73.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36445\n",
      "INFO:tensorflow:loss = 4.707661, step = 22800 (73.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39407\n",
      "INFO:tensorflow:loss = 5.4192843, step = 22900 (71.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36136\n",
      "INFO:tensorflow:loss = 5.70104, step = 23000 (73.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36415\n",
      "INFO:tensorflow:loss = 5.364554, step = 23100 (73.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41384\n",
      "INFO:tensorflow:loss = 5.6232014, step = 23200 (70.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43405\n",
      "INFO:tensorflow:loss = 5.164052, step = 23300 (69.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36459\n",
      "INFO:tensorflow:loss = 6.287996, step = 23400 (73.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35685\n",
      "INFO:tensorflow:loss = 5.495798, step = 23500 (73.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36859\n",
      "INFO:tensorflow:loss = 5.04962, step = 23600 (73.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34476\n",
      "INFO:tensorflow:loss = 5.589208, step = 23700 (74.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37162\n",
      "INFO:tensorflow:loss = 5.3130007, step = 23800 (72.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36275\n",
      "INFO:tensorflow:loss = 5.036575, step = 23900 (73.382 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23762\n",
      "INFO:tensorflow:loss = 4.896024, step = 24000 (80.797 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T03:46:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-03:53:07\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 6.068777, metrics-onlinereview/targets/accuracy = 0.14669904, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31221402, metrics-onlinereview/targets/approx_bleu_score = 0.0068357377, metrics-onlinereview/targets/neg_log_perplexity = -5.9851894, metrics-onlinereview/targets/rouge_2_fscore = 0.030523842, metrics-onlinereview/targets/rouge_L_fscore = 0.16022521\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_file_v1/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24001): loss = 6.068777, metrics-onlinereview/targets/neg_log_perplexity = -5.9851894, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 24000, metrics-onlinereview/targets/approx_bleu_score = 0.0068357377, metrics-onlinereview/targets/accuracy_top5 = 0.31221402, metrics-onlinereview/targets/rouge_2_fscore = 0.030523842, metrics-onlinereview/targets/accuracy = 0.14669904, metrics-onlinereview/targets/rouge_L_fscore = 0.16022521\n",
      "INFO:tensorflow:global_step/sec: 0.220502\n",
      "INFO:tensorflow:loss = 5.8879495, step = 24100 (453.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39295\n",
      "INFO:tensorflow:loss = 5.3170133, step = 24200 (71.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38124\n",
      "INFO:tensorflow:loss = 5.9134474, step = 24300 (72.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40948\n",
      "INFO:tensorflow:loss = 5.8182487, step = 24400 (70.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36632\n",
      "INFO:tensorflow:loss = 5.2242975, step = 24500 (73.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4067\n",
      "INFO:tensorflow:loss = 5.449936, step = 24600 (71.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40495\n",
      "INFO:tensorflow:loss = 4.6597013, step = 24700 (71.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40178\n",
      "INFO:tensorflow:loss = 3.5587287, step = 24800 (71.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37355\n",
      "INFO:tensorflow:loss = 5.3809724, step = 24900 (72.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39388\n",
      "INFO:tensorflow:loss = 5.234384, step = 25000 (71.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35276\n",
      "INFO:tensorflow:loss = 5.296148, step = 25100 (73.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39112\n",
      "INFO:tensorflow:loss = 8.000368, step = 25200 (71.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37449\n",
      "INFO:tensorflow:loss = 5.5616627, step = 25300 (72.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39214\n",
      "INFO:tensorflow:loss = 5.6034894, step = 25400 (71.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3798\n",
      "INFO:tensorflow:loss = 5.370342, step = 25500 (72.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3588\n",
      "INFO:tensorflow:loss = 5.488964, step = 25600 (73.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41422\n",
      "INFO:tensorflow:loss = 5.541659, step = 25700 (70.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36373\n",
      "INFO:tensorflow:loss = 5.5199175, step = 25800 (73.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41754\n",
      "INFO:tensorflow:loss = 4.658113, step = 25900 (70.546 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23909\n",
      "INFO:tensorflow:loss = 5.1194277, step = 26000 (80.703 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T04:17:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-04:23:01\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 6.082715, metrics-onlinereview/targets/accuracy = 0.1441778, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30530396, metrics-onlinereview/targets/approx_bleu_score = 0.0059212823, metrics-onlinereview/targets/neg_log_perplexity = -6.0017204, metrics-onlinereview/targets/rouge_2_fscore = 0.027421068, metrics-onlinereview/targets/rouge_L_fscore = 0.15074512\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_file_v1/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26001): loss = 6.082715, metrics-onlinereview/targets/neg_log_perplexity = -6.0017204, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 26000, metrics-onlinereview/targets/approx_bleu_score = 0.0059212823, metrics-onlinereview/targets/accuracy_top5 = 0.30530396, metrics-onlinereview/targets/rouge_2_fscore = 0.027421068, metrics-onlinereview/targets/accuracy = 0.1441778, metrics-onlinereview/targets/rouge_L_fscore = 0.15074512\n",
      "INFO:tensorflow:global_step/sec: 0.238842\n",
      "INFO:tensorflow:loss = 5.275516, step = 26100 (418.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42075\n",
      "INFO:tensorflow:loss = 4.457667, step = 26200 (70.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39065\n",
      "INFO:tensorflow:loss = 6.429537, step = 26300 (71.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34847\n",
      "INFO:tensorflow:loss = 4.3254075, step = 26400 (74.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39297\n",
      "INFO:tensorflow:loss = 6.240425, step = 26500 (71.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37292\n",
      "INFO:tensorflow:loss = 5.763892, step = 26600 (72.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39186\n",
      "INFO:tensorflow:loss = 5.1374855, step = 26700 (71.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30972\n",
      "INFO:tensorflow:loss = 6.016756, step = 26800 (76.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38028\n",
      "INFO:tensorflow:loss = 6.0471916, step = 26900 (72.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34162\n",
      "INFO:tensorflow:loss = 5.7513733, step = 27000 (74.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35474\n",
      "INFO:tensorflow:loss = 5.803107, step = 27100 (73.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42569\n",
      "INFO:tensorflow:loss = 5.4543443, step = 27200 (70.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35381\n",
      "INFO:tensorflow:loss = 5.306592, step = 27300 (73.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37776\n",
      "INFO:tensorflow:loss = 5.0368366, step = 27400 (72.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41914\n",
      "INFO:tensorflow:loss = 5.3726525, step = 27500 (70.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37321\n",
      "INFO:tensorflow:loss = 5.732678, step = 27600 (72.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37102\n",
      "INFO:tensorflow:loss = 5.3599114, step = 27700 (72.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33831\n",
      "INFO:tensorflow:loss = 5.404833, step = 27800 (74.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39162\n",
      "INFO:tensorflow:loss = 5.6863723, step = 27900 (71.858 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23739\n",
      "INFO:tensorflow:loss = 5.4168353, step = 28000 (80.814 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T04:47:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-04:53:23\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 6.0575047, metrics-onlinereview/targets/accuracy = 0.15178822, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31431505, metrics-onlinereview/targets/approx_bleu_score = 0.0062709507, metrics-onlinereview/targets/neg_log_perplexity = -5.9580464, metrics-onlinereview/targets/rouge_2_fscore = 0.02911387, metrics-onlinereview/targets/rouge_L_fscore = 0.1509944\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_file_v1/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28001): loss = 6.0575047, metrics-onlinereview/targets/neg_log_perplexity = -5.9580464, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 28000, metrics-onlinereview/targets/approx_bleu_score = 0.0062709507, metrics-onlinereview/targets/accuracy_top5 = 0.31431505, metrics-onlinereview/targets/rouge_2_fscore = 0.02911387, metrics-onlinereview/targets/accuracy = 0.15178822, metrics-onlinereview/targets/rouge_L_fscore = 0.1509944\n",
      "INFO:tensorflow:global_step/sec: 0.231488\n",
      "INFO:tensorflow:loss = 5.8935614, step = 28100 (431.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.378\n",
      "INFO:tensorflow:loss = 5.5402102, step = 28200 (72.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32119\n",
      "INFO:tensorflow:loss = 4.816077, step = 28300 (75.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40451\n",
      "INFO:tensorflow:loss = 5.3368134, step = 28400 (71.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3998\n",
      "INFO:tensorflow:loss = 5.4371557, step = 28500 (71.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41423\n",
      "INFO:tensorflow:loss = 5.478585, step = 28600 (70.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42917\n",
      "INFO:tensorflow:loss = 7.1852155, step = 28700 (69.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37919\n",
      "INFO:tensorflow:loss = 4.967416, step = 28800 (72.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40606\n",
      "INFO:tensorflow:loss = 5.4134164, step = 28900 (71.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38041\n",
      "INFO:tensorflow:loss = 5.0009193, step = 29000 (72.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38595\n",
      "INFO:tensorflow:loss = 5.372158, step = 29100 (72.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37039\n",
      "INFO:tensorflow:loss = 4.5849514, step = 29200 (72.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37727\n",
      "INFO:tensorflow:loss = 5.1083236, step = 29300 (72.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40238\n",
      "INFO:tensorflow:loss = 6.3812165, step = 29400 (71.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43389\n",
      "INFO:tensorflow:loss = 5.3622456, step = 29500 (69.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35679\n",
      "INFO:tensorflow:loss = 5.690376, step = 29600 (73.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35022\n",
      "INFO:tensorflow:loss = 5.5378056, step = 29700 (74.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36119\n",
      "INFO:tensorflow:loss = 5.4654794, step = 29800 (73.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38792\n",
      "INFO:tensorflow:loss = 6.7704988, step = 29900 (72.051 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_file_v1/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 1.21534\n",
      "INFO:tensorflow:loss = 4.348468, step = 30000 (82.281 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T05:17:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-05:23:59\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 6.0651007, metrics-onlinereview/targets/accuracy = 0.15286207, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31333458, metrics-onlinereview/targets/approx_bleu_score = 0.0057481863, metrics-onlinereview/targets/neg_log_perplexity = -5.9783373, metrics-onlinereview/targets/rouge_2_fscore = 0.025680253, metrics-onlinereview/targets/rouge_L_fscore = 0.14488699\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_file_v1/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30001): loss = 6.0651007, metrics-onlinereview/targets/neg_log_perplexity = -5.9783373, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 30000, metrics-onlinereview/targets/approx_bleu_score = 0.0057481863, metrics-onlinereview/targets/accuracy_top5 = 0.31333458, metrics-onlinereview/targets/rouge_2_fscore = 0.025680253, metrics-onlinereview/targets/accuracy = 0.15286207, metrics-onlinereview/targets/rouge_L_fscore = 0.14488699\n",
      "INFO:tensorflow:global_step/sec: 0.220897\n",
      "INFO:tensorflow:loss = 5.2660165, step = 30100 (452.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37852\n",
      "INFO:tensorflow:loss = 5.178146, step = 30200 (72.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41796\n",
      "INFO:tensorflow:loss = 5.366917, step = 30300 (70.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38855\n",
      "INFO:tensorflow:loss = 5.362253, step = 30400 (72.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39413\n",
      "INFO:tensorflow:loss = 5.162743, step = 30500 (71.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39498\n",
      "INFO:tensorflow:loss = 5.1187124, step = 30600 (71.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39405\n",
      "INFO:tensorflow:loss = 4.6871424, step = 30700 (71.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40701\n",
      "INFO:tensorflow:loss = 5.590024, step = 30800 (71.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38225\n",
      "INFO:tensorflow:loss = 4.925518, step = 30900 (72.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36835\n",
      "INFO:tensorflow:loss = 5.959722, step = 31000 (73.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41065\n",
      "INFO:tensorflow:loss = 5.2878313, step = 31100 (70.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39284\n",
      "INFO:tensorflow:loss = 5.28498, step = 31200 (71.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35436\n",
      "INFO:tensorflow:loss = 5.148059, step = 31300 (73.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33403\n",
      "INFO:tensorflow:loss = 5.526043, step = 31400 (74.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34711\n",
      "INFO:tensorflow:loss = 5.11571, step = 31500 (74.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36179\n",
      "INFO:tensorflow:loss = 5.303258, step = 31600 (73.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41444\n",
      "INFO:tensorflow:loss = 5.3522186, step = 31700 (70.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38635\n",
      "INFO:tensorflow:loss = 6.442797, step = 31800 (72.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40407\n",
      "INFO:tensorflow:loss = 5.446026, step = 31900 (71.221 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.24094\n",
      "INFO:tensorflow:loss = 4.2251577, step = 32000 (80.583 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T05:48:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-05:54:02\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 6.0261726, metrics-onlinereview/targets/accuracy = 0.15552339, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31884396, metrics-onlinereview/targets/approx_bleu_score = 0.006426132, metrics-onlinereview/targets/neg_log_perplexity = -5.948828, metrics-onlinereview/targets/rouge_2_fscore = 0.02875843, metrics-onlinereview/targets/rouge_L_fscore = 0.15556072\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_file_v1/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32001): loss = 6.0261726, metrics-onlinereview/targets/neg_log_perplexity = -5.948828, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 32000, metrics-onlinereview/targets/approx_bleu_score = 0.006426132, metrics-onlinereview/targets/accuracy_top5 = 0.31884396, metrics-onlinereview/targets/rouge_2_fscore = 0.02875843, metrics-onlinereview/targets/accuracy = 0.15552339, metrics-onlinereview/targets/rouge_L_fscore = 0.15556072\n",
      "INFO:tensorflow:global_step/sec: 0.237697\n",
      "INFO:tensorflow:loss = 5.256192, step = 32100 (420.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.421\n",
      "INFO:tensorflow:loss = 5.7276154, step = 32200 (70.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42107\n",
      "INFO:tensorflow:loss = 4.6995454, step = 32300 (70.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37744\n",
      "INFO:tensorflow:loss = 5.3340406, step = 32400 (72.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37721\n",
      "INFO:tensorflow:loss = 5.073787, step = 32500 (72.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37715\n",
      "INFO:tensorflow:loss = 5.8807597, step = 32600 (72.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39444\n",
      "INFO:tensorflow:loss = 5.256448, step = 32700 (71.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38866\n",
      "INFO:tensorflow:loss = 5.3916106, step = 32800 (72.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40448\n",
      "INFO:tensorflow:loss = 5.0629826, step = 32900 (71.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42063\n",
      "INFO:tensorflow:loss = 5.189991, step = 33000 (70.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43035\n",
      "INFO:tensorflow:loss = 3.6237724, step = 33100 (69.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3798\n",
      "INFO:tensorflow:loss = 5.4985385, step = 33200 (72.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37338\n",
      "INFO:tensorflow:loss = 5.6137195, step = 33400 (72.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38825\n",
      "INFO:tensorflow:loss = 5.219327, step = 33500 (72.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.345\n",
      "INFO:tensorflow:loss = 5.635162, step = 33600 (74.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38517\n",
      "INFO:tensorflow:loss = 5.477452, step = 33700 (72.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42283\n",
      "INFO:tensorflow:loss = 5.7903175, step = 33800 (70.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37029\n",
      "INFO:tensorflow:loss = 5.9246955, step = 33900 (72.983 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.25327\n",
      "INFO:tensorflow:loss = 6.1562176, step = 34000 (79.789 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T06:18:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-06:24:09\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 6.02284, metrics-onlinereview/targets/accuracy = 0.15533663, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31954432, metrics-onlinereview/targets/approx_bleu_score = 0.0061465446, metrics-onlinereview/targets/neg_log_perplexity = -5.9320626, metrics-onlinereview/targets/rouge_2_fscore = 0.028424826, metrics-onlinereview/targets/rouge_L_fscore = 0.15083256\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_file_v1/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34001): loss = 6.02284, metrics-onlinereview/targets/neg_log_perplexity = -5.9320626, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 34000, metrics-onlinereview/targets/approx_bleu_score = 0.0061465446, metrics-onlinereview/targets/accuracy_top5 = 0.31954432, metrics-onlinereview/targets/rouge_2_fscore = 0.028424826, metrics-onlinereview/targets/accuracy = 0.15533663, metrics-onlinereview/targets/rouge_L_fscore = 0.15083256\n",
      "INFO:tensorflow:global_step/sec: 0.231263\n",
      "INFO:tensorflow:loss = 5.2730594, step = 34100 (432.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3871\n",
      "INFO:tensorflow:loss = 6.345861, step = 34200 (72.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3771\n",
      "INFO:tensorflow:loss = 5.576519, step = 34300 (72.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35444\n",
      "INFO:tensorflow:loss = 6.889335, step = 34400 (73.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34817\n",
      "INFO:tensorflow:loss = 5.6950045, step = 34500 (74.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38556\n",
      "INFO:tensorflow:loss = 5.0638304, step = 34600 (72.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35289\n",
      "INFO:tensorflow:loss = 3.5467813, step = 34700 (73.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32981\n",
      "INFO:tensorflow:loss = 6.4508224, step = 34800 (75.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40974\n",
      "INFO:tensorflow:loss = 5.3148413, step = 34900 (70.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35126\n",
      "INFO:tensorflow:loss = 5.2206016, step = 35000 (74.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44123\n",
      "INFO:tensorflow:loss = 5.213384, step = 35100 (69.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35754\n",
      "INFO:tensorflow:loss = 5.419023, step = 35200 (73.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40128\n",
      "INFO:tensorflow:loss = 4.805331, step = 35300 (71.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34238\n",
      "INFO:tensorflow:loss = 5.993348, step = 35400 (74.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41861\n",
      "INFO:tensorflow:loss = 6.64602, step = 35500 (70.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37041\n",
      "INFO:tensorflow:loss = 4.8406434, step = 35600 (72.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41827\n",
      "INFO:tensorflow:loss = 5.0790462, step = 35700 (70.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36055\n",
      "INFO:tensorflow:loss = 5.6524987, step = 35800 (73.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39738\n",
      "INFO:tensorflow:loss = 4.7926917, step = 35900 (71.564 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.25188\n",
      "INFO:tensorflow:loss = 5.4292793, step = 36000 (79.880 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T06:48:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-06:54:30\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 6.0233593, metrics-onlinereview/targets/accuracy = 0.1546363, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32071155, metrics-onlinereview/targets/approx_bleu_score = 0.006491999, metrics-onlinereview/targets/neg_log_perplexity = -5.94254, metrics-onlinereview/targets/rouge_2_fscore = 0.029732656, metrics-onlinereview/targets/rouge_L_fscore = 0.15468204\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_file_v1/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36001): loss = 6.0233593, metrics-onlinereview/targets/neg_log_perplexity = -5.94254, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 36000, metrics-onlinereview/targets/approx_bleu_score = 0.006491999, metrics-onlinereview/targets/accuracy_top5 = 0.32071155, metrics-onlinereview/targets/rouge_2_fscore = 0.029732656, metrics-onlinereview/targets/accuracy = 0.1546363, metrics-onlinereview/targets/rouge_L_fscore = 0.15468204\n",
      "INFO:tensorflow:global_step/sec: 0.230434\n",
      "INFO:tensorflow:loss = 5.2909627, step = 36100 (433.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4045\n",
      "INFO:tensorflow:loss = 5.2328277, step = 36200 (71.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34965\n",
      "INFO:tensorflow:loss = 4.58665, step = 36300 (74.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35916\n",
      "INFO:tensorflow:loss = 5.044024, step = 36400 (73.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36999\n",
      "INFO:tensorflow:loss = 5.2340055, step = 36500 (72.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34119\n",
      "INFO:tensorflow:loss = 5.0402484, step = 36600 (74.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3763\n",
      "INFO:tensorflow:loss = 4.8526716, step = 36700 (72.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41651\n",
      "INFO:tensorflow:loss = 5.4500895, step = 36800 (70.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34211\n",
      "INFO:tensorflow:loss = 5.28665, step = 36900 (74.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38738\n",
      "INFO:tensorflow:loss = 4.7183585, step = 37000 (72.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37835\n",
      "INFO:tensorflow:loss = 5.0874853, step = 37100 (72.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40353\n",
      "INFO:tensorflow:loss = 5.621849, step = 37200 (71.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44722\n",
      "INFO:tensorflow:loss = 5.320383, step = 37300 (69.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36741\n",
      "INFO:tensorflow:loss = 5.0989456, step = 37400 (73.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35026\n",
      "INFO:tensorflow:loss = 5.382256, step = 37500 (74.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36917\n",
      "INFO:tensorflow:loss = 4.9294844, step = 37600 (73.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35584\n",
      "INFO:tensorflow:loss = 6.479594, step = 37700 (73.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36613\n",
      "INFO:tensorflow:loss = 4.853098, step = 37800 (73.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43033\n",
      "INFO:tensorflow:loss = 5.1916995, step = 37900 (69.918 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.22077\n",
      "INFO:tensorflow:loss = 4.7059426, step = 38000 (81.911 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T07:18:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-07:24:12\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 6.032048, metrics-onlinereview/targets/accuracy = 0.15309553, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32108507, metrics-onlinereview/targets/approx_bleu_score = 0.0066493168, metrics-onlinereview/targets/neg_log_perplexity = -5.9427752, metrics-onlinereview/targets/rouge_2_fscore = 0.029675465, metrics-onlinereview/targets/rouge_L_fscore = 0.15491511\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_file_v1/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38001): loss = 6.032048, metrics-onlinereview/targets/neg_log_perplexity = -5.9427752, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 38000, metrics-onlinereview/targets/approx_bleu_score = 0.0066493168, metrics-onlinereview/targets/accuracy_top5 = 0.32108507, metrics-onlinereview/targets/rouge_2_fscore = 0.029675465, metrics-onlinereview/targets/accuracy = 0.15309553, metrics-onlinereview/targets/rouge_L_fscore = 0.15491511\n",
      "INFO:tensorflow:global_step/sec: 0.252788\n",
      "INFO:tensorflow:loss = 5.265899, step = 38100 (395.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36108\n",
      "INFO:tensorflow:loss = 5.4882274, step = 38200 (73.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38683\n",
      "INFO:tensorflow:loss = 4.780855, step = 38300 (72.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37484\n",
      "INFO:tensorflow:loss = 4.8747888, step = 38400 (72.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35877\n",
      "INFO:tensorflow:loss = 4.7764654, step = 38500 (73.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44771\n",
      "INFO:tensorflow:loss = 5.5853486, step = 38600 (69.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35923\n",
      "INFO:tensorflow:loss = 5.833613, step = 38700 (73.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38781\n",
      "INFO:tensorflow:loss = 5.179281, step = 38800 (72.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36386\n",
      "INFO:tensorflow:loss = 4.901767, step = 38900 (73.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35441\n",
      "INFO:tensorflow:loss = 3.6755784, step = 39000 (73.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36721\n",
      "INFO:tensorflow:loss = 5.2564597, step = 39100 (73.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34129\n",
      "INFO:tensorflow:loss = 5.129712, step = 39200 (74.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4321\n",
      "INFO:tensorflow:loss = 5.651293, step = 39300 (69.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41048\n",
      "INFO:tensorflow:loss = 5.3530693, step = 39400 (70.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37927\n",
      "INFO:tensorflow:loss = 5.111057, step = 39500 (72.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39652\n",
      "INFO:tensorflow:loss = 5.1932178, step = 39600 (71.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35044\n",
      "INFO:tensorflow:loss = 5.3295856, step = 39700 (74.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39587\n",
      "INFO:tensorflow:loss = 5.0200243, step = 39800 (71.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40781\n",
      "INFO:tensorflow:loss = 4.9016533, step = 39900 (71.035 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.653999.\n",
      "Time: 27279.99 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_v1'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 2048 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "# hparams.num_encoder_layers = 2\n",
    "# hparams.num_hidden_layers = 6\n",
    "# hparams.num_decoder_layers = 2 \n",
    "# hparams.dropout =0.4\n",
    "# hparams.num_heads =16\n",
    "# hparams.attention_dropout = 0.5 ##\n",
    "# hparams.max_input_seq_length = ????\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40000,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=1000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     checkpoints = []\n",
    "#     if not os.path.exists('Data/Checkpoints/'):\n",
    "#         os.makedirs('Data/Checkpoints/')\n",
    "#     checkpoints.append(ModelCheckpoint('Data/Checkpoints/best_weights.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1))\n",
    "#     checkpoints.append(TensorBoard(log_dir='Data/Checkpoints/./logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_file_v1', '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None, 'use_tpu': False, '_save_checkpoints_steps': 1000, '_tf_random_seed': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_task_id': 0, '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_device_fn': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_master': '', '_num_ps_replicas': 0, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc28fd5f0f0>, '_evaluation_master': '', '_environment': 'local', '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc28fd5f128>, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc290620620>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc28fd4ef28>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc28fd4ee80>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc28f346198>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc28f346198>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.820176, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.43283\n",
      "INFO:tensorflow:loss = 9.0315, step = 100 (41.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81802\n",
      "INFO:tensorflow:loss = 7.848617, step = 200 (35.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72231\n",
      "INFO:tensorflow:loss = 7.7164655, step = 300 (36.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70048\n",
      "INFO:tensorflow:loss = 7.837867, step = 400 (37.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85136\n",
      "INFO:tensorflow:loss = 6.4716654, step = 500 (35.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78405\n",
      "INFO:tensorflow:loss = 6.669176, step = 600 (35.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8769\n",
      "INFO:tensorflow:loss = 5.6054273, step = 700 (34.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78363\n",
      "INFO:tensorflow:loss = 5.6846113, step = 800 (35.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7076\n",
      "INFO:tensorflow:loss = 8.744803, step = 900 (36.934 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23067\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:03:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:05:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 6.8931675, metrics-onlinereview/targets/accuracy = 0.080210656, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.1829046, metrics-onlinereview/targets/approx_bleu_score = 0.0052986084, metrics-onlinereview/targets/neg_log_perplexity = -6.820747, metrics-onlinereview/targets/rouge_2_fscore = 0.018404728, metrics-onlinereview/targets/rouge_L_fscore = 0.13956645\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: model_file_v1/model.ckpt-1000\n",
      "INFO:tensorflow:Validation (step 1000): loss = 6.8931675, metrics-onlinereview/targets/neg_log_perplexity = -6.820747, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 1000, metrics-onlinereview/targets/approx_bleu_score = 0.0052986084, metrics-onlinereview/targets/accuracy_top5 = 0.1829046, metrics-onlinereview/targets/rouge_2_fscore = 0.018404728, metrics-onlinereview/targets/accuracy = 0.080210656, metrics-onlinereview/targets/rouge_L_fscore = 0.13956645\n",
      "INFO:tensorflow:loss = 5.874517, step = 1000 (159.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.664183\n",
      "INFO:tensorflow:loss = 5.5345335, step = 1100 (35.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75596\n",
      "INFO:tensorflow:loss = 5.4034715, step = 1200 (36.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76143\n",
      "INFO:tensorflow:loss = 7.0822883, step = 1300 (36.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79581\n",
      "INFO:tensorflow:loss = 6.3155684, step = 1400 (35.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77281\n",
      "INFO:tensorflow:loss = 5.612577, step = 1500 (36.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83191\n",
      "INFO:tensorflow:loss = 5.419204, step = 1600 (35.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79558\n",
      "INFO:tensorflow:loss = 5.619882, step = 1700 (35.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.67101\n",
      "INFO:tensorflow:loss = 6.316434, step = 1800 (37.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80336\n",
      "INFO:tensorflow:loss = 6.220013, step = 1900 (35.672 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24119\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:11:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:13:05\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.587814, metrics-onlinereview/targets/accuracy = 0.1176828, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.24306259, metrics-onlinereview/targets/approx_bleu_score = 0.003401608, metrics-onlinereview/targets/neg_log_perplexity = -6.5061903, metrics-onlinereview/targets/rouge_2_fscore = 0.008256864, metrics-onlinereview/targets/rouge_L_fscore = 0.10412798\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_v1/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): loss = 6.587814, metrics-onlinereview/targets/neg_log_perplexity = -6.5061903, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 2000, metrics-onlinereview/targets/approx_bleu_score = 0.003401608, metrics-onlinereview/targets/accuracy_top5 = 0.24306259, metrics-onlinereview/targets/rouge_2_fscore = 0.008256864, metrics-onlinereview/targets/accuracy = 0.1176828, metrics-onlinereview/targets/rouge_L_fscore = 0.10412798\n",
      "INFO:tensorflow:loss = 6.080802, step = 2000 (149.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.709543\n",
      "INFO:tensorflow:loss = 6.737644, step = 2100 (36.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74221\n",
      "INFO:tensorflow:loss = 7.5938034, step = 2200 (36.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74302\n",
      "INFO:tensorflow:loss = 6.4351707, step = 2300 (36.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73267\n",
      "INFO:tensorflow:loss = 4.9659643, step = 2400 (36.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71254\n",
      "INFO:tensorflow:loss = 5.7850485, step = 2500 (36.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76663\n",
      "INFO:tensorflow:loss = 4.065698, step = 2600 (36.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83012\n",
      "INFO:tensorflow:loss = 5.588816, step = 2700 (35.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79302\n",
      "INFO:tensorflow:loss = 5.9991236, step = 2800 (35.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85035\n",
      "INFO:tensorflow:loss = 5.3072453, step = 2900 (35.084 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.17123\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:19:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:21:02\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 6.4799147, metrics-onlinereview/targets/accuracy = 0.116872594, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.25035447, metrics-onlinereview/targets/approx_bleu_score = 0.004673335, metrics-onlinereview/targets/neg_log_perplexity = -6.3943763, metrics-onlinereview/targets/rouge_2_fscore = 0.015254237, metrics-onlinereview/targets/rouge_L_fscore = 0.11970963\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: model_file_v1/model.ckpt-3000\n",
      "INFO:tensorflow:Validation (step 3000): loss = 6.4799147, metrics-onlinereview/targets/neg_log_perplexity = -6.3943763, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 3000, metrics-onlinereview/targets/approx_bleu_score = 0.004673335, metrics-onlinereview/targets/accuracy_top5 = 0.25035447, metrics-onlinereview/targets/rouge_2_fscore = 0.015254237, metrics-onlinereview/targets/accuracy = 0.116872594, metrics-onlinereview/targets/rouge_L_fscore = 0.11970963\n",
      "INFO:tensorflow:loss = 6.7374144, step = 3000 (152.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.705581\n",
      "INFO:tensorflow:loss = 5.272836, step = 3100 (35.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.6923\n",
      "INFO:tensorflow:loss = 6.9848566, step = 3200 (37.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69002\n",
      "INFO:tensorflow:loss = 5.612186, step = 3300 (37.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78098\n",
      "INFO:tensorflow:loss = 6.158658, step = 3400 (35.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86712\n",
      "INFO:tensorflow:loss = 5.569326, step = 3500 (34.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74902\n",
      "INFO:tensorflow:loss = 6.4299417, step = 3600 (36.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78387\n",
      "INFO:tensorflow:loss = 5.4569235, step = 3700 (35.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81048\n",
      "INFO:tensorflow:loss = 5.693967, step = 3800 (35.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73458\n",
      "INFO:tensorflow:loss = 5.55251, step = 3900 (36.571 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24323\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:27:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:28:59\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 6.3806973, metrics-onlinereview/targets/accuracy = 0.13105124, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.264128, metrics-onlinereview/targets/approx_bleu_score = 0.0053905603, metrics-onlinereview/targets/neg_log_perplexity = -6.324194, metrics-onlinereview/targets/rouge_2_fscore = 0.01944869, metrics-onlinereview/targets/rouge_L_fscore = 0.1172692\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_v1/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): loss = 6.3806973, metrics-onlinereview/targets/neg_log_perplexity = -6.324194, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 4000, metrics-onlinereview/targets/approx_bleu_score = 0.0053905603, metrics-onlinereview/targets/accuracy_top5 = 0.264128, metrics-onlinereview/targets/rouge_2_fscore = 0.01944869, metrics-onlinereview/targets/accuracy = 0.13105124, metrics-onlinereview/targets/rouge_L_fscore = 0.1172692\n",
      "INFO:tensorflow:loss = 5.6789007, step = 4000 (151.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.698002\n",
      "INFO:tensorflow:loss = 4.8722725, step = 4100 (36.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82411\n",
      "INFO:tensorflow:loss = 5.713871, step = 4200 (35.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73624\n",
      "INFO:tensorflow:loss = 6.281771, step = 4300 (36.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8168\n",
      "INFO:tensorflow:loss = 4.746562, step = 4400 (35.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74755\n",
      "INFO:tensorflow:loss = 6.755494, step = 4500 (36.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75417\n",
      "INFO:tensorflow:loss = 6.562761, step = 4600 (36.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72662\n",
      "INFO:tensorflow:loss = 4.8850365, step = 4700 (36.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82105\n",
      "INFO:tensorflow:loss = 5.659468, step = 4800 (35.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83215\n",
      "INFO:tensorflow:loss = 5.538517, step = 4900 (35.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21542\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:35:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:37:03\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 6.3732653, metrics-onlinereview/targets/accuracy = 0.12963338, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26554587, metrics-onlinereview/targets/approx_bleu_score = 0.0065116566, metrics-onlinereview/targets/neg_log_perplexity = -6.298871, metrics-onlinereview/targets/rouge_2_fscore = 0.025693776, metrics-onlinereview/targets/rouge_L_fscore = 0.14417171\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: model_file_v1/model.ckpt-5000\n",
      "INFO:tensorflow:Validation (step 5000): loss = 6.3732653, metrics-onlinereview/targets/neg_log_perplexity = -6.298871, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 5000, metrics-onlinereview/targets/approx_bleu_score = 0.0065116566, metrics-onlinereview/targets/accuracy_top5 = 0.26554587, metrics-onlinereview/targets/rouge_2_fscore = 0.025693776, metrics-onlinereview/targets/accuracy = 0.12963338, metrics-onlinereview/targets/rouge_L_fscore = 0.14417171\n",
      "INFO:tensorflow:loss = 5.9924664, step = 5000 (160.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660979\n",
      "INFO:tensorflow:loss = 5.7233114, step = 5100 (36.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70317\n",
      "INFO:tensorflow:loss = 4.3370147, step = 5200 (36.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81768\n",
      "INFO:tensorflow:loss = 5.0449953, step = 5300 (35.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73599\n",
      "INFO:tensorflow:loss = 5.1950793, step = 5400 (36.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8103\n",
      "INFO:tensorflow:loss = 6.082032, step = 5500 (35.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82207\n",
      "INFO:tensorflow:loss = 5.796518, step = 5600 (35.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71291\n",
      "INFO:tensorflow:loss = 5.7853613, step = 5700 (36.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.803\n",
      "INFO:tensorflow:loss = 3.9295673, step = 5800 (35.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75725\n",
      "INFO:tensorflow:loss = 4.7107296, step = 5900 (36.268 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20511\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:43:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:45:11\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 6.377694, metrics-onlinereview/targets/accuracy = 0.13307677, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.27081224, metrics-onlinereview/targets/approx_bleu_score = 0.006701106, metrics-onlinereview/targets/neg_log_perplexity = -6.3014193, metrics-onlinereview/targets/rouge_2_fscore = 0.024723686, metrics-onlinereview/targets/rouge_L_fscore = 0.14334732\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_v1/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): loss = 6.377694, metrics-onlinereview/targets/neg_log_perplexity = -6.3014193, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 6000, metrics-onlinereview/targets/approx_bleu_score = 0.006701106, metrics-onlinereview/targets/accuracy_top5 = 0.27081224, metrics-onlinereview/targets/rouge_2_fscore = 0.024723686, metrics-onlinereview/targets/accuracy = 0.13307677, metrics-onlinereview/targets/rouge_L_fscore = 0.14334732\n",
      "INFO:tensorflow:loss = 5.1227336, step = 6000 (162.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.653414\n",
      "INFO:tensorflow:loss = 4.3471932, step = 6100 (35.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68253\n",
      "INFO:tensorflow:loss = 6.00374, step = 6200 (37.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75424\n",
      "INFO:tensorflow:loss = 5.4301476, step = 6300 (36.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76826\n",
      "INFO:tensorflow:loss = 5.4889727, step = 6400 (36.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83866\n",
      "INFO:tensorflow:loss = 5.511093, step = 6500 (35.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83288\n",
      "INFO:tensorflow:loss = 5.989005, step = 6600 (35.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73385\n",
      "INFO:tensorflow:loss = 5.4539523, step = 6700 (36.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76964\n",
      "INFO:tensorflow:loss = 5.583195, step = 6800 (36.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69982\n",
      "INFO:tensorflow:loss = 5.262391, step = 6900 (37.040 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26321\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:51:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:53:18\n",
      "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, loss = 6.340396, metrics-onlinereview/targets/accuracy = 0.13084869, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.28175005, metrics-onlinereview/targets/approx_bleu_score = 0.0072638267, metrics-onlinereview/targets/neg_log_perplexity = -6.2551384, metrics-onlinereview/targets/rouge_2_fscore = 0.029246984, metrics-onlinereview/targets/rouge_L_fscore = 0.15972947\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: model_file_v1/model.ckpt-7000\n",
      "INFO:tensorflow:Validation (step 7000): loss = 6.340396, metrics-onlinereview/targets/neg_log_perplexity = -6.2551384, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 7000, metrics-onlinereview/targets/approx_bleu_score = 0.0072638267, metrics-onlinereview/targets/accuracy_top5 = 0.28175005, metrics-onlinereview/targets/rouge_2_fscore = 0.029246984, metrics-onlinereview/targets/accuracy = 0.13084869, metrics-onlinereview/targets/rouge_L_fscore = 0.15972947\n",
      "INFO:tensorflow:loss = 6.3822513, step = 7000 (162.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650893\n",
      "INFO:tensorflow:loss = 5.6725636, step = 7100 (35.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.67875\n",
      "INFO:tensorflow:loss = 5.2081027, step = 7200 (37.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81907\n",
      "INFO:tensorflow:loss = 5.228724, step = 7300 (35.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8692\n",
      "INFO:tensorflow:loss = 5.9943733, step = 7400 (34.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74243\n",
      "INFO:tensorflow:loss = 5.1650653, step = 7500 (36.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87896\n",
      "INFO:tensorflow:loss = 5.6824384, step = 7600 (34.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72752\n",
      "INFO:tensorflow:loss = 5.291372, step = 7700 (36.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80573\n",
      "INFO:tensorflow:loss = 5.5231423, step = 7800 (35.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8372\n",
      "INFO:tensorflow:loss = 5.9224, step = 7900 (35.248 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25715\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:59:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-17:01:27\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 6.393666, metrics-onlinereview/targets/accuracy = 0.12477213, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26939437, metrics-onlinereview/targets/approx_bleu_score = 0.0068583908, metrics-onlinereview/targets/neg_log_perplexity = -6.3029304, metrics-onlinereview/targets/rouge_2_fscore = 0.02608918, metrics-onlinereview/targets/rouge_L_fscore = 0.14761074\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_file_v1/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): loss = 6.393666, metrics-onlinereview/targets/neg_log_perplexity = -6.3029304, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 8000, metrics-onlinereview/targets/approx_bleu_score = 0.0068583908, metrics-onlinereview/targets/accuracy_top5 = 0.26939437, metrics-onlinereview/targets/rouge_2_fscore = 0.02608918, metrics-onlinereview/targets/accuracy = 0.12477213, metrics-onlinereview/targets/rouge_L_fscore = 0.14761074\n",
      "INFO:tensorflow:loss = 5.760723, step = 8000 (166.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.63306\n",
      "INFO:tensorflow:loss = 5.3723745, step = 8100 (35.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7667\n",
      "INFO:tensorflow:loss = 6.308387, step = 8200 (36.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74763\n",
      "INFO:tensorflow:loss = 6.4910836, step = 8300 (36.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.65092\n",
      "INFO:tensorflow:loss = 6.3829865, step = 8400 (37.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80865\n",
      "INFO:tensorflow:loss = 6.3292904, step = 8500 (35.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7955\n",
      "INFO:tensorflow:loss = 7.4166446, step = 8600 (35.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79102\n",
      "INFO:tensorflow:loss = 5.892159, step = 8700 (35.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85631\n",
      "INFO:tensorflow:loss = 5.5596533, step = 8800 (35.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73849\n",
      "INFO:tensorflow:loss = 5.757562, step = 8900 (36.517 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24259\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T17:07:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-17:09:23\n",
      "INFO:tensorflow:Saving dict for global step 9000: global_step = 9000, loss = 6.382387, metrics-onlinereview/targets/accuracy = 0.12922828, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26433057, metrics-onlinereview/targets/approx_bleu_score = 0.005818227, metrics-onlinereview/targets/neg_log_perplexity = -6.301665, metrics-onlinereview/targets/rouge_2_fscore = 0.023459261, metrics-onlinereview/targets/rouge_L_fscore = 0.1333496\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: model_file_v1/model.ckpt-9000\n",
      "INFO:tensorflow:Validation (step 9000): loss = 6.382387, metrics-onlinereview/targets/neg_log_perplexity = -6.301665, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 9000, metrics-onlinereview/targets/approx_bleu_score = 0.005818227, metrics-onlinereview/targets/accuracy_top5 = 0.26433057, metrics-onlinereview/targets/rouge_2_fscore = 0.023459261, metrics-onlinereview/targets/accuracy = 0.12922828, metrics-onlinereview/targets/rouge_L_fscore = 0.1333496\n",
      "INFO:tensorflow:loss = 5.3969903, step = 9000 (151.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.700008\n",
      "INFO:tensorflow:loss = 5.646725, step = 9100 (36.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7602\n",
      "INFO:tensorflow:loss = 6.658905, step = 9200 (36.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81412\n",
      "INFO:tensorflow:loss = 5.025133, step = 9300 (35.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74433\n",
      "INFO:tensorflow:loss = 5.105712, step = 9400 (36.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73796\n",
      "INFO:tensorflow:loss = 5.267669, step = 9500 (36.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77318\n",
      "INFO:tensorflow:loss = 5.2262473, step = 9600 (36.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78308\n",
      "INFO:tensorflow:loss = 4.34492, step = 9700 (35.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79986\n",
      "INFO:tensorflow:loss = 5.018489, step = 9800 (35.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72967\n",
      "INFO:tensorflow:loss = 5.3967323, step = 9900 (36.635 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.365423.\n",
      "Time: 4757.36 s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------decoding check-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_file_v1', '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None, 'use_tpu': False, '_save_checkpoints_steps': 1000, '_tf_random_seed': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_task_id': 0, '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_device_fn': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_master': '', '_num_ps_replicas': 0, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc3e2d59908>, '_evaluation_master': '', '_environment': 'local', '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc27bb07b70>, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc4843c0c80>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_v1\") #model.ckpt\n",
    "\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# #Restore and summarize\n",
    "# def summarize(inputs):\n",
    "#     encoded_inputs = encode(inputs)\n",
    "#     with tfe.restore_variables_on_create(ckpt_path):\n",
    "#         model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "#     return decode(model_output)\n",
    "\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "# # inputs = '''\n",
    "# # happy with purchase even though it came a lot later than expected.'''\n",
    "# outputs = summarize(inputs)\n",
    "\n",
    "# print(\"Inputs: %s\" % inputs)\n",
    "# print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_file_v1/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"they the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\"\tScore:-273.903870\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\"they the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the a\"\tScore:-275.411835\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">q\n"
     ]
    }
   ],
   "source": [
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_file_v1/model.ckpt-40000'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create hparams and the model\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=ende_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_v1/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "\n",
      "Outputs: to a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = t2t_model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "# inputs = '''\n",
    "# happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "\n",
      "Outputs: peter peter;the muppetical american novel features a protagonist protagonist muppetan afterthought in which realworld both physical and moral challenges and through which through which receivers with a buddhist spirit, by the eduble of muppets with beads, both real and ignored  create florida engaging water for learning is an nonprofamerican work, set, set in the depths of the depression and featuring a young man whose assistance d create create create create create create create of faith him into a and unknown way of life life remaining;\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "# inputs = '''\n",
    "# happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc51491b320>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc51491b278>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc5147b6ba8>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc5147b6ba8>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_smoothing': 0.1, 'learning_rate_constant': 1.0, 'optimizer_multistep_accumulate_steps': None, 'learning_rate_warmup_steps': 8000, 'optimizer_adafactor_decay_type': 'pow', 'use_fixed_batch_size': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'multiply_embedding_mode': 'sqrt_depth', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'parameter_attention_key_channels': 0, 'summarize_grads': False, 'num_hidden_layers': 6, 'pad_batch': False, 'weight_noise': 0.0, 'learning_rate_decay_scheme': 'noam', 'multiproblem_fixed_train_length': -1, 'max_target_seq_length': 0, 'kernel_height': 3, 'dropout': 0.2, 'grad_noise_scale': 0.0, 'learning_rate_minimum': None, 'ffn_layer': 'dense_relu_dense', 'optimizer_adafactor_memory_exponent': 0.8, 'force_full_predict': False, 'multiproblem_mixing_schedule': 'constant', 'min_length': 0, 'shared_embedding': False, 'optimizer_adam_beta1': 0.9, 'num_decoder_layers': 0, 'factored_logits': False, 'layer_preprocess_sequence': 'n', 'proximity_bias': False, 'attention_key_channels': 0, 'kernel_width': 1, 'layer_prepostprocess_dropout': 0.1, 'conv_first_kernel': 3, 'video_num_input_frames': 1, 'learning_rate': 0.1, 'moe_overhead_train': 1.0, 'norm_type': 'layer', 'mlperf_mode': False, 'optimizer_adafactor_beta1': 0.0, 'split_to_length': 0, 'attention_value_channels': 0, 'eval_run_autoregressive': False, 'num_heads': 8, 'attention_dropout_broadcast_dims': '', 'unidirectional_encoder': False, 'vocab_divisor': 1, 'weight_dtype': 'float32', 'max_relative_position': 0, 'relu_dropout_broadcast_dims': '', 'tpu_enable_host_call': False, 'causal_decoder_self_attention': True, 'add_relative_to_values': False, 'layer_prepostprocess_dropout_broadcast_dims': '', 'symbol_modality_skip_top': False, 'optimizer_adafactor_factored': True, 'multiproblem_vocab_size': -1, 'eval_drop_long_sequences': False, 'clip_grad_norm': 0.0, 'nbr_decoder_problems': 1, 'multiproblem_reweight_label_loss': False, 'optimizer_adafactor_beta2': 0.999, 'norm_epsilon': 1e-06, 'learning_rate_decay_steps': 5000, 'heads_share_relative_embedding': False, 'num_encoder_layers': 0, 'symbol_modality_num_shards': 16, 'symbol_dropout': 0.0, 'max_length': 0, 'moe_k': 2, 'length_bucket_step': 1.1, 'layer_postprocess_sequence': 'da', 'multiproblem_max_input_length': -1, 'summarize_vars': False, 'multiproblem_schedule_max_examples': 10000000.0, 'max_input_seq_length': 1024, 'learning_rate_cosine_cycle_steps': 250000, 'pretrained_model_dir': '', 'overload_eval_metric_name': '', 'sampling_method': 'argmax', 'learning_rate_decay_staircase': False, 'activation_dtype': 'float32', 'multiproblem_max_target_length': -1, 'moe_num_experts': 16, 'use_pad_remover': True, 'sampling_temp': 1.0, 'learning_rate_schedule': 'legacy', 'attention_dropout': 0.2, 'modality': {}, 'hidden_size': 512, 'weight_decay': 0.0, 'no_data_parallelism': False, 'pos': 'timing', 'initializer': 'uniform_unit_scaling', 'use_target_space_embedding': True, 'batch_shuffle_size': 512, 'multiproblem_target_eval_only': False, 'attention_variables_3d': False, 'scheduled_sampling_warmup_steps': 50000, 'optimizer_adafactor_clipping_threshold': 1.0, 'shared_embedding_and_softmax_weights': True, 'moe_loss_coef': 0.001, 'batch_size': 2048, 'optimizer_zero_grads': False, 'optimizer_momentum_momentum': 0.9, 'initializer_gain': 1.0, 'multiproblem_schedule_threshold': 0.5, 'filter_size': 2048, 'moe_overhead_eval': 2.0, 'parameter_attention_value_channels': 0, 'video_num_target_frames': 1, 'multiproblem_label_weight': 0.5, 'optimizer_adam_epsilon': 1e-09, 'optimizer_adam_beta2': 0.98, 'warm_start_from_second': '', 'compress_steps': 0, 'min_length_bucket': 8, 'multiproblem_per_task_threshold': '', 'learning_rate_decay_rate': 1.0, 'relu_dropout': 0.1, 'scheduled_sampling_prob': 0.0, 'moe_hidden_sizes': '2048', 'optimizer_momentum_nesterov': False, 'self_attention_type': 'dot_product', 'optimizer': 'Adam', 'prepend_mode': 'prepend_inputs_full_attention', 'daisy_chain_variables': True}\n",
      "{'decode_to_file': None, 'max_input_size': -1, 'eos_penalty': 0.0, 'shard_google_format': False, 'guess_and_check_top_k': 0, 'identity_output': False, 'batch_size': 0, 'mlperf_decode_step': 0.0, 'alpha': 0.6, 'num_samples': -1, 'write_beam_scores': False, 'log_results': True, 'max_display_outputs': 10, 'force_decode_length': False, 'beam_size': 4, 'vgg_ckpt_path': '', 'shards': 1, 'guess_and_check_epsilon': -1, 'decode_timeout_mins': 240, 'save_images': False, 'shard_id': 0, 'decode_in_memory': False, 'frames_per_second': 10, 'extra_length': 100, 'display_decoded_images': False, 'mlperf_threshold': 25.0, 'block_size': 0, 'border_percent': 2, 'delimiter': '\\n', 'mlperf_success': False, 'summaries_log_dir': 'decode', 'multiproblem_task_id': -1, 'max_display_decodes': 5, 'num_decodes': 1, 'skip_eos_postprocess': False, 'return_beams': True, 'shards_start_offset': 0}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f338c30b470>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_keep_checkpoint_max': 20, '_num_ps_replicas': 0, '_train_distribute': None, '_master': '', '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, 't2t_device_info': {'num_async_replicas': 1}, '_log_step_count_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f338c30b4a8>, '_tf_random_seed': None, '_model_dir': 'model_file_1024', '_is_chief': True, '_save_checkpoints_steps': 2000, '_protocol': None, 'use_tpu': False, '_evaluation_master': '', '_task_type': None, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f338dd6b8c8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f338c30b240>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f338c30b2e8>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9e80>, 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9e80>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.770576, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.29689\n",
      "INFO:tensorflow:loss = 8.474687, step = 100 (77.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43305\n",
      "INFO:tensorflow:loss = 7.4154024, step = 200 (69.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45241\n",
      "INFO:tensorflow:loss = 7.140645, step = 300 (68.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4319\n",
      "INFO:tensorflow:loss = 6.9852133, step = 400 (69.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46155\n",
      "INFO:tensorflow:loss = 6.3340445, step = 500 (68.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39018\n",
      "INFO:tensorflow:loss = 6.7953463, step = 600 (71.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42654\n",
      "INFO:tensorflow:loss = 6.0979958, step = 700 (70.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46319\n",
      "INFO:tensorflow:loss = 5.415983, step = 800 (68.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46071\n",
      "INFO:tensorflow:loss = 5.648411, step = 900 (68.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43433\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T08:31:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-08:34:51\n",
      "INFO:tensorflow:Saving dict for global step 0: global_step = 0, loss = 11.0515995, metrics-onlinereview/targets/accuracy = 0.0005135867, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.0005135867, metrics-onlinereview/targets/approx_bleu_score = 0.9623243, metrics-onlinereview/targets/neg_log_perplexity = -11.070524, metrics-onlinereview/targets/rouge_2_fscore = 0.9815187, metrics-onlinereview/targets/rouge_L_fscore = 0.96953005\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: model_file_1024/model.ckpt-0\n",
      "INFO:tensorflow:Validation (step 1000): metrics-onlinereview/targets/accuracy = 0.0005135867, metrics-onlinereview/targets/rouge_L_fscore = 0.96953005, metrics-onlinereview/targets/approx_bleu_score = 0.9623243, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 0, loss = 11.0515995, metrics-onlinereview/targets/rouge_2_fscore = 0.9815187, metrics-onlinereview/targets/neg_log_perplexity = -11.070524, metrics-onlinereview/targets/accuracy_top5 = 0.0005135867\n",
      "INFO:tensorflow:loss = 6.0966616, step = 1000 (299.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.335307\n",
      "INFO:tensorflow:loss = 6.0009837, step = 1100 (68.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4323\n",
      "INFO:tensorflow:loss = 6.0174203, step = 1200 (69.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46812\n",
      "INFO:tensorflow:loss = 6.114157, step = 1300 (68.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42044\n",
      "INFO:tensorflow:loss = 6.485152, step = 1400 (70.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45493\n",
      "INFO:tensorflow:loss = 5.2633862, step = 1500 (68.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43675\n",
      "INFO:tensorflow:loss = 5.589402, step = 1600 (69.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46726\n",
      "INFO:tensorflow:loss = 6.446329, step = 1700 (68.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42254\n",
      "INFO:tensorflow:loss = 7.1443377, step = 1800 (70.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48515\n",
      "INFO:tensorflow:loss = 5.257056, step = 1900 (67.336 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28452\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T08:46:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-08:50:29\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.5215197, metrics-onlinereview/targets/accuracy = 0.11667756, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.24698852, metrics-onlinereview/targets/approx_bleu_score = 0.0035763844, metrics-onlinereview/targets/neg_log_perplexity = -6.465775, metrics-onlinereview/targets/rouge_2_fscore = 0.015278744, metrics-onlinereview/targets/rouge_L_fscore = 0.10692082\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_1024/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-onlinereview/targets/accuracy = 0.11667756, metrics-onlinereview/targets/rouge_L_fscore = 0.10692082, metrics-onlinereview/targets/approx_bleu_score = 0.0035763844, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 2000, loss = 6.5215197, metrics-onlinereview/targets/rouge_2_fscore = 0.015278744, metrics-onlinereview/targets/neg_log_perplexity = -6.465775, metrics-onlinereview/targets/accuracy_top5 = 0.24698852\n",
      "INFO:tensorflow:loss = 6.103618, step = 2000 (317.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.324196\n",
      "INFO:tensorflow:loss = 5.945787, step = 2100 (69.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48592\n",
      "INFO:tensorflow:loss = 6.1591687, step = 2200 (67.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44197\n",
      "INFO:tensorflow:loss = 5.7320733, step = 2300 (69.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41844\n",
      "INFO:tensorflow:loss = 6.049508, step = 2400 (70.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40872\n",
      "INFO:tensorflow:loss = 5.8643894, step = 2500 (70.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4581\n",
      "INFO:tensorflow:loss = 5.735228, step = 2600 (68.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4443\n",
      "INFO:tensorflow:loss = 5.455402, step = 2700 (69.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45994\n",
      "INFO:tensorflow:loss = 5.8682413, step = 2800 (68.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45167\n",
      "INFO:tensorflow:loss = 4.5194893, step = 2900 (68.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47318\n",
      "INFO:tensorflow:loss = 6.584581, step = 3000 (67.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42075\n",
      "INFO:tensorflow:loss = 5.8924537, step = 3100 (70.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44141\n",
      "INFO:tensorflow:loss = 5.059181, step = 3200 (69.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45052\n",
      "INFO:tensorflow:loss = 5.6358476, step = 3300 (68.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44366\n",
      "INFO:tensorflow:loss = 5.2168803, step = 3400 (69.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44541\n",
      "INFO:tensorflow:loss = 6.069017, step = 3500 (69.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42193\n",
      "INFO:tensorflow:loss = 6.601388, step = 3600 (70.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44604\n",
      "INFO:tensorflow:loss = 5.3086915, step = 3700 (69.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42842\n",
      "INFO:tensorflow:loss = 5.761847, step = 3800 (70.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44877\n",
      "INFO:tensorflow:loss = 4.8947954, step = 3900 (69.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29786\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T09:13:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-09:17:43\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 6.3023176, metrics-onlinereview/targets/accuracy = 0.13161826, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.27897096, metrics-onlinereview/targets/approx_bleu_score = 0.007836981, metrics-onlinereview/targets/neg_log_perplexity = -6.2329416, metrics-onlinereview/targets/rouge_2_fscore = 0.032367717, metrics-onlinereview/targets/rouge_L_fscore = 0.15846929\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_1024/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-onlinereview/targets/accuracy = 0.13161826, metrics-onlinereview/targets/rouge_L_fscore = 0.15846929, metrics-onlinereview/targets/approx_bleu_score = 0.007836981, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 4000, loss = 6.3023176, metrics-onlinereview/targets/rouge_2_fscore = 0.032367717, metrics-onlinereview/targets/neg_log_perplexity = -6.2329416, metrics-onlinereview/targets/accuracy_top5 = 0.27897096\n",
      "INFO:tensorflow:loss = 4.304379, step = 4000 (317.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.323442\n",
      "INFO:tensorflow:loss = 4.093212, step = 4100 (68.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43183\n",
      "INFO:tensorflow:loss = 6.1118064, step = 4200 (69.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46332\n",
      "INFO:tensorflow:loss = 5.3247337, step = 4300 (68.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42205\n",
      "INFO:tensorflow:loss = 5.24512, step = 4400 (70.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45273\n",
      "INFO:tensorflow:loss = 6.1704507, step = 4500 (68.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44917\n",
      "INFO:tensorflow:loss = 6.2087417, step = 4600 (68.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44543\n",
      "INFO:tensorflow:loss = 4.8068466, step = 4700 (69.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43643\n",
      "INFO:tensorflow:loss = 6.3497024, step = 4800 (69.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45181\n",
      "INFO:tensorflow:loss = 5.6760216, step = 4900 (68.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40716\n",
      "INFO:tensorflow:loss = 6.027562, step = 5000 (71.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41046\n",
      "INFO:tensorflow:loss = 5.375517, step = 5100 (70.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44989\n",
      "INFO:tensorflow:loss = 5.963265, step = 5200 (68.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43721\n",
      "INFO:tensorflow:loss = 5.466444, step = 5300 (69.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45018\n",
      "INFO:tensorflow:loss = 5.7370815, step = 5400 (68.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43402\n",
      "INFO:tensorflow:loss = 5.341766, step = 5500 (69.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42859\n",
      "INFO:tensorflow:loss = 5.6707344, step = 5600 (69.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46657\n",
      "INFO:tensorflow:loss = 5.1341405, step = 5700 (68.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44643\n",
      "INFO:tensorflow:loss = 5.030021, step = 5800 (69.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46242\n",
      "INFO:tensorflow:loss = 6.3985853, step = 5900 (68.378 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28752\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T09:41:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-09:44:59\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 6.297705, metrics-onlinereview/targets/accuracy = 0.13535345, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.28438696, metrics-onlinereview/targets/approx_bleu_score = 0.0060779965, metrics-onlinereview/targets/neg_log_perplexity = -6.218066, metrics-onlinereview/targets/rouge_2_fscore = 0.02686138, metrics-onlinereview/targets/rouge_L_fscore = 0.1471846\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_1024/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-onlinereview/targets/accuracy = 0.13535345, metrics-onlinereview/targets/rouge_L_fscore = 0.1471846, metrics-onlinereview/targets/approx_bleu_score = 0.0060779965, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 6000, loss = 6.297705, metrics-onlinereview/targets/rouge_2_fscore = 0.02686138, metrics-onlinereview/targets/neg_log_perplexity = -6.218066, metrics-onlinereview/targets/accuracy_top5 = 0.28438696\n",
      "INFO:tensorflow:loss = 5.3594885, step = 6000 (319.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.321398\n",
      "INFO:tensorflow:loss = 5.543237, step = 6100 (69.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45603\n",
      "INFO:tensorflow:loss = 5.363432, step = 6200 (68.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42449\n",
      "INFO:tensorflow:loss = 5.229918, step = 6300 (70.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44854\n",
      "INFO:tensorflow:loss = 5.9069057, step = 6400 (69.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49185\n",
      "INFO:tensorflow:loss = 5.8393736, step = 6500 (67.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41731\n",
      "INFO:tensorflow:loss = 5.9459743, step = 6600 (70.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46593\n",
      "INFO:tensorflow:loss = 5.7445073, step = 6700 (68.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4629\n",
      "INFO:tensorflow:loss = 5.659652, step = 6800 (68.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46161\n",
      "INFO:tensorflow:loss = 6.29222, step = 6900 (68.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44072\n",
      "INFO:tensorflow:loss = 5.128782, step = 7000 (69.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45667\n",
      "INFO:tensorflow:loss = 6.9421644, step = 7100 (68.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44679\n",
      "INFO:tensorflow:loss = 5.3076425, step = 7200 (69.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.423\n",
      "INFO:tensorflow:loss = 5.9486914, step = 7300 (70.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40875\n",
      "INFO:tensorflow:loss = 5.275352, step = 7400 (70.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46435\n",
      "INFO:tensorflow:loss = 5.2331333, step = 7500 (68.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46359\n",
      "INFO:tensorflow:loss = 5.4384637, step = 7600 (68.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47257\n",
      "INFO:tensorflow:loss = 6.199023, step = 7700 (67.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43053\n",
      "INFO:tensorflow:loss = 5.5056577, step = 7800 (69.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4279\n",
      "INFO:tensorflow:loss = 5.1543703, step = 7900 (70.031 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28058\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T10:08:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-10:12:18\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 6.192898, metrics-onlinereview/targets/accuracy = 0.14086282, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.2951256, metrics-onlinereview/targets/approx_bleu_score = 0.007178058, metrics-onlinereview/targets/neg_log_perplexity = -6.103052, metrics-onlinereview/targets/rouge_2_fscore = 0.032307442, metrics-onlinereview/targets/rouge_L_fscore = 0.16124889\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_file_1024/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-onlinereview/targets/accuracy = 0.14086282, metrics-onlinereview/targets/rouge_L_fscore = 0.16124889, metrics-onlinereview/targets/approx_bleu_score = 0.007178058, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 8000, loss = 6.192898, metrics-onlinereview/targets/rouge_2_fscore = 0.032307442, metrics-onlinereview/targets/neg_log_perplexity = -6.103052, metrics-onlinereview/targets/accuracy_top5 = 0.2951256\n",
      "INFO:tensorflow:loss = 5.105674, step = 8000 (325.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.315769\n",
      "INFO:tensorflow:loss = 5.0658717, step = 8100 (69.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4771\n",
      "INFO:tensorflow:loss = 5.585265, step = 8200 (67.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42815\n",
      "INFO:tensorflow:loss = 4.9085226, step = 8300 (70.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47569\n",
      "INFO:tensorflow:loss = 5.4031005, step = 8400 (67.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44615\n",
      "INFO:tensorflow:loss = 7.0974736, step = 8500 (69.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43366\n",
      "INFO:tensorflow:loss = 4.7616, step = 8600 (69.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43682\n",
      "INFO:tensorflow:loss = 4.797701, step = 8700 (69.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49153\n",
      "INFO:tensorflow:loss = 6.1875443, step = 8800 (67.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46188\n",
      "INFO:tensorflow:loss = 5.080865, step = 8900 (68.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45429\n",
      "INFO:tensorflow:loss = 5.163539, step = 9000 (68.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45228\n",
      "INFO:tensorflow:loss = 4.752872, step = 9100 (68.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46916\n",
      "INFO:tensorflow:loss = 6.111898, step = 9200 (68.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43627\n",
      "INFO:tensorflow:loss = 5.032136, step = 9300 (69.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4608\n",
      "INFO:tensorflow:loss = 5.361062, step = 9400 (68.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45906\n",
      "INFO:tensorflow:loss = 6.3446107, step = 9500 (68.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41775\n",
      "INFO:tensorflow:loss = 5.407556, step = 9600 (70.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43605\n",
      "INFO:tensorflow:loss = 5.452623, step = 9700 (69.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42303\n",
      "INFO:tensorflow:loss = 5.100716, step = 9800 (70.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46019\n",
      "INFO:tensorflow:loss = 5.4086623, step = 9900 (68.485 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29129\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T10:35:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-10:39:33\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 6.1126122, metrics-onlinereview/targets/accuracy = 0.15169483, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30259594, metrics-onlinereview/targets/approx_bleu_score = 0.0068740374, metrics-onlinereview/targets/neg_log_perplexity = -6.0281157, metrics-onlinereview/targets/rouge_2_fscore = 0.030308122, metrics-onlinereview/targets/rouge_L_fscore = 0.15593894\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_file_1024/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-onlinereview/targets/accuracy = 0.15169483, metrics-onlinereview/targets/rouge_L_fscore = 0.15593894, metrics-onlinereview/targets/approx_bleu_score = 0.0068740374, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 10000, loss = 6.1126122, metrics-onlinereview/targets/rouge_2_fscore = 0.030308122, metrics-onlinereview/targets/neg_log_perplexity = -6.0281157, metrics-onlinereview/targets/accuracy_top5 = 0.30259594\n",
      "INFO:tensorflow:loss = 5.2055845, step = 10000 (324.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.315917\n",
      "INFO:tensorflow:loss = 4.5901747, step = 10100 (69.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43277\n",
      "INFO:tensorflow:loss = 5.107212, step = 10200 (69.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44082\n",
      "INFO:tensorflow:loss = 5.3095565, step = 10300 (69.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43882\n",
      "INFO:tensorflow:loss = 4.331663, step = 10400 (69.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45516\n",
      "INFO:tensorflow:loss = 5.6070566, step = 10500 (68.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45179\n",
      "INFO:tensorflow:loss = 5.5458517, step = 10600 (68.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42999\n",
      "INFO:tensorflow:loss = 5.1919146, step = 10700 (69.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45623\n",
      "INFO:tensorflow:loss = 5.444103, step = 10800 (68.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.433\n",
      "INFO:tensorflow:loss = 5.4508023, step = 10900 (69.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40235\n",
      "INFO:tensorflow:loss = 5.051626, step = 11000 (71.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42092\n",
      "INFO:tensorflow:loss = 5.290074, step = 11100 (70.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4312\n",
      "INFO:tensorflow:loss = 5.121175, step = 11200 (69.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41639\n",
      "INFO:tensorflow:loss = 4.8975368, step = 11300 (70.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41843\n",
      "INFO:tensorflow:loss = 4.525736, step = 11400 (70.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45968\n",
      "INFO:tensorflow:loss = 6.2388773, step = 11500 (68.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40887\n",
      "INFO:tensorflow:loss = 5.445615, step = 11600 (70.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45351\n",
      "INFO:tensorflow:loss = 5.471923, step = 11700 (68.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41945\n",
      "INFO:tensorflow:loss = 5.150622, step = 11800 (70.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42679\n",
      "INFO:tensorflow:loss = 6.5163326, step = 11900 (70.090 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.26982\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T11:03:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-11:06:58\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 6.0685377, metrics-onlinereview/targets/accuracy = 0.14945373, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3140816, metrics-onlinereview/targets/approx_bleu_score = 0.0065573025, metrics-onlinereview/targets/neg_log_perplexity = -5.9846625, metrics-onlinereview/targets/rouge_2_fscore = 0.03142793, metrics-onlinereview/targets/rouge_L_fscore = 0.15420105\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_file_1024/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-onlinereview/targets/accuracy = 0.14945373, metrics-onlinereview/targets/rouge_L_fscore = 0.15420105, metrics-onlinereview/targets/approx_bleu_score = 0.0065573025, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 12000, loss = 6.0685377, metrics-onlinereview/targets/rouge_2_fscore = 0.03142793, metrics-onlinereview/targets/neg_log_perplexity = -5.9846625, metrics-onlinereview/targets/accuracy_top5 = 0.3140816\n",
      "INFO:tensorflow:loss = 5.8580008, step = 12000 (320.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.323674\n",
      "INFO:tensorflow:loss = 6.077808, step = 12100 (67.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46191\n",
      "INFO:tensorflow:loss = 5.5282516, step = 12200 (68.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45706\n",
      "INFO:tensorflow:loss = 4.499129, step = 12300 (68.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44669\n",
      "INFO:tensorflow:loss = 4.917034, step = 12400 (69.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44145\n",
      "INFO:tensorflow:loss = 4.5351176, step = 12500 (69.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43465\n",
      "INFO:tensorflow:loss = 5.488203, step = 12600 (69.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44415\n",
      "INFO:tensorflow:loss = 5.315154, step = 12700 (69.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4542\n",
      "INFO:tensorflow:loss = 6.0830183, step = 12800 (68.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42049\n",
      "INFO:tensorflow:loss = 5.7929273, step = 12900 (70.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43146\n",
      "INFO:tensorflow:loss = 5.0163393, step = 13000 (69.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43715\n",
      "INFO:tensorflow:loss = 4.965904, step = 13100 (69.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46118\n",
      "INFO:tensorflow:loss = 5.2292414, step = 13200 (68.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4101\n",
      "INFO:tensorflow:loss = 4.752645, step = 13300 (70.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45568\n",
      "INFO:tensorflow:loss = 4.873629, step = 13400 (68.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45297\n",
      "INFO:tensorflow:loss = 6.7284503, step = 13500 (68.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4399\n",
      "INFO:tensorflow:loss = 4.6238637, step = 13600 (69.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42889\n",
      "INFO:tensorflow:loss = 5.8172803, step = 13700 (69.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42719\n",
      "INFO:tensorflow:loss = 6.273542, step = 13800 (70.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42308\n",
      "INFO:tensorflow:loss = 4.709913, step = 13900 (70.270 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.26887\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T11:30:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-11:34:16\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 6.063507, metrics-onlinereview/targets/accuracy = 0.15421608, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31170043, metrics-onlinereview/targets/approx_bleu_score = 0.007472696, metrics-onlinereview/targets/neg_log_perplexity = -5.9796333, metrics-onlinereview/targets/rouge_2_fscore = 0.033762313, metrics-onlinereview/targets/rouge_L_fscore = 0.15894845\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_file_1024/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-onlinereview/targets/accuracy = 0.15421608, metrics-onlinereview/targets/rouge_L_fscore = 0.15894845, metrics-onlinereview/targets/approx_bleu_score = 0.007472696, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 14000, loss = 6.063507, metrics-onlinereview/targets/rouge_2_fscore = 0.033762313, metrics-onlinereview/targets/neg_log_perplexity = -5.9796333, metrics-onlinereview/targets/accuracy_top5 = 0.31170043\n",
      "INFO:tensorflow:loss = 6.2074223, step = 14000 (320.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.322404\n",
      "INFO:tensorflow:loss = 4.8176236, step = 14100 (68.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43303\n",
      "INFO:tensorflow:loss = 5.3861074, step = 14200 (69.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46781\n",
      "INFO:tensorflow:loss = 4.4412293, step = 14300 (68.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45751\n",
      "INFO:tensorflow:loss = 5.249289, step = 14400 (68.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45577\n",
      "INFO:tensorflow:loss = 4.85845, step = 14500 (68.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44141\n",
      "INFO:tensorflow:loss = 5.004478, step = 14600 (69.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42879\n",
      "INFO:tensorflow:loss = 5.081585, step = 14700 (69.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43564\n",
      "INFO:tensorflow:loss = 5.799625, step = 14800 (69.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4304\n",
      "INFO:tensorflow:loss = 5.006578, step = 14900 (69.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45736\n",
      "INFO:tensorflow:loss = 5.28285, step = 15000 (68.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4164\n",
      "INFO:tensorflow:loss = 5.362399, step = 15100 (70.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4397\n",
      "INFO:tensorflow:loss = 4.7875166, step = 15200 (69.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45692\n",
      "INFO:tensorflow:loss = 5.018182, step = 15300 (68.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40884\n",
      "INFO:tensorflow:loss = 4.3207517, step = 15400 (70.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44814\n",
      "INFO:tensorflow:loss = 5.6340256, step = 15500 (69.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43204\n",
      "INFO:tensorflow:loss = 6.242541, step = 15600 (69.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44294\n",
      "INFO:tensorflow:loss = 5.6172447, step = 15700 (69.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45401\n",
      "INFO:tensorflow:loss = 5.045605, step = 15800 (68.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41595\n",
      "INFO:tensorflow:loss = 5.451747, step = 15900 (70.625 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.26134\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T11:57:41Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-12:01:29\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 6.043327, metrics-onlinereview/targets/accuracy = 0.14880008, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31174713, metrics-onlinereview/targets/approx_bleu_score = 0.008397646, metrics-onlinereview/targets/neg_log_perplexity = -5.952726, metrics-onlinereview/targets/rouge_2_fscore = 0.033551868, metrics-onlinereview/targets/rouge_L_fscore = 0.16979842\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_file_1024/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-onlinereview/targets/accuracy = 0.14880008, metrics-onlinereview/targets/rouge_L_fscore = 0.16979842, metrics-onlinereview/targets/approx_bleu_score = 0.008397646, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 16000, loss = 6.043327, metrics-onlinereview/targets/rouge_2_fscore = 0.033551868, metrics-onlinereview/targets/neg_log_perplexity = -5.952726, metrics-onlinereview/targets/accuracy_top5 = 0.31174713\n",
      "INFO:tensorflow:loss = 4.923867, step = 16000 (314.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329665\n",
      "INFO:tensorflow:loss = 6.624532, step = 16100 (68.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41575\n",
      "INFO:tensorflow:loss = 5.2180004, step = 16200 (70.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42582\n",
      "INFO:tensorflow:loss = 4.4500756, step = 16300 (70.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47881\n",
      "INFO:tensorflow:loss = 4.827623, step = 16400 (67.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44705\n",
      "INFO:tensorflow:loss = 5.6687727, step = 16500 (69.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43965\n",
      "INFO:tensorflow:loss = 5.442421, step = 16600 (69.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45377\n",
      "INFO:tensorflow:loss = 4.71094, step = 16700 (68.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43284\n",
      "INFO:tensorflow:loss = 5.841444, step = 16800 (69.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45703\n",
      "INFO:tensorflow:loss = 5.5121427, step = 16900 (68.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4275\n",
      "INFO:tensorflow:loss = 5.4383144, step = 17000 (70.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44615\n",
      "INFO:tensorflow:loss = 4.6214466, step = 17100 (69.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46744\n",
      "INFO:tensorflow:loss = 5.3002944, step = 17200 (68.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44549\n",
      "INFO:tensorflow:loss = 5.1049113, step = 17300 (69.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42535\n",
      "INFO:tensorflow:loss = 4.952604, step = 17400 (70.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4485\n",
      "INFO:tensorflow:loss = 5.84659, step = 17500 (69.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46158\n",
      "INFO:tensorflow:loss = 5.101609, step = 17600 (68.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43912\n",
      "INFO:tensorflow:loss = 6.21156, step = 17700 (69.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46351\n",
      "INFO:tensorflow:loss = 5.1439896, step = 17800 (68.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45897\n",
      "INFO:tensorflow:loss = 5.39197, step = 17900 (68.541 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.252\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T12:24:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-12:28:36\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 6.0337963, metrics-onlinereview/targets/accuracy = 0.15356243, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32029134, metrics-onlinereview/targets/approx_bleu_score = 0.007525772, metrics-onlinereview/targets/neg_log_perplexity = -5.9491854, metrics-onlinereview/targets/rouge_2_fscore = 0.0350646, metrics-onlinereview/targets/rouge_L_fscore = 0.17079763\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_file_1024/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-onlinereview/targets/accuracy = 0.15356243, metrics-onlinereview/targets/rouge_L_fscore = 0.17079763, metrics-onlinereview/targets/approx_bleu_score = 0.007525772, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 18000, loss = 6.0337963, metrics-onlinereview/targets/rouge_2_fscore = 0.0350646, metrics-onlinereview/targets/neg_log_perplexity = -5.9491854, metrics-onlinereview/targets/accuracy_top5 = 0.32029134\n",
      "INFO:tensorflow:loss = 5.7261124, step = 18000 (313.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329974\n",
      "INFO:tensorflow:loss = 5.6021996, step = 18100 (69.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46853\n",
      "INFO:tensorflow:loss = 5.6818123, step = 18200 (68.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46028\n",
      "INFO:tensorflow:loss = 6.099424, step = 18300 (68.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4443\n",
      "INFO:tensorflow:loss = 4.9972196, step = 18400 (69.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45517\n",
      "INFO:tensorflow:loss = 4.6506996, step = 18500 (68.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42499\n",
      "INFO:tensorflow:loss = 5.3661246, step = 18600 (70.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4522\n",
      "INFO:tensorflow:loss = 6.4020905, step = 18700 (68.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41729\n",
      "INFO:tensorflow:loss = 5.9485893, step = 18800 (70.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44896\n",
      "INFO:tensorflow:loss = 4.9090486, step = 18900 (69.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41819\n",
      "INFO:tensorflow:loss = 4.70453, step = 19000 (70.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45889\n",
      "INFO:tensorflow:loss = 5.56942, step = 19100 (68.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42459\n",
      "INFO:tensorflow:loss = 5.142416, step = 19200 (70.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46948\n",
      "INFO:tensorflow:loss = 6.2952633, step = 19300 (68.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45574\n",
      "INFO:tensorflow:loss = 4.6777525, step = 19400 (68.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42066\n",
      "INFO:tensorflow:loss = 4.614853, step = 19500 (70.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46405\n",
      "INFO:tensorflow:loss = 3.3138192, step = 19600 (68.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4885\n",
      "INFO:tensorflow:loss = 5.420281, step = 19700 (67.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42806\n",
      "INFO:tensorflow:loss = 4.80111, step = 19800 (70.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41002\n",
      "INFO:tensorflow:loss = 5.8126316, step = 19900 (70.924 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28588\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T12:51:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-12:55:44\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 6.002579, metrics-onlinereview/targets/accuracy = 0.15510318, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3196377, metrics-onlinereview/targets/approx_bleu_score = 0.008219458, metrics-onlinereview/targets/neg_log_perplexity = -5.926431, metrics-onlinereview/targets/rouge_2_fscore = 0.03615849, metrics-onlinereview/targets/rouge_L_fscore = 0.17452545\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_file_1024/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-onlinereview/targets/accuracy = 0.15510318, metrics-onlinereview/targets/rouge_L_fscore = 0.17452545, metrics-onlinereview/targets/approx_bleu_score = 0.008219458, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 20000, loss = 6.002579, metrics-onlinereview/targets/rouge_2_fscore = 0.03615849, metrics-onlinereview/targets/neg_log_perplexity = -5.926431, metrics-onlinereview/targets/accuracy_top5 = 0.3196377\n",
      "INFO:tensorflow:loss = 5.324378, step = 20000 (313.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.32823\n",
      "INFO:tensorflow:loss = 6.132631, step = 20100 (68.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44643\n",
      "INFO:tensorflow:loss = 4.932728, step = 20200 (69.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43681\n",
      "INFO:tensorflow:loss = 4.665776, step = 20300 (69.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44581\n",
      "INFO:tensorflow:loss = 5.0754647, step = 20400 (69.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41433\n",
      "INFO:tensorflow:loss = 5.548028, step = 20500 (70.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46168\n",
      "INFO:tensorflow:loss = 5.7195053, step = 20600 (68.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48364\n",
      "INFO:tensorflow:loss = 5.4425225, step = 20700 (67.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43269\n",
      "INFO:tensorflow:loss = 5.0265026, step = 20800 (69.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42053\n",
      "INFO:tensorflow:loss = 5.4467263, step = 20900 (70.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43632\n",
      "INFO:tensorflow:loss = 5.2612567, step = 21000 (69.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43581\n",
      "INFO:tensorflow:loss = 5.175757, step = 21100 (69.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43454\n",
      "INFO:tensorflow:loss = 4.8582144, step = 21200 (69.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44215\n",
      "INFO:tensorflow:loss = 4.9423685, step = 21400 (69.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47564\n",
      "INFO:tensorflow:loss = 4.8593316, step = 21500 (67.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46642\n",
      "INFO:tensorflow:loss = 5.2674346, step = 21600 (68.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42966\n",
      "INFO:tensorflow:loss = 5.105188, step = 21700 (69.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48239\n",
      "INFO:tensorflow:loss = 4.432801, step = 21800 (67.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3987\n",
      "INFO:tensorflow:loss = 5.0301614, step = 21900 (71.499 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29198\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T13:19:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-13:22:57\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 6.011952, metrics-onlinereview/targets/accuracy = 0.15813802, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32239237, metrics-onlinereview/targets/approx_bleu_score = 0.007004881, metrics-onlinereview/targets/neg_log_perplexity = -5.927717, metrics-onlinereview/targets/rouge_2_fscore = 0.031659868, metrics-onlinereview/targets/rouge_L_fscore = 0.15863447\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_file_1024/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-onlinereview/targets/accuracy = 0.15813802, metrics-onlinereview/targets/rouge_L_fscore = 0.15863447, metrics-onlinereview/targets/approx_bleu_score = 0.007004881, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 22000, loss = 6.011952, metrics-onlinereview/targets/rouge_2_fscore = 0.031659868, metrics-onlinereview/targets/neg_log_perplexity = -5.927717, metrics-onlinereview/targets/accuracy_top5 = 0.32239237\n",
      "INFO:tensorflow:loss = 4.95845, step = 22000 (315.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.326106\n",
      "INFO:tensorflow:loss = 5.936863, step = 22100 (68.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47475\n",
      "INFO:tensorflow:loss = 6.0109754, step = 22200 (67.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42586\n",
      "INFO:tensorflow:loss = 6.089514, step = 22300 (70.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46121\n",
      "INFO:tensorflow:loss = 5.4540815, step = 22400 (68.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40539\n",
      "INFO:tensorflow:loss = 5.803571, step = 22500 (71.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47033\n",
      "INFO:tensorflow:loss = 4.950421, step = 22600 (68.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42208\n",
      "INFO:tensorflow:loss = 5.032919, step = 22700 (70.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43834\n",
      "INFO:tensorflow:loss = 4.567685, step = 22800 (69.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43523\n",
      "INFO:tensorflow:loss = 5.056297, step = 22900 (69.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41125\n",
      "INFO:tensorflow:loss = 6.378318, step = 23000 (71.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47554\n",
      "INFO:tensorflow:loss = 5.7975087, step = 23100 (67.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46004\n",
      "INFO:tensorflow:loss = 5.3395495, step = 23200 (68.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45001\n",
      "INFO:tensorflow:loss = 5.3709974, step = 23300 (68.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43901\n",
      "INFO:tensorflow:loss = 5.820514, step = 23400 (69.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42397\n",
      "INFO:tensorflow:loss = 5.243031, step = 23500 (70.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47464\n",
      "INFO:tensorflow:loss = 6.6599827, step = 23600 (67.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43537\n",
      "INFO:tensorflow:loss = 5.9939795, step = 23700 (69.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42594\n",
      "INFO:tensorflow:loss = 5.1627913, step = 23800 (70.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43642\n",
      "INFO:tensorflow:loss = 5.706682, step = 23900 (69.632 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30627\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T13:46:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-13:50:04\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 5.9728026, metrics-onlinereview/targets/accuracy = 0.1573443, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3228593, metrics-onlinereview/targets/approx_bleu_score = 0.0065374784, metrics-onlinereview/targets/neg_log_perplexity = -5.8901834, metrics-onlinereview/targets/rouge_2_fscore = 0.03012637, metrics-onlinereview/targets/rouge_L_fscore = 0.15433027\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_file_1024/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-onlinereview/targets/accuracy = 0.1573443, metrics-onlinereview/targets/rouge_L_fscore = 0.15433027, metrics-onlinereview/targets/approx_bleu_score = 0.0065374784, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 24000, loss = 5.9728026, metrics-onlinereview/targets/rouge_2_fscore = 0.03012637, metrics-onlinereview/targets/neg_log_perplexity = -5.8901834, metrics-onlinereview/targets/accuracy_top5 = 0.3228593\n",
      "INFO:tensorflow:loss = 5.1218863, step = 24000 (311.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329865\n",
      "INFO:tensorflow:loss = 5.6156764, step = 24100 (68.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40403\n",
      "INFO:tensorflow:loss = 5.4833727, step = 24200 (71.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44794\n",
      "INFO:tensorflow:loss = 6.0890226, step = 24300 (69.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4503\n",
      "INFO:tensorflow:loss = 5.803597, step = 24400 (68.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45871\n",
      "INFO:tensorflow:loss = 5.3451586, step = 24500 (68.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49082\n",
      "INFO:tensorflow:loss = 5.081483, step = 24600 (67.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46921\n",
      "INFO:tensorflow:loss = 5.6177044, step = 24700 (68.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42696\n",
      "INFO:tensorflow:loss = 4.694119, step = 24800 (70.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42939\n",
      "INFO:tensorflow:loss = 5.8861046, step = 24900 (69.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49774\n",
      "INFO:tensorflow:loss = 5.4680934, step = 25000 (67.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43311\n",
      "INFO:tensorflow:loss = 5.002526, step = 25100 (69.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4574\n",
      "INFO:tensorflow:loss = 6.172061, step = 25200 (68.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41715\n",
      "INFO:tensorflow:loss = 5.8083024, step = 25300 (70.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46637\n",
      "INFO:tensorflow:loss = 4.686273, step = 25400 (68.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48763\n",
      "INFO:tensorflow:loss = 5.087484, step = 25500 (67.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39726\n",
      "INFO:tensorflow:loss = 5.6317325, step = 25600 (71.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42791\n",
      "INFO:tensorflow:loss = 5.371612, step = 25700 (70.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47607\n",
      "INFO:tensorflow:loss = 5.240768, step = 25800 (67.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43704\n",
      "INFO:tensorflow:loss = 5.1325407, step = 25900 (69.588 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29008\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T14:13:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-14:17:09\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 6.000366, metrics-onlinereview/targets/accuracy = 0.15790457, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32612756, metrics-onlinereview/targets/approx_bleu_score = 0.0072176675, metrics-onlinereview/targets/neg_log_perplexity = -5.91726, metrics-onlinereview/targets/rouge_2_fscore = 0.03288804, metrics-onlinereview/targets/rouge_L_fscore = 0.16356736\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_file_1024/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-onlinereview/targets/accuracy = 0.15790457, metrics-onlinereview/targets/rouge_L_fscore = 0.16356736, metrics-onlinereview/targets/approx_bleu_score = 0.0072176675, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 26000, loss = 6.000366, metrics-onlinereview/targets/rouge_2_fscore = 0.03288804, metrics-onlinereview/targets/neg_log_perplexity = -5.91726, metrics-onlinereview/targets/accuracy_top5 = 0.32612756\n",
      "INFO:tensorflow:loss = 5.2140937, step = 26000 (313.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.328985\n",
      "INFO:tensorflow:loss = 5.397033, step = 26100 (68.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45347\n",
      "INFO:tensorflow:loss = 5.012558, step = 26200 (68.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39189\n",
      "INFO:tensorflow:loss = 5.084871, step = 26300 (71.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43243\n",
      "INFO:tensorflow:loss = 5.122351, step = 26400 (69.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44483\n",
      "INFO:tensorflow:loss = 5.336405, step = 26500 (69.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43275\n",
      "INFO:tensorflow:loss = 4.8035836, step = 26600 (69.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48914\n",
      "INFO:tensorflow:loss = 6.343443, step = 26700 (67.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40824\n",
      "INFO:tensorflow:loss = 7.525537, step = 26800 (71.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45527\n",
      "INFO:tensorflow:loss = 5.525395, step = 26900 (68.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44562\n",
      "INFO:tensorflow:loss = 5.522787, step = 27000 (69.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43154\n",
      "INFO:tensorflow:loss = 5.606523, step = 27100 (70.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43098\n",
      "INFO:tensorflow:loss = 6.3081994, step = 27200 (69.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42355\n",
      "INFO:tensorflow:loss = 3.7584395, step = 27300 (70.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41793\n",
      "INFO:tensorflow:loss = 6.21327, step = 27400 (70.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45353\n",
      "INFO:tensorflow:loss = 5.275637, step = 27500 (68.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40364\n",
      "INFO:tensorflow:loss = 5.377768, step = 27600 (71.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46562\n",
      "INFO:tensorflow:loss = 4.654789, step = 27700 (68.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44774\n",
      "INFO:tensorflow:loss = 6.2305226, step = 27800 (69.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40669\n",
      "INFO:tensorflow:loss = 4.979254, step = 27900 (71.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30422\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T14:40:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-14:44:25\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 5.987508, metrics-onlinereview/targets/accuracy = 0.16131291, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32659444, metrics-onlinereview/targets/approx_bleu_score = 0.00713956, metrics-onlinereview/targets/neg_log_perplexity = -5.9161625, metrics-onlinereview/targets/rouge_2_fscore = 0.032589585, metrics-onlinereview/targets/rouge_L_fscore = 0.16146216\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_file_1024/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-onlinereview/targets/accuracy = 0.16131291, metrics-onlinereview/targets/rouge_L_fscore = 0.16146216, metrics-onlinereview/targets/approx_bleu_score = 0.00713956, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 28000, loss = 5.987508, metrics-onlinereview/targets/rouge_2_fscore = 0.032589585, metrics-onlinereview/targets/neg_log_perplexity = -5.9161625, metrics-onlinereview/targets/accuracy_top5 = 0.32659444\n",
      "INFO:tensorflow:loss = 5.111837, step = 28000 (313.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.327894\n",
      "INFO:tensorflow:loss = 5.121701, step = 28100 (68.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41284\n",
      "INFO:tensorflow:loss = 5.085155, step = 28200 (70.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46761\n",
      "INFO:tensorflow:loss = 4.9560027, step = 28300 (68.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41872\n",
      "INFO:tensorflow:loss = 5.057991, step = 28400 (70.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45674\n",
      "INFO:tensorflow:loss = 4.4066005, step = 28500 (68.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44716\n",
      "INFO:tensorflow:loss = 5.199949, step = 28600 (69.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40569\n",
      "INFO:tensorflow:loss = 6.1696935, step = 28700 (71.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43407\n",
      "INFO:tensorflow:loss = 4.976958, step = 28800 (69.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.433\n",
      "INFO:tensorflow:loss = 4.8853126, step = 28900 (69.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44536\n",
      "INFO:tensorflow:loss = 4.736077, step = 29000 (69.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44641\n",
      "INFO:tensorflow:loss = 4.731477, step = 29100 (69.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44276\n",
      "INFO:tensorflow:loss = 3.2524943, step = 29200 (69.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41002\n",
      "INFO:tensorflow:loss = 4.6983266, step = 29300 (70.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47055\n",
      "INFO:tensorflow:loss = 5.0824018, step = 29400 (67.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44351\n",
      "INFO:tensorflow:loss = 5.4241486, step = 29500 (69.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47384\n",
      "INFO:tensorflow:loss = 5.732973, step = 29600 (67.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42426\n",
      "INFO:tensorflow:loss = 4.9666066, step = 29700 (70.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43567\n",
      "INFO:tensorflow:loss = 5.207524, step = 29800 (69.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44618\n",
      "INFO:tensorflow:loss = 5.481906, step = 29900 (69.151 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.27\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T15:07:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-15:11:38\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 5.9701967, metrics-onlinereview/targets/accuracy = 0.16149968, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3304697, metrics-onlinereview/targets/approx_bleu_score = 0.007436079, metrics-onlinereview/targets/neg_log_perplexity = -5.8823113, metrics-onlinereview/targets/rouge_2_fscore = 0.03409414, metrics-onlinereview/targets/rouge_L_fscore = 0.16833045\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_file_1024/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-onlinereview/targets/accuracy = 0.16149968, metrics-onlinereview/targets/rouge_L_fscore = 0.16833045, metrics-onlinereview/targets/approx_bleu_score = 0.007436079, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 30000, loss = 5.9701967, metrics-onlinereview/targets/rouge_2_fscore = 0.03409414, metrics-onlinereview/targets/neg_log_perplexity = -5.8823113, metrics-onlinereview/targets/accuracy_top5 = 0.3304697\n",
      "INFO:tensorflow:loss = 5.1504064, step = 30000 (313.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329195\n",
      "INFO:tensorflow:loss = 4.8344617, step = 30100 (68.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45789\n",
      "INFO:tensorflow:loss = 5.526994, step = 30200 (68.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44842\n",
      "INFO:tensorflow:loss = 4.538605, step = 30300 (69.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46997\n",
      "INFO:tensorflow:loss = 4.8907113, step = 30400 (68.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47635\n",
      "INFO:tensorflow:loss = 5.43333, step = 30500 (67.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44562\n",
      "INFO:tensorflow:loss = 4.968667, step = 30600 (69.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43806\n",
      "INFO:tensorflow:loss = 5.2410603, step = 30700 (69.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45524\n",
      "INFO:tensorflow:loss = 5.5204864, step = 30800 (68.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47016\n",
      "INFO:tensorflow:loss = 4.803669, step = 30900 (68.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40317\n",
      "INFO:tensorflow:loss = 5.2728834, step = 31000 (71.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47818\n",
      "INFO:tensorflow:loss = 4.032076, step = 31100 (67.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4266\n",
      "INFO:tensorflow:loss = 4.8367615, step = 31200 (70.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43215\n",
      "INFO:tensorflow:loss = 5.213784, step = 31300 (69.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42957\n",
      "INFO:tensorflow:loss = 5.3658514, step = 31400 (69.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41211\n",
      "INFO:tensorflow:loss = 4.8552456, step = 31500 (70.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47277\n",
      "INFO:tensorflow:loss = 5.0132957, step = 31600 (67.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42619\n",
      "INFO:tensorflow:loss = 5.0184283, step = 31700 (70.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40859\n",
      "INFO:tensorflow:loss = 5.0598025, step = 31800 (70.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47371\n",
      "INFO:tensorflow:loss = 4.8953624, step = 31900 (67.862 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.27599\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T15:34:58Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-15:38:44\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 5.927443, metrics-onlinereview/targets/accuracy = 0.16397423, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.33205715, metrics-onlinereview/targets/approx_bleu_score = 0.00726938, metrics-onlinereview/targets/neg_log_perplexity = -5.8496966, metrics-onlinereview/targets/rouge_2_fscore = 0.032726485, metrics-onlinereview/targets/rouge_L_fscore = 0.16292448\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_file_1024/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-onlinereview/targets/accuracy = 0.16397423, metrics-onlinereview/targets/rouge_L_fscore = 0.16292448, metrics-onlinereview/targets/approx_bleu_score = 0.00726938, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 32000, loss = 5.927443, metrics-onlinereview/targets/rouge_2_fscore = 0.032726485, metrics-onlinereview/targets/neg_log_perplexity = -5.8496966, metrics-onlinereview/targets/accuracy_top5 = 0.33205715\n",
      "INFO:tensorflow:loss = 4.9640107, step = 32000 (312.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.331409\n",
      "INFO:tensorflow:loss = 5.5631804, step = 32100 (68.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48006\n",
      "INFO:tensorflow:loss = 4.760596, step = 32200 (67.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44505\n",
      "INFO:tensorflow:loss = 5.1540465, step = 32300 (69.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41753\n",
      "INFO:tensorflow:loss = 5.5570626, step = 32400 (70.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43141\n",
      "INFO:tensorflow:loss = 5.7112465, step = 32500 (69.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46124\n",
      "INFO:tensorflow:loss = 5.053082, step = 32600 (68.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41403\n",
      "INFO:tensorflow:loss = 5.427329, step = 32700 (70.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4036\n",
      "INFO:tensorflow:loss = 5.550207, step = 32800 (71.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43496\n",
      "INFO:tensorflow:loss = 5.08343, step = 32900 (69.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42634\n",
      "INFO:tensorflow:loss = 4.462511, step = 33000 (70.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41049\n",
      "INFO:tensorflow:loss = 5.046847, step = 33100 (70.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45941\n",
      "INFO:tensorflow:loss = 4.962405, step = 33200 (68.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45144\n",
      "INFO:tensorflow:loss = 5.5032063, step = 33300 (68.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45271\n",
      "INFO:tensorflow:loss = 5.536225, step = 33400 (68.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44306\n",
      "INFO:tensorflow:loss = 5.3308144, step = 33500 (69.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44936\n",
      "INFO:tensorflow:loss = 5.058494, step = 33600 (68.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43842\n",
      "INFO:tensorflow:loss = 6.816619, step = 33700 (69.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46672\n",
      "INFO:tensorflow:loss = 5.361608, step = 33800 (68.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43397\n",
      "INFO:tensorflow:loss = 5.778666, step = 33900 (69.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.2979\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T16:02:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-16:05:54\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 5.9630303, metrics-onlinereview/targets/accuracy = 0.16187319, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3314502, metrics-onlinereview/targets/approx_bleu_score = 0.0071745687, metrics-onlinereview/targets/neg_log_perplexity = -5.8672395, metrics-onlinereview/targets/rouge_2_fscore = 0.03264477, metrics-onlinereview/targets/rouge_L_fscore = 0.16098127\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_file_1024/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-onlinereview/targets/accuracy = 0.16187319, metrics-onlinereview/targets/rouge_L_fscore = 0.16098127, metrics-onlinereview/targets/approx_bleu_score = 0.0071745687, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 34000, loss = 5.9630303, metrics-onlinereview/targets/rouge_2_fscore = 0.03264477, metrics-onlinereview/targets/neg_log_perplexity = -5.8672395, metrics-onlinereview/targets/accuracy_top5 = 0.3314502\n",
      "INFO:tensorflow:loss = 5.8242974, step = 34000 (311.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.32771\n",
      "INFO:tensorflow:loss = 6.171229, step = 34100 (70.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41596\n",
      "INFO:tensorflow:loss = 4.5307674, step = 34200 (70.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43221\n",
      "INFO:tensorflow:loss = 5.2019877, step = 34300 (69.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42869\n",
      "INFO:tensorflow:loss = 5.191807, step = 34400 (69.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42832\n",
      "INFO:tensorflow:loss = 4.74556, step = 34500 (70.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45716\n",
      "INFO:tensorflow:loss = 6.3597302, step = 34600 (68.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45369\n",
      "INFO:tensorflow:loss = 6.2945523, step = 34700 (68.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43768\n",
      "INFO:tensorflow:loss = 5.868195, step = 34800 (69.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41738\n",
      "INFO:tensorflow:loss = 4.8166013, step = 34900 (70.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46767\n",
      "INFO:tensorflow:loss = 4.828045, step = 35000 (68.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43436\n",
      "INFO:tensorflow:loss = 4.773371, step = 35100 (69.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46101\n",
      "INFO:tensorflow:loss = 4.8284197, step = 35200 (68.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43137\n",
      "INFO:tensorflow:loss = 5.696464, step = 35300 (69.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41356\n",
      "INFO:tensorflow:loss = 5.1974344, step = 35400 (70.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4223\n",
      "INFO:tensorflow:loss = 4.8679633, step = 35500 (70.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45821\n",
      "INFO:tensorflow:loss = 5.5732336, step = 35600 (68.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45228\n",
      "INFO:tensorflow:loss = 6.1135488, step = 35700 (68.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40995\n",
      "INFO:tensorflow:loss = 4.966718, step = 35800 (70.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46219\n",
      "INFO:tensorflow:loss = 5.8636675, step = 35900 (68.398 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31236\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T16:29:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-16:33:07\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 5.9799123, metrics-onlinereview/targets/accuracy = 0.16280699, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.33126342, metrics-onlinereview/targets/approx_bleu_score = 0.008165897, metrics-onlinereview/targets/neg_log_perplexity = -5.8790317, metrics-onlinereview/targets/rouge_2_fscore = 0.036699418, metrics-onlinereview/targets/rouge_L_fscore = 0.17361273\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_file_1024/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-onlinereview/targets/accuracy = 0.16280699, metrics-onlinereview/targets/rouge_L_fscore = 0.17361273, metrics-onlinereview/targets/approx_bleu_score = 0.008165897, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 36000, loss = 5.9799123, metrics-onlinereview/targets/rouge_2_fscore = 0.036699418, metrics-onlinereview/targets/neg_log_perplexity = -5.8790317, metrics-onlinereview/targets/accuracy_top5 = 0.33126342\n",
      "INFO:tensorflow:loss = 5.185281, step = 36000 (310.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.331099\n",
      "INFO:tensorflow:loss = 4.851425, step = 36100 (67.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49253\n",
      "INFO:tensorflow:loss = 5.379012, step = 36200 (66.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42527\n",
      "INFO:tensorflow:loss = 5.608263, step = 36300 (70.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45085\n",
      "INFO:tensorflow:loss = 5.0922866, step = 36400 (68.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4478\n",
      "INFO:tensorflow:loss = 5.235683, step = 36500 (69.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43816\n",
      "INFO:tensorflow:loss = 5.3230815, step = 36600 (69.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43274\n",
      "INFO:tensorflow:loss = 5.0816607, step = 36700 (69.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44735\n",
      "INFO:tensorflow:loss = 6.104564, step = 36800 (69.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47029\n",
      "INFO:tensorflow:loss = 4.6244545, step = 36900 (68.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46618\n",
      "INFO:tensorflow:loss = 5.165022, step = 37000 (68.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43941\n",
      "INFO:tensorflow:loss = 5.241523, step = 37100 (69.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4534\n",
      "INFO:tensorflow:loss = 3.8189843, step = 37200 (68.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44984\n",
      "INFO:tensorflow:loss = 4.8430834, step = 37300 (68.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41635\n",
      "INFO:tensorflow:loss = 4.9214168, step = 37400 (70.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44973\n",
      "INFO:tensorflow:loss = 5.3521733, step = 37500 (68.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44717\n",
      "INFO:tensorflow:loss = 4.38858, step = 37600 (69.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4221\n",
      "INFO:tensorflow:loss = 5.386729, step = 37700 (70.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42199\n",
      "INFO:tensorflow:loss = 5.0689206, step = 37800 (70.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49105\n",
      "INFO:tensorflow:loss = 5.218135, step = 37900 (67.069 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.27523\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T16:56:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-17:00:11\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 5.919916, metrics-onlinereview/targets/accuracy = 0.16416098, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3345784, metrics-onlinereview/targets/approx_bleu_score = 0.007694773, metrics-onlinereview/targets/neg_log_perplexity = -5.837925, metrics-onlinereview/targets/rouge_2_fscore = 0.032571167, metrics-onlinereview/targets/rouge_L_fscore = 0.16052724\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_file_1024/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-onlinereview/targets/accuracy = 0.16416098, metrics-onlinereview/targets/rouge_L_fscore = 0.16052724, metrics-onlinereview/targets/approx_bleu_score = 0.007694773, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 38000, loss = 5.919916, metrics-onlinereview/targets/rouge_2_fscore = 0.032571167, metrics-onlinereview/targets/neg_log_perplexity = -5.837925, metrics-onlinereview/targets/accuracy_top5 = 0.3345784\n",
      "INFO:tensorflow:loss = 4.607046, step = 38000 (313.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.328234\n",
      "INFO:tensorflow:loss = 5.6715407, step = 38100 (69.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44268\n",
      "INFO:tensorflow:loss = 5.125754, step = 38200 (69.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4394\n",
      "INFO:tensorflow:loss = 4.7525, step = 38300 (69.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43865\n",
      "INFO:tensorflow:loss = 6.0949054, step = 38400 (69.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43857\n",
      "INFO:tensorflow:loss = 5.1377006, step = 38500 (69.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44312\n",
      "INFO:tensorflow:loss = 5.836142, step = 38600 (69.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43772\n",
      "INFO:tensorflow:loss = 5.274136, step = 38700 (69.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44942\n",
      "INFO:tensorflow:loss = 5.3284984, step = 38800 (68.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43877\n",
      "INFO:tensorflow:loss = 5.157766, step = 38900 (69.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44126\n",
      "INFO:tensorflow:loss = 5.211857, step = 39000 (69.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45301\n",
      "INFO:tensorflow:loss = 4.8680763, step = 39100 (68.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44677\n",
      "INFO:tensorflow:loss = 5.2262454, step = 39200 (69.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41895\n",
      "INFO:tensorflow:loss = 5.2413063, step = 39300 (70.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46195\n",
      "INFO:tensorflow:loss = 5.0902467, step = 39400 (68.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40543\n",
      "INFO:tensorflow:loss = 5.0667396, step = 39500 (71.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47684\n",
      "INFO:tensorflow:loss = 5.599395, step = 39600 (67.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41302\n",
      "INFO:tensorflow:loss = 6.280602, step = 39700 (70.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43591\n",
      "INFO:tensorflow:loss = 4.578023, step = 39800 (69.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48288\n",
      "INFO:tensorflow:loss = 5.237047, step = 39900 (67.435 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_1024/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 4.8786154.\n",
      "Time: 32721.31 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_1024'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 2048 #2048 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "# hparams.num_encoder_layers = 2\n",
    "# hparams.num_hidden_layers = 6\n",
    "# hparams.num_decoder_layers = 2 \n",
    "hparams.dropout =0.2\n",
    "# hparams.num_heads =16\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_input_seq_length = 1024\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_1024 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40000,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=1000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_1024.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_smoothing': 0.1, 'learning_rate_constant': 1.0, 'optimizer_multistep_accumulate_steps': None, 'learning_rate_warmup_steps': 8000, 'optimizer_adafactor_decay_type': 'pow', 'use_fixed_batch_size': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'multiply_embedding_mode': 'sqrt_depth', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'parameter_attention_key_channels': 0, 'summarize_grads': False, 'num_hidden_layers': 6, 'pad_batch': False, 'weight_noise': 0.0, 'learning_rate_decay_scheme': 'noam', 'multiproblem_fixed_train_length': -1, 'max_target_seq_length': 0, 'kernel_height': 3, 'dropout': 0.3, 'grad_noise_scale': 0.0, 'learning_rate_minimum': None, 'ffn_layer': 'dense_relu_dense', 'optimizer_adafactor_memory_exponent': 0.8, 'force_full_predict': False, 'multiproblem_mixing_schedule': 'constant', 'min_length': 0, 'shared_embedding': False, 'optimizer_adam_beta1': 0.9, 'num_decoder_layers': 6, 'factored_logits': False, 'layer_preprocess_sequence': 'n', 'proximity_bias': False, 'attention_key_channels': 0, 'kernel_width': 1, 'layer_prepostprocess_dropout': 0.1, 'conv_first_kernel': 3, 'video_num_input_frames': 1, 'learning_rate': 0.05, 'moe_overhead_train': 1.0, 'norm_type': 'layer', 'mlperf_mode': False, 'optimizer_adafactor_beta1': 0.0, 'split_to_length': 0, 'attention_value_channels': 0, 'eval_run_autoregressive': False, 'num_heads': 8, 'attention_dropout_broadcast_dims': '', 'unidirectional_encoder': False, 'vocab_divisor': 1, 'weight_dtype': 'float32', 'max_relative_position': 0, 'relu_dropout_broadcast_dims': '', 'tpu_enable_host_call': False, 'causal_decoder_self_attention': True, 'add_relative_to_values': False, 'layer_prepostprocess_dropout_broadcast_dims': '', 'symbol_modality_skip_top': False, 'optimizer_adafactor_factored': True, 'multiproblem_vocab_size': -1, 'eval_drop_long_sequences': False, 'clip_grad_norm': 0.0, 'nbr_decoder_problems': 1, 'multiproblem_reweight_label_loss': False, 'optimizer_adafactor_beta2': 0.999, 'norm_epsilon': 1e-06, 'learning_rate_decay_steps': 5000, 'heads_share_relative_embedding': False, 'num_encoder_layers': 6, 'symbol_modality_num_shards': 16, 'symbol_dropout': 0.0, 'max_length': 0, 'moe_k': 2, 'length_bucket_step': 1.1, 'layer_postprocess_sequence': 'da', 'multiproblem_max_input_length': -1, 'summarize_vars': False, 'multiproblem_schedule_max_examples': 10000000.0, 'max_input_seq_length': 512, 'learning_rate_cosine_cycle_steps': 250000, 'pretrained_model_dir': '', 'overload_eval_metric_name': '', 'sampling_method': 'argmax', 'learning_rate_decay_staircase': False, 'activation_dtype': 'float32', 'multiproblem_max_target_length': -1, 'moe_num_experts': 16, 'use_pad_remover': True, 'sampling_temp': 1.0, 'learning_rate_schedule': 'legacy', 'attention_dropout': 0.2, 'modality': {}, 'hidden_size': 512, 'weight_decay': 0.0, 'no_data_parallelism': False, 'pos': 'timing', 'initializer': 'uniform_unit_scaling', 'use_target_space_embedding': True, 'batch_shuffle_size': 512, 'multiproblem_target_eval_only': False, 'attention_variables_3d': False, 'scheduled_sampling_warmup_steps': 50000, 'optimizer_adafactor_clipping_threshold': 1.0, 'shared_embedding_and_softmax_weights': True, 'moe_loss_coef': 0.001, 'batch_size': 2048, 'optimizer_zero_grads': False, 'optimizer_momentum_momentum': 0.9, 'initializer_gain': 1.0, 'multiproblem_schedule_threshold': 0.5, 'filter_size': 2048, 'moe_overhead_eval': 2.0, 'parameter_attention_value_channels': 0, 'video_num_target_frames': 1, 'multiproblem_label_weight': 0.5, 'optimizer_adam_epsilon': 1e-09, 'optimizer_adam_beta2': 0.98, 'warm_start_from_second': '', 'compress_steps': 0, 'min_length_bucket': 8, 'multiproblem_per_task_threshold': '', 'learning_rate_decay_rate': 1.0, 'relu_dropout': 0.1, 'scheduled_sampling_prob': 0.0, 'moe_hidden_sizes': '2048', 'optimizer_momentum_nesterov': False, 'self_attention_type': 'dot_product', 'optimizer': 'Adam', 'prepend_mode': 'prepend_inputs_full_attention', 'daisy_chain_variables': True}\n",
      "{'decode_to_file': None, 'max_input_size': -1, 'eos_penalty': 0.0, 'shard_google_format': False, 'guess_and_check_top_k': 0, 'identity_output': False, 'batch_size': 0, 'mlperf_decode_step': 0.0, 'alpha': 0.6, 'num_samples': -1, 'write_beam_scores': False, 'log_results': True, 'max_display_outputs': 10, 'force_decode_length': False, 'beam_size': 2, 'vgg_ckpt_path': '', 'shards': 1, 'guess_and_check_epsilon': -1, 'decode_timeout_mins': 240, 'save_images': False, 'shard_id': 0, 'decode_in_memory': False, 'frames_per_second': 10, 'extra_length': 100, 'display_decoded_images': False, 'mlperf_threshold': 25.0, 'block_size': 0, 'border_percent': 2, 'delimiter': '\\n', 'mlperf_success': False, 'summaries_log_dir': 'decode', 'multiproblem_task_id': -1, 'max_display_decodes': 5, 'num_decodes': 1, 'skip_eos_postprocess': False, 'return_beams': True, 'shards_start_offset': 0}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3101c55f98>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_keep_checkpoint_max': 20, '_num_ps_replicas': 0, '_train_distribute': None, '_master': '', '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, 't2t_device_info': {'num_async_replicas': 1}, '_log_step_count_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f3101c55fd0>, '_tf_random_seed': None, '_model_dir': 'model_file_512', '_is_chief': True, '_save_checkpoints_steps': 2000, '_protocol': None, 'use_tpu': False, '_evaluation_master': '', '_task_type': None, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f32a311bc80>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f3101c55d68>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f3101c55e10>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9cc0>, 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9cc0>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.050000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.654486, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.35093\n",
      "INFO:tensorflow:loss = 8.656198, step = 100 (74.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54083\n",
      "INFO:tensorflow:loss = 8.078813, step = 200 (64.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49276\n",
      "INFO:tensorflow:loss = 7.880606, step = 300 (66.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47041\n",
      "INFO:tensorflow:loss = 7.304089, step = 400 (68.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50496\n",
      "INFO:tensorflow:loss = 6.934419, step = 500 (66.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47781\n",
      "INFO:tensorflow:loss = 6.2114887, step = 600 (67.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5107\n",
      "INFO:tensorflow:loss = 6.257911, step = 700 (66.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47691\n",
      "INFO:tensorflow:loss = 6.2291884, step = 800 (67.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48053\n",
      "INFO:tensorflow:loss = 6.28161, step = 900 (67.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48697\n",
      "INFO:tensorflow:loss = 6.1255293, step = 1000 (67.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47714\n",
      "INFO:tensorflow:loss = 6.0599184, step = 1100 (67.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47681\n",
      "INFO:tensorflow:loss = 5.93154, step = 1200 (67.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46841\n",
      "INFO:tensorflow:loss = 6.5152, step = 1300 (68.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49326\n",
      "INFO:tensorflow:loss = 6.704829, step = 1400 (66.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45834\n",
      "INFO:tensorflow:loss = 5.8276787, step = 1500 (68.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49353\n",
      "INFO:tensorflow:loss = 5.9881473, step = 1600 (66.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47379\n",
      "INFO:tensorflow:loss = 5.845578, step = 1700 (67.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47935\n",
      "INFO:tensorflow:loss = 5.7483573, step = 1800 (67.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47333\n",
      "INFO:tensorflow:loss = 6.3365674, step = 1900 (67.875 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.318\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T17:47:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-17:50:46\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.4515486, metrics-onlinereview/targets/accuracy = 0.12568305, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26580513, metrics-onlinereview/targets/approx_bleu_score = 0.005627802, metrics-onlinereview/targets/neg_log_perplexity = -6.4053545, metrics-onlinereview/targets/rouge_2_fscore = 0.025895845, metrics-onlinereview/targets/rouge_L_fscore = 0.15256143\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_512/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-onlinereview/targets/accuracy = 0.12568305, metrics-onlinereview/targets/rouge_L_fscore = 0.15256143, metrics-onlinereview/targets/approx_bleu_score = 0.005627802, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 2000, loss = 6.4515486, metrics-onlinereview/targets/rouge_2_fscore = 0.025895845, metrics-onlinereview/targets/neg_log_perplexity = -6.4053545, metrics-onlinereview/targets/accuracy_top5 = 0.26580513\n",
      "INFO:tensorflow:loss = 5.489689, step = 2000 (259.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.398991\n",
      "INFO:tensorflow:loss = 5.998634, step = 2100 (66.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48082\n",
      "INFO:tensorflow:loss = 5.3882527, step = 2200 (67.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47563\n",
      "INFO:tensorflow:loss = 5.5590267, step = 2300 (67.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49081\n",
      "INFO:tensorflow:loss = 5.7816625, step = 2400 (67.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50553\n",
      "INFO:tensorflow:loss = 5.4538355, step = 2500 (66.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50221\n",
      "INFO:tensorflow:loss = 5.7310066, step = 2600 (66.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49572\n",
      "INFO:tensorflow:loss = 5.4543858, step = 2700 (66.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49147\n",
      "INFO:tensorflow:loss = 4.940754, step = 2800 (67.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45657\n",
      "INFO:tensorflow:loss = 6.682967, step = 2900 (68.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47884\n",
      "INFO:tensorflow:loss = 6.325022, step = 3000 (67.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49803\n",
      "INFO:tensorflow:loss = 5.1473417, step = 3100 (66.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50093\n",
      "INFO:tensorflow:loss = 6.1184874, step = 3200 (66.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5057\n",
      "INFO:tensorflow:loss = 5.1359386, step = 3300 (66.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51108\n",
      "INFO:tensorflow:loss = 5.640804, step = 3400 (66.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49608\n",
      "INFO:tensorflow:loss = 5.32197, step = 3500 (66.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49328\n",
      "INFO:tensorflow:loss = 5.405191, step = 3600 (66.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48819\n",
      "INFO:tensorflow:loss = 5.3277464, step = 3700 (67.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47347\n",
      "INFO:tensorflow:loss = 5.8195605, step = 3800 (67.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47592\n",
      "INFO:tensorflow:loss = 5.562814, step = 3900 (67.756 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32579\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T18:13:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-18:16:19\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 6.1941586, metrics-onlinereview/targets/accuracy = 0.14167763, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29727572, metrics-onlinereview/targets/approx_bleu_score = 0.006567325, metrics-onlinereview/targets/neg_log_perplexity = -6.1311007, metrics-onlinereview/targets/rouge_2_fscore = 0.028980125, metrics-onlinereview/targets/rouge_L_fscore = 0.16235875\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_512/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-onlinereview/targets/accuracy = 0.14167763, metrics-onlinereview/targets/rouge_L_fscore = 0.16235875, metrics-onlinereview/targets/approx_bleu_score = 0.006567325, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 4000, loss = 6.1941586, metrics-onlinereview/targets/rouge_2_fscore = 0.028980125, metrics-onlinereview/targets/neg_log_perplexity = -6.1311007, metrics-onlinereview/targets/accuracy_top5 = 0.29727572\n",
      "INFO:tensorflow:loss = 5.5108385, step = 4000 (258.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39876\n",
      "INFO:tensorflow:loss = 5.836657, step = 4100 (67.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47861\n",
      "INFO:tensorflow:loss = 5.1099815, step = 4200 (67.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47719\n",
      "INFO:tensorflow:loss = 6.4796753, step = 4300 (67.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5146\n",
      "INFO:tensorflow:loss = 5.16279, step = 4400 (66.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48382\n",
      "INFO:tensorflow:loss = 6.039131, step = 4500 (67.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48194\n",
      "INFO:tensorflow:loss = 5.051485, step = 4600 (67.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47878\n",
      "INFO:tensorflow:loss = 5.3959174, step = 4700 (67.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48253\n",
      "INFO:tensorflow:loss = 5.4881616, step = 4800 (67.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49844\n",
      "INFO:tensorflow:loss = 5.3756957, step = 4900 (66.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49642\n",
      "INFO:tensorflow:loss = 6.8377514, step = 5000 (66.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49885\n",
      "INFO:tensorflow:loss = 3.969979, step = 5100 (66.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49197\n",
      "INFO:tensorflow:loss = 5.573962, step = 5200 (67.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47993\n",
      "INFO:tensorflow:loss = 5.3365026, step = 5300 (67.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47484\n",
      "INFO:tensorflow:loss = 5.0400186, step = 5400 (67.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45641\n",
      "INFO:tensorflow:loss = 5.1513352, step = 5500 (68.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48546\n",
      "INFO:tensorflow:loss = 4.6894217, step = 5600 (67.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47323\n",
      "INFO:tensorflow:loss = 4.746397, step = 5700 (67.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4806\n",
      "INFO:tensorflow:loss = 5.799064, step = 5800 (67.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48774\n",
      "INFO:tensorflow:loss = 5.2054605, step = 5900 (67.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33504\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T18:39:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-18:41:55\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 6.1146007, metrics-onlinereview/targets/accuracy = 0.15001395, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31191418, metrics-onlinereview/targets/approx_bleu_score = 0.0061012106, metrics-onlinereview/targets/neg_log_perplexity = -6.0485616, metrics-onlinereview/targets/rouge_2_fscore = 0.026924923, metrics-onlinereview/targets/rouge_L_fscore = 0.15827425\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_512/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-onlinereview/targets/accuracy = 0.15001395, metrics-onlinereview/targets/rouge_L_fscore = 0.15827425, metrics-onlinereview/targets/approx_bleu_score = 0.0061012106, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 6000, loss = 6.1146007, metrics-onlinereview/targets/rouge_2_fscore = 0.026924923, metrics-onlinereview/targets/neg_log_perplexity = -6.0485616, metrics-onlinereview/targets/accuracy_top5 = 0.31191418\n",
      "INFO:tensorflow:loss = 5.3700056, step = 6000 (255.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.403233\n",
      "INFO:tensorflow:loss = 5.539827, step = 6100 (67.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46792\n",
      "INFO:tensorflow:loss = 4.7662306, step = 6200 (68.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5042\n",
      "INFO:tensorflow:loss = 4.7392726, step = 6300 (66.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46818\n",
      "INFO:tensorflow:loss = 5.334494, step = 6400 (68.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5\n",
      "INFO:tensorflow:loss = 5.731506, step = 6500 (66.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49192\n",
      "INFO:tensorflow:loss = 4.6899576, step = 6600 (67.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48475\n",
      "INFO:tensorflow:loss = 5.878016, step = 6700 (67.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50114\n",
      "INFO:tensorflow:loss = 4.7679553, step = 6800 (66.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48448\n",
      "INFO:tensorflow:loss = 5.1010556, step = 6900 (67.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48429\n",
      "INFO:tensorflow:loss = 5.0082374, step = 7000 (67.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48453\n",
      "INFO:tensorflow:loss = 6.677371, step = 7100 (67.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47356\n",
      "INFO:tensorflow:loss = 4.928766, step = 7200 (67.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5\n",
      "INFO:tensorflow:loss = 4.7393537, step = 7300 (66.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50294\n",
      "INFO:tensorflow:loss = 4.91656, step = 7400 (66.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4587\n",
      "INFO:tensorflow:loss = 5.084554, step = 7500 (68.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48178\n",
      "INFO:tensorflow:loss = 4.6284075, step = 7600 (67.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49175\n",
      "INFO:tensorflow:loss = 5.6290507, step = 7700 (67.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49948\n",
      "INFO:tensorflow:loss = 5.8600836, step = 7800 (66.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47471\n",
      "INFO:tensorflow:loss = 6.036185, step = 7900 (67.810 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33847\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T19:04:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-19:07:32\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 6.0247126, metrics-onlinereview/targets/accuracy = 0.15480037, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3192932, metrics-onlinereview/targets/approx_bleu_score = 0.0068069124, metrics-onlinereview/targets/neg_log_perplexity = -5.9496055, metrics-onlinereview/targets/rouge_2_fscore = 0.03010694, metrics-onlinereview/targets/rouge_L_fscore = 0.1605822\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_file_512/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-onlinereview/targets/accuracy = 0.15480037, metrics-onlinereview/targets/rouge_L_fscore = 0.1605822, metrics-onlinereview/targets/approx_bleu_score = 0.0068069124, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 8000, loss = 6.0247126, metrics-onlinereview/targets/rouge_2_fscore = 0.03010694, metrics-onlinereview/targets/neg_log_perplexity = -5.9496055, metrics-onlinereview/targets/accuracy_top5 = 0.3192932\n",
      "INFO:tensorflow:loss = 5.1643014, step = 8000 (258.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39735\n",
      "INFO:tensorflow:loss = 6.1296773, step = 8100 (67.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52153\n",
      "INFO:tensorflow:loss = 5.854442, step = 8200 (65.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48429\n",
      "INFO:tensorflow:loss = 5.069006, step = 8300 (67.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48688\n",
      "INFO:tensorflow:loss = 5.347451, step = 8400 (67.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4862\n",
      "INFO:tensorflow:loss = 5.453908, step = 8500 (67.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45559\n",
      "INFO:tensorflow:loss = 5.230478, step = 8600 (68.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49786\n",
      "INFO:tensorflow:loss = 5.0310807, step = 8700 (66.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50358\n",
      "INFO:tensorflow:loss = 5.163292, step = 8800 (66.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47364\n",
      "INFO:tensorflow:loss = 4.863632, step = 8900 (67.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48156\n",
      "INFO:tensorflow:loss = 5.122403, step = 9000 (67.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47318\n",
      "INFO:tensorflow:loss = 5.6323733, step = 9100 (67.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47298\n",
      "INFO:tensorflow:loss = 5.526429, step = 9200 (67.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49864\n",
      "INFO:tensorflow:loss = 4.6986794, step = 9300 (66.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50217\n",
      "INFO:tensorflow:loss = 5.735426, step = 9400 (66.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50332\n",
      "INFO:tensorflow:loss = 4.936908, step = 9500 (66.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48062\n",
      "INFO:tensorflow:loss = 5.5933623, step = 9600 (67.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48266\n",
      "INFO:tensorflow:loss = 4.603574, step = 9700 (67.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47191\n",
      "INFO:tensorflow:loss = 5.201209, step = 9800 (67.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47392\n",
      "INFO:tensorflow:loss = 5.7649384, step = 9900 (67.847 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31446\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T19:30:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-19:33:13\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 5.9721575, metrics-onlinereview/targets/accuracy = 0.16154122, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31981173, metrics-onlinereview/targets/approx_bleu_score = 0.0076858504, metrics-onlinereview/targets/neg_log_perplexity = -5.9031587, metrics-onlinereview/targets/rouge_2_fscore = 0.034135822, metrics-onlinereview/targets/rouge_L_fscore = 0.16919631\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_file_512/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-onlinereview/targets/accuracy = 0.16154122, metrics-onlinereview/targets/rouge_L_fscore = 0.16919631, metrics-onlinereview/targets/approx_bleu_score = 0.0076858504, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 10000, loss = 5.9721575, metrics-onlinereview/targets/rouge_2_fscore = 0.034135822, metrics-onlinereview/targets/neg_log_perplexity = -5.9031587, metrics-onlinereview/targets/accuracy_top5 = 0.31981173\n",
      "INFO:tensorflow:loss = 4.8092628, step = 10000 (261.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.396938\n",
      "INFO:tensorflow:loss = 5.6422596, step = 10100 (66.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4836\n",
      "INFO:tensorflow:loss = 4.9892616, step = 10200 (67.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48455\n",
      "INFO:tensorflow:loss = 5.8348093, step = 10300 (67.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48769\n",
      "INFO:tensorflow:loss = 5.911745, step = 10400 (67.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49172\n",
      "INFO:tensorflow:loss = 4.8244324, step = 10500 (67.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48691\n",
      "INFO:tensorflow:loss = 5.034621, step = 10600 (67.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49259\n",
      "INFO:tensorflow:loss = 5.4485106, step = 10700 (66.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50061\n",
      "INFO:tensorflow:loss = 4.9355135, step = 10800 (66.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46576\n",
      "INFO:tensorflow:loss = 4.8996124, step = 10900 (68.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47425\n",
      "INFO:tensorflow:loss = 5.4927006, step = 11000 (67.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50882\n",
      "INFO:tensorflow:loss = 5.1593986, step = 11100 (66.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51258\n",
      "INFO:tensorflow:loss = 4.911454, step = 11200 (66.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45281\n",
      "INFO:tensorflow:loss = 5.368621, step = 11300 (68.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46523\n",
      "INFO:tensorflow:loss = 5.265393, step = 11400 (68.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49021\n",
      "INFO:tensorflow:loss = 5.061565, step = 11500 (67.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50911\n",
      "INFO:tensorflow:loss = 4.722021, step = 11600 (66.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47618\n",
      "INFO:tensorflow:loss = 5.7551913, step = 11700 (67.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48272\n",
      "INFO:tensorflow:loss = 5.179935, step = 11800 (67.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47411\n",
      "INFO:tensorflow:loss = 5.5330772, step = 11900 (67.837 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33947\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T19:55:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-19:58:52\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 5.888302, metrics-onlinereview/targets/accuracy = 0.16860117, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.33955565, metrics-onlinereview/targets/approx_bleu_score = 0.008743093, metrics-onlinereview/targets/neg_log_perplexity = -5.8121552, metrics-onlinereview/targets/rouge_2_fscore = 0.03841544, metrics-onlinereview/targets/rouge_L_fscore = 0.1780571\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_file_512/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-onlinereview/targets/accuracy = 0.16860117, metrics-onlinereview/targets/rouge_L_fscore = 0.1780571, metrics-onlinereview/targets/approx_bleu_score = 0.008743093, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 12000, loss = 5.888302, metrics-onlinereview/targets/rouge_2_fscore = 0.03841544, metrics-onlinereview/targets/neg_log_perplexity = -5.8121552, metrics-onlinereview/targets/accuracy_top5 = 0.33955565\n",
      "INFO:tensorflow:loss = 5.942033, step = 12000 (261.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39235\n",
      "INFO:tensorflow:loss = 4.839759, step = 12100 (67.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51382\n",
      "INFO:tensorflow:loss = 5.7831903, step = 12200 (66.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48371\n",
      "INFO:tensorflow:loss = 4.585309, step = 12300 (67.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.487\n",
      "INFO:tensorflow:loss = 5.260409, step = 12400 (67.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47118\n",
      "INFO:tensorflow:loss = 6.1303463, step = 12500 (67.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48733\n",
      "INFO:tensorflow:loss = 5.355536, step = 12600 (67.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50438\n",
      "INFO:tensorflow:loss = 5.202258, step = 12700 (66.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48939\n",
      "INFO:tensorflow:loss = 5.1634192, step = 12800 (67.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48869\n",
      "INFO:tensorflow:loss = 5.56127, step = 12900 (67.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48306\n",
      "INFO:tensorflow:loss = 5.1089725, step = 13000 (67.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48314\n",
      "INFO:tensorflow:loss = 5.3180957, step = 13100 (67.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47023\n",
      "INFO:tensorflow:loss = 5.4897127, step = 13200 (68.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47982\n",
      "INFO:tensorflow:loss = 4.833177, step = 13300 (67.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48735\n",
      "INFO:tensorflow:loss = 4.9067, step = 13400 (67.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4976\n",
      "INFO:tensorflow:loss = 5.2310643, step = 13500 (66.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51825\n",
      "INFO:tensorflow:loss = 4.729617, step = 13600 (65.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4933\n",
      "INFO:tensorflow:loss = 5.0100636, step = 13700 (66.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46202\n",
      "INFO:tensorflow:loss = 4.9768686, step = 13800 (68.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48876\n",
      "INFO:tensorflow:loss = 5.2820654, step = 13900 (67.171 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32959\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T20:21:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-20:24:31\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 5.8435073, metrics-onlinereview/targets/accuracy = 0.17382634, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.34721392, metrics-onlinereview/targets/approx_bleu_score = 0.008406743, metrics-onlinereview/targets/neg_log_perplexity = -5.7673225, metrics-onlinereview/targets/rouge_2_fscore = 0.036379334, metrics-onlinereview/targets/rouge_L_fscore = 0.17327946\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_file_512/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-onlinereview/targets/accuracy = 0.17382634, metrics-onlinereview/targets/rouge_L_fscore = 0.17327946, metrics-onlinereview/targets/approx_bleu_score = 0.008406743, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 14000, loss = 5.8435073, metrics-onlinereview/targets/rouge_2_fscore = 0.036379334, metrics-onlinereview/targets/neg_log_perplexity = -5.7673225, metrics-onlinereview/targets/accuracy_top5 = 0.34721392\n",
      "INFO:tensorflow:loss = 4.558926, step = 14000 (261.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.394352\n",
      "INFO:tensorflow:loss = 4.9269376, step = 14100 (67.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48813\n",
      "INFO:tensorflow:loss = 5.9511847, step = 14200 (67.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49164\n",
      "INFO:tensorflow:loss = 5.53206, step = 14300 (67.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49091\n",
      "INFO:tensorflow:loss = 5.494746, step = 14400 (67.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48774\n",
      "INFO:tensorflow:loss = 4.950574, step = 14500 (67.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49008\n",
      "INFO:tensorflow:loss = 5.5850825, step = 14600 (67.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48657\n",
      "INFO:tensorflow:loss = 5.195501, step = 14700 (67.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48772\n",
      "INFO:tensorflow:loss = 5.343928, step = 14800 (67.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49845\n",
      "INFO:tensorflow:loss = 4.7751846, step = 14900 (66.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48568\n",
      "INFO:tensorflow:loss = 3.7587965, step = 15000 (67.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48574\n",
      "INFO:tensorflow:loss = 4.722055, step = 15100 (67.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46976\n",
      "INFO:tensorflow:loss = 5.304425, step = 15200 (68.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49365\n",
      "INFO:tensorflow:loss = 5.425795, step = 15300 (66.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49983\n",
      "INFO:tensorflow:loss = 4.9951134, step = 15400 (66.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50529\n",
      "INFO:tensorflow:loss = 5.4982862, step = 15500 (66.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4815\n",
      "INFO:tensorflow:loss = 5.503653, step = 15600 (67.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47974\n",
      "INFO:tensorflow:loss = 5.5489182, step = 15700 (67.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4603\n",
      "INFO:tensorflow:loss = 4.712205, step = 15800 (68.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50071\n",
      "INFO:tensorflow:loss = 5.436945, step = 15900 (66.637 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30006\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T20:47:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-20:50:12\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 5.7998366, metrics-onlinereview/targets/accuracy = 0.17741613, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.35411432, metrics-onlinereview/targets/approx_bleu_score = 0.007360437, metrics-onlinereview/targets/neg_log_perplexity = -5.7181864, metrics-onlinereview/targets/rouge_2_fscore = 0.033012684, metrics-onlinereview/targets/rouge_L_fscore = 0.16316362\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_file_512/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-onlinereview/targets/accuracy = 0.17741613, metrics-onlinereview/targets/rouge_L_fscore = 0.16316362, metrics-onlinereview/targets/approx_bleu_score = 0.007360437, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 16000, loss = 5.7998366, metrics-onlinereview/targets/rouge_2_fscore = 0.033012684, metrics-onlinereview/targets/neg_log_perplexity = -5.7181864, metrics-onlinereview/targets/accuracy_top5 = 0.35411432\n",
      "INFO:tensorflow:loss = 5.4518747, step = 16000 (263.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.394024\n",
      "INFO:tensorflow:loss = 5.3454914, step = 16100 (67.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45802\n",
      "INFO:tensorflow:loss = 4.862818, step = 16200 (68.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47553\n",
      "INFO:tensorflow:loss = 5.291992, step = 16300 (67.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49409\n",
      "INFO:tensorflow:loss = 4.8902683, step = 16400 (66.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49023\n",
      "INFO:tensorflow:loss = 5.58996, step = 16500 (67.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5024\n",
      "INFO:tensorflow:loss = 5.2281866, step = 16600 (66.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47988\n",
      "INFO:tensorflow:loss = 4.7916927, step = 16700 (67.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49106\n",
      "INFO:tensorflow:loss = 4.621133, step = 16800 (67.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49495\n",
      "INFO:tensorflow:loss = 4.8892493, step = 16900 (66.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48889\n",
      "INFO:tensorflow:loss = 4.8045263, step = 17000 (67.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50641\n",
      "INFO:tensorflow:loss = 4.9748735, step = 17100 (66.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49556\n",
      "INFO:tensorflow:loss = 5.650028, step = 17200 (66.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50366\n",
      "INFO:tensorflow:loss = 5.6305065, step = 17300 (66.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47646\n",
      "INFO:tensorflow:loss = 4.797312, step = 17400 (67.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48615\n",
      "INFO:tensorflow:loss = 5.1564956, step = 17500 (67.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47748\n",
      "INFO:tensorflow:loss = 5.6628137, step = 17600 (67.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48085\n",
      "INFO:tensorflow:loss = 6.1294503, step = 17700 (67.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48798\n",
      "INFO:tensorflow:loss = 4.875013, step = 17800 (67.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48805\n",
      "INFO:tensorflow:loss = 5.3958917, step = 17900 (67.204 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32615\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T21:12:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-21:15:51\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 5.7679844, metrics-onlinereview/targets/accuracy = 0.18375812, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3643652, metrics-onlinereview/targets/approx_bleu_score = 0.008046566, metrics-onlinereview/targets/neg_log_perplexity = -5.690407, metrics-onlinereview/targets/rouge_2_fscore = 0.031805422, metrics-onlinereview/targets/rouge_L_fscore = 0.16082157\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_file_512/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-onlinereview/targets/accuracy = 0.18375812, metrics-onlinereview/targets/rouge_L_fscore = 0.16082157, metrics-onlinereview/targets/approx_bleu_score = 0.008046566, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 18000, loss = 5.7679844, metrics-onlinereview/targets/rouge_2_fscore = 0.031805422, metrics-onlinereview/targets/neg_log_perplexity = -5.690407, metrics-onlinereview/targets/accuracy_top5 = 0.3643652\n",
      "INFO:tensorflow:loss = 4.660479, step = 18000 (261.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.394865\n",
      "INFO:tensorflow:loss = 5.0459385, step = 18100 (67.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48102\n",
      "INFO:tensorflow:loss = 4.5519505, step = 18200 (67.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4888\n",
      "INFO:tensorflow:loss = 5.173895, step = 18300 (67.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48429\n",
      "INFO:tensorflow:loss = 4.758399, step = 18400 (67.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47704\n",
      "INFO:tensorflow:loss = 6.204877, step = 18500 (67.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48933\n",
      "INFO:tensorflow:loss = 4.8584404, step = 18600 (67.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4801\n",
      "INFO:tensorflow:loss = 5.329815, step = 18700 (67.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4873\n",
      "INFO:tensorflow:loss = 4.8687325, step = 18800 (67.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49403\n",
      "INFO:tensorflow:loss = 4.9688096, step = 18900 (66.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.471\n",
      "INFO:tensorflow:loss = 4.7541943, step = 19000 (67.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48546\n",
      "INFO:tensorflow:loss = 4.629081, step = 19100 (67.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45295\n",
      "INFO:tensorflow:loss = 5.2006407, step = 19200 (68.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47348\n",
      "INFO:tensorflow:loss = 4.9305887, step = 19300 (67.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48099\n",
      "INFO:tensorflow:loss = 4.9546714, step = 19400 (67.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49014\n",
      "INFO:tensorflow:loss = 4.9344506, step = 19500 (67.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50565\n",
      "INFO:tensorflow:loss = 4.859984, step = 19600 (66.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46449\n",
      "INFO:tensorflow:loss = 5.149105, step = 19700 (68.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50651\n",
      "INFO:tensorflow:loss = 4.548, step = 19800 (66.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47945\n",
      "INFO:tensorflow:loss = 4.2897267, step = 19900 (67.595 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31868\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T21:38:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-21:41:34\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 5.7247906, metrics-onlinereview/targets/accuracy = 0.18778668, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.36823422, metrics-onlinereview/targets/approx_bleu_score = 0.008419151, metrics-onlinereview/targets/neg_log_perplexity = -5.6535544, metrics-onlinereview/targets/rouge_2_fscore = 0.03615847, metrics-onlinereview/targets/rouge_L_fscore = 0.16460909\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_file_512/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-onlinereview/targets/accuracy = 0.18778668, metrics-onlinereview/targets/rouge_L_fscore = 0.16460909, metrics-onlinereview/targets/approx_bleu_score = 0.008419151, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 20000, loss = 5.7247906, metrics-onlinereview/targets/rouge_2_fscore = 0.03615847, metrics-onlinereview/targets/neg_log_perplexity = -5.6535544, metrics-onlinereview/targets/accuracy_top5 = 0.36823422\n",
      "INFO:tensorflow:loss = 5.5388966, step = 20000 (262.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39409\n",
      "INFO:tensorflow:loss = 4.2200394, step = 20100 (67.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49922\n",
      "INFO:tensorflow:loss = 4.776902, step = 20200 (66.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50475\n",
      "INFO:tensorflow:loss = 4.711614, step = 20300 (66.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48751\n",
      "INFO:tensorflow:loss = 5.1289077, step = 20400 (67.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48975\n",
      "INFO:tensorflow:loss = 6.011681, step = 20500 (67.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48011\n",
      "INFO:tensorflow:loss = 4.453381, step = 20600 (67.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49486\n",
      "INFO:tensorflow:loss = 4.820993, step = 20700 (66.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49796\n",
      "INFO:tensorflow:loss = 5.107766, step = 20800 (66.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48818\n",
      "INFO:tensorflow:loss = 4.4117517, step = 20900 (67.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49979\n",
      "INFO:tensorflow:loss = 4.9866347, step = 21000 (66.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49247\n",
      "INFO:tensorflow:loss = 4.987914, step = 21100 (67.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47537\n",
      "INFO:tensorflow:loss = 4.3517447, step = 21200 (67.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.501\n",
      "INFO:tensorflow:loss = 5.768038, step = 21300 (66.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47627\n",
      "INFO:tensorflow:loss = 4.995862, step = 21400 (67.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46781\n",
      "INFO:tensorflow:loss = 5.232364, step = 21500 (68.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48025\n",
      "INFO:tensorflow:loss = 5.4026175, step = 21600 (67.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50679\n",
      "INFO:tensorflow:loss = 4.535718, step = 21700 (66.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50435\n",
      "INFO:tensorflow:loss = 5.725147, step = 21800 (66.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46675\n",
      "INFO:tensorflow:loss = 5.1692, step = 21900 (68.177 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.3252\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T22:04:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-22:07:10\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 5.701307, metrics-onlinereview/targets/accuracy = 0.19006023, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37086675, metrics-onlinereview/targets/approx_bleu_score = 0.007915966, metrics-onlinereview/targets/neg_log_perplexity = -5.619588, metrics-onlinereview/targets/rouge_2_fscore = 0.034012757, metrics-onlinereview/targets/rouge_L_fscore = 0.16400017\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_file_512/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-onlinereview/targets/accuracy = 0.19006023, metrics-onlinereview/targets/rouge_L_fscore = 0.16400017, metrics-onlinereview/targets/approx_bleu_score = 0.007915966, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 22000, loss = 5.701307, metrics-onlinereview/targets/rouge_2_fscore = 0.034012757, metrics-onlinereview/targets/neg_log_perplexity = -5.619588, metrics-onlinereview/targets/accuracy_top5 = 0.37086675\n",
      "INFO:tensorflow:loss = 5.092459, step = 22000 (260.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.396949\n",
      "INFO:tensorflow:loss = 5.124733, step = 22100 (66.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47876\n",
      "INFO:tensorflow:loss = 4.06077, step = 22200 (67.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47807\n",
      "INFO:tensorflow:loss = 4.969809, step = 22300 (67.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49439\n",
      "INFO:tensorflow:loss = 4.727132, step = 22400 (66.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47906\n",
      "INFO:tensorflow:loss = 5.01583, step = 22500 (67.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48861\n",
      "INFO:tensorflow:loss = 5.469768, step = 22600 (67.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46621\n",
      "INFO:tensorflow:loss = 4.695943, step = 22700 (68.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4693\n",
      "INFO:tensorflow:loss = 5.3774867, step = 22800 (68.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47315\n",
      "INFO:tensorflow:loss = 5.050478, step = 22900 (67.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50278\n",
      "INFO:tensorflow:loss = 4.735502, step = 23000 (66.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50505\n",
      "INFO:tensorflow:loss = 5.1722546, step = 23100 (66.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47884\n",
      "INFO:tensorflow:loss = 4.9339247, step = 23200 (67.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49116\n",
      "INFO:tensorflow:loss = 5.5601254, step = 23300 (67.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4947\n",
      "INFO:tensorflow:loss = 4.8831677, step = 23400 (66.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51127\n",
      "INFO:tensorflow:loss = 3.9832253, step = 23500 (66.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50412\n",
      "INFO:tensorflow:loss = 4.7824903, step = 23600 (66.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48947\n",
      "INFO:tensorflow:loss = 5.2789993, step = 23700 (67.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47588\n",
      "INFO:tensorflow:loss = 5.6743984, step = 23800 (67.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49226\n",
      "INFO:tensorflow:loss = 5.685864, step = 23900 (67.013 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31219\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T22:29:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-22:32:51\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 5.6593714, metrics-onlinereview/targets/accuracy = 0.19173548, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37629133, metrics-onlinereview/targets/approx_bleu_score = 0.007936861, metrics-onlinereview/targets/neg_log_perplexity = -5.5836167, metrics-onlinereview/targets/rouge_2_fscore = 0.033289578, metrics-onlinereview/targets/rouge_L_fscore = 0.15846902\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_file_512/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-onlinereview/targets/accuracy = 0.19173548, metrics-onlinereview/targets/rouge_L_fscore = 0.15846902, metrics-onlinereview/targets/approx_bleu_score = 0.007936861, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 24000, loss = 5.6593714, metrics-onlinereview/targets/rouge_2_fscore = 0.033289578, metrics-onlinereview/targets/neg_log_perplexity = -5.5836167, metrics-onlinereview/targets/accuracy_top5 = 0.37629133\n",
      "INFO:tensorflow:loss = 4.365264, step = 24000 (263.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39276\n",
      "INFO:tensorflow:loss = 5.1992826, step = 24100 (66.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48075\n",
      "INFO:tensorflow:loss = 5.869078, step = 24200 (67.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47979\n",
      "INFO:tensorflow:loss = 4.9233756, step = 24300 (67.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49978\n",
      "INFO:tensorflow:loss = 6.0976806, step = 24400 (66.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47983\n",
      "INFO:tensorflow:loss = 5.393106, step = 24500 (67.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4826\n",
      "INFO:tensorflow:loss = 4.600236, step = 24600 (67.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49631\n",
      "INFO:tensorflow:loss = 5.5819044, step = 24700 (66.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49356\n",
      "INFO:tensorflow:loss = 4.167716, step = 24800 (66.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50537\n",
      "INFO:tensorflow:loss = 4.4065843, step = 24900 (66.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48695\n",
      "INFO:tensorflow:loss = 4.444923, step = 25000 (67.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48881\n",
      "INFO:tensorflow:loss = 4.737345, step = 25100 (67.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48884\n",
      "INFO:tensorflow:loss = 4.5668306, step = 25200 (67.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50186\n",
      "INFO:tensorflow:loss = 5.12888, step = 25300 (66.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49781\n",
      "INFO:tensorflow:loss = 4.7743993, step = 25400 (66.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48387\n",
      "INFO:tensorflow:loss = 4.921939, step = 25500 (67.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46631\n",
      "INFO:tensorflow:loss = 6.3783417, step = 25600 (68.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46999\n",
      "INFO:tensorflow:loss = 4.9049273, step = 25700 (68.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48155\n",
      "INFO:tensorflow:loss = 6.0891957, step = 25800 (67.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48087\n",
      "INFO:tensorflow:loss = 4.93602, step = 25900 (67.526 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33722\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T22:55:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-22:58:30\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 5.63562, metrics-onlinereview/targets/accuracy = 0.19388935, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37808624, metrics-onlinereview/targets/approx_bleu_score = 0.009198895, metrics-onlinereview/targets/neg_log_perplexity = -5.5528107, metrics-onlinereview/targets/rouge_2_fscore = 0.03920489, metrics-onlinereview/targets/rouge_L_fscore = 0.17137934\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_file_512/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-onlinereview/targets/accuracy = 0.19388935, metrics-onlinereview/targets/rouge_L_fscore = 0.17137934, metrics-onlinereview/targets/approx_bleu_score = 0.009198895, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 26000, loss = 5.63562, metrics-onlinereview/targets/rouge_2_fscore = 0.03920489, metrics-onlinereview/targets/neg_log_perplexity = -5.5528107, metrics-onlinereview/targets/accuracy_top5 = 0.37808624\n",
      "INFO:tensorflow:loss = 4.844414, step = 26000 (260.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.393338\n",
      "INFO:tensorflow:loss = 4.428263, step = 26100 (68.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48181\n",
      "INFO:tensorflow:loss = 5.2506876, step = 26200 (67.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50577\n",
      "INFO:tensorflow:loss = 4.6190405, step = 26300 (66.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48162\n",
      "INFO:tensorflow:loss = 5.0217824, step = 26400 (67.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48485\n",
      "INFO:tensorflow:loss = 4.9839177, step = 26500 (67.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47983\n",
      "INFO:tensorflow:loss = 5.2767773, step = 26600 (67.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46994\n",
      "INFO:tensorflow:loss = 4.646066, step = 26700 (68.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49542\n",
      "INFO:tensorflow:loss = 4.8190494, step = 26800 (66.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48668\n",
      "INFO:tensorflow:loss = 4.793758, step = 26900 (67.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50535\n",
      "INFO:tensorflow:loss = 4.6381364, step = 27000 (66.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48828\n",
      "INFO:tensorflow:loss = 5.3087177, step = 27100 (67.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50504\n",
      "INFO:tensorflow:loss = 5.2769823, step = 27200 (66.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48492\n",
      "INFO:tensorflow:loss = 5.002012, step = 27300 (67.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50967\n",
      "INFO:tensorflow:loss = 4.69773, step = 27400 (66.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51553\n",
      "INFO:tensorflow:loss = 5.264971, step = 27500 (65.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48369\n",
      "INFO:tensorflow:loss = 4.8241343, step = 27600 (67.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49793\n",
      "INFO:tensorflow:loss = 4.8665075, step = 27700 (66.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48734\n",
      "INFO:tensorflow:loss = 5.5071716, step = 27800 (67.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49921\n",
      "INFO:tensorflow:loss = 4.1744995, step = 27900 (66.704 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30593\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T23:21:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-23:24:07\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 5.6238055, metrics-onlinereview/targets/accuracy = 0.19632244, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38458776, metrics-onlinereview/targets/approx_bleu_score = 0.009757901, metrics-onlinereview/targets/neg_log_perplexity = -5.5472364, metrics-onlinereview/targets/rouge_2_fscore = 0.04055389, metrics-onlinereview/targets/rouge_L_fscore = 0.17839287\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_file_512/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-onlinereview/targets/accuracy = 0.19632244, metrics-onlinereview/targets/rouge_L_fscore = 0.17839287, metrics-onlinereview/targets/approx_bleu_score = 0.009757901, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 28000, loss = 5.6238055, metrics-onlinereview/targets/rouge_2_fscore = 0.04055389, metrics-onlinereview/targets/neg_log_perplexity = -5.5472364, metrics-onlinereview/targets/accuracy_top5 = 0.38458776\n",
      "INFO:tensorflow:loss = 4.8593154, step = 28000 (262.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.393715\n",
      "INFO:tensorflow:loss = 4.9248323, step = 28100 (67.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47473\n",
      "INFO:tensorflow:loss = 5.268981, step = 28200 (67.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46602\n",
      "INFO:tensorflow:loss = 5.076331, step = 28300 (68.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4802\n",
      "INFO:tensorflow:loss = 5.0212474, step = 28400 (67.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51557\n",
      "INFO:tensorflow:loss = 4.6751127, step = 28500 (65.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46845\n",
      "INFO:tensorflow:loss = 4.618636, step = 28600 (68.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49293\n",
      "INFO:tensorflow:loss = 4.327935, step = 28700 (66.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49343\n",
      "INFO:tensorflow:loss = 4.619907, step = 28800 (66.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49107\n",
      "INFO:tensorflow:loss = 4.5850215, step = 28900 (67.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47355\n",
      "INFO:tensorflow:loss = 4.8841434, step = 29000 (67.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45566\n",
      "INFO:tensorflow:loss = 4.659264, step = 29100 (68.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48372\n",
      "INFO:tensorflow:loss = 4.7801642, step = 29200 (67.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48147\n",
      "INFO:tensorflow:loss = 5.182662, step = 29300 (67.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4988\n",
      "INFO:tensorflow:loss = 4.4825287, step = 29400 (66.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48783\n",
      "INFO:tensorflow:loss = 4.9284782, step = 29500 (67.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49837\n",
      "INFO:tensorflow:loss = 4.1343756, step = 29600 (66.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47374\n",
      "INFO:tensorflow:loss = 5.362726, step = 29700 (67.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48875\n",
      "INFO:tensorflow:loss = 5.035307, step = 29800 (67.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45887\n",
      "INFO:tensorflow:loss = 4.8132296, step = 29900 (68.548 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31075\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T23:46:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-23:49:53\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 5.601707, metrics-onlinereview/targets/accuracy = 0.19819713, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38622314, metrics-onlinereview/targets/approx_bleu_score = 0.009441368, metrics-onlinereview/targets/neg_log_perplexity = -5.5225873, metrics-onlinereview/targets/rouge_2_fscore = 0.039573018, metrics-onlinereview/targets/rouge_L_fscore = 0.17741816\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_file_512/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-onlinereview/targets/accuracy = 0.19819713, metrics-onlinereview/targets/rouge_L_fscore = 0.17741816, metrics-onlinereview/targets/approx_bleu_score = 0.009441368, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 30000, loss = 5.601707, metrics-onlinereview/targets/rouge_2_fscore = 0.039573018, metrics-onlinereview/targets/neg_log_perplexity = -5.5225873, metrics-onlinereview/targets/accuracy_top5 = 0.38622314\n",
      "INFO:tensorflow:loss = 4.907816, step = 30000 (264.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.393004\n",
      "INFO:tensorflow:loss = 4.9657264, step = 30100 (66.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49085\n",
      "INFO:tensorflow:loss = 4.834134, step = 30200 (67.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49274\n",
      "INFO:tensorflow:loss = 5.0629177, step = 30300 (66.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48796\n",
      "INFO:tensorflow:loss = 5.817253, step = 30400 (67.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48486\n",
      "INFO:tensorflow:loss = 4.8284974, step = 30500 (67.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50327\n",
      "INFO:tensorflow:loss = 4.987588, step = 30600 (66.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46047\n",
      "INFO:tensorflow:loss = 5.6307635, step = 30700 (68.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53299\n",
      "INFO:tensorflow:loss = 4.6352224, step = 30800 (65.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51746\n",
      "INFO:tensorflow:loss = 5.0453916, step = 30900 (65.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.478\n",
      "INFO:tensorflow:loss = 4.8477683, step = 31000 (67.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47991\n",
      "INFO:tensorflow:loss = 5.7603297, step = 31100 (67.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47207\n",
      "INFO:tensorflow:loss = 4.629049, step = 31200 (67.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49283\n",
      "INFO:tensorflow:loss = 5.3933277, step = 31300 (66.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48759\n",
      "INFO:tensorflow:loss = 4.8707557, step = 31400 (67.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50574\n",
      "INFO:tensorflow:loss = 4.352401, step = 31500 (66.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47413\n",
      "INFO:tensorflow:loss = 5.1423173, step = 31600 (67.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52807\n",
      "INFO:tensorflow:loss = 4.9398365, step = 31700 (65.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50434\n",
      "INFO:tensorflow:loss = 5.201266, step = 31800 (66.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49624\n",
      "INFO:tensorflow:loss = 3.8214562, step = 31900 (66.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29909\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T00:12:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-00:15:30\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 5.5817995, metrics-onlinereview/targets/accuracy = 0.19995214, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38737985, metrics-onlinereview/targets/approx_bleu_score = 0.008773056, metrics-onlinereview/targets/neg_log_perplexity = -5.5065694, metrics-onlinereview/targets/rouge_2_fscore = 0.03742939, metrics-onlinereview/targets/rouge_L_fscore = 0.17144422\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_file_512/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-onlinereview/targets/accuracy = 0.19995214, metrics-onlinereview/targets/rouge_L_fscore = 0.17144422, metrics-onlinereview/targets/approx_bleu_score = 0.008773056, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 32000, loss = 5.5817995, metrics-onlinereview/targets/rouge_2_fscore = 0.03742939, metrics-onlinereview/targets/neg_log_perplexity = -5.5065694, metrics-onlinereview/targets/accuracy_top5 = 0.38737985\n",
      "INFO:tensorflow:loss = 4.3416786, step = 32000 (264.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.391425\n",
      "INFO:tensorflow:loss = 4.768297, step = 32100 (67.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50259\n",
      "INFO:tensorflow:loss = 4.8599715, step = 32200 (66.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5069\n",
      "INFO:tensorflow:loss = 4.416666, step = 32300 (66.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47823\n",
      "INFO:tensorflow:loss = 4.8626285, step = 32400 (67.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49857\n",
      "INFO:tensorflow:loss = 4.6943755, step = 32500 (66.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48549\n",
      "INFO:tensorflow:loss = 5.1740303, step = 32600 (67.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49807\n",
      "INFO:tensorflow:loss = 5.116475, step = 32700 (66.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46625\n",
      "INFO:tensorflow:loss = 5.150635, step = 32800 (68.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4806\n",
      "INFO:tensorflow:loss = 5.027944, step = 32900 (67.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48473\n",
      "INFO:tensorflow:loss = 4.1525264, step = 33000 (67.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48374\n",
      "INFO:tensorflow:loss = 5.693417, step = 33100 (67.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49799\n",
      "INFO:tensorflow:loss = 4.589471, step = 33200 (66.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48276\n",
      "INFO:tensorflow:loss = 4.3746767, step = 33300 (67.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49141\n",
      "INFO:tensorflow:loss = 5.2135224, step = 33400 (67.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46736\n",
      "INFO:tensorflow:loss = 4.982939, step = 33500 (68.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50816\n",
      "INFO:tensorflow:loss = 6.047804, step = 33600 (66.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47284\n",
      "INFO:tensorflow:loss = 5.6194124, step = 33700 (67.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48635\n",
      "INFO:tensorflow:loss = 4.562308, step = 33800 (67.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49352\n",
      "INFO:tensorflow:loss = 5.3348002, step = 33900 (66.956 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31502\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T00:38:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-00:41:11\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 5.5612984, metrics-onlinereview/targets/accuracy = 0.20342228, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38965338, metrics-onlinereview/targets/approx_bleu_score = 0.00981635, metrics-onlinereview/targets/neg_log_perplexity = -5.4831653, metrics-onlinereview/targets/rouge_2_fscore = 0.04012339, metrics-onlinereview/targets/rouge_L_fscore = 0.17349893\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_file_512/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-onlinereview/targets/accuracy = 0.20342228, metrics-onlinereview/targets/rouge_L_fscore = 0.17349893, metrics-onlinereview/targets/approx_bleu_score = 0.00981635, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 34000, loss = 5.5612984, metrics-onlinereview/targets/rouge_2_fscore = 0.04012339, metrics-onlinereview/targets/neg_log_perplexity = -5.4831653, metrics-onlinereview/targets/accuracy_top5 = 0.38965338\n",
      "INFO:tensorflow:loss = 4.397624, step = 34000 (263.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.392716\n",
      "INFO:tensorflow:loss = 4.775798, step = 34100 (66.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48387\n",
      "INFO:tensorflow:loss = 4.445285, step = 34200 (67.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50247\n",
      "INFO:tensorflow:loss = 5.2567363, step = 34300 (66.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50986\n",
      "INFO:tensorflow:loss = 4.903633, step = 34400 (66.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4661\n",
      "INFO:tensorflow:loss = 5.1837354, step = 34500 (68.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46477\n",
      "INFO:tensorflow:loss = 5.0366488, step = 34600 (68.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49524\n",
      "INFO:tensorflow:loss = 5.049615, step = 34700 (66.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49011\n",
      "INFO:tensorflow:loss = 6.057758, step = 34800 (67.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50037\n",
      "INFO:tensorflow:loss = 4.3067894, step = 34900 (66.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4926\n",
      "INFO:tensorflow:loss = 6.2460604, step = 35000 (66.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47048\n",
      "INFO:tensorflow:loss = 4.844031, step = 35100 (68.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50102\n",
      "INFO:tensorflow:loss = 5.7682004, step = 35200 (66.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47399\n",
      "INFO:tensorflow:loss = 4.6180434, step = 35300 (67.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48918\n",
      "INFO:tensorflow:loss = 4.572449, step = 35400 (67.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4804\n",
      "INFO:tensorflow:loss = 4.4533896, step = 35500 (67.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47797\n",
      "INFO:tensorflow:loss = 4.6911554, step = 35600 (67.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47022\n",
      "INFO:tensorflow:loss = 4.831323, step = 35700 (68.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49952\n",
      "INFO:tensorflow:loss = 5.1370687, step = 35800 (66.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48037\n",
      "INFO:tensorflow:loss = 4.3721237, step = 35900 (67.553 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.3218\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T01:03:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-01:06:52\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 5.54368, metrics-onlinereview/targets/accuracy = 0.2057756, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39196682, metrics-onlinereview/targets/approx_bleu_score = 0.009108487, metrics-onlinereview/targets/neg_log_perplexity = -5.470333, metrics-onlinereview/targets/rouge_2_fscore = 0.037886232, metrics-onlinereview/targets/rouge_L_fscore = 0.17249538\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_file_512/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-onlinereview/targets/accuracy = 0.2057756, metrics-onlinereview/targets/rouge_L_fscore = 0.17249538, metrics-onlinereview/targets/approx_bleu_score = 0.009108487, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 36000, loss = 5.54368, metrics-onlinereview/targets/rouge_2_fscore = 0.037886232, metrics-onlinereview/targets/neg_log_perplexity = -5.470333, metrics-onlinereview/targets/accuracy_top5 = 0.39196682\n",
      "INFO:tensorflow:loss = 4.370446, step = 36000 (262.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.395279\n",
      "INFO:tensorflow:loss = 5.1066203, step = 36100 (66.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47584\n",
      "INFO:tensorflow:loss = 5.232556, step = 36200 (67.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46755\n",
      "INFO:tensorflow:loss = 4.210358, step = 36300 (68.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50682\n",
      "INFO:tensorflow:loss = 4.588856, step = 36400 (66.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5082\n",
      "INFO:tensorflow:loss = 4.532184, step = 36500 (66.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48105\n",
      "INFO:tensorflow:loss = 5.84898, step = 36600 (67.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46446\n",
      "INFO:tensorflow:loss = 5.253609, step = 36700 (68.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4766\n",
      "INFO:tensorflow:loss = 4.8054447, step = 36800 (67.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50191\n",
      "INFO:tensorflow:loss = 5.335325, step = 36900 (66.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.465\n",
      "INFO:tensorflow:loss = 4.7245674, step = 37000 (68.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49833\n",
      "INFO:tensorflow:loss = 4.7486167, step = 37100 (66.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48747\n",
      "INFO:tensorflow:loss = 4.834613, step = 37200 (67.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46233\n",
      "INFO:tensorflow:loss = 5.191928, step = 37300 (68.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47288\n",
      "INFO:tensorflow:loss = 5.486403, step = 37400 (67.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49016\n",
      "INFO:tensorflow:loss = 5.1019516, step = 37500 (67.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47737\n",
      "INFO:tensorflow:loss = 5.0009956, step = 37600 (67.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50345\n",
      "INFO:tensorflow:loss = 5.284436, step = 37700 (66.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48928\n",
      "INFO:tensorflow:loss = 4.1280866, step = 37800 (67.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48565\n",
      "INFO:tensorflow:loss = 4.710208, step = 37900 (67.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30987\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T01:29:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-01:32:37\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 5.528153, metrics-onlinereview/targets/accuracy = 0.20685254, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3953572, metrics-onlinereview/targets/approx_bleu_score = 0.009839934, metrics-onlinereview/targets/neg_log_perplexity = -5.4478498, metrics-onlinereview/targets/rouge_2_fscore = 0.040919136, metrics-onlinereview/targets/rouge_L_fscore = 0.1762026\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_file_512/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-onlinereview/targets/accuracy = 0.20685254, metrics-onlinereview/targets/rouge_L_fscore = 0.1762026, metrics-onlinereview/targets/approx_bleu_score = 0.009839934, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 38000, loss = 5.528153, metrics-onlinereview/targets/rouge_2_fscore = 0.040919136, metrics-onlinereview/targets/neg_log_perplexity = -5.4478498, metrics-onlinereview/targets/accuracy_top5 = 0.3953572\n",
      "INFO:tensorflow:loss = 4.426422, step = 38000 (266.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.388219\n",
      "INFO:tensorflow:loss = 4.3290596, step = 38100 (67.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47827\n",
      "INFO:tensorflow:loss = 5.0493565, step = 38200 (67.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50226\n",
      "INFO:tensorflow:loss = 5.213697, step = 38300 (66.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50447\n",
      "INFO:tensorflow:loss = 4.6889834, step = 38400 (66.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49118\n",
      "INFO:tensorflow:loss = 4.5424767, step = 38500 (67.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49249\n",
      "INFO:tensorflow:loss = 5.138793, step = 38600 (67.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47385\n",
      "INFO:tensorflow:loss = 4.862534, step = 38700 (67.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47925\n",
      "INFO:tensorflow:loss = 5.451172, step = 38800 (67.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47637\n",
      "INFO:tensorflow:loss = 4.530423, step = 38900 (67.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47779\n",
      "INFO:tensorflow:loss = 4.8707747, step = 39000 (67.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52438\n",
      "INFO:tensorflow:loss = 5.4296746, step = 39100 (65.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47416\n",
      "INFO:tensorflow:loss = 4.076049, step = 39200 (67.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50849\n",
      "INFO:tensorflow:loss = 4.368683, step = 39300 (66.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46426\n",
      "INFO:tensorflow:loss = 3.9241366, step = 39400 (68.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49014\n",
      "INFO:tensorflow:loss = 5.91794, step = 39500 (67.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49808\n",
      "INFO:tensorflow:loss = 4.17875, step = 39600 (66.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46211\n",
      "INFO:tensorflow:loss = 5.2239223, step = 39700 (68.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49489\n",
      "INFO:tensorflow:loss = 5.1912007, step = 39800 (66.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46656\n",
      "INFO:tensorflow:loss = 5.6639066, step = 39900 (68.190 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.467051.\n",
      "Time: 30702.57 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_512'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 2048 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "hparams.num_encoder_layers = 6\n",
    "# hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.3\n",
    "# hparams.num_heads =16\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_input_seq_length = 512\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_512 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40000,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_512.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Decoding check--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "model_file_512/model.ckpt-40000\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "DATA_LOC = './data' \n",
    "t2t_problem = problems.problem('onlinereview')\n",
    "vocab_name = \"./data/vocab.onlinereview.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint('model_file_512') #model.ckpt\n",
    "print(ckpt_path)\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Greedy Decoding\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/modalities.py:114: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py:621: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:1037: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Review: \n",
      "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.\n",
      "Pred_summary: ...........................................................................................................\n",
      "Gold_summary:i was disappointed that you would only allow me to purchase 4 when your inventory showed that you had 14 available\n",
      "-------------------------------------------------- \n",
      "\n",
      "Review: \n",
      "my daughter wore this every other day for maybe half an hour at most the waistband has completely separated from the elastic after two weeks of this light use\n",
      "\n",
      "Pred_summary: ......................................................................................\n",
      "Gold_summary:this was great until it fell apart two weeks later\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-35f1489f2fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgold1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreview2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreview3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpred_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pred_summary: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpred_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ae6255fe1ccb>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mencoded_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_variables_on_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, features, decode_length, beam_size, top_beams, alpha, use_tpu)\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbeam_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Greedy Decoding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_greedy_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Beam Decoding with beam size %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36m_greedy_infer\u001b[0;34m(self, features, decode_length, use_tpu)\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_decode_tpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   def _beam_decode(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36m_fast_decode\u001b[0;34m(self, features, decode_length, beam_size, top_beams, alpha)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         force_decode_length=self._decode_hparams.force_decode_length)\n\u001b[0m\u001b[1;32m    704\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpartial_targets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbeam_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtop_beams\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36mfast_decode\u001b[0;34m(encoder_output, encoder_decoder_attention_bias, symbols_to_logits_fn, hparams, decode_length, vocab_size, beam_size, top_beams, alpha, sos_id, eos_id, batch_size, force_decode_length, scope_prefix, cache)\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_shape_invariants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m         ])\n\u001b[1;32m   1068\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3531\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36minner_loop\u001b[0;34m(i, hit_eos, next_id, decoded_ids, cache, log_prob)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_eos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m       \u001b[0;34m\"\"\"One step of greedy decoding.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m       \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbols_to_logits_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m       \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m       \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sampling_temp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36msymbols_to_logits_fn\u001b[0;34m(ids, i, cache)\u001b[0m\n\u001b[1;32m    654\u001b[0m       \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m       \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_self_attention_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36mpreprocess_targets\u001b[0;34m(targets, i)\u001b[0m\n\u001b[1;32m    633\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shard_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_modality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_modality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets_bottom_sharded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten4d3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\u001b[0m in \u001b[0;36mtargets_bottom_sharded\u001b[0;34m(self, xs, data_parallelism)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_input_depth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_parallelism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets_bottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDEFAULT_DEV_STRING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m               \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmy_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmy_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmy_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmy_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/modalities.py\u001b[0m in \u001b[0;36mtargets_bottom\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    125\u001b[0m         self._model_hparams.get(\"shared_embedding\")):\n\u001b[1;32m    126\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shared\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# perhaps there were no inputs, and this is a new variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/modalities.py\u001b[0m in \u001b[0;36mbottom_simple\u001b[0;34m(self, x, name, reuse)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m       x = common_layers.dropout_no_scaling(\n\u001b[1;32m    110\u001b[0m           x, 1.0 - self._model_hparams.symbol_dropout)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/modalities.py\u001b[0m in \u001b[0;36m_get_weights\u001b[0;34m(self, hidden_dim)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Convert ret to tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1254\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1255\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1126\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   1127\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ConcatV2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         name, _ctx._post_execution_callbacks, values, axis)\n\u001b[0m\u001b[1;32m   1129\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "review1 = '''\n",
    "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.'''\n",
    "\n",
    "gold1 = '''i was disappointed that you would only allow me to purchase 4 when your inventory showed that you had 14 available'''\n",
    "\n",
    "review2 = '''\n",
    "my daughter wore this every other day for maybe half an hour at most the waistband has completely separated from the elastic after two weeks of this light use\n",
    "'''\n",
    "gold2 = '''this was great until it fell apart two weeks later'''\n",
    "\n",
    "review3 = '''\n",
    "unfortunately this skirts elastic is not stretchy enough to accommodate the 29 year old range , this is crazy i would say it only stretches through about 1 size i would throw this in a costume play chest with a safety pin handy and call it a day  \n",
    "'''\n",
    "gold3 = '''i should have paid more attention to the age range'''\n",
    "\n",
    "for review, summary in [(review1,gold1), (review2, gold2), (review3, gold3)]:\n",
    "    pred_summary = summarize(review)\n",
    "    print(\"Review: %s\" % review)\n",
    "    print(\"Pred_summary: %s\" % pred_summary)\n",
    "    print(\"Gold_summary:%s\" % summary)\n",
    "    print('-----'*10, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_file_512/model.ckpt-40000\n",
      "Inputs: \n",
      "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.\n",
      "Outputs: ...........................................................................................................\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "DATA_LOC = './data' \n",
    "t2t_problem = problems.problem('onlinereview')\n",
    "vocab_name = \"./data/vocab.onlinereview.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_512/\") #model.ckpt\n",
    "print(ckpt_path)\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "\n",
    "inputs = '''\n",
    "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.'''\n",
    "# inputs = '''\n",
    "# happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.\n",
      "Outputs: ...........................................................................................................\n"
     ]
    }
   ],
   "source": [
    "inputs = '''\n",
    "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.'''\n",
    "# inputs = '''\n",
    "# happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f323da502e8>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_keep_checkpoint_max': 20, '_num_ps_replicas': 0, '_train_distribute': None, '_master': '', '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, 't2t_device_info': {'num_async_replicas': 1}, '_log_step_count_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f323da505f8>, '_tf_random_seed': None, '_model_dir': 'model_file_512', '_is_chief': True, '_save_checkpoints_steps': 1000, '_protocol': None, 'use_tpu': False, '_evaluation_master': '', '_task_type': None, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f32ca784d08>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">unfortunately this skirts elastic is not stretchy enough to accommodate the 29 yr old range., this is crazy!!  i would say it only stretches through about 1 size..  i would throw this in a costume play chest with a safety pin handy and call it a day\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_file_512/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"size\"\tScore:-5.504393\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\".\"\tScore:-5.930940\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">q\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_512\") #model.ckpt\n",
    "\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n",
    "\n",
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overload_eval_metric_name': '', 'summarize_grads': False, 'compress_steps': 0, 'learning_rate_decay_rate': 1.0, 'split_to_length': 0, 'max_input_seq_length': 0, 'clip_grad_norm': 0.0, 'video_num_target_frames': 1, 'tpu_enable_host_call': False, 'optimizer_adafactor_memory_exponent': 0.8, 'eval_drop_long_sequences': False, 'parameter_attention_value_channels': 0, 'heads_share_relative_embedding': False, 'use_fixed_batch_size': False, 'optimizer_zero_grads': False, 'sampling_temp': 1.0, 'multiproblem_per_task_threshold': '', 'scheduled_sampling_warmup_steps': 50000, 'proximity_bias': False, 'factored_logits': False, 'parameter_attention_key_channels': 0, 'multiproblem_max_input_length': -1, 'learning_rate_minimum': None, 'moe_loss_coef': 0.001, 'kernel_width': 1, 'pos': 'timing', 'relu_dropout_broadcast_dims': '', 'num_hidden_layers': 6, 'layer_postprocess_sequence': 'da', 'use_pad_remover': True, 'attention_value_channels': 0, 'max_target_seq_length': 0, 'vocab_divisor': 1, 'multiproblem_schedule_threshold': 0.5, 'initializer': 'uniform_unit_scaling', 'learning_rate_constant': 2.0, 'layer_prepostprocess_dropout_broadcast_dims': '', 'num_decoder_layers': 0, 'multiproblem_max_target_length': -1, 'grad_noise_scale': 0.0, 'optimizer_momentum_nesterov': False, 'optimizer_adafactor_beta2': 0.999, 'layer_prepostprocess_dropout': 0.1, 'conv_first_kernel': 3, 'sampling_method': 'argmax', 'moe_hidden_sizes': '2048', 'moe_k': 2, 'num_heads': 8, 'pad_batch': False, 'max_relative_position': 0, 'num_encoder_layers': 0, 'relu_dropout': 0.1, 'optimizer_adam_epsilon': 1e-09, 'force_full_predict': False, 'max_length': 512, 'multiproblem_label_weight': 0.5, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'weight_noise': 0.0, 'min_length': 0, 'add_relative_to_values': False, 'learning_rate_schedule': 'constant*linear_warmup*rsqrt_decay*rsqrt_hidden_size', 'hidden_size': 512, 'warm_start_from_second': '', 'moe_overhead_eval': 2.0, 'multiproblem_schedule_max_examples': 10000000.0, 'use_target_space_embedding': True, 'learning_rate': 0.05, 'attention_dropout_broadcast_dims': '', 'norm_epsilon': 1e-06, 'attention_variables_3d': False, 'label_smoothing': 0.1, 'daisy_chain_variables': True, 'shared_embedding': False, 'unidirectional_encoder': False, 'multiproblem_fixed_train_length': -1, 'optimizer_adam_beta2': 0.997, 'modality': {}, 'learning_rate_decay_staircase': False, 'min_length_bucket': 8, 'optimizer_multistep_accumulate_steps': None, 'optimizer_adafactor_factored': True, 'mlperf_mode': False, 'multiply_embedding_mode': 'sqrt_depth', 'symbol_modality_skip_top': False, 'learning_rate_decay_steps': 5000, 'multiproblem_target_eval_only': False, 'dropout': 0.1, 'video_num_input_frames': 1, 'self_attention_type': 'dot_product', 'summarize_vars': False, 'learning_rate_decay_scheme': 'noam', 'optimizer_adafactor_clipping_threshold': 1.0, 'learning_rate_cosine_cycle_steps': 250000, 'scheduled_sampling_prob': 0.0, 'optimizer_adafactor_decay_type': 'pow', 'multiproblem_vocab_size': -1, 'optimizer_adafactor_beta1': 0.0, 'activation_dtype': 'float32', 'filter_size': 2048, 'causal_decoder_self_attention': True, 'attention_key_channels': 0, 'length_bucket_step': 1.1, 'optimizer_adam_beta1': 0.9, 'batch_size': 2048, 'eval_run_autoregressive': False, 'prepend_mode': 'none', 'pretrained_model_dir': '', 'moe_overhead_train': 1.0, 'multiproblem_reweight_label_loss': False, 'symbol_dropout': 0.0, 'learning_rate_warmup_steps': 8000, 'optimizer': 'Adam', 'moe_num_experts': 16, 'kernel_height': 3, 'optimizer_momentum_momentum': 0.9, 'multiproblem_mixing_schedule': 'constant', 'initializer_gain': 1.0, 'scheduled_sampling_gold_mixin_prob': 0.5, 'shared_embedding_and_softmax_weights': True, 'nbr_decoder_problems': 1, 'symbol_modality_num_shards': 16, 'no_data_parallelism': False, 'weight_decay': 0.0, 'batch_shuffle_size': 512, 'attention_dropout': 0.1, 'weight_dtype': 'float32', 'layer_preprocess_sequence': 'n', 'ffn_layer': 'dense_relu_dense', 'norm_type': 'layer'}\n",
      "{'border_percent': 2, 'decode_in_memory': False, 'identity_output': False, 'return_beams': True, 'mlperf_success': False, 'multiproblem_task_id': -1, 'force_decode_length': False, 'delimiter': '\\n', 'vgg_ckpt_path': '', 'max_display_outputs': 10, 'shard_id': 0, 'num_samples': -1, 'skip_eos_postprocess': False, 'batch_size': 0, 'frames_per_second': 10, 'decode_to_file': None, 'guess_and_check_top_k': 0, 'beam_size': 4, 'max_display_decodes': 5, 'block_size': 0, 'extra_length': 100, 'display_decoded_images': False, 'shards_start_offset': 0, 'shard_google_format': False, 'write_beam_scores': False, 'shards': 1, 'max_input_size': -1, 'mlperf_threshold': 25.0, 'decode_timeout_mins': 240, 'log_results': True, 'alpha': 0.6, 'eos_penalty': 0.0, 'mlperf_decode_step': 0.0, 'num_decodes': 1, 'save_images': False, 'guess_and_check_epsilon': -1, 'summaries_log_dir': 'decode'}\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_base512'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_base'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "# hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 2048 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "# hparams.num_encoder_layers = 6\n",
    "hparams.num_hidden_layers = 6\n",
    "# hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.1\n",
    "# hparams.num_heads =16\n",
    "hparams.attention_dropout = 0.1 ##\n",
    "hparams.max_length = 512\n",
    "# hparams.max_input_seq_length = 512\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_train_distribute': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f34fa435b70>, '_save_checkpoints_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f34fa435ba8>, '_num_worker_replicas': 0, '_model_dir': 'model_file_base512', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': 2000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, 't2t_device_info': {'num_async_replicas': 1}, '_is_chief': True, '_evaluation_master': '', '_device_fn': None, '_environment': 'local', '_tf_random_seed': None, '_protocol': None, '_eval_distribute': None, '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_task_id': 0, 'use_tpu': False, '_master': ''}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f34fa6d1d08>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f34fa4359e8>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f34fa435940>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f34fa6d29b0>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f34fa6d29b0>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.668534, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.39006\n",
      "INFO:tensorflow:loss = 7.833201, step = 100 (41.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77496\n",
      "INFO:tensorflow:loss = 7.1196885, step = 200 (36.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8128\n",
      "INFO:tensorflow:loss = 6.24838, step = 300 (35.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82287\n",
      "INFO:tensorflow:loss = 5.849509, step = 400 (35.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76943\n",
      "INFO:tensorflow:loss = 5.8909655, step = 500 (36.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73563\n",
      "INFO:tensorflow:loss = 5.7225013, step = 600 (36.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75887\n",
      "INFO:tensorflow:loss = 5.550065, step = 700 (36.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73938\n",
      "INFO:tensorflow:loss = 5.7753158, step = 800 (36.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80407\n",
      "INFO:tensorflow:loss = 5.4831934, step = 900 (35.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8185\n",
      "INFO:tensorflow:loss = 6.007456, step = 1000 (35.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8035\n",
      "INFO:tensorflow:loss = 5.0054708, step = 1100 (35.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75471\n",
      "INFO:tensorflow:loss = 5.5591846, step = 1200 (36.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79113\n",
      "INFO:tensorflow:loss = 5.7041974, step = 1300 (35.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81116\n",
      "INFO:tensorflow:loss = 6.2894917, step = 1400 (35.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74676\n",
      "INFO:tensorflow:loss = 4.7149725, step = 1500 (36.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76412\n",
      "INFO:tensorflow:loss = 5.5632987, step = 1600 (36.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75449\n",
      "INFO:tensorflow:loss = 5.2632036, step = 1700 (36.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68361\n",
      "INFO:tensorflow:loss = 5.572054, step = 1800 (37.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78971\n",
      "INFO:tensorflow:loss = 5.146169, step = 1900 (35.845 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.27343\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:235: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T02:33:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-02:35:25\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.139378, metrics-onlinereview/targets/accuracy = 0.15303273, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3176453, metrics-onlinereview/targets/approx_bleu_score = 0.012483946, metrics-onlinereview/targets/neg_log_perplexity = -6.0743055, metrics-onlinereview/targets/rouge_2_fscore = 0.01707468, metrics-onlinereview/targets/rouge_L_fscore = 0.14350758\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_base512/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.01707468, metrics-onlinereview/targets/neg_log_perplexity = -6.0743055, metrics-onlinereview/targets/accuracy = 0.15303273, metrics-onlinereview/targets/accuracy_top5 = 0.3176453, metrics-onlinereview/targets/rouge_L_fscore = 0.14350758, global_step = 2000, metrics-onlinereview/targets/approx_bleu_score = 0.012483946, loss = 6.139378\n",
      "INFO:tensorflow:loss = 5.498241, step = 2000 (140.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.7564\n",
      "INFO:tensorflow:loss = 4.897821, step = 2100 (36.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81262\n",
      "INFO:tensorflow:loss = 5.2285237, step = 2200 (35.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72666\n",
      "INFO:tensorflow:loss = 5.790504, step = 2300 (36.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7722\n",
      "INFO:tensorflow:loss = 5.4522367, step = 2400 (36.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76594\n",
      "INFO:tensorflow:loss = 4.6883454, step = 2500 (36.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75227\n",
      "INFO:tensorflow:loss = 4.8758574, step = 2600 (36.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76519\n",
      "INFO:tensorflow:loss = 5.709551, step = 2700 (36.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79942\n",
      "INFO:tensorflow:loss = 5.989872, step = 2800 (35.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78399\n",
      "INFO:tensorflow:loss = 5.1593165, step = 2900 (35.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78674\n",
      "INFO:tensorflow:loss = 5.6219525, step = 3000 (35.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75759\n",
      "INFO:tensorflow:loss = 4.767274, step = 3100 (36.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74672\n",
      "INFO:tensorflow:loss = 5.6498694, step = 3200 (36.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75125\n",
      "INFO:tensorflow:loss = 4.903107, step = 3300 (36.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74965\n",
      "INFO:tensorflow:loss = 5.1374545, step = 3400 (36.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72819\n",
      "INFO:tensorflow:loss = 4.8112087, step = 3500 (36.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73579\n",
      "INFO:tensorflow:loss = 4.886846, step = 3600 (36.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80363\n",
      "INFO:tensorflow:loss = 6.0869226, step = 3700 (35.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77228\n",
      "INFO:tensorflow:loss = 4.959165, step = 3800 (36.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73671\n",
      "INFO:tensorflow:loss = 5.460257, step = 3900 (36.539 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26581\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T02:47:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-02:49:06\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 5.8629603, metrics-onlinereview/targets/accuracy = 0.17444241, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3448263, metrics-onlinereview/targets/approx_bleu_score = 0.015531702, metrics-onlinereview/targets/neg_log_perplexity = -5.793319, metrics-onlinereview/targets/rouge_2_fscore = 0.024802653, metrics-onlinereview/targets/rouge_L_fscore = 0.16988102\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_base512/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.024802653, metrics-onlinereview/targets/neg_log_perplexity = -5.793319, metrics-onlinereview/targets/accuracy = 0.17444241, metrics-onlinereview/targets/accuracy_top5 = 0.3448263, metrics-onlinereview/targets/rouge_L_fscore = 0.16988102, global_step = 4000, metrics-onlinereview/targets/approx_bleu_score = 0.015531702, loss = 5.8629603\n",
      "INFO:tensorflow:loss = 4.568301, step = 4000 (134.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.792549\n",
      "INFO:tensorflow:loss = 4.623152, step = 4100 (36.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78022\n",
      "INFO:tensorflow:loss = 6.133462, step = 4200 (35.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74133\n",
      "INFO:tensorflow:loss = 5.1831985, step = 4300 (36.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70984\n",
      "INFO:tensorflow:loss = 5.2052183, step = 4400 (36.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71361\n",
      "INFO:tensorflow:loss = 4.474229, step = 4500 (36.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76731\n",
      "INFO:tensorflow:loss = 4.932763, step = 4600 (36.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75341\n",
      "INFO:tensorflow:loss = 5.2339478, step = 4700 (36.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80048\n",
      "INFO:tensorflow:loss = 5.487855, step = 4800 (35.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74217\n",
      "INFO:tensorflow:loss = 5.0896115, step = 4900 (36.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81612\n",
      "INFO:tensorflow:loss = 4.802202, step = 5000 (35.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74616\n",
      "INFO:tensorflow:loss = 4.844097, step = 5100 (36.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71648\n",
      "INFO:tensorflow:loss = 4.592871, step = 5200 (36.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81552\n",
      "INFO:tensorflow:loss = 4.662302, step = 5300 (35.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76385\n",
      "INFO:tensorflow:loss = 4.7928386, step = 5400 (36.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75418\n",
      "INFO:tensorflow:loss = 4.2413936, step = 5500 (36.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74442\n",
      "INFO:tensorflow:loss = 5.7242923, step = 5600 (36.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78439\n",
      "INFO:tensorflow:loss = 4.807164, step = 5700 (35.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74273\n",
      "INFO:tensorflow:loss = 5.4502378, step = 5800 (36.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69353\n",
      "INFO:tensorflow:loss = 4.982812, step = 5900 (37.126 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26017\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T03:01:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-03:02:49\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 5.710669, metrics-onlinereview/targets/accuracy = 0.18505418, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.35912424, metrics-onlinereview/targets/approx_bleu_score = 0.01618113, metrics-onlinereview/targets/neg_log_perplexity = -5.6421447, metrics-onlinereview/targets/rouge_2_fscore = 0.02539896, metrics-onlinereview/targets/rouge_L_fscore = 0.17354101\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_base512/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.02539896, metrics-onlinereview/targets/neg_log_perplexity = -5.6421447, metrics-onlinereview/targets/accuracy = 0.18505418, metrics-onlinereview/targets/accuracy_top5 = 0.35912424, metrics-onlinereview/targets/rouge_L_fscore = 0.17354101, global_step = 6000, metrics-onlinereview/targets/approx_bleu_score = 0.01618113, loss = 5.710669\n",
      "INFO:tensorflow:loss = 4.861722, step = 6000 (133.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.800013\n",
      "INFO:tensorflow:loss = 5.3285213, step = 6100 (35.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77047\n",
      "INFO:tensorflow:loss = 5.112071, step = 6200 (36.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77767\n",
      "INFO:tensorflow:loss = 4.8324375, step = 6300 (36.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74281\n",
      "INFO:tensorflow:loss = 4.436623, step = 6400 (36.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75334\n",
      "INFO:tensorflow:loss = 4.770795, step = 6500 (36.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.777\n",
      "INFO:tensorflow:loss = 5.262529, step = 6600 (36.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71253\n",
      "INFO:tensorflow:loss = 4.6759496, step = 6700 (36.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79801\n",
      "INFO:tensorflow:loss = 5.6421843, step = 6800 (35.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77548\n",
      "INFO:tensorflow:loss = 4.5623307, step = 6900 (36.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77043\n",
      "INFO:tensorflow:loss = 6.128767, step = 7000 (36.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73747\n",
      "INFO:tensorflow:loss = 5.1315346, step = 7100 (36.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73528\n",
      "INFO:tensorflow:loss = 5.670977, step = 7200 (36.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77103\n",
      "INFO:tensorflow:loss = 5.306435, step = 7300 (36.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73328\n",
      "INFO:tensorflow:loss = 4.9476833, step = 7400 (36.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75951\n",
      "INFO:tensorflow:loss = 4.9249773, step = 7500 (36.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79733\n",
      "INFO:tensorflow:loss = 4.951039, step = 7600 (35.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77682\n",
      "INFO:tensorflow:loss = 5.3411746, step = 7700 (36.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7347\n",
      "INFO:tensorflow:loss = 4.3489947, step = 7800 (36.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79567\n",
      "INFO:tensorflow:loss = 4.441148, step = 7900 (35.769 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.19626\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T03:15:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-03:16:29\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 5.681333, metrics-onlinereview/targets/accuracy = 0.18672971, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3617679, metrics-onlinereview/targets/approx_bleu_score = 0.016398126, metrics-onlinereview/targets/neg_log_perplexity = -5.619781, metrics-onlinereview/targets/rouge_2_fscore = 0.027045362, metrics-onlinereview/targets/rouge_L_fscore = 0.17465292\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_file_base512/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.027045362, metrics-onlinereview/targets/neg_log_perplexity = -5.619781, metrics-onlinereview/targets/accuracy = 0.18672971, metrics-onlinereview/targets/accuracy_top5 = 0.3617679, metrics-onlinereview/targets/rouge_L_fscore = 0.17465292, global_step = 8000, metrics-onlinereview/targets/approx_bleu_score = 0.016398126, loss = 5.681333\n",
      "INFO:tensorflow:loss = 4.2720613, step = 8000 (132.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.807442\n",
      "INFO:tensorflow:loss = 4.719175, step = 8100 (36.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71644\n",
      "INFO:tensorflow:loss = 4.374146, step = 8200 (36.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83714\n",
      "INFO:tensorflow:loss = 4.4112906, step = 8300 (35.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73779\n",
      "INFO:tensorflow:loss = 4.409781, step = 8400 (36.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74379\n",
      "INFO:tensorflow:loss = 4.8005505, step = 8500 (36.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78315\n",
      "INFO:tensorflow:loss = 5.401048, step = 8600 (35.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76657\n",
      "INFO:tensorflow:loss = 5.177061, step = 8700 (36.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72716\n",
      "INFO:tensorflow:loss = 4.5511, step = 8800 (36.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80971\n",
      "INFO:tensorflow:loss = 5.140165, step = 8900 (35.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70577\n",
      "INFO:tensorflow:loss = 5.9929614, step = 9000 (36.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76575\n",
      "INFO:tensorflow:loss = 4.9300213, step = 9100 (36.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7886\n",
      "INFO:tensorflow:loss = 4.9412065, step = 9200 (35.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77173\n",
      "INFO:tensorflow:loss = 3.8770409, step = 9300 (36.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75809\n",
      "INFO:tensorflow:loss = 4.821394, step = 9400 (36.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77009\n",
      "INFO:tensorflow:loss = 4.350798, step = 9500 (36.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78917\n",
      "INFO:tensorflow:loss = 4.8609457, step = 9600 (35.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74498\n",
      "INFO:tensorflow:loss = 4.6357903, step = 9700 (36.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74079\n",
      "INFO:tensorflow:loss = 5.213681, step = 9800 (36.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74777\n",
      "INFO:tensorflow:loss = 4.792222, step = 9900 (36.393 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.27081\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T03:28:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-03:30:15\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 5.6588836, metrics-onlinereview/targets/accuracy = 0.18825632, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3613583, metrics-onlinereview/targets/approx_bleu_score = 0.01613223, metrics-onlinereview/targets/neg_log_perplexity = -5.5937834, metrics-onlinereview/targets/rouge_2_fscore = 0.026527336, metrics-onlinereview/targets/rouge_L_fscore = 0.17123574\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_file_base512/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.026527336, metrics-onlinereview/targets/neg_log_perplexity = -5.5937834, metrics-onlinereview/targets/accuracy = 0.18825632, metrics-onlinereview/targets/accuracy_top5 = 0.3613583, metrics-onlinereview/targets/rouge_L_fscore = 0.17123574, global_step = 10000, metrics-onlinereview/targets/approx_bleu_score = 0.01613223, loss = 5.6588836\n",
      "INFO:tensorflow:loss = 5.96848, step = 10000 (137.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.772238\n",
      "INFO:tensorflow:loss = 5.6324105, step = 10100 (36.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74106\n",
      "INFO:tensorflow:loss = 4.644046, step = 10200 (36.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71608\n",
      "INFO:tensorflow:loss = 4.9932656, step = 10300 (36.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75448\n",
      "INFO:tensorflow:loss = 4.996547, step = 10400 (36.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73638\n",
      "INFO:tensorflow:loss = 4.829054, step = 10500 (36.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79384\n",
      "INFO:tensorflow:loss = 4.544895, step = 10600 (35.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79001\n",
      "INFO:tensorflow:loss = 4.646449, step = 10700 (35.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77516\n",
      "INFO:tensorflow:loss = 4.2847924, step = 10800 (36.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70066\n",
      "INFO:tensorflow:loss = 4.6257405, step = 10900 (37.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75596\n",
      "INFO:tensorflow:loss = 5.010505, step = 11000 (36.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79317\n",
      "INFO:tensorflow:loss = 5.838736, step = 11100 (35.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78419\n",
      "INFO:tensorflow:loss = 4.497185, step = 11200 (35.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79421\n",
      "INFO:tensorflow:loss = 5.3079753, step = 11300 (35.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81796\n",
      "INFO:tensorflow:loss = 4.7571597, step = 11400 (35.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77158\n",
      "INFO:tensorflow:loss = 4.1894426, step = 11500 (36.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.66721\n",
      "INFO:tensorflow:loss = 4.259307, step = 11600 (37.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80253\n",
      "INFO:tensorflow:loss = 4.956692, step = 11700 (35.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80474\n",
      "INFO:tensorflow:loss = 5.051812, step = 11800 (35.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75649\n",
      "INFO:tensorflow:loss = 5.0452456, step = 11900 (36.278 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20964\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T03:42:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-03:43:59\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 5.6026583, metrics-onlinereview/targets/accuracy = 0.19060208, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3701456, metrics-onlinereview/targets/approx_bleu_score = 0.017302891, metrics-onlinereview/targets/neg_log_perplexity = -5.5357275, metrics-onlinereview/targets/rouge_2_fscore = 0.027988415, metrics-onlinereview/targets/rouge_L_fscore = 0.17925219\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_file_base512/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.027988415, metrics-onlinereview/targets/neg_log_perplexity = -5.5357275, metrics-onlinereview/targets/accuracy = 0.19060208, metrics-onlinereview/targets/accuracy_top5 = 0.3701456, metrics-onlinereview/targets/rouge_L_fscore = 0.17925219, global_step = 12000, metrics-onlinereview/targets/approx_bleu_score = 0.017302891, loss = 5.6026583\n",
      "INFO:tensorflow:loss = 5.002572, step = 12000 (136.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.789692\n",
      "INFO:tensorflow:loss = 5.1597457, step = 12100 (35.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77768\n",
      "INFO:tensorflow:loss = 4.9473042, step = 12200 (36.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.65869\n",
      "INFO:tensorflow:loss = 4.221984, step = 12300 (37.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70252\n",
      "INFO:tensorflow:loss = 4.8436866, step = 12400 (37.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78937\n",
      "INFO:tensorflow:loss = 4.4299984, step = 12500 (35.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73208\n",
      "INFO:tensorflow:loss = 4.8654165, step = 12600 (36.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75173\n",
      "INFO:tensorflow:loss = 5.9992695, step = 12700 (36.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74855\n",
      "INFO:tensorflow:loss = 4.1515493, step = 12800 (36.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77072\n",
      "INFO:tensorflow:loss = 4.2518973, step = 12900 (36.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76754\n",
      "INFO:tensorflow:loss = 5.3345675, step = 13000 (36.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81468\n",
      "INFO:tensorflow:loss = 5.16833, step = 13100 (35.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78286\n",
      "INFO:tensorflow:loss = 6.093575, step = 13200 (35.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72639\n",
      "INFO:tensorflow:loss = 5.0713997, step = 13300 (36.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76234\n",
      "INFO:tensorflow:loss = 4.644578, step = 13400 (36.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81419\n",
      "INFO:tensorflow:loss = 4.5278716, step = 13500 (35.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72786\n",
      "INFO:tensorflow:loss = 4.879728, step = 13600 (36.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73386\n",
      "INFO:tensorflow:loss = 5.2481575, step = 13700 (36.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75883\n",
      "INFO:tensorflow:loss = 4.6630273, step = 13800 (36.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8114\n",
      "INFO:tensorflow:loss = 5.3449874, step = 13900 (35.569 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26623\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T03:56:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-03:57:45\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 5.600187, metrics-onlinereview/targets/accuracy = 0.18989463, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3692892, metrics-onlinereview/targets/approx_bleu_score = 0.017479971, metrics-onlinereview/targets/neg_log_perplexity = -5.538343, metrics-onlinereview/targets/rouge_2_fscore = 0.027969144, metrics-onlinereview/targets/rouge_L_fscore = 0.18106726\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_file_base512/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.027969144, metrics-onlinereview/targets/neg_log_perplexity = -5.538343, metrics-onlinereview/targets/accuracy = 0.18989463, metrics-onlinereview/targets/accuracy_top5 = 0.3692892, metrics-onlinereview/targets/rouge_L_fscore = 0.18106726, global_step = 14000, metrics-onlinereview/targets/approx_bleu_score = 0.017479971, loss = 5.600187\n",
      "INFO:tensorflow:loss = 4.569345, step = 14000 (137.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.776796\n",
      "INFO:tensorflow:loss = 4.5901656, step = 14100 (35.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77811\n",
      "INFO:tensorflow:loss = 4.429108, step = 14200 (35.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7249\n",
      "INFO:tensorflow:loss = 5.071658, step = 14300 (36.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7566\n",
      "INFO:tensorflow:loss = 4.8784027, step = 14400 (36.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72293\n",
      "INFO:tensorflow:loss = 4.4501014, step = 14500 (36.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77211\n",
      "INFO:tensorflow:loss = 5.1902585, step = 14600 (36.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72735\n",
      "INFO:tensorflow:loss = 5.252724, step = 14700 (36.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76355\n",
      "INFO:tensorflow:loss = 4.499196, step = 14800 (36.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78754\n",
      "INFO:tensorflow:loss = 5.741953, step = 14900 (35.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.6874\n",
      "INFO:tensorflow:loss = 5.04773, step = 15000 (37.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79359\n",
      "INFO:tensorflow:loss = 4.819371, step = 15100 (35.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75752\n",
      "INFO:tensorflow:loss = 4.5884786, step = 15200 (36.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74733\n",
      "INFO:tensorflow:loss = 4.853619, step = 15300 (36.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78679\n",
      "INFO:tensorflow:loss = 5.7734604, step = 15400 (35.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77611\n",
      "INFO:tensorflow:loss = 4.88663, step = 15500 (36.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75018\n",
      "INFO:tensorflow:loss = 4.7042336, step = 15600 (36.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79657\n",
      "INFO:tensorflow:loss = 5.09759, step = 15700 (35.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75281\n",
      "INFO:tensorflow:loss = 4.661079, step = 15800 (36.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77369\n",
      "INFO:tensorflow:loss = 4.7361093, step = 15900 (36.054 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23893\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T04:10:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-04:11:29\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 5.602531, metrics-onlinereview/targets/accuracy = 0.19000633, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.36954984, metrics-onlinereview/targets/approx_bleu_score = 0.017813014, metrics-onlinereview/targets/neg_log_perplexity = -5.5346947, metrics-onlinereview/targets/rouge_2_fscore = 0.027697314, metrics-onlinereview/targets/rouge_L_fscore = 0.17893401\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_file_base512/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.027697314, metrics-onlinereview/targets/neg_log_perplexity = -5.5346947, metrics-onlinereview/targets/accuracy = 0.19000633, metrics-onlinereview/targets/accuracy_top5 = 0.36954984, metrics-onlinereview/targets/rouge_L_fscore = 0.17893401, global_step = 16000, metrics-onlinereview/targets/approx_bleu_score = 0.017813014, loss = 5.602531\n",
      "INFO:tensorflow:loss = 4.7159123, step = 16000 (135.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.790718\n",
      "INFO:tensorflow:loss = 5.143986, step = 16100 (35.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79475\n",
      "INFO:tensorflow:loss = 4.927797, step = 16200 (35.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81185\n",
      "INFO:tensorflow:loss = 4.5182266, step = 16300 (35.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75405\n",
      "INFO:tensorflow:loss = 4.4972334, step = 16400 (36.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68357\n",
      "INFO:tensorflow:loss = 4.513603, step = 16500 (37.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68625\n",
      "INFO:tensorflow:loss = 4.1095047, step = 16600 (37.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77043\n",
      "INFO:tensorflow:loss = 4.8857555, step = 16700 (36.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77033\n",
      "INFO:tensorflow:loss = 4.9956884, step = 16800 (36.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75791\n",
      "INFO:tensorflow:loss = 5.336637, step = 16900 (36.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75931\n",
      "INFO:tensorflow:loss = 5.264248, step = 17000 (36.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76153\n",
      "INFO:tensorflow:loss = 4.94137, step = 17100 (36.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73259\n",
      "INFO:tensorflow:loss = 4.980322, step = 17200 (36.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8131\n",
      "INFO:tensorflow:loss = 4.670749, step = 17300 (35.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71578\n",
      "INFO:tensorflow:loss = 5.1519423, step = 17400 (36.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79231\n",
      "INFO:tensorflow:loss = 5.057797, step = 17500 (35.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75074\n",
      "INFO:tensorflow:loss = 5.1279054, step = 17600 (36.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72036\n",
      "INFO:tensorflow:loss = 4.773878, step = 17700 (36.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75825\n",
      "INFO:tensorflow:loss = 4.6007957, step = 17800 (36.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7432\n",
      "INFO:tensorflow:loss = 5.5176787, step = 17900 (36.455 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25083\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T04:23:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-04:25:05\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 5.601443, metrics-onlinereview/targets/accuracy = 0.19123507, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37070408, metrics-onlinereview/targets/approx_bleu_score = 0.017328043, metrics-onlinereview/targets/neg_log_perplexity = -5.5316935, metrics-onlinereview/targets/rouge_2_fscore = 0.028053043, metrics-onlinereview/targets/rouge_L_fscore = 0.17631435\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_file_base512/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.028053043, metrics-onlinereview/targets/neg_log_perplexity = -5.5316935, metrics-onlinereview/targets/accuracy = 0.19123507, metrics-onlinereview/targets/accuracy_top5 = 0.37070408, metrics-onlinereview/targets/rouge_L_fscore = 0.17631435, global_step = 18000, metrics-onlinereview/targets/approx_bleu_score = 0.017328043, loss = 5.601443\n",
      "INFO:tensorflow:loss = 4.7112494, step = 18000 (126.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.849456\n",
      "INFO:tensorflow:loss = 4.363704, step = 18100 (35.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74394\n",
      "INFO:tensorflow:loss = 4.7698927, step = 18200 (36.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76901\n",
      "INFO:tensorflow:loss = 4.6734304, step = 18300 (36.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7876\n",
      "INFO:tensorflow:loss = 4.8885345, step = 18400 (35.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7915\n",
      "INFO:tensorflow:loss = 4.8168926, step = 18500 (35.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79484\n",
      "INFO:tensorflow:loss = 4.7120094, step = 18600 (35.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74832\n",
      "INFO:tensorflow:loss = 4.5122504, step = 18700 (36.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73643\n",
      "INFO:tensorflow:loss = 4.855846, step = 18800 (36.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77274\n",
      "INFO:tensorflow:loss = 4.8241982, step = 18900 (36.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7604\n",
      "INFO:tensorflow:loss = 4.887633, step = 19000 (36.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84008\n",
      "INFO:tensorflow:loss = 4.9888616, step = 19100 (35.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73983\n",
      "INFO:tensorflow:loss = 4.7331915, step = 19200 (36.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77156\n",
      "INFO:tensorflow:loss = 4.817922, step = 19300 (36.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76548\n",
      "INFO:tensorflow:loss = 4.774102, step = 19400 (36.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83136\n",
      "INFO:tensorflow:loss = 4.3704443, step = 19500 (35.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74127\n",
      "INFO:tensorflow:loss = 4.5086756, step = 19600 (36.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72631\n",
      "INFO:tensorflow:loss = 4.764079, step = 19700 (36.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83551\n",
      "INFO:tensorflow:loss = 4.4678974, step = 19800 (35.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82129\n",
      "INFO:tensorflow:loss = 4.863263, step = 19900 (35.445 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18537\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T04:37:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-04:38:37\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 5.56109, metrics-onlinereview/targets/accuracy = 0.1945489, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37468815, metrics-onlinereview/targets/approx_bleu_score = 0.017443918, metrics-onlinereview/targets/neg_log_perplexity = -5.49318, metrics-onlinereview/targets/rouge_2_fscore = 0.028862111, metrics-onlinereview/targets/rouge_L_fscore = 0.18455309\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_file_base512/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.028862111, metrics-onlinereview/targets/neg_log_perplexity = -5.49318, metrics-onlinereview/targets/accuracy = 0.1945489, metrics-onlinereview/targets/accuracy_top5 = 0.37468815, metrics-onlinereview/targets/rouge_L_fscore = 0.18455309, global_step = 20000, metrics-onlinereview/targets/approx_bleu_score = 0.017443918, loss = 5.56109\n",
      "INFO:tensorflow:loss = 4.48828, step = 20000 (128.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.845679\n",
      "INFO:tensorflow:loss = 4.1850796, step = 20100 (35.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75818\n",
      "INFO:tensorflow:loss = 5.0226574, step = 20200 (36.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75228\n",
      "INFO:tensorflow:loss = 5.429348, step = 20300 (36.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75824\n",
      "INFO:tensorflow:loss = 5.853878, step = 20400 (36.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76207\n",
      "INFO:tensorflow:loss = 4.940981, step = 20500 (36.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75631\n",
      "INFO:tensorflow:loss = 5.033987, step = 20600 (36.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81326\n",
      "INFO:tensorflow:loss = 4.2790966, step = 20700 (35.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79496\n",
      "INFO:tensorflow:loss = 4.592026, step = 20800 (35.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70498\n",
      "INFO:tensorflow:loss = 5.112173, step = 20900 (36.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77846\n",
      "INFO:tensorflow:loss = 4.7353992, step = 21000 (35.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75861\n",
      "INFO:tensorflow:loss = 4.953588, step = 21100 (36.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78311\n",
      "INFO:tensorflow:loss = 5.8941507, step = 21200 (35.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74608\n",
      "INFO:tensorflow:loss = 4.8657413, step = 21300 (36.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76066\n",
      "INFO:tensorflow:loss = 5.148178, step = 21400 (36.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79579\n",
      "INFO:tensorflow:loss = 5.620042, step = 21500 (35.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76131\n",
      "INFO:tensorflow:loss = 5.5443063, step = 21600 (36.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76462\n",
      "INFO:tensorflow:loss = 4.538785, step = 21700 (36.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80912\n",
      "INFO:tensorflow:loss = 4.737864, step = 21800 (35.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80702\n",
      "INFO:tensorflow:loss = 5.447168, step = 21900 (35.625 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23444\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T04:50:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-04:52:10\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 5.573253, metrics-onlinereview/targets/accuracy = 0.19075102, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37308708, metrics-onlinereview/targets/approx_bleu_score = 0.016640404, metrics-onlinereview/targets/neg_log_perplexity = -5.5001483, metrics-onlinereview/targets/rouge_2_fscore = 0.027933754, metrics-onlinereview/targets/rouge_L_fscore = 0.1779421\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_file_base512/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.027933754, metrics-onlinereview/targets/neg_log_perplexity = -5.5001483, metrics-onlinereview/targets/accuracy = 0.19075102, metrics-onlinereview/targets/accuracy_top5 = 0.37308708, metrics-onlinereview/targets/rouge_L_fscore = 0.1779421, global_step = 22000, metrics-onlinereview/targets/approx_bleu_score = 0.016640404, loss = 5.573253\n",
      "INFO:tensorflow:loss = 4.539836, step = 22000 (127.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.833178\n",
      "INFO:tensorflow:loss = 4.576233, step = 22100 (36.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69813\n",
      "INFO:tensorflow:loss = 5.015773, step = 22200 (37.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75287\n",
      "INFO:tensorflow:loss = 4.7101707, step = 22300 (36.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79464\n",
      "INFO:tensorflow:loss = 5.18616, step = 22400 (35.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75551\n",
      "INFO:tensorflow:loss = 4.331468, step = 22500 (36.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7745\n",
      "INFO:tensorflow:loss = 5.3812847, step = 22600 (36.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75669\n",
      "INFO:tensorflow:loss = 5.1040306, step = 22700 (36.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81378\n",
      "INFO:tensorflow:loss = 4.710356, step = 22800 (35.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77386\n",
      "INFO:tensorflow:loss = 4.8355613, step = 22900 (36.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71005\n",
      "INFO:tensorflow:loss = 4.854834, step = 23000 (36.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80681\n",
      "INFO:tensorflow:loss = 4.371704, step = 23100 (35.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77515\n",
      "INFO:tensorflow:loss = 4.7818823, step = 23200 (36.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76634\n",
      "INFO:tensorflow:loss = 4.6853857, step = 23300 (36.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81504\n",
      "INFO:tensorflow:loss = 4.7013564, step = 23400 (35.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75284\n",
      "INFO:tensorflow:loss = 4.434099, step = 23500 (36.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8077\n",
      "INFO:tensorflow:loss = 4.958705, step = 23600 (35.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78695\n",
      "INFO:tensorflow:loss = 4.6119347, step = 23700 (35.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72517\n",
      "INFO:tensorflow:loss = 4.9698477, step = 23800 (36.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71376\n",
      "INFO:tensorflow:loss = 5.0375385, step = 23900 (36.849 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25887\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T05:04:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-05:05:47\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 5.5489874, metrics-onlinereview/targets/accuracy = 0.19469784, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3764754, metrics-onlinereview/targets/approx_bleu_score = 0.017976185, metrics-onlinereview/targets/neg_log_perplexity = -5.479819, metrics-onlinereview/targets/rouge_2_fscore = 0.029655416, metrics-onlinereview/targets/rouge_L_fscore = 0.18268901\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_file_base512/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.029655416, metrics-onlinereview/targets/neg_log_perplexity = -5.479819, metrics-onlinereview/targets/accuracy = 0.19469784, metrics-onlinereview/targets/accuracy_top5 = 0.3764754, metrics-onlinereview/targets/rouge_L_fscore = 0.18268901, global_step = 24000, metrics-onlinereview/targets/approx_bleu_score = 0.017976185, loss = 5.5489874\n",
      "INFO:tensorflow:loss = 4.6321707, step = 24000 (129.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.826947\n",
      "INFO:tensorflow:loss = 4.373464, step = 24100 (36.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72133\n",
      "INFO:tensorflow:loss = 4.558335, step = 24200 (36.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80565\n",
      "INFO:tensorflow:loss = 5.027339, step = 24300 (35.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72284\n",
      "INFO:tensorflow:loss = 4.6798477, step = 24400 (36.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75055\n",
      "INFO:tensorflow:loss = 4.7997956, step = 24500 (36.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80936\n",
      "INFO:tensorflow:loss = 5.0263953, step = 24600 (35.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83962\n",
      "INFO:tensorflow:loss = 4.791318, step = 24700 (35.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7748\n",
      "INFO:tensorflow:loss = 5.07734, step = 24800 (36.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76333\n",
      "INFO:tensorflow:loss = 5.038454, step = 24900 (36.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77404\n",
      "INFO:tensorflow:loss = 4.642369, step = 25000 (36.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82535\n",
      "INFO:tensorflow:loss = 4.3586183, step = 25100 (35.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78142\n",
      "INFO:tensorflow:loss = 4.6600304, step = 25200 (35.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77438\n",
      "INFO:tensorflow:loss = 4.7417345, step = 25300 (36.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75437\n",
      "INFO:tensorflow:loss = 4.7699947, step = 25400 (36.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75927\n",
      "INFO:tensorflow:loss = 4.6118007, step = 25500 (36.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72516\n",
      "INFO:tensorflow:loss = 4.3277655, step = 25600 (36.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78925\n",
      "INFO:tensorflow:loss = 4.3098392, step = 25700 (35.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81504\n",
      "INFO:tensorflow:loss = 4.847303, step = 25800 (35.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75583\n",
      "INFO:tensorflow:loss = 4.7336054, step = 25900 (36.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26162\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T05:18:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-05:19:21\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 5.522042, metrics-onlinereview/targets/accuracy = 0.19555423, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3798265, metrics-onlinereview/targets/approx_bleu_score = 0.017901642, metrics-onlinereview/targets/neg_log_perplexity = -5.454268, metrics-onlinereview/targets/rouge_2_fscore = 0.029352589, metrics-onlinereview/targets/rouge_L_fscore = 0.18256958\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_file_base512/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.029352589, metrics-onlinereview/targets/neg_log_perplexity = -5.454268, metrics-onlinereview/targets/accuracy = 0.19555423, metrics-onlinereview/targets/accuracy_top5 = 0.3798265, metrics-onlinereview/targets/rouge_L_fscore = 0.18256958, global_step = 26000, metrics-onlinereview/targets/approx_bleu_score = 0.017901642, loss = 5.522042\n",
      "INFO:tensorflow:loss = 4.9679823, step = 26000 (128.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.828968\n",
      "INFO:tensorflow:loss = 5.041181, step = 26100 (35.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74483\n",
      "INFO:tensorflow:loss = 4.9115424, step = 26200 (36.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77022\n",
      "INFO:tensorflow:loss = 5.041258, step = 26300 (36.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80438\n",
      "INFO:tensorflow:loss = 4.6511083, step = 26400 (35.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75988\n",
      "INFO:tensorflow:loss = 4.5299172, step = 26500 (36.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73468\n",
      "INFO:tensorflow:loss = 5.0865684, step = 26600 (36.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77682\n",
      "INFO:tensorflow:loss = 4.7569776, step = 26700 (36.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79819\n",
      "INFO:tensorflow:loss = 4.2013664, step = 26800 (35.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77864\n",
      "INFO:tensorflow:loss = 5.0071893, step = 26900 (35.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72118\n",
      "INFO:tensorflow:loss = 4.72252, step = 27000 (36.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78233\n",
      "INFO:tensorflow:loss = 5.342898, step = 27100 (35.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7563\n",
      "INFO:tensorflow:loss = 4.7489924, step = 27200 (36.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83195\n",
      "INFO:tensorflow:loss = 5.5176816, step = 27300 (35.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70733\n",
      "INFO:tensorflow:loss = 5.3183894, step = 27400 (36.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73959\n",
      "INFO:tensorflow:loss = 5.046487, step = 27500 (36.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73282\n",
      "INFO:tensorflow:loss = 4.9404106, step = 27600 (36.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81692\n",
      "INFO:tensorflow:loss = 4.2264967, step = 27700 (35.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75464\n",
      "INFO:tensorflow:loss = 5.063169, step = 27800 (36.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81363\n",
      "INFO:tensorflow:loss = 4.7764173, step = 27900 (35.542 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.22784\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T05:31:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-05:32:56\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 5.534771, metrics-onlinereview/targets/accuracy = 0.19488402, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37900734, metrics-onlinereview/targets/approx_bleu_score = 0.017229544, metrics-onlinereview/targets/neg_log_perplexity = -5.4677773, metrics-onlinereview/targets/rouge_2_fscore = 0.028327785, metrics-onlinereview/targets/rouge_L_fscore = 0.18088666\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_file_base512/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.028327785, metrics-onlinereview/targets/neg_log_perplexity = -5.4677773, metrics-onlinereview/targets/accuracy = 0.19488402, metrics-onlinereview/targets/accuracy_top5 = 0.37900734, metrics-onlinereview/targets/rouge_L_fscore = 0.18088666, global_step = 28000, metrics-onlinereview/targets/approx_bleu_score = 0.017229544, loss = 5.534771\n",
      "INFO:tensorflow:loss = 4.654585, step = 28000 (128.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.841714\n",
      "INFO:tensorflow:loss = 5.2688303, step = 28100 (35.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74171\n",
      "INFO:tensorflow:loss = 4.146075, step = 28200 (36.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79318\n",
      "INFO:tensorflow:loss = 4.906544, step = 28300 (35.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7962\n",
      "INFO:tensorflow:loss = 4.8156543, step = 28400 (35.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75274\n",
      "INFO:tensorflow:loss = 5.061925, step = 28500 (36.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76653\n",
      "INFO:tensorflow:loss = 4.953492, step = 28600 (36.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76194\n",
      "INFO:tensorflow:loss = 4.4528766, step = 28700 (36.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79622\n",
      "INFO:tensorflow:loss = 4.738792, step = 28800 (35.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77763\n",
      "INFO:tensorflow:loss = 4.8712316, step = 28900 (36.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81796\n",
      "INFO:tensorflow:loss = 5.282029, step = 29000 (35.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73613\n",
      "INFO:tensorflow:loss = 4.7847733, step = 29100 (36.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.778\n",
      "INFO:tensorflow:loss = 4.9423914, step = 29200 (35.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76729\n",
      "INFO:tensorflow:loss = 4.7792645, step = 29300 (36.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71057\n",
      "INFO:tensorflow:loss = 4.4556932, step = 29400 (36.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74203\n",
      "INFO:tensorflow:loss = 5.3505325, step = 29500 (36.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78146\n",
      "INFO:tensorflow:loss = 4.881147, step = 29600 (35.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78013\n",
      "INFO:tensorflow:loss = 4.8952355, step = 29700 (35.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73317\n",
      "INFO:tensorflow:loss = 4.8268933, step = 29800 (36.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78033\n",
      "INFO:tensorflow:loss = 4.8933244, step = 29900 (35.967 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21791\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T05:45:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-05:46:28\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 5.52792, metrics-onlinereview/targets/accuracy = 0.19581488, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3807201, metrics-onlinereview/targets/approx_bleu_score = 0.017834643, metrics-onlinereview/targets/neg_log_perplexity = -5.460936, metrics-onlinereview/targets/rouge_2_fscore = 0.02942467, metrics-onlinereview/targets/rouge_L_fscore = 0.18417524\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_file_base512/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.02942467, metrics-onlinereview/targets/neg_log_perplexity = -5.460936, metrics-onlinereview/targets/accuracy = 0.19581488, metrics-onlinereview/targets/accuracy_top5 = 0.3807201, metrics-onlinereview/targets/rouge_L_fscore = 0.18417524, global_step = 30000, metrics-onlinereview/targets/approx_bleu_score = 0.017834643, loss = 5.52792\n",
      "INFO:tensorflow:loss = 4.3960342, step = 30000 (126.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.851672\n",
      "INFO:tensorflow:loss = 4.2714868, step = 30100 (35.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77004\n",
      "INFO:tensorflow:loss = 4.412603, step = 30200 (36.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75163\n",
      "INFO:tensorflow:loss = 4.7261343, step = 30300 (36.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.65119\n",
      "INFO:tensorflow:loss = 5.66808, step = 30400 (37.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83004\n",
      "INFO:tensorflow:loss = 4.7186956, step = 30500 (35.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82065\n",
      "INFO:tensorflow:loss = 4.7370915, step = 30600 (35.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85296\n",
      "INFO:tensorflow:loss = 4.709075, step = 30700 (35.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73071\n",
      "INFO:tensorflow:loss = 4.9504724, step = 30800 (36.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.741\n",
      "INFO:tensorflow:loss = 5.412496, step = 30900 (36.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76913\n",
      "INFO:tensorflow:loss = 4.705143, step = 31000 (36.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78516\n",
      "INFO:tensorflow:loss = 4.861393, step = 31100 (35.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72156\n",
      "INFO:tensorflow:loss = 5.903889, step = 31200 (36.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.6877\n",
      "INFO:tensorflow:loss = 4.611922, step = 31300 (37.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72075\n",
      "INFO:tensorflow:loss = 4.5499864, step = 31400 (36.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8458\n",
      "INFO:tensorflow:loss = 5.308441, step = 31500 (35.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77656\n",
      "INFO:tensorflow:loss = 5.051724, step = 31600 (36.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71795\n",
      "INFO:tensorflow:loss = 4.692361, step = 31700 (36.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7983\n",
      "INFO:tensorflow:loss = 4.4439845, step = 31800 (35.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79007\n",
      "INFO:tensorflow:loss = 4.8923945, step = 31900 (35.841 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26215\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T05:58:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-06:00:01\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 5.5213428, metrics-onlinereview/targets/accuracy = 0.1980117, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38090628, metrics-onlinereview/targets/approx_bleu_score = 0.01845314, metrics-onlinereview/targets/neg_log_perplexity = -5.453442, metrics-onlinereview/targets/rouge_2_fscore = 0.030231202, metrics-onlinereview/targets/rouge_L_fscore = 0.18387686\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_file_base512/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.030231202, metrics-onlinereview/targets/neg_log_perplexity = -5.453442, metrics-onlinereview/targets/accuracy = 0.1980117, metrics-onlinereview/targets/accuracy_top5 = 0.38090628, metrics-onlinereview/targets/rouge_L_fscore = 0.18387686, global_step = 32000, metrics-onlinereview/targets/approx_bleu_score = 0.01845314, loss = 5.5213428\n",
      "INFO:tensorflow:loss = 4.6608715, step = 32000 (125.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.854507\n",
      "INFO:tensorflow:loss = 4.5095363, step = 32100 (35.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79072\n",
      "INFO:tensorflow:loss = 5.045899, step = 32200 (35.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74842\n",
      "INFO:tensorflow:loss = 4.823258, step = 32300 (36.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79953\n",
      "INFO:tensorflow:loss = 5.0451527, step = 32400 (35.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77095\n",
      "INFO:tensorflow:loss = 4.8372326, step = 32500 (36.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75211\n",
      "INFO:tensorflow:loss = 4.583284, step = 32600 (36.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76545\n",
      "INFO:tensorflow:loss = 4.4105453, step = 32700 (36.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78393\n",
      "INFO:tensorflow:loss = 5.4444246, step = 32800 (35.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74973\n",
      "INFO:tensorflow:loss = 4.8456564, step = 32900 (36.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83045\n",
      "INFO:tensorflow:loss = 4.8639655, step = 33000 (35.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.806\n",
      "INFO:tensorflow:loss = 5.3450756, step = 33100 (35.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78585\n",
      "INFO:tensorflow:loss = 4.974452, step = 33200 (35.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79176\n",
      "INFO:tensorflow:loss = 4.536973, step = 33300 (35.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78134\n",
      "INFO:tensorflow:loss = 4.433925, step = 33400 (35.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79644\n",
      "INFO:tensorflow:loss = 4.666675, step = 33500 (35.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79792\n",
      "INFO:tensorflow:loss = 4.9586215, step = 33600 (35.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7854\n",
      "INFO:tensorflow:loss = 5.3064165, step = 33700 (35.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.6745\n",
      "INFO:tensorflow:loss = 4.667253, step = 33800 (37.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83446\n",
      "INFO:tensorflow:loss = 4.869477, step = 33900 (35.280 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25958\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T06:12:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-06:13:29\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 5.535694, metrics-onlinereview/targets/accuracy = 0.19614998, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37815094, metrics-onlinereview/targets/approx_bleu_score = 0.017655158, metrics-onlinereview/targets/neg_log_perplexity = -5.4656086, metrics-onlinereview/targets/rouge_2_fscore = 0.029242542, metrics-onlinereview/targets/rouge_L_fscore = 0.17955285\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_file_base512/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.029242542, metrics-onlinereview/targets/neg_log_perplexity = -5.4656086, metrics-onlinereview/targets/accuracy = 0.19614998, metrics-onlinereview/targets/accuracy_top5 = 0.37815094, metrics-onlinereview/targets/rouge_L_fscore = 0.17955285, global_step = 34000, metrics-onlinereview/targets/approx_bleu_score = 0.017655158, loss = 5.535694\n",
      "INFO:tensorflow:loss = 4.799318, step = 34000 (125.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.855417\n",
      "INFO:tensorflow:loss = 4.570812, step = 34100 (36.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75332\n",
      "INFO:tensorflow:loss = 4.1501045, step = 34200 (36.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77443\n",
      "INFO:tensorflow:loss = 5.214208, step = 34300 (36.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76763\n",
      "INFO:tensorflow:loss = 4.644946, step = 34400 (36.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79576\n",
      "INFO:tensorflow:loss = 3.8610942, step = 34500 (35.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68348\n",
      "INFO:tensorflow:loss = 4.220734, step = 34600 (37.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72966\n",
      "INFO:tensorflow:loss = 5.824121, step = 34700 (36.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79941\n",
      "INFO:tensorflow:loss = 5.3316884, step = 34800 (35.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73906\n",
      "INFO:tensorflow:loss = 4.608413, step = 34900 (36.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78243\n",
      "INFO:tensorflow:loss = 4.6750765, step = 35000 (35.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73297\n",
      "INFO:tensorflow:loss = 4.7352, step = 35100 (36.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82503\n",
      "INFO:tensorflow:loss = 4.4753494, step = 35200 (35.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7724\n",
      "INFO:tensorflow:loss = 4.640792, step = 35300 (36.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77924\n",
      "INFO:tensorflow:loss = 4.6296754, step = 35400 (35.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75682\n",
      "INFO:tensorflow:loss = 4.7520556, step = 35500 (36.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79674\n",
      "INFO:tensorflow:loss = 4.6467648, step = 35600 (35.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76674\n",
      "INFO:tensorflow:loss = 4.7341137, step = 35700 (36.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81016\n",
      "INFO:tensorflow:loss = 4.606816, step = 35800 (35.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78108\n",
      "INFO:tensorflow:loss = 6.3556876, step = 35900 (35.957 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.22959\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T06:25:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-06:26:59\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 5.498755, metrics-onlinereview/targets/accuracy = 0.19931489, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3831031, metrics-onlinereview/targets/approx_bleu_score = 0.017643785, metrics-onlinereview/targets/neg_log_perplexity = -5.4295163, metrics-onlinereview/targets/rouge_2_fscore = 0.029877927, metrics-onlinereview/targets/rouge_L_fscore = 0.18413788\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_file_base512/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.029877927, metrics-onlinereview/targets/neg_log_perplexity = -5.4295163, metrics-onlinereview/targets/accuracy = 0.19931489, metrics-onlinereview/targets/accuracy_top5 = 0.3831031, metrics-onlinereview/targets/rouge_L_fscore = 0.18413788, global_step = 36000, metrics-onlinereview/targets/approx_bleu_score = 0.017643785, loss = 5.498755\n",
      "INFO:tensorflow:loss = 4.8028526, step = 36000 (123.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.874602\n",
      "INFO:tensorflow:loss = 4.822978, step = 36100 (35.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76563\n",
      "INFO:tensorflow:loss = 4.7702017, step = 36200 (36.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77554\n",
      "INFO:tensorflow:loss = 4.6452293, step = 36300 (36.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82895\n",
      "INFO:tensorflow:loss = 4.823131, step = 36400 (35.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7327\n",
      "INFO:tensorflow:loss = 5.0553503, step = 36500 (36.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80267\n",
      "INFO:tensorflow:loss = 5.456061, step = 36600 (35.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7645\n",
      "INFO:tensorflow:loss = 4.361908, step = 36700 (36.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7828\n",
      "INFO:tensorflow:loss = 4.7333994, step = 36800 (35.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79869\n",
      "INFO:tensorflow:loss = 5.628758, step = 36900 (35.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72947\n",
      "INFO:tensorflow:loss = 5.034029, step = 37000 (36.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75559\n",
      "INFO:tensorflow:loss = 4.3718944, step = 37100 (36.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72589\n",
      "INFO:tensorflow:loss = 4.543514, step = 37200 (36.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76327\n",
      "INFO:tensorflow:loss = 4.6496115, step = 37300 (36.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76347\n",
      "INFO:tensorflow:loss = 4.709428, step = 37400 (36.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79873\n",
      "INFO:tensorflow:loss = 5.582274, step = 37500 (35.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79008\n",
      "INFO:tensorflow:loss = 5.0787783, step = 37600 (35.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71895\n",
      "INFO:tensorflow:loss = 4.685494, step = 37700 (36.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81042\n",
      "INFO:tensorflow:loss = 4.8811164, step = 37800 (35.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7532\n",
      "INFO:tensorflow:loss = 6.2158837, step = 37900 (36.322 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_file_base512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23847\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T06:39:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_base512/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-06:40:30\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 5.4846134, metrics-onlinereview/targets/accuracy = 0.19886808, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38414565, metrics-onlinereview/targets/approx_bleu_score = 0.018626453, metrics-onlinereview/targets/neg_log_perplexity = -5.4134436, metrics-onlinereview/targets/rouge_2_fscore = 0.030604329, metrics-onlinereview/targets/rouge_L_fscore = 0.18426472\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_file_base512/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/rouge_2_fscore = 0.030604329, metrics-onlinereview/targets/neg_log_perplexity = -5.4134436, metrics-onlinereview/targets/accuracy = 0.19886808, metrics-onlinereview/targets/accuracy_top5 = 0.38414565, metrics-onlinereview/targets/rouge_L_fscore = 0.18426472, global_step = 38000, metrics-onlinereview/targets/approx_bleu_score = 0.018626453, loss = 5.4846134\n",
      "INFO:tensorflow:loss = 5.070147, step = 38000 (125.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.855581\n",
      "INFO:tensorflow:loss = 4.609896, step = 38100 (36.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7965\n",
      "INFO:tensorflow:loss = 4.957347, step = 38200 (35.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80022\n",
      "INFO:tensorflow:loss = 4.598413, step = 38300 (35.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7683\n",
      "INFO:tensorflow:loss = 4.424941, step = 38400 (36.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81757\n",
      "INFO:tensorflow:loss = 3.9719224, step = 38500 (35.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78914\n",
      "INFO:tensorflow:loss = 4.537398, step = 38600 (35.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74183\n",
      "INFO:tensorflow:loss = 5.1756825, step = 38700 (36.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75355\n",
      "INFO:tensorflow:loss = 4.4475403, step = 38800 (36.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78742\n",
      "INFO:tensorflow:loss = 4.9683146, step = 38900 (35.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81101\n",
      "INFO:tensorflow:loss = 5.1852865, step = 39000 (35.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74669\n",
      "INFO:tensorflow:loss = 4.941957, step = 39100 (36.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7434\n",
      "INFO:tensorflow:loss = 4.744109, step = 39200 (36.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.67224\n",
      "INFO:tensorflow:loss = 4.4812884, step = 39300 (37.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75122\n",
      "INFO:tensorflow:loss = 4.99928, step = 39400 (36.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77963\n",
      "INFO:tensorflow:loss = 4.469267, step = 39500 (35.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80903\n",
      "INFO:tensorflow:loss = 4.8491817, step = 39600 (35.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79924\n",
      "INFO:tensorflow:loss = 5.6971817, step = 39700 (35.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79154\n",
      "INFO:tensorflow:loss = 4.782617, step = 39800 (35.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74765\n",
      "INFO:tensorflow:loss = 5.393648, step = 39900 (36.395 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_base512/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 4.743437.\n",
      "Time: 16320.77 s\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_base = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40000,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_base.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_train_distribute': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f3279c4c438>, '_save_checkpoints_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f34bd8c3d30>, '_num_worker_replicas': 0, '_model_dir': 'model_file_base512', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, 't2t_device_info': {'num_async_replicas': 1}, '_is_chief': True, '_evaluation_master': '', '_device_fn': None, '_environment': 'local', '_tf_random_seed': None, '_protocol': None, '_eval_distribute': None, '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_task_id': 0, 'use_tpu': False, '_master': ''}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f34bdb25730>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">what is there not to love about the writing of khalil gibran. i finally took the time, and not much is needed, to read the prophet.every page flows seamlessly from one to the other and his narrative writing style is infused with lessons of love, life, and more.this is a book that i will read time and time again. like many other of the greats i keep on my book shelf.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_file_base512/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"a must read for anyone who wants to know about the world\"\tScore:-11.715166\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\"a must read for anyone who want to know about the world\"\tScore:-11.719825\n",
      "INFO:tensorflow:BEAM 2:\n",
      "INFO:tensorflow:\"a must read for anyone who want to know about the world.\"\tScore:-11.859009\n",
      "INFO:tensorflow:BEAM 3:\n",
      "INFO:tensorflow:\"a must read for anyone who wants to know about the world.\"\tScore:-11.884241\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">q\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_base512\") #model.ckpt\n",
    "\n",
    "HPARAMS = 'transformer_base'\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "# hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "# def create_decode_hparams():\n",
    "#     decode_hp = decoding.decode_hparams()\n",
    "#     decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "# #     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "#     decode_in_memory = decode_hp.decode_in_memory\n",
    "#     decode_hp.decode_in_memory = decode_in_memory\n",
    "#     decode_hp.return_beams =True\n",
    "#     decode_hp.beam_size = 2\n",
    "# #     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "# #     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "#     return decode_hp\n",
    "# decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n",
    "\n",
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_file_base512/model.ckpt-40000\n",
      "Inputs: \n",
      "very thorough review of mksap and a great companion to the text book or online, especially if you like to review material in different formats.  there are a lot references to the tables and figures that require you to go back to the book or the online version, so it is definitely not complete. but i like the discussion. too many bad jokes, some are borderline and probably inappropriate, but a few are harmless and amusing. a classmate of mine does a great job with one of the sessions.outputs = summarize(inputs)\n",
      "Outputs: great for the price, but not a great price\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "DATA_LOC = './data' \n",
    "t2t_problem = problems.problem('onlinereview')\n",
    "vocab_name = \"./data/vocab.onlinereview.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_base'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "# hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_base512/\") #model.ckpt\n",
    "print(ckpt_path)\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "\n",
    "# inputs = '''\n",
    "# we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.'''\n",
    "inputs = '''\n",
    "very thorough review of mksap and a great companion to the text book or online, especially if you like to review material in different formats.  there are a lot references to the tables and figures that require you to go back to the book or the online version, so it is definitely not complete. but i like the discussion. too many bad jokes, some are borderline and probably inappropriate, but a few are harmless and amusing. a classmate of mine does a great job with one of the sessions.outputs = summarize(inputs)'''\n",
    "outputs = summarize(inputs)\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- ###########-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "import generate_problem # self-defined 'generate_problem.py' file in the same folder.\n",
    "\n",
    "# define the directory for generated data\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' # Where data files from internet stored\n",
    "DATA_LOC = './data' # Where pre-prcessed data is stored\n",
    "\n",
    "# Generated training data\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada58>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada90>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_master': '', 't2t_device_info': {'num_async_replicas': 1}, '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f585c98e470>, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_num_worker_replicas': 0, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_environment': 'local', '_is_chief': True, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f585c98e668>, '_protocol': None, 'use_tpu': False, '_keep_checkpoint_max': 20, '_evaluation_master': '', '_tf_random_seed': None, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_train_distribute': None, '_task_id': 0, '_model_dir': 'model_files_256', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_steps': 1000, '_task_type': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f585cea8598>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "# t2t_trainer\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n",
    "# BEAM_SIZE=4\n",
    "# ALPHA=0.6\n",
    "\n",
    "# data_dir=DATA_LOC\n",
    "# problem = t2t_problem\n",
    "# model = MODEL\n",
    "# hparams_set = HPARAMS\n",
    "# output_dir = TRAIN_DIR\n",
    "\n",
    "# decode_to_file = 'decode_from_file'\n",
    "#########\n",
    "t2t_problem.get_hparams().was_reversed =False\n",
    "####\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "\n",
    "####\n",
    "# hparams = registry.hparams('transformer_base_single_gpu')\n",
    "# hparams.add_hparam(\"data_dir\", DATA_LOC)\n",
    "# t2t_problem.get_hparams().was_reversed =False\n",
    "# hparams = t2t_problem.get_hparams(hparams)\n",
    "# hparams\n",
    "######\n",
    "\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada58>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f585caada90>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f585ce47710>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f597c0ba2e8>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f597c0ba320>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f599c039e48>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f599c039e48>}), ('was_copy', False), ('was_reversed', True)])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2t_problem.get_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_feature_encoders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-f3287950e6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_feature_encoders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_feature_encoders' is not defined"
     ]
    }
   ],
   "source": [
    "get_feature_encoders(DATA_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'t2t_device_info': {'num_async_replicas': 1}, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, 'use_tpu': False, '_num_worker_replicas': 0, '_device_fn': None, '_train_distribute': None, '_task_id': 0, '_tf_random_seed': None, '_save_checkpoints_secs': None, '_evaluation_master': '', '_model_dir': 'model_files_1024_new', '_task_type': None, '_save_checkpoints_steps': 1000, '_environment': 'local', '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7ff4c7ba6a20>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff4c7ba6cf8>, '_save_summary_steps': 100, '_protocol': None, '_eval_distribute': None, '_log_step_count_steps': 100, '_master': ''}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7ff54a7567b8>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024_new/\") #model.ckpt\n",
    "TRAIN_DIR = 'model_files_1024_new'\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4a18f65fd0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4a18ea4048>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4a19fbd978>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4a19fbd978>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'t2t_device_info': {'num_async_replicas': 1}, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, 'use_tpu': False, '_num_worker_replicas': 0, '_device_fn': None, '_train_distribute': None, '_task_id': 0, '_tf_random_seed': None, '_save_checkpoints_secs': None, '_evaluation_master': '', '_model_dir': 'model_files_full_new', '_task_type': None, '_save_checkpoints_steps': 1000, '_environment': 'local', '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7ff4c7ba6a90>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff4c7ba6a58>, '_save_summary_steps': 100, '_protocol': None, '_eval_distribute': None, '_log_step_count_steps': 100, '_master': ''}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7ff54a756c80>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint(\"model_files_full_new\")\n",
    "ckpt_path #= './model_files_1024/model.ckpt-22000'\n",
    "\n",
    "TRAIN_DIR = 'model_files_full_new'\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HParams' object has no attribute 'problem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f8f638b8fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_interactively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_hp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_interactively\u001b[0;34m(estimator, hparams, decode_hp, checkpoint_path)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0;34m\"\"\"Interactive decoding.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mis_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m   is_text2class = isinstance(hparams.problem,\n\u001b[1;32m    580\u001b[0m                              text_problems.Text2ClassProblem)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HParams' object has no attribute 'problem'"
     ]
    }
   ],
   "source": [
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "review2 = '''\n",
    "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
    "'''\n",
    "s2 = '''\n",
    "happy with purchase even though it came a lot later than expected.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infer'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.estimator.ModeKeys.PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/modalities.py:114: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py:621: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:1037: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "inputs = review2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "model_decoder = registry.model(MODEL)(hparams, Modes.EVAL)\n",
    "\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "encoded_inputs = encode(inputs)\n",
    "with tfe.restore_variables_on_create(ckpt_path):\n",
    "    model_output = model_decoder.infer(encoded_inputs)[\"outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "  \"shard\": decode_hp.shards,\n",
    "  \"dataset_split\": None,\n",
    "  \"max_records\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decoder = registry.model(MODEL)(hparams, Modes.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_input_fn = t2t_problem.make_estimator_input_fn(\n",
    "    tf.estimator.ModeKeys.PREDICT, hparams, dataset_kwargs=dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_input_fn = t2t_problem.make_estimator_input_fn(\n",
    "    Modes.PREDICT, hparams, dataset_kwargs=dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'input_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e77265129b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 checkpoint_path=ckpt_path)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/decoding.py\u001b[0m in \u001b[0;36mdecode_once\u001b[0;34m(estimator, problem_name, hparams, infer_input_fn, decode_hp, decode_to_file, output_dir, log_results, checkpoint_path)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;31m# Get the predictions as an iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   predictions = estimator.predict(infer_input_fn,\n\u001b[0;32m--> 253\u001b[0;31m                                   checkpoint_path=checkpoint_path)\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'input_fn'"
     ]
    }
   ],
   "source": [
    "# infer_input_fn = model_output\n",
    "\n",
    "decoding.decode_once(estimator,\n",
    "                t2t_problem,\n",
    "                hparams,\n",
    "                infer_input_fn,\n",
    "                decode_hp,\n",
    "                decode_to_file,\n",
    "                output_dir,\n",
    "                log_results=True,\n",
    "                checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  Args:\n",
    "    estimator: tf.estimator.Estimator instance. Used to generate encoded\n",
    "      predictions.\n",
    "    problem_name: str. Name of problem.\n",
    "    hparams: HParams instance. HParams for model training.\n",
    "    infer_input_fn: zero-arg function. Input function for estimator.\n",
    "    decode_hp: HParams instance. See decode_hparams() above.\n",
    "    decode_to_file: str. Prefix for filenames. Used to generated filenames to\n",
    "      which decoded predictions are written.\n",
    "    output_dir: str. Output directory. Only used for writing images.\n",
    "    log_results: bool. If False, return encoded predictions without any\n",
    "      further processing.\n",
    "    checkpoint_path: str. Path to load model checkpoint from. If unspecified,\n",
    "      Estimator's default is used.\n",
    "  Returns:\n",
    "    If decode_hp.decode_in_memory is True:\n",
    "      List of dicts, one per example. Values are either numpy arrays or decoded\n",
    "      strings.\n",
    "    If decode_hp.decode_in_memory is False:\n",
    "      An empty list.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fdd24ae2080>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_task_type': None, '_train_distribute': None, '_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", 't2t_device_info': {'num_async_replicas': 1}, '_device_fn': None, '_evaluation_master': '', '_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdd24ae20b8>, '_protocol': None, '_environment': 'local', '_model_dir': 'model_files_256', '_num_worker_replicas': 0, 'use_tpu': False, '_tf_random_seed': None, '_save_checkpoints_steps': 1000, '_task_id': 0, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fdd25abe840>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 9\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64797184\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40001\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into model_files_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/online_revew_project_usyd-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40385_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40385_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40385_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-28T14:02:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_files_256/model.ckpt-40001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-28-14:03:25\n",
      "INFO:tensorflow:Saving dict for global step 40001: global_step = 40001, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89221823, metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91662514, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93793267\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40001: model_files_256/model.ckpt-40001\n",
      "INFO:tensorflow:Validation (step 40002): metrics-online_revew_project_usyd_rev/targets/neg_log_perplexity = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_top5 = 0.0, metrics-online_revew_project_usyd_rev/targets/accuracy_per_sequence = 1.0, metrics-online_revew_project_usyd_rev/targets/accuracy = 0.0, global_step = 40001, metrics-online_revew_project_usyd_rev/targets/approx_bleu_score = 0.89221823, loss = 0.0, metrics-online_revew_project_usyd_rev/targets/rouge_2_fscore = 0.91662514, metrics-online_revew_project_usyd_rev/targets/rouge_L_fscore = 0.93793267\n",
      "INFO:tensorflow:loss = 0.39651114, step = 40001\n",
      "INFO:tensorflow:global_step/sec: 0.873113\n",
      "INFO:tensorflow:loss = 0.42706436, step = 40101 (38.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01556\n",
      "INFO:tensorflow:loss = 0.28093913, step = 40201 (33.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00659\n",
      "INFO:tensorflow:loss = 0.5703713, step = 40301 (33.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00643\n",
      "INFO:tensorflow:loss = 0.524451, step = 40401 (33.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07053\n",
      "INFO:tensorflow:loss = 0.32810357, step = 40501 (32.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03513\n",
      "INFO:tensorflow:loss = 0.55903786, step = 40601 (32.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03153\n",
      "INFO:tensorflow:loss = 0.14611869, step = 40701 (32.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02187\n",
      "INFO:tensorflow:loss = 0.41055575, step = 40801 (33.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04566\n",
      "INFO:tensorflow:loss = 0.38706577, step = 40901 (32.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into model_files_256/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 2.3757\n",
      "INFO:tensorflow:loss = 0.26943615, step = 41001 (42.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00123\n",
      "INFO:tensorflow:loss = 0.42616627, step = 41101 (33.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00059\n",
      "INFO:tensorflow:loss = 0.36144212, step = 41201 (33.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02449\n",
      "INFO:tensorflow:loss = 0.40964493, step = 41301 (33.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02828\n",
      "INFO:tensorflow:loss = 0.28787893, step = 41401 (33.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03015\n",
      "INFO:tensorflow:loss = 0.24273534, step = 41501 (33.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02748\n",
      "INFO:tensorflow:loss = 0.2890115, step = 41601 (33.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.023\n",
      "INFO:tensorflow:loss = 0.60741675, step = 41701 (33.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03995\n",
      "INFO:tensorflow:loss = 0.7905096, step = 41801 (32.894 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b6844955f7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mt2t_model_256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# running time check (running on 1GPU server)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_eval_and_decode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m           hooks=self._train_spec.hooks)\n\u001b[0m\u001b[1;32m    473\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_eval_dir_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m       self._estimator.evaluate(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# select the transformer model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
    "import json\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_256'\n",
    "\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.batch_size = 1024 \n",
    "hparams.learning_rate = 0.2 # default 0.2\n",
    "hparams.num_encoder_layers = 6 # default 0\n",
    "hparams.num_decoder_layers = 6 # default 0\n",
    "hparams.max_input_seq_length = 256\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=MODEL,\n",
    "        problem_name=t2t_problem, #PROBLEM,\n",
    "        data_dir='./data', \n",
    "        train_steps=40001, \n",
    "        eval_steps=200 \n",
    "    )\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_eval_and_decode()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensor2tensor.bin import t2t_decoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS \\\n",
    "  --output_dir=$TRAIN_DIR \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --decode_from_file=$DECODE_FILE \\\n",
    "  --decode_to_file=translation.en\n",
    "\n",
    "def main(argv):\n",
    "    t2t_decoder.main(argv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import generate_problem\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' \n",
    "DATA_LOC = './data' \n",
    "\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) \n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_2014'\n",
    "\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registry.model(MODEL)(hparams, Modes.PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_files_1024/model.ckpt-40001'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWS: \n",
      "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
      "\n",
      "PRED_SUMMARY: read 10; i the the did not get the item i ordered.  when its company they got back with me me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase the has 10;\n",
      "GOLD_SUMMARY: \n",
      "happy with purchase even though it came a lot later than expected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review1 = '''\n",
    "we have many of the old , old issue but the number had depleted there were not enough books to allow us to use them regularly with the additional supply the books will be used more often they are a good old standby for gospel singing\n",
    "'''\n",
    "review2 = '''\n",
    "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
    "'''\n",
    "s2 = '''\n",
    "happy with purchase even though it came a lot later than expected.\n",
    "'''\n",
    "\n",
    "summary = summarize(review2)\n",
    "\n",
    "print(\"REVIEWS: %s\" % review2)\n",
    "print(\"PRED_SUMMARY: %s\" % summary)\n",
    "print(\"GOLD_SUMMARY: %s\" % s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
