{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_v3 Max length variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable TF Eager execution at the beginning  ==> for decoder later\n",
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate t2t data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviews that the summary contains exactly same sentences with review text are dropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Importing user module train from path /tf/jupyter-code/code/t2t_new\n",
      "INFO:tensorflow:Generating problems:\n",
      "    onlinereview:\n",
      "      * onlinereview\n",
      "INFO:tensorflow:Generating data for onlinereview.\n",
      "INFO:tensorflow:Generating vocab file: ./data/vocab.onlinereview.32768.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.12965989112854004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.26036643981933594 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5206942558288574 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9959280490875244 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0407860279083252 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 153103\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [tracklocked] took 0.13071799278259277 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [photodiscoloration] took 0.2608821392059326 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5500085353851318 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 57272\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [keeler9670] took 0.1308445930480957 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [iwouldliketoreviewthelepanupgradeprocedureon] took 0.26286983489990234 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5063157081604004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58117\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [9781589804715successful] took 0.1309354305267334 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [playplaypen] took 0.26076388359069824 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49381351470947266 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 58059\n",
      "INFO:tensorflow:Trying min_count 750\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.1307694911956787 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2609367370605469 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5211169719696045 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9982104301452637 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0427327156066895 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 122366\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [woodorhightemperaturesiliconetools] took 0.1304328441619873 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [mphkph] took 0.260941743850708 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5528564453125 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 45993\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [distressmussomatization] took 0.13041400909423828 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [mg21035sr61035] took 0.2608020305633545 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.48694419860839844 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [emancipationonward] took 0.520841121673584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 46746\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [212fdisplay] took 0.1303555965423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [newcastleupontyne] took 0.26249170303344727 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5042061805725098 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [comwattslfpbav666adaptvalvecompressiondpb004vt4zi4refsr] took 0.520988941192627 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 46687\n",
      "INFO:tensorflow:Trying min_count 875\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13022255897521973 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2608470916748047 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5212345123291016 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9987821578979492 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0432980060577393 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 112348\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [,,,,,,,,,,,, , , , , , . .  . . .  .. . . .  ..  . . . .  .  .. ,, ,...... ...  ,,.. .. .. ..  ,,.. .. .. ..] took 0.13115739822387695 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [depinnedswapped] took 0.2604541778564453 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5630483627319336 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 42333\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [levelground] took 0.13036227226257324 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [otherwisewonderful] took 0.26075005531311035 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49868202209472656 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [p115117consciousness] took 0.521615743637085 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 43036\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [9780471460053] took 0.1301271915435791 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [w1additivity] took 0.2610206604003906 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5148520469665527 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [casualthe] took 0.5203678607940674 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 42970\n",
      "INFO:tensorflow:Trying min_count 938\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13022637367248535 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2607700824737549 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.521214485168457 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 1.002939224243164 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0438389778137207 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 108170\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [ufothemed] took 0.13042712211608887 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [scapinooverture] took 0.26084375381469727 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5715944766998291 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40825\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [p51k] took 0.13043546676635742 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [claimmyth] took 0.26041197776794434 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49933290481567383 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [stirreth] took 0.5210912227630615 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41496\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [systemlogitech] took 0.1303560733795166 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [merciful3542god] took 0.260514497756958 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5221271514892578 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [musicborn] took 0.5209805965423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 41430\n",
      "INFO:tensorflow:Trying min_count 969\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13022446632385254 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.26273083686828613 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5254840850830078 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9970543384552002 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0446727275848389 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 106207\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [differentscenarios] took 0.13006234169006348 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [sd425] took 0.26052260398864746 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5732643604278564 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40130\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [islandstellar] took 0.13069748878479004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [pricesoundutility] took 0.2606673240661621 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49613356590270996 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [infraredplates] took 0.5209789276123047 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40759\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [intercontinentalballisticmissile] took 0.13048815727233887 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [prealgebra] took 0.26034116744995117 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.520545244216919 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [snotnosebrat] took 0.5221157073974609 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40706\n",
      "INFO:tensorflow:Trying min_count 985\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13025546073913574 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2609562873840332 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5216953754425049 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9963455200195312 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0441772937774658 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 105224\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [fantasytechnosciencereligiosity] took 0.13046598434448242 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [clackclackclack] took 0.26054978370666504 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5711402893066406 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39795\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [comjfklbjchapterassassinationassassinationdp0982892004refsr] took 0.13054776191711426 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [goofingoffbeforetheshow] took 0.2604484558105469 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.496990442276001 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [superultrakawaiicutiekoochykoochybooboo] took 0.5207059383392334 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40406\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [0553275194] took 0.1302950382232666 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [40nice] took 0.2604823112487793 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5236611366271973 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [sneakerpumalink] took 0.5206971168518066 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40336\n",
      "INFO:tensorflow:Trying min_count 993\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13019609451293945 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2606379985809326 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5254948139190674 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9951467514038086 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.046219825744629 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104719\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [jordanoverall] took 0.1301441192626953 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [woodclickingtogether] took 0.260317325592041 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5697999000549316 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39626\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [countries04b] took 0.1303555965423584 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [oneononedekes] took 0.26029324531555176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.49656248092651367 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [editiondirty] took 0.520923376083374 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40244\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [carnabeat] took 0.13040637969970703 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [weagreed] took 0.2604660987854004 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5250394344329834 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [lovefurypassionenergy] took 0.5206625461578369 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40181\n",
      "INFO:tensorflow:Trying min_count 997\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13007664680480957 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.26024937629699707 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5207791328430176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9991931915283203 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0439879894256592 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104510\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [decoglow] took 0.13025188446044922 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [ckgauml] took 0.260256290435791 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5711197853088379 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39531\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [loosycounterclockwise] took 0.1303548812866211 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [soloveitchikian] took 0.2607574462890625 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.4952988624572754 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [cleaningvery] took 0.5211200714111328 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40183\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [tebaldibergonziserafin] took 0.13044142723083496 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [chocolatealmondraisin] took 0.2604985237121582 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5235962867736816 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [theirdedication] took 0.5206570625305176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40104\n",
      "INFO:tensorflow:Trying min_count 999\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.1304917335510254 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2608518600463867 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5213892459869385 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9980509281158447 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.0436899662017822 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104395\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [workshoppresented] took 0.130462646484375 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [goodifnotamazing] took 0.26284146308898926 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.584650993347168 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39489\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [morala] took 0.13022804260253906 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [pateresquereflection] took 0.26068902015686035 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5085837841033936 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [coveredrobotsandmonsters] took 0.5210459232330322 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40135\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [np700z5as03us] took 0.13052845001220703 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [kxtg6324] took 0.26131439208984375 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5230984687805176 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [cheapyweepy] took 0.5204038619995117 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40073\n",
      "INFO:tensorflow:Trying min_count 1000\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:Processing token [fountainstill] took 0.13012313842773438 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [compoundit] took 0.2607712745666504 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [realadulthoods] took 0.5216066837310791 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.9996099472045898 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [gvn670oc2gd] took 1.044715404510498 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 104338\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:Processing token [arapeyev] took 0.13038992881774902 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [copbotsquot] took 0.2603592872619629 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5722789764404297 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 39462\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:Processing token [whathappenedtoeverybodyafterleavingschool] took 0.13036608695983887 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [amiacute] took 0.2608222961425781 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.496596097946167 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [generallydirected] took 0.52158522605896 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40121\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:Processing token [adjustmentsintegrates] took 0.1310727596282959 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [0x145a4810] took 0.2605752944946289 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [5871400010058714000101587140001025871400199158714001992587140019935871400299158714002992587140029935871400310058714008001587140080025871400800358714009100587140091015871400910258714012400587140124015871401240258714012403587140124045871401240558714012406a5871401340058714013401587140134025871401340358714013404587140134055871401340658714013407a58714014400587140144015871401440258714014403587140144045871401440558714014406a58714019400587140194015871401940258714019403587140194045871401940558714019406a5871410280058714112400587141124015871411240258714113400587141134015871411340258714114400587141144015871411440258714119400587141194015871411940258714131100587141311015871413110258714132100587141321015871413210258714134100587141341015871413410258714139100587141391015871413910258714143400587141434015871414340258714143403587141434045871414340558714144400587141444015871414440258714144403587141444045871415340058714153401587141534025871415440058714154401587141834005871418340158714183402587141834035871418340458714184400587141844015871418440258714184403587141844045871420220058714209200587142421005871424999158714302200587143022015871430920058714309201587144194005871443220058714432201587144322025871443920058714439201587144392025871453840058714538401587148522005871485320058714854200587148592005871507220058715072201587150732005871507320158715074200587150742015871507920058715079201587151028005871510280158715103800587151038015871510480058715104801587151098005871510980158715132400587151324015871513240258715132403587151394005871513940158715139402587151394035871514240058715142401587151424025871514240358715142404587151424055871514940058715149401587151494025871514940358715149404587151494055871515240058715152401587151574005871515840058715158401587151594005871515940158715162400587151624015871516340058715163401587151634025871516440058715164401587151694005871516940158715173400587151824005871518240158715182402587151824035871518240458715188400587151884015871518840258715188403587151884045871518940058715189401587151894025871518940358715189404587151924005871519240158715192402587151934005871519340158715193402587151944005871519440158715194402587151994005871519940158715199402587152129005871521390058715214900587152199005871523290058715232900a5871523390058715233900a5871523490058715234900a5871523890058715238900a5871523990058715239900a587152427005871524270158715242702587152487005871524870158715248702587152497005871524970158715249702587152524005871525240158715252402587152534005871525340158715253402587152544005871525440158715254402587152594005871525940158715259402587152629005871526390058715264900587152699005871528290058715283900587152849005871528990058715362100a58715363100a58715369100a58715372100a58715373100a58715378100a58715379100a58715382100a58715383100a58715389100a58716072200587160722015871607320058716073201587160742005871607420158716079200587160792015871610280058716102801587161038005871610380158716104800587161048015871610980058716109801587161424005871614240158716142402587161424035871614240458716142405587161494005871614940158716149402587161494035871614940458716149405587161524005871615240158716157400587161584005871615840158716159400587161594015871616240058716162401587161634005871616340158716163402587161644005871616440158716169400587161694015871618240058716182401587161824025871618840058716188401587161884025871618940058716189401587161894025871619240058716192401587161924025871619340058716193401587161934025871619440058716194401587161944025871619940058716199401587161994025871623290058716232900a5871623390058716233900a5871623490058716234900a5871623890058716238900a5871623990058716239900a587162427005871624270158716242702587162487005871624870158716248702587162497005871624970158716249702587162524005871625240158716252402587162534005871625340158716253402587162544005871625440158716254402587162594005871625940158716259402587172421005871724380058717243801587172459915871724840058717248401587172522005871725220158717252202587172592005871725920158717259202587182439005871914240058719142401587191424025871914240358719149400587191494015871914940258719149403bbbd2432kb0bbbd2432kf0bbbd2432kw0bgbd2432kb0bgbd2432kf0bgbd2432kw0cdb400kb0cdb400kb0acdb400kb1bcdb400kw0cdb400kw0acdb400kw1bcdb500cgb0cdb500cgb1cdb500cgb2cdb500cgb3cdb500cgc0cdb500cgc1cdb500cgc2cdb500cgc3cdb500cgs0cdb500cgs1cdb500cgs2cdb500cgs3cdb600kb0cdb600kb0acdb600kb1bcdb600ks0cdb600ks0acdb600ks1bcdb600kw0cdb600kw0acdb600kw1bcdbe241ab0cdbe241aq0cdbe241aw0cdbe566ab0cdbe566ab1cdbe566aq0cdbe566aq1cdbe566as0cdbe566as1cdbe566as2cdbe566aw0dgbd2432kb0dgbd2432kb1dgbd2432kf0dgbd2432kf1dgbd2432kw0dgbd2432kw1f71c12phs1f71c24rjb1fbd2400kb0fbd2400kb2afbd2400kb3afbd2400kb4afbd2400kq0fbd2400kq2afbd2400kq3afbd2400kq4afbd2400ks0afbd2400ks1afbd2400ks2afbd2400kw0fbd2400kw2afbd2400kw3afbd2400kw4afdb101saw0fdb101saw1fdb101saw2fdb101saw3fdb102sdw0fdb1050reb0fdb1050reb1fdb1050reb2fdb1050reb3fdb1050reb4fdb1050reb5fdb1050rec0fdb1050rec1fdb1050rec2fdb1050rec3fdb1050rec4fdb1050rec5fdb1050rem0fdb1050rem1fdb1050rem2fdb1050rem3fdb1050rem4fdb1050rem5fdb1050req0fdb1050req1fdb1050req2fdb1050req3fdb1050req4fdb1050req5fdb1050res0fdb1050res1fdb1050res2fdb1050res3fdb1050res4fdb1050res5fdb1051reb0fdb1051reb1fdb1051reb2fdb1051rem0fdb1051rem1fdb1051rem2fdb1051req0fdb1051req1fdb1051req2fdb1051res0fdb1051res1fdb1051res2fdb10nrbb0fdb10nrbb1fdb10nrbb2fdb1100rhb0fdb1100rhb2fdb1100rhb2afdb1100rhb3afdb1100rhb3bfdb1100rhc0fdb1100rhc2fdb1100rhc2afdb1100rhc3afdb1100rhc3bfdb1100rhm0fdb1100rhm2fdb1100rhm2afdb1100rhm3afdb1100rhm3bfdb1100rhq0fdb1100rhq2fdb1100rhq2afdb1100rhq3afdb1100rhq3bfdb1100rhs0fdb1100rhs2fdb1100rhs2afdb1100rhs3afdb1100rhs3bfdb125rhb1fdb125rhb2fdb125rhb3fdb125rhd2fdb125rhd3fdb125rhs1fdb125rhs2fdb125rhs3fdb125rhu0fdb125rhu1fdb126rbb0fdb126rbb1fdb126rbb2fdb126rbb3fdb126rbb4fdb126rbq0fdb126rbq1fdb126rbq2fdb126rbq3fdb126rbq4fdb126rbs0fdb126rbs1fdb126rbs2fdb126rbs3fdb126rbs4fdb130rgb0fdb130rgb1fdb130rgb2fdb130rgb3fdb130rgq0fdb130rgq1fdb130rgq2fdb130rgq3fdb130rgs0fdb130rgs1fdb130rgs2fdb130rgs3fdb210lcs0fdb2110lcb0fdb2110lcc0fdb2110lcq0fdb2110lcs0fdb2310lcb0fdb2310lcc0fdb2310lcc1fdb2310lcc2fdb2310lcq0fdb2310lcs0fdb2320reb0fdb2320reb1fdb2320reb2fdb2320rec0fdb2320rec1fdb2320rec2fdb2320res0fdb2320res1fdb2320res2fdb2321rec0fdb2321rec1fdb2510lcc0fdb2510lcc1fdb345lbb0fdb345lbb1fdb345lbs0fdb345lbs1fdb345lfr2fdb345lfs2fdb421rfr6fdb421rfr7fdb421rfs6fdb421rfs7fdb421rfs8fdb435rfr6fdb435rfr7fdb435rfs4fdb435rfs5fdb510cfb0fdb510cfb1fdb510cfb2fdb510cfs0fdb510cfs1fdb510cfs2fdb510cgc0fdb510cgc2fdb510lcb0fdb510lcb1fdb510lcb2fdb510lcb3fdb510lcb4fdb510lcb5fdb510lcb6fdb510lcs0fdb510lcs1fdb510lcs2fdb510lcs3fdb510lcs4fdb510lcs5fdb510lcs6fdb520rhb0fdb520rhb2fdb520rhb2afdb520rhb3fdb520rhb3afdb520rhb3bfdb520rhc0afdb520rhc1afdb520rhc1bfdb520rhs0fdb520rhs2fdb520rhs2afdb520rhs3afdb520rhs3bfdb634cfs1fdb634cfs3fdb634cfs4fdb635rbb0fdb635rbb1fdb635rbq0fdb635rbq1fdb635rbs0fdb635rbs1fdb635rfr5fdb635rfr6fdb635rfs5fdb635rfs6fdb641rab0fdb641rab1fdb641rab2fdb641ras0fdb641ras1fdb641ras2fdb641rjb1fdb641rjs1fdb657rjc1fdb658rac0fdb658rac1fdb700bfb0fdb700bfb1fdb700bfb2fdb700bfc0fdb700bfc1fdb700bfc2fdb700bfq0fdb700bfq1fdb700bfq2fdb700bfs0fdb700bfs1fdb700bfs2fdb710lcb0fdb710lcb1fdb710lcc0fdb710lcq0fdb710lcq1fdb710lcs0fdb710lcs1fdb740rcb0fdb740rcs0fdb750rcb0fdb750rcb1fdb750rcc0fdb750rcc1fdb750rcc2fdb750rcq0fdb750rcq1fdb750rcs0fdb750rcs1fdb751scb0fdb751scc0fdb751scc1fdb751scq0fdb751scs0fdb760rem0fdb780rcb0fdb780rcq0fdb780rcs0fdb856rjb1fdb856rjs1fdb856rjt1fdb857rjb1fdb857rjs1fdb946neb0fdb946nec0fdb946neq0fdb946nes0fdb954sdb0fdb954sdc0fdb954sdc1fdb954sdq0fdb954sds0fdb955sdb0fdb955sdc0fdb955sdc1fdb955sdq0fdb955sds0fdb956rbb0fdb956rbc0fdb956rbc1fdb956rbs0fdb989rcb0fdb989rcc0fdb989rcq0fdb989rcs0fdbb240fb0fdbb240fb1fdbb240fb2fdbb240fb3fdbb240fb4fdbb240fb5fdbb240fs0fdbb240fs1fdbb240fs2fdbb240fs3fdbb240fs4fdbb240fs5fdbb840dc0fdbb840dc1fdbb840dc2fdbb944cb0fdbb944cb1fdbb944cb2fdbb944cc0fdbb944cq0fdbb944cq1fdbb944cq2fdbb944cs0fdbb944cs1fdbb944cs2fdbb945dc0fdbb945dc1fdbb945dc2fdbc24bas0fdbc24bas1fdbc24bas2fdbc24bas3fdbc45bab0fdbc45bab1fdbc45bab2fdbc45bas0fdbc45bas1fdbc45bas2fdbc56bab0fdbc56bab1fdbc56bas0fdbc56bas1fdbl955bb0fdbl955bb1fdbl955bq0fdbl955bs0fdbl955bs1fdbl960bb0fdbl960bb1fdbl960bc0fdbl960bq0fdbl960bq1fdbl960bs0fdbl960bs1fdbs956cc0fdp635rbs0fdp635rbs1fdp635rfr4fdp635rfr5fdp641ras0fdp641ras1fdp750rcs0fdp750rcs1fdr252rbb0fdr252rbb1fdr252rbb2fdr252rbs0fdr252rbs1fdr252rbs2fds251rjr0fds252rbs0fds252rbs1fds252rbs2ffbd2403lb0affbd2403lb0bffbd2403lb1bffbd2403lb1cffbd2403ls0bffbd2403ls1bffbd2403ls1cffbd2403lw0affbd2403lw0bffbd2403lw1bffbd2403lw1cffbd2405kb0ffbd2405kb0affbd2405kb1affbd2405kb1bffbd2405ks0ffbd2405ks0affbd2405ks1affbd2405ks1bffbd2405kw0ffbd2405kw0affbd2405kw1affbd2405kw1bffbd2407lb0affbd2407lb0bffbd2407lm0affbd2407lm0bffbd2407lq0affbd2407lq0bffbd2407lq1bffbd2407lq1cffbd2407ls0affbd2407ls0bffbd2407ls1bffbd2407ls1cffbd2407lw0affbd2407lw0bfgbd2431kb0fgbd2431kb1fgbd2431kb1afgbd2431kf0fgbd2431kf1fgbd2431kf1afgbd2431kq0fgbd2431kq1fgbd2431kq1afgbd2431kw0fgbd2431kw1fgbd2431kw1afgbd2431nb0afgbd2431nf0afgbd2431nw0afgbd2432kb0fgbd2432kb1fgbd2432kf0fgbd2432kf1fgbd2432kw0fgbd2432kw1fgbd2451kb0fgbd2451kb1fgbd2451kf0fgbd2451kf1fgbd2451kw0fgbd2451kw1gdb742rjb0gdb742rjb1gdb742rjb2gdb742rjb3gdb742rjs0gdb742rjs1gdb742rjs2gdb742rjs3gdb754rcb0gdb754rcq0gdb754rcs0gdb755rjb0gdb755rjb1gdb755rjb2gdb755rjd0gdb755rjd1gdb755rjd2gdb755rjq0gdb755rjq1gdb755rjs0gdb755rjs1gdb755rjs2gdp635rhr1gdp635rhr2gld2150rcb0gld2150rcb1gld2150rcc0gld2150rcc1gld2150rcq0gld2150rcq1gld2150rcs0gld2150rcs1gld2155rdb0gld2155rdc0gld2155rdc1gld2155rdc2gld2155rdq0gld2155rds0gld2160scb0gld2160scb1gld2160scc0gld2160scc1gld2160scq0gld2160scq1gld2160scs0gld2160scs1gld2161scb0gld2161scb1gld2161scc0gld2161scc1gld2161scq0gld2161scq1gld2161scs0gld2161scs1gld2162rdc0gld2350rcb0gld2350rcb1gld2350rcc0gld2350rcc1gld2350rcq0gld2350rcq1gld2350rcs0gld2350rcs1gld2355rdb0gld2355rdc0gld2355rdc1gld2355rdq0gld2355rds0gld2555ndb0gld2555ndq0gld2555nds0gldb653ab0gldb653ab1gldb653aq0gldb653aq1gldb653aq2gldb653as1gldb756ab1gldb756aq0gldb756aq1gldb756as1gldb953cs0gldb954bb0gldb954bs0gldb954bs1gldb957ab0gldb957ab1gldb957ab2gldb957aq0gldb957aq1gldb957aq2gldb957as0gldb957as1gldb957as2gldb957jb1gldb957js1gldb958ab0gldb958ab1gldb958ab2gldb958aq0gldb958aq1gldb958aq2gldb958as0gldb958as1gldb958as2gldb958jb1gldb958js1gldb958jt1gpdb698jc1gpdb998jc1gsb5712bb0gsb5712bb1gsb5712bc0gsb5712bc1gsb5712bq0gsb5712bq1gsb5712bs0gsb5712bs1gsb5755db0gsb5755dc0gsb5755dq0gsb5755ds0kabd2405ms0akabd2405ms1bkabd2405mw0akabd2405mw1blgbd2431lb0algbd2431lf0algbd2431lf0blgbd2431lq0algbd2431lw0algbd2431nf0blgbd2432lb0algbd2432lf0algbd2432lw0amdb122lbs0mdb122lbs1mdb122rfs2mdb124bas0mdb124bas1mdb124bhs1mdb125rhb1mdb125rhb2mdb125rhb3mdb125rhd1mdb125rhd2mdb125rhd3mdb125rhs1mdb125rhs2mdb125rhs3mdb421rhs2mdb421rhs3mdb421rjb0ngs5712ab0ngs5712ab1ngs5712aq0ngs5712aq1ngs5712as0ngs5712as1pld2560lcc0pld2560lcc1pld2560lcc2pld4555rfc0pld4555rfc1pld4555rfc2pld4555rfc3pldb998ac0pldb998ac1pldb999ac0pldb999cc0plds999cc0tdb210rfb0tdb210rfb1tdb210rfb2tdb210rfb3tdb210rfb4tdb210rfb5tdb210rfb7atdb210rfs0tdb210rfs1tdb210rfs2tdb210rfs3tdb210rfs4tdb210rfs5tdb210rfs7awdb11nrdb0wdb11nrdb1wdb11nrdb2wdb11nrdb3wdb11nrdb4wdb11nrdb5wdb11nrdq0wdb11nrds0wdb11nrds1wdb11nrds2wdb11nrds3wdb11nrds4wdb11nrds5wdb635rbq0wdb635rbs0wdb745reb0wdb745reb1wdb745reb2wdb745res0wdb745res1wdb745res2wdb954mbs0wdb956mbc0wwbd2400hb0wwbd2400hb1awwbd2400hb2awwbd2400hw0wwbd2400hw1awwbd2400hw2a] took 0.5225009918212891 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:Processing token [journeytothemotherland] took 0.5210280418395996 seconds, consider setting Text2TextProblem.max_subtoken_length to a smaller value.\n",
      "INFO:tensorflow:vocab_size = 40055\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n",
      "INFO:tensorflow:Generating case 3000000.\n",
      "INFO:tensorflow:Generating case 3100000.\n",
      "INFO:tensorflow:Generating case 3200000.\n",
      "INFO:tensorflow:Generating case 3300000.\n",
      "INFO:tensorflow:Generating case 3400000.\n",
      "INFO:tensorflow:Generating case 3500000.\n",
      "INFO:tensorflow:Generating case 3600000.\n",
      "INFO:tensorflow:Generated 3637767 Examples\n",
      "INFO:tensorflow:Found vocab file: ./data/vocab.onlinereview.32768.subwords\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n",
      "INFO:tensorflow:Generating case 3000000.\n",
      "INFO:tensorflow:Generating case 3100000.\n",
      "INFO:tensorflow:Generating case 3200000.\n",
      "INFO:tensorflow:Generating case 3300000.\n",
      "INFO:tensorflow:Generating case 3400000.\n",
      "INFO:tensorflow:Generating case 3500000.\n",
      "INFO:tensorflow:Generating case 3600000.\n",
      "INFO:tensorflow:Generated 3637767 Examples\n",
      "INFO:tensorflow:Found vocab file: ./data/vocab.onlinereview.32768.subwords\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generating case 300000.\n",
      "INFO:tensorflow:Generating case 400000.\n",
      "INFO:tensorflow:Generating case 500000.\n",
      "INFO:tensorflow:Generating case 600000.\n",
      "INFO:tensorflow:Generating case 700000.\n",
      "INFO:tensorflow:Generating case 800000.\n",
      "INFO:tensorflow:Generating case 900000.\n",
      "INFO:tensorflow:Generating case 1000000.\n",
      "INFO:tensorflow:Generating case 1100000.\n",
      "INFO:tensorflow:Generating case 1200000.\n",
      "INFO:tensorflow:Generating case 1300000.\n",
      "INFO:tensorflow:Generating case 1400000.\n",
      "INFO:tensorflow:Generating case 1500000.\n",
      "INFO:tensorflow:Generating case 1600000.\n",
      "INFO:tensorflow:Generating case 1700000.\n",
      "INFO:tensorflow:Generating case 1800000.\n",
      "INFO:tensorflow:Generating case 1900000.\n",
      "INFO:tensorflow:Generating case 2000000.\n",
      "INFO:tensorflow:Generating case 2100000.\n",
      "INFO:tensorflow:Generating case 2200000.\n",
      "INFO:tensorflow:Generating case 2300000.\n",
      "INFO:tensorflow:Generating case 2400000.\n",
      "INFO:tensorflow:Generating case 2500000.\n",
      "INFO:tensorflow:Generating case 2600000.\n",
      "INFO:tensorflow:Generating case 2700000.\n",
      "INFO:tensorflow:Generating case 2800000.\n",
      "INFO:tensorflow:Generating case 2900000.\n",
      "INFO:tensorflow:Generating case 3000000.\n",
      "INFO:tensorflow:Generating case 3100000.\n",
      "INFO:tensorflow:Generating case 3200000.\n",
      "INFO:tensorflow:Generating case 3300000.\n",
      "INFO:tensorflow:Generating case 3400000.\n",
      "INFO:tensorflow:Generating case 3500000.\n",
      "INFO:tensorflow:Generating case 3600000.\n",
      "INFO:tensorflow:Generated 3637767 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:467: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:read: 100000\n",
      "INFO:tensorflow:read: 200000\n",
      "INFO:tensorflow:read: 300000\n",
      "INFO:tensorflow:write: 100000\n",
      "INFO:tensorflow:write: 200000\n",
      "INFO:tensorflow:write: 300000\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# DATA_DIR=./data\n",
    "# TMP_DIR=$DATA_DIR/tmp\n",
    "# rm -rf $DATA_DIR $TMP_DIR\n",
    "# mkdir -p $DATA_DIR $TMP_DIR\n",
    "# # Generate data\n",
    "# t2t-datagen \\\n",
    "#   --t2t_usr_dir=./train \\\n",
    "#   --problem=\"onlinereview\" \\\n",
    "#   --data_dir=$DATA_DIR \\\n",
    "#   --tmp_dir=$TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3637767 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Importing user module train from path /tf/jupyter-code/code/t2t/new\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_train_distribute': None, '_save_checkpoints_secs': None, 'use_tpu': False, '_task_id': 0, '_save_summary_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fcbfc3d15f8>, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_device_fn': None, '_master': '', '_tf_random_seed': None, '_model_dir': './trained_model', '_is_chief': True, '_evaluation_master': '', '_task_type': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, '_protocol': None, 't2t_device_info': {'num_async_replicas': 1}, '_num_worker_replicas': 0, '_num_ps_replicas': 0, '_eval_distribute': None, '_save_checkpoints_steps': 1000, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbfc3d1630>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fcbfc408510>) includes params argument, but params are not passed to Estimator.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n",
      "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "INFO:tensorflow:Trainable Variables Total size: 1399808\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:19.673212: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-06-02 10:36:21.376349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-02 10:36:21.376871: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x80e2e30 executing computations on platform CUDA. Devices:\n",
      "2019-06-02 10:36:21.376886: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5\n",
      "2019-06-02 10:36:21.378531: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3407980000 Hz\n",
      "2019-06-02 10:36:21.378922: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x83ce4e0 executing computations on platform Host. Devices:\n",
      "2019-06-02 10:36:21.378965: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-02 10:36:21.379444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-06-02 10:36:21.379473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:21.380085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:21.380095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:21.380113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:21.380283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "2019-06-02 10:36:28.771530: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "2019-06-02 10:36:39.015856: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:101] Filling up shuffle buffer (this may take a while): 295 of 512\n",
      "2019-06-02 10:36:41.610738: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:140] Shuffle buffer filled.\n",
      "INFO:tensorflow:loss = 7.4019403, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./trained_model/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T10:36:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:50.269893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:50.269940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:50.269958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:50.269961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:50.270065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-10:36:52\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 8.828742, metrics-onlinereview/targets/accuracy = 0.00069252076, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.00069252076, metrics-onlinereview/targets/approx_bleu_score = 0.778015, metrics-onlinereview/targets/neg_log_perplexity = -8.803953, metrics-onlinereview/targets/rouge_2_fscore = 0.84111744, metrics-onlinereview/targets/rouge_L_fscore = 0.8062627\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Loss for final step: 7.4723377.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_3692_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_3692_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_3692_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T10:36:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-02 10:36:57.293478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-02 10:36:57.293510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-02 10:36:57.293515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-02 10:36:57.293518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-02 10:36:57.293611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-10:36:59\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 8.828742, metrics-onlinereview/targets/accuracy = 0.00069252076, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.00069252076, metrics-onlinereview/targets/approx_bleu_score = 0.778015, metrics-onlinereview/targets/neg_log_perplexity = -8.803953, metrics-onlinereview/targets/rouge_2_fscore = 0.84111744, metrics-onlinereview/targets/rouge_L_fscore = 0.8062627\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# DATA_DIR=./data\n",
    "# OUTDIR=./trained_model\n",
    "# rm -rf $OUTDIR\n",
    "# t2t-trainer \\\n",
    "#   --data_dir=./data \\\n",
    "#   --t2t_usr_dir=./train \\\n",
    "#   --problem=\"onlinereview\" \\\n",
    "#   --model=transformer \\\n",
    "#   --hparams_set=onlinereviewhp \\\n",
    "#   --output_dir=$OUTDIR --job-dir=$OUTDIR --train_steps=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<train.problem.onlinereview at 0x7fb3a829d588>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train import problem\n",
    "problem.onlinereview('onlinereview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import problems\n",
    "\n",
    "DATA_LOC = './data' \n",
    "t2t_problem = problems.problem('onlinereview')\n",
    "vocab_name = \"./data/vocab.onlinereview.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "#     print(\"inputs\",inputs)\n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "#         print(\"integers\", integers)\n",
    "#         print(\"targets\", encoders[\"targets\"])\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder at 0x7f33a7790160>,\n",
       " 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder at 0x7f33a7790160>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# ende_problem.generate_data(data_dir, tmp_dir)\n",
    "example = tfe.Iterator(t2t_problem.dataset(Modes.TRAIN, DATA_LOC)).next()\n",
    "inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
    "targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs, encoded:\n",
      "[168, 3, 2, 610, 253, 90, 9462, 11, 62, 13, 2, 766, 6, 458, 11, 12253, 7573, 6650, 87, 18, 110, 21, 776, 34, 204, 32, 3, 77, 83, 18, 718, 7, 143, 219, 11, 5, 175, 397, 241, 3, 23, 307, 461, 103, 15153, 11, 10, 672, 13, 75, 3, 11, 10, 1134, 3, 7, 37, 219, 11, 16, 13, 7, 25, 388, 2, 2698, 16, 2, 1114, 44, 15109, 258, 2, 2886, 21, 196, 310, 3, 24, 75, 24, 458, 11, 133, 8, 7, 702, 7, 143, 22, 71, 2, 892, 124, 8, 7, 103, 18, 931, 16, 3, 94, 2, 766, 87, 18, 110, 21, 776, 23, 7, 68, 3565, 16, 10, 18, 2, 180, 8, 7, 1614, 24934, 121, 2, 1313, 21, 2, 117, 310, 9, 11, 3, 36, 2, 595, 310, 3, 6, 116, 11, 79, 568, 32, 1600, 4, 22, 32, 4554, 509, 23, 3187, 7, 44, 222, 43, 5, 4295, 20, 5, 270, 16, 10, 39, 1442, 12, 4244, 1439, 3, 12, 9348, 28, 3, 59, 7, 103, 299, 872, 49, 160, 17, 32, 16, 10, 18, 13, 2, 624, 1007, 10, 89, 253, 19306, 8, 11, 10, 15780, 4, 132, 11, 842, 9, 1235, 2, 644, 9, 11, 7, 44, 352, 18, 1815, 27, 875, 121, 11, 3, 36, 1522, 1046, 38, 11, 10, 188, 6, 740, 54, 38, 7, 660, 13, 7, 44, 516, 11, 3, 23, 11, 25, 253, 563, 4, 11, 10, 18, 260, 2, 70, 8, 7, 2173, 2, 200, 25, 5, 587, 12, 16, 479, 13, 4490, 3, 7, 68, 188, 6, 293, 54, 164, 723, 150, 2, 270, 3011, 6, 2, 1549, 4, 52, 5, 15090, 1291, 17, 2, 624, 8, 7, 404, 7, 65, 1117, 2, 82, 515, 155, 7, 375, 14, 270, 13, 401, 16, 876, 276, 1244, 14, 17, 6051, 875, 99, 8, 17, 146, 3, 377, 11, 10, 56, 3, 23, 17, 875, 99, 3, 7, 68, 188, 20, 5, 175, 397, 17, 200, 3, 4, 32, 598, 397, 17, 4554, 78, 11, 103, 299, 2227, 124, 765, 59, 1807, 6, 2, 371, 989, 3, 94, 9, 2, 2357, 13, 1]\n",
      "Inputs, decoded:\n",
      "right, the title pretty much sums it up.the button to turn it onoffdim did not work on mine from day one, which does not mean i should give it a 1 star review, but nothing else could redeem it is value.well, it is bright, i will give it that.i was under the impression that the switch would toggle between the lighting on each side, as well as turn it off. i guess i should have read the description better. i could not test that, because the button did not work on mine but i am guessing that is not the case. i considered taping over the lights on the back side of it, or the front side, to make it only face one direction and have one brightness level but frankly i would feel like a fool with a light that is all covered in electrical tape, in uni, when i could probably spend about 5 for one that is not.the usb connection is also pretty sketchy. it is wobbly and while it sort of holds the weight of it i would rather not damage my laptop over it, or constantly wonder if it is going to fall out if i move.i would return it, but it was pretty cheap and it is not worth the time. i suppose the price was a plus in that sense.anyways, i am going to try out another brand where the light clips to the monitor and has a retractable cord for the usb. i wish i had noticed the other type before i purchased this light.hope that helps anyone considering this for purely laptop use. for books, maybe it is great, but for laptop use, i am going with a 1 star for price, and one extra star for brightness; it could probably serve better uses when attached to the battery pack, because of the output.\n",
      "------------------------------\n",
      "Targets, encoded:\n",
      "[766, 87, 18, 110, 29, 624, 1007, 10, 19306, 29, 1218, 519, 1]\n",
      "Targets, decoded:\n",
      "button did not work  usb connection is sketchy  annoying design\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Example inputs as int-tensor.\n",
    "print(\"Inputs, encoded:\")\n",
    "print(inputs)\n",
    "print(\"Inputs, decoded:\")\n",
    "# Example inputs as a sentence.\n",
    "print(decode(inputs))\n",
    "\n",
    "print(\"---\"*10)\n",
    "# Example targets as int-tensor.\n",
    "print(\"Targets, encoded:\")\n",
    "print(targets)\n",
    "# Example targets as a sentence.\n",
    "print(\"Targets, decoded:\")\n",
    "print(decode(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyper params and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_file_v1', '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None, 'use_tpu': False, '_save_checkpoints_steps': 1000, '_tf_random_seed': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_task_id': 0, '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_device_fn': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_master': '', '_num_ps_replicas': 0, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc28fd5f0f0>, '_evaluation_master': '', '_environment': 'local', '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc28fd5f128>, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc290620620>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc28fd4ef28>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc28fd4ee80>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc28f346198>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc28f346198>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.820176, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.43283\n",
      "INFO:tensorflow:loss = 9.0315, step = 100 (41.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81802\n",
      "INFO:tensorflow:loss = 7.848617, step = 200 (35.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72231\n",
      "INFO:tensorflow:loss = 7.7164655, step = 300 (36.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70048\n",
      "INFO:tensorflow:loss = 7.837867, step = 400 (37.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85136\n",
      "INFO:tensorflow:loss = 6.4716654, step = 500 (35.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78405\n",
      "INFO:tensorflow:loss = 6.669176, step = 600 (35.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8769\n",
      "INFO:tensorflow:loss = 5.6054273, step = 700 (34.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78363\n",
      "INFO:tensorflow:loss = 5.6846113, step = 800 (35.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7076\n",
      "INFO:tensorflow:loss = 8.744803, step = 900 (36.934 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.23067\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:03:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:05:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 6.8931675, metrics-onlinereview/targets/accuracy = 0.080210656, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.1829046, metrics-onlinereview/targets/approx_bleu_score = 0.0052986084, metrics-onlinereview/targets/neg_log_perplexity = -6.820747, metrics-onlinereview/targets/rouge_2_fscore = 0.018404728, metrics-onlinereview/targets/rouge_L_fscore = 0.13956645\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: model_file_v1/model.ckpt-1000\n",
      "INFO:tensorflow:Validation (step 1000): loss = 6.8931675, metrics-onlinereview/targets/neg_log_perplexity = -6.820747, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 1000, metrics-onlinereview/targets/approx_bleu_score = 0.0052986084, metrics-onlinereview/targets/accuracy_top5 = 0.1829046, metrics-onlinereview/targets/rouge_2_fscore = 0.018404728, metrics-onlinereview/targets/accuracy = 0.080210656, metrics-onlinereview/targets/rouge_L_fscore = 0.13956645\n",
      "INFO:tensorflow:loss = 5.874517, step = 1000 (159.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.664183\n",
      "INFO:tensorflow:loss = 5.5345335, step = 1100 (35.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75596\n",
      "INFO:tensorflow:loss = 5.4034715, step = 1200 (36.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76143\n",
      "INFO:tensorflow:loss = 7.0822883, step = 1300 (36.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79581\n",
      "INFO:tensorflow:loss = 6.3155684, step = 1400 (35.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77281\n",
      "INFO:tensorflow:loss = 5.612577, step = 1500 (36.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83191\n",
      "INFO:tensorflow:loss = 5.419204, step = 1600 (35.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79558\n",
      "INFO:tensorflow:loss = 5.619882, step = 1700 (35.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.67101\n",
      "INFO:tensorflow:loss = 6.316434, step = 1800 (37.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80336\n",
      "INFO:tensorflow:loss = 6.220013, step = 1900 (35.672 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24119\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:11:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:13:05\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.587814, metrics-onlinereview/targets/accuracy = 0.1176828, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.24306259, metrics-onlinereview/targets/approx_bleu_score = 0.003401608, metrics-onlinereview/targets/neg_log_perplexity = -6.5061903, metrics-onlinereview/targets/rouge_2_fscore = 0.008256864, metrics-onlinereview/targets/rouge_L_fscore = 0.10412798\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_v1/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): loss = 6.587814, metrics-onlinereview/targets/neg_log_perplexity = -6.5061903, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 2000, metrics-onlinereview/targets/approx_bleu_score = 0.003401608, metrics-onlinereview/targets/accuracy_top5 = 0.24306259, metrics-onlinereview/targets/rouge_2_fscore = 0.008256864, metrics-onlinereview/targets/accuracy = 0.1176828, metrics-onlinereview/targets/rouge_L_fscore = 0.10412798\n",
      "INFO:tensorflow:loss = 6.080802, step = 2000 (149.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.709543\n",
      "INFO:tensorflow:loss = 6.737644, step = 2100 (36.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74221\n",
      "INFO:tensorflow:loss = 7.5938034, step = 2200 (36.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74302\n",
      "INFO:tensorflow:loss = 6.4351707, step = 2300 (36.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73267\n",
      "INFO:tensorflow:loss = 4.9659643, step = 2400 (36.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71254\n",
      "INFO:tensorflow:loss = 5.7850485, step = 2500 (36.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76663\n",
      "INFO:tensorflow:loss = 4.065698, step = 2600 (36.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83012\n",
      "INFO:tensorflow:loss = 5.588816, step = 2700 (35.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79302\n",
      "INFO:tensorflow:loss = 5.9991236, step = 2800 (35.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85035\n",
      "INFO:tensorflow:loss = 5.3072453, step = 2900 (35.084 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.17123\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:19:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:21:02\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 6.4799147, metrics-onlinereview/targets/accuracy = 0.116872594, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.25035447, metrics-onlinereview/targets/approx_bleu_score = 0.004673335, metrics-onlinereview/targets/neg_log_perplexity = -6.3943763, metrics-onlinereview/targets/rouge_2_fscore = 0.015254237, metrics-onlinereview/targets/rouge_L_fscore = 0.11970963\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: model_file_v1/model.ckpt-3000\n",
      "INFO:tensorflow:Validation (step 3000): loss = 6.4799147, metrics-onlinereview/targets/neg_log_perplexity = -6.3943763, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 3000, metrics-onlinereview/targets/approx_bleu_score = 0.004673335, metrics-onlinereview/targets/accuracy_top5 = 0.25035447, metrics-onlinereview/targets/rouge_2_fscore = 0.015254237, metrics-onlinereview/targets/accuracy = 0.116872594, metrics-onlinereview/targets/rouge_L_fscore = 0.11970963\n",
      "INFO:tensorflow:loss = 6.7374144, step = 3000 (152.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.705581\n",
      "INFO:tensorflow:loss = 5.272836, step = 3100 (35.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.6923\n",
      "INFO:tensorflow:loss = 6.9848566, step = 3200 (37.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69002\n",
      "INFO:tensorflow:loss = 5.612186, step = 3300 (37.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78098\n",
      "INFO:tensorflow:loss = 6.158658, step = 3400 (35.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86712\n",
      "INFO:tensorflow:loss = 5.569326, step = 3500 (34.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74902\n",
      "INFO:tensorflow:loss = 6.4299417, step = 3600 (36.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78387\n",
      "INFO:tensorflow:loss = 5.4569235, step = 3700 (35.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81048\n",
      "INFO:tensorflow:loss = 5.693967, step = 3800 (35.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73458\n",
      "INFO:tensorflow:loss = 5.55251, step = 3900 (36.571 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24323\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:27:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:28:59\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 6.3806973, metrics-onlinereview/targets/accuracy = 0.13105124, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.264128, metrics-onlinereview/targets/approx_bleu_score = 0.0053905603, metrics-onlinereview/targets/neg_log_perplexity = -6.324194, metrics-onlinereview/targets/rouge_2_fscore = 0.01944869, metrics-onlinereview/targets/rouge_L_fscore = 0.1172692\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_v1/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): loss = 6.3806973, metrics-onlinereview/targets/neg_log_perplexity = -6.324194, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 4000, metrics-onlinereview/targets/approx_bleu_score = 0.0053905603, metrics-onlinereview/targets/accuracy_top5 = 0.264128, metrics-onlinereview/targets/rouge_2_fscore = 0.01944869, metrics-onlinereview/targets/accuracy = 0.13105124, metrics-onlinereview/targets/rouge_L_fscore = 0.1172692\n",
      "INFO:tensorflow:loss = 5.6789007, step = 4000 (151.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.698002\n",
      "INFO:tensorflow:loss = 4.8722725, step = 4100 (36.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82411\n",
      "INFO:tensorflow:loss = 5.713871, step = 4200 (35.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73624\n",
      "INFO:tensorflow:loss = 6.281771, step = 4300 (36.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8168\n",
      "INFO:tensorflow:loss = 4.746562, step = 4400 (35.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74755\n",
      "INFO:tensorflow:loss = 6.755494, step = 4500 (36.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75417\n",
      "INFO:tensorflow:loss = 6.562761, step = 4600 (36.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72662\n",
      "INFO:tensorflow:loss = 4.8850365, step = 4700 (36.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82105\n",
      "INFO:tensorflow:loss = 5.659468, step = 4800 (35.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83215\n",
      "INFO:tensorflow:loss = 5.538517, step = 4900 (35.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.21542\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:35:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:37:03\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 6.3732653, metrics-onlinereview/targets/accuracy = 0.12963338, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26554587, metrics-onlinereview/targets/approx_bleu_score = 0.0065116566, metrics-onlinereview/targets/neg_log_perplexity = -6.298871, metrics-onlinereview/targets/rouge_2_fscore = 0.025693776, metrics-onlinereview/targets/rouge_L_fscore = 0.14417171\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: model_file_v1/model.ckpt-5000\n",
      "INFO:tensorflow:Validation (step 5000): loss = 6.3732653, metrics-onlinereview/targets/neg_log_perplexity = -6.298871, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 5000, metrics-onlinereview/targets/approx_bleu_score = 0.0065116566, metrics-onlinereview/targets/accuracy_top5 = 0.26554587, metrics-onlinereview/targets/rouge_2_fscore = 0.025693776, metrics-onlinereview/targets/accuracy = 0.12963338, metrics-onlinereview/targets/rouge_L_fscore = 0.14417171\n",
      "INFO:tensorflow:loss = 5.9924664, step = 5000 (160.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660979\n",
      "INFO:tensorflow:loss = 5.7233114, step = 5100 (36.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70317\n",
      "INFO:tensorflow:loss = 4.3370147, step = 5200 (36.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81768\n",
      "INFO:tensorflow:loss = 5.0449953, step = 5300 (35.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73599\n",
      "INFO:tensorflow:loss = 5.1950793, step = 5400 (36.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8103\n",
      "INFO:tensorflow:loss = 6.082032, step = 5500 (35.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82207\n",
      "INFO:tensorflow:loss = 5.796518, step = 5600 (35.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71291\n",
      "INFO:tensorflow:loss = 5.7853613, step = 5700 (36.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.803\n",
      "INFO:tensorflow:loss = 3.9295673, step = 5800 (35.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75725\n",
      "INFO:tensorflow:loss = 4.7107296, step = 5900 (36.268 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.20511\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:43:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:45:11\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 6.377694, metrics-onlinereview/targets/accuracy = 0.13307677, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.27081224, metrics-onlinereview/targets/approx_bleu_score = 0.006701106, metrics-onlinereview/targets/neg_log_perplexity = -6.3014193, metrics-onlinereview/targets/rouge_2_fscore = 0.024723686, metrics-onlinereview/targets/rouge_L_fscore = 0.14334732\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_v1/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): loss = 6.377694, metrics-onlinereview/targets/neg_log_perplexity = -6.3014193, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 6000, metrics-onlinereview/targets/approx_bleu_score = 0.006701106, metrics-onlinereview/targets/accuracy_top5 = 0.27081224, metrics-onlinereview/targets/rouge_2_fscore = 0.024723686, metrics-onlinereview/targets/accuracy = 0.13307677, metrics-onlinereview/targets/rouge_L_fscore = 0.14334732\n",
      "INFO:tensorflow:loss = 5.1227336, step = 6000 (162.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.653414\n",
      "INFO:tensorflow:loss = 4.3471932, step = 6100 (35.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68253\n",
      "INFO:tensorflow:loss = 6.00374, step = 6200 (37.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75424\n",
      "INFO:tensorflow:loss = 5.4301476, step = 6300 (36.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76826\n",
      "INFO:tensorflow:loss = 5.4889727, step = 6400 (36.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83866\n",
      "INFO:tensorflow:loss = 5.511093, step = 6500 (35.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83288\n",
      "INFO:tensorflow:loss = 5.989005, step = 6600 (35.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73385\n",
      "INFO:tensorflow:loss = 5.4539523, step = 6700 (36.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76964\n",
      "INFO:tensorflow:loss = 5.583195, step = 6800 (36.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69982\n",
      "INFO:tensorflow:loss = 5.262391, step = 6900 (37.040 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26321\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:51:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-16:53:18\n",
      "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, loss = 6.340396, metrics-onlinereview/targets/accuracy = 0.13084869, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.28175005, metrics-onlinereview/targets/approx_bleu_score = 0.0072638267, metrics-onlinereview/targets/neg_log_perplexity = -6.2551384, metrics-onlinereview/targets/rouge_2_fscore = 0.029246984, metrics-onlinereview/targets/rouge_L_fscore = 0.15972947\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: model_file_v1/model.ckpt-7000\n",
      "INFO:tensorflow:Validation (step 7000): loss = 6.340396, metrics-onlinereview/targets/neg_log_perplexity = -6.2551384, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 7000, metrics-onlinereview/targets/approx_bleu_score = 0.0072638267, metrics-onlinereview/targets/accuracy_top5 = 0.28175005, metrics-onlinereview/targets/rouge_2_fscore = 0.029246984, metrics-onlinereview/targets/accuracy = 0.13084869, metrics-onlinereview/targets/rouge_L_fscore = 0.15972947\n",
      "INFO:tensorflow:loss = 6.3822513, step = 7000 (162.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650893\n",
      "INFO:tensorflow:loss = 5.6725636, step = 7100 (35.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.67875\n",
      "INFO:tensorflow:loss = 5.2081027, step = 7200 (37.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81907\n",
      "INFO:tensorflow:loss = 5.228724, step = 7300 (35.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8692\n",
      "INFO:tensorflow:loss = 5.9943733, step = 7400 (34.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74243\n",
      "INFO:tensorflow:loss = 5.1650653, step = 7500 (36.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87896\n",
      "INFO:tensorflow:loss = 5.6824384, step = 7600 (34.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72752\n",
      "INFO:tensorflow:loss = 5.291372, step = 7700 (36.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80573\n",
      "INFO:tensorflow:loss = 5.5231423, step = 7800 (35.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8372\n",
      "INFO:tensorflow:loss = 5.9224, step = 7900 (35.248 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.25715\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T16:59:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-17:01:27\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 6.393666, metrics-onlinereview/targets/accuracy = 0.12477213, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26939437, metrics-onlinereview/targets/approx_bleu_score = 0.0068583908, metrics-onlinereview/targets/neg_log_perplexity = -6.3029304, metrics-onlinereview/targets/rouge_2_fscore = 0.02608918, metrics-onlinereview/targets/rouge_L_fscore = 0.14761074\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_file_v1/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): loss = 6.393666, metrics-onlinereview/targets/neg_log_perplexity = -6.3029304, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 8000, metrics-onlinereview/targets/approx_bleu_score = 0.0068583908, metrics-onlinereview/targets/accuracy_top5 = 0.26939437, metrics-onlinereview/targets/rouge_2_fscore = 0.02608918, metrics-onlinereview/targets/accuracy = 0.12477213, metrics-onlinereview/targets/rouge_L_fscore = 0.14761074\n",
      "INFO:tensorflow:loss = 5.760723, step = 8000 (166.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.63306\n",
      "INFO:tensorflow:loss = 5.3723745, step = 8100 (35.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7667\n",
      "INFO:tensorflow:loss = 6.308387, step = 8200 (36.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74763\n",
      "INFO:tensorflow:loss = 6.4910836, step = 8300 (36.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.65092\n",
      "INFO:tensorflow:loss = 6.3829865, step = 8400 (37.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80865\n",
      "INFO:tensorflow:loss = 6.3292904, step = 8500 (35.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7955\n",
      "INFO:tensorflow:loss = 7.4166446, step = 8600 (35.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79102\n",
      "INFO:tensorflow:loss = 5.892159, step = 8700 (35.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85631\n",
      "INFO:tensorflow:loss = 5.5596533, step = 8800 (35.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73849\n",
      "INFO:tensorflow:loss = 5.757562, step = 8900 (36.517 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.24259\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-02T17:07:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-02-17:09:23\n",
      "INFO:tensorflow:Saving dict for global step 9000: global_step = 9000, loss = 6.382387, metrics-onlinereview/targets/accuracy = 0.12922828, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26433057, metrics-onlinereview/targets/approx_bleu_score = 0.005818227, metrics-onlinereview/targets/neg_log_perplexity = -6.301665, metrics-onlinereview/targets/rouge_2_fscore = 0.023459261, metrics-onlinereview/targets/rouge_L_fscore = 0.1333496\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: model_file_v1/model.ckpt-9000\n",
      "INFO:tensorflow:Validation (step 9000): loss = 6.382387, metrics-onlinereview/targets/neg_log_perplexity = -6.301665, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 9000, metrics-onlinereview/targets/approx_bleu_score = 0.005818227, metrics-onlinereview/targets/accuracy_top5 = 0.26433057, metrics-onlinereview/targets/rouge_2_fscore = 0.023459261, metrics-onlinereview/targets/accuracy = 0.12922828, metrics-onlinereview/targets/rouge_L_fscore = 0.1333496\n",
      "INFO:tensorflow:loss = 5.3969903, step = 9000 (151.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.700008\n",
      "INFO:tensorflow:loss = 5.646725, step = 9100 (36.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7602\n",
      "INFO:tensorflow:loss = 6.658905, step = 9200 (36.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81412\n",
      "INFO:tensorflow:loss = 5.025133, step = 9300 (35.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74433\n",
      "INFO:tensorflow:loss = 5.105712, step = 9400 (36.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.73796\n",
      "INFO:tensorflow:loss = 5.267669, step = 9500 (36.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77318\n",
      "INFO:tensorflow:loss = 5.2262473, step = 9600 (36.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78308\n",
      "INFO:tensorflow:loss = 4.34492, step = 9700 (35.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79986\n",
      "INFO:tensorflow:loss = 5.018489, step = 9800 (35.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72967\n",
      "INFO:tensorflow:loss = 5.3967323, step = 9900 (36.635 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.365423.\n",
      "Time: 4757.36 s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multiproblem_mixing_schedule': 'constant', 'modality': {}, 'kernel_height': 3, 'initializer': 'uniform_unit_scaling', 'mlperf_mode': False, 'learning_rate_decay_scheme': 'noam', 'heads_share_relative_embedding': False, 'proximity_bias': False, 'multiproblem_schedule_max_examples': 10000000.0, 'kernel_width': 1, 'sampling_method': 'argmax', 'optimizer_momentum_nesterov': False, 'pad_batch': False, 'eval_drop_long_sequences': False, 'multiproblem_fixed_train_length': -1, 'shared_embedding': False, 'layer_prepostprocess_dropout': 0.1, 'learning_rate_minimum': None, 'max_input_seq_length': 0, 'multiproblem_schedule_threshold': 0.5, 'learning_rate_warmup_steps': 8000, 'hidden_size': 512, 'weight_dtype': 'float32', 'parameter_attention_key_channels': 0, 'factored_logits': False, 'optimizer_adam_epsilon': 1e-09, 'learning_rate_decay_staircase': False, 'multiproblem_max_target_length': -1, 'min_length_bucket': 8, 'causal_decoder_self_attention': True, 'summarize_grads': False, 'norm_epsilon': 1e-06, 'batch_shuffle_size': 512, 'prepend_mode': 'prepend_inputs_full_attention', 'symbol_dropout': 0.0, 'num_decoder_layers': 0, 'grad_noise_scale': 0.0, 'optimizer_zero_grads': False, 'overload_eval_metric_name': '', 'optimizer_adafactor_memory_exponent': 0.8, 'moe_k': 2, 'optimizer_adafactor_factored': True, 'shared_embedding_and_softmax_weights': True, 'pos': 'timing', 'optimizer_adafactor_clipping_threshold': 1.0, 'eval_run_autoregressive': False, 'optimizer_multistep_accumulate_steps': None, 'warm_start_from_second': '', 'compress_steps': 0, 'learning_rate': 0.1, 'learning_rate_decay_steps': 5000, 'optimizer_adafactor_beta2': 0.999, 'optimizer_momentum_momentum': 0.9, 'weight_noise': 0.0, 'optimizer_adafactor_beta1': 0.0, 'max_length': 0, 'multiproblem_per_task_threshold': '', 'summarize_vars': False, 'sampling_temp': 1.0, 'dropout': 0.2, 'moe_overhead_train': 1.0, 'use_pad_remover': True, 'daisy_chain_variables': True, 'split_to_length': 0, 'attention_variables_3d': False, 'ffn_layer': 'dense_relu_dense', 'length_bucket_step': 1.1, 'norm_type': 'layer', 'symbol_modality_skip_top': False, 'multiproblem_target_eval_only': False, 'optimizer_adam_beta2': 0.98, 'parameter_attention_value_channels': 0, 'multiproblem_max_input_length': -1, 'scheduled_sampling_warmup_steps': 50000, 'max_relative_position': 0, 'moe_hidden_sizes': '2048', 'num_hidden_layers': 6, 'activation_dtype': 'float32', 'optimizer_adam_beta1': 0.9, 'vocab_divisor': 1, 'relu_dropout': 0.1, 'optimizer_adafactor_decay_type': 'pow', 'initializer_gain': 1.0, 'multiproblem_label_weight': 0.5, 'multiproblem_reweight_label_loss': False, 'learning_rate_constant': 1.0, 'multiply_embedding_mode': 'sqrt_depth', 'no_data_parallelism': False, 'max_target_seq_length': 0, 'scheduled_sampling_gold_mixin_prob': 0.5, 'nbr_decoder_problems': 1, 'learning_rate_decay_rate': 1.0, 'moe_overhead_eval': 2.0, 'add_relative_to_values': False, 'symbol_modality_num_shards': 16, 'num_encoder_layers': 0, 'attention_dropout': 0.1, 'min_length': 0, 'layer_postprocess_sequence': 'da', 'video_num_input_frames': 1, 'num_heads': 8, 'learning_rate_schedule': 'legacy', 'use_target_space_embedding': True, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'unidirectional_encoder': False, 'self_attention_type': 'dot_product', 'scheduled_sampling_prob': 0.0, 'use_fixed_batch_size': False, 'multiproblem_vocab_size': -1, 'moe_num_experts': 16, 'video_num_target_frames': 1, 'pretrained_model_dir': '', 'attention_value_channels': 0, 'layer_prepostprocess_dropout_broadcast_dims': '', 'weight_decay': 0.0, 'layer_preprocess_sequence': 'n', 'label_smoothing': 0.1, 'tpu_enable_host_call': False, 'attention_dropout_broadcast_dims': '', 'clip_grad_norm': 0.0, 'conv_first_kernel': 3, 'batch_size': 2048, 'force_full_predict': False, 'moe_loss_coef': 0.001, 'filter_size': 2048, 'optimizer': 'Adam', 'relu_dropout_broadcast_dims': '', 'attention_key_channels': 0, 'learning_rate_cosine_cycle_steps': 250000}\n",
      "{'decode_timeout_mins': 240, 'max_display_decodes': 5, 'mlperf_threshold': 25.0, 'skip_eos_postprocess': False, 'shards_start_offset': 0, 'save_images': False, 'summaries_log_dir': 'decode', 'border_percent': 2, 'vgg_ckpt_path': '', 'write_beam_scores': False, 'force_decode_length': False, 'mlperf_decode_step': 0.0, 'mlperf_success': False, 'num_samples': -1, 'frames_per_second': 10, 'decode_in_memory': False, 'alpha': 0.6, 'batch_size': 0, 'display_decoded_images': False, 'delimiter': '\\n', 'log_results': True, 'extra_length': 100, 'beam_size': 4, 'num_decodes': 1, 'shard_google_format': False, 'return_beams': False, 'identity_output': False, 'multiproblem_task_id': -1, 'eos_penalty': 0.0, 'guess_and_check_top_k': 0, 'decode_to_file': None, 'max_input_size': -1, 'max_display_outputs': 10, 'block_size': 0, 'shards': 1, 'shard_id': 0, 'guess_and_check_epsilon': -1}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_file_v1', '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None, 'use_tpu': False, '_save_checkpoints_steps': 2000, '_tf_random_seed': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_task_id': 0, '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_device_fn': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_master': '', '_num_ps_replicas': 0, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc3d0664358>, '_evaluation_master': '', '_environment': 'local', '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc3d0664390>, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc2906206a8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc3d06641d0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc3d0664128>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc3e2d59da0>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc3e2d59da0>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-10000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T00:14:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-00:20:22\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 6.412321, metrics-onlinereview/targets/accuracy = 0.12671585, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.27117378, metrics-onlinereview/targets/approx_bleu_score = 0.005338237, metrics-onlinereview/targets/neg_log_perplexity = -6.333966, metrics-onlinereview/targets/rouge_2_fscore = 0.02271182, metrics-onlinereview/targets/rouge_L_fscore = 0.14463001\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_file_v1/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10001): loss = 6.412321, metrics-onlinereview/targets/neg_log_perplexity = -6.333966, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 10000, metrics-onlinereview/targets/approx_bleu_score = 0.005338237, metrics-onlinereview/targets/accuracy_top5 = 0.27117378, metrics-onlinereview/targets/rouge_2_fscore = 0.02271182, metrics-onlinereview/targets/accuracy = 0.12671585, metrics-onlinereview/targets/rouge_L_fscore = 0.14463001\n",
      "INFO:tensorflow:loss = 5.120249, step = 10000\n",
      "INFO:tensorflow:global_step/sec: 0.241603\n",
      "INFO:tensorflow:loss = 6.703458, step = 10100 (78.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35544\n",
      "INFO:tensorflow:loss = 7.366435, step = 10200 (73.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36362\n",
      "INFO:tensorflow:loss = 5.563476, step = 10300 (73.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39353\n",
      "INFO:tensorflow:loss = 5.3176966, step = 10400 (71.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3837\n",
      "INFO:tensorflow:loss = 6.8763413, step = 10500 (72.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37122\n",
      "INFO:tensorflow:loss = 5.392751, step = 10700 (72.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34143\n",
      "INFO:tensorflow:loss = 5.2732897, step = 10800 (74.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35263\n",
      "INFO:tensorflow:loss = 6.0564747, step = 10900 (73.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42216\n",
      "INFO:tensorflow:loss = 6.1092257, step = 11000 (70.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37922\n",
      "INFO:tensorflow:loss = 5.5613728, step = 11100 (72.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34684\n",
      "INFO:tensorflow:loss = 5.3524885, step = 11200 (74.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38949\n",
      "INFO:tensorflow:loss = 5.484736, step = 11300 (71.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39563\n",
      "INFO:tensorflow:loss = 6.137744, step = 11400 (71.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37134\n",
      "INFO:tensorflow:loss = 5.0498257, step = 11500 (72.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39739\n",
      "INFO:tensorflow:loss = 4.4332604, step = 11600 (71.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42005\n",
      "INFO:tensorflow:loss = 5.158435, step = 11700 (70.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35192\n",
      "INFO:tensorflow:loss = 5.388855, step = 11800 (73.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40613\n",
      "INFO:tensorflow:loss = 5.669346, step = 11900 (71.116 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.25337\n",
      "INFO:tensorflow:loss = 5.463659, step = 12000 (79.783 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T00:44:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-00:50:08\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 6.2296486, metrics-onlinereview/targets/accuracy = 0.13427958, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29218414, metrics-onlinereview/targets/approx_bleu_score = 0.006102796, metrics-onlinereview/targets/neg_log_perplexity = -6.1495867, metrics-onlinereview/targets/rouge_2_fscore = 0.0268439, metrics-onlinereview/targets/rouge_L_fscore = 0.14961135\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_file_v1/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12001): loss = 6.2296486, metrics-onlinereview/targets/neg_log_perplexity = -6.1495867, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 12000, metrics-onlinereview/targets/approx_bleu_score = 0.006102796, metrics-onlinereview/targets/accuracy_top5 = 0.29218414, metrics-onlinereview/targets/rouge_2_fscore = 0.0268439, metrics-onlinereview/targets/accuracy = 0.13427958, metrics-onlinereview/targets/rouge_L_fscore = 0.14961135\n",
      "INFO:tensorflow:global_step/sec: 0.254539\n",
      "INFO:tensorflow:loss = 7.703032, step = 12100 (392.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38398\n",
      "INFO:tensorflow:loss = 5.7119637, step = 12200 (72.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38839\n",
      "INFO:tensorflow:loss = 5.8248672, step = 12300 (72.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34955\n",
      "INFO:tensorflow:loss = 6.0224495, step = 12400 (74.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42102\n",
      "INFO:tensorflow:loss = 5.6915965, step = 12500 (70.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36861\n",
      "INFO:tensorflow:loss = 5.583126, step = 12600 (73.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40321\n",
      "INFO:tensorflow:loss = 5.2983193, step = 12700 (71.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41244\n",
      "INFO:tensorflow:loss = 4.967099, step = 12800 (70.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38973\n",
      "INFO:tensorflow:loss = 5.5804067, step = 12900 (71.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39699\n",
      "INFO:tensorflow:loss = 5.655112, step = 13000 (71.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.2932\n",
      "INFO:tensorflow:loss = 4.980192, step = 13100 (77.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38107\n",
      "INFO:tensorflow:loss = 5.8364787, step = 13200 (72.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31474\n",
      "INFO:tensorflow:loss = 5.646711, step = 13300 (76.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34159\n",
      "INFO:tensorflow:loss = 4.4810896, step = 13400 (74.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37446\n",
      "INFO:tensorflow:loss = 4.8372703, step = 13500 (72.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42784\n",
      "INFO:tensorflow:loss = 5.6893945, step = 13600 (70.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38935\n",
      "INFO:tensorflow:loss = 5.474726, step = 13700 (71.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42588\n",
      "INFO:tensorflow:loss = 5.0018225, step = 13800 (70.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40317\n",
      "INFO:tensorflow:loss = 5.3870554, step = 13900 (71.267 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.22511\n",
      "INFO:tensorflow:loss = 5.4713273, step = 14000 (81.625 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T01:14:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-01:20:41\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 6.1986637, metrics-onlinereview/targets/accuracy = 0.13890186, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29568586, metrics-onlinereview/targets/approx_bleu_score = 0.006955121, metrics-onlinereview/targets/neg_log_perplexity = -6.107355, metrics-onlinereview/targets/rouge_2_fscore = 0.031935383, metrics-onlinereview/targets/rouge_L_fscore = 0.16306564\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_file_v1/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14001): loss = 6.1986637, metrics-onlinereview/targets/neg_log_perplexity = -6.107355, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 14000, metrics-onlinereview/targets/approx_bleu_score = 0.006955121, metrics-onlinereview/targets/accuracy_top5 = 0.29568586, metrics-onlinereview/targets/rouge_2_fscore = 0.031935383, metrics-onlinereview/targets/accuracy = 0.13890186, metrics-onlinereview/targets/rouge_L_fscore = 0.16306564\n",
      "INFO:tensorflow:global_step/sec: 0.221965\n",
      "INFO:tensorflow:loss = 5.09781, step = 14100 (450.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41183\n",
      "INFO:tensorflow:loss = 5.7814507, step = 14200 (70.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40267\n",
      "INFO:tensorflow:loss = 5.5115695, step = 14300 (71.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38325\n",
      "INFO:tensorflow:loss = 6.2638474, step = 14400 (72.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40023\n",
      "INFO:tensorflow:loss = 5.2880054, step = 14500 (71.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38577\n",
      "INFO:tensorflow:loss = 5.4528985, step = 14600 (72.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38243\n",
      "INFO:tensorflow:loss = 5.2785335, step = 14700 (72.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3563\n",
      "INFO:tensorflow:loss = 6.168658, step = 14800 (73.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38571\n",
      "INFO:tensorflow:loss = 5.4518847, step = 14900 (72.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34722\n",
      "INFO:tensorflow:loss = 4.7924833, step = 15000 (74.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42398\n",
      "INFO:tensorflow:loss = 5.821923, step = 15100 (70.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43097\n",
      "INFO:tensorflow:loss = 5.2823687, step = 15200 (69.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41121\n",
      "INFO:tensorflow:loss = 5.3669825, step = 15300 (70.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43276\n",
      "INFO:tensorflow:loss = 5.4712934, step = 15400 (69.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37891\n",
      "INFO:tensorflow:loss = 6.114046, step = 15500 (72.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43626\n",
      "INFO:tensorflow:loss = 5.665798, step = 15600 (69.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35674\n",
      "INFO:tensorflow:loss = 5.1528397, step = 15700 (73.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3992\n",
      "INFO:tensorflow:loss = 4.8033023, step = 15800 (71.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39392\n",
      "INFO:tensorflow:loss = 5.376248, step = 15900 (71.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23269\n",
      "INFO:tensorflow:loss = 5.4503136, step = 16000 (81.122 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T01:44:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-01:51:06\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 6.1855373, metrics-onlinereview/targets/accuracy = 0.14310393, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29573256, metrics-onlinereview/targets/approx_bleu_score = 0.005000565, metrics-onlinereview/targets/neg_log_perplexity = -6.1081653, metrics-onlinereview/targets/rouge_2_fscore = 0.023418918, metrics-onlinereview/targets/rouge_L_fscore = 0.13549443\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_file_v1/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16001): loss = 6.1855373, metrics-onlinereview/targets/neg_log_perplexity = -6.1081653, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 16000, metrics-onlinereview/targets/approx_bleu_score = 0.005000565, metrics-onlinereview/targets/accuracy_top5 = 0.29573256, metrics-onlinereview/targets/rouge_2_fscore = 0.023418918, metrics-onlinereview/targets/accuracy = 0.14310393, metrics-onlinereview/targets/rouge_L_fscore = 0.13549443\n",
      "INFO:tensorflow:global_step/sec: 0.22069\n",
      "INFO:tensorflow:loss = 5.7777033, step = 16100 (453.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33832\n",
      "INFO:tensorflow:loss = 5.13559, step = 16200 (74.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4531\n",
      "INFO:tensorflow:loss = 5.1361694, step = 16300 (68.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38478\n",
      "INFO:tensorflow:loss = 4.768937, step = 16400 (72.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34028\n",
      "INFO:tensorflow:loss = 4.9504075, step = 16500 (74.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42701\n",
      "INFO:tensorflow:loss = 5.079594, step = 16600 (70.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38282\n",
      "INFO:tensorflow:loss = 5.4980626, step = 16700 (72.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32953\n",
      "INFO:tensorflow:loss = 6.4483724, step = 16800 (75.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39404\n",
      "INFO:tensorflow:loss = 5.6227775, step = 16900 (71.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43295\n",
      "INFO:tensorflow:loss = 5.1653366, step = 17000 (69.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37079\n",
      "INFO:tensorflow:loss = 5.0222545, step = 17100 (72.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43246\n",
      "INFO:tensorflow:loss = 5.546145, step = 17200 (69.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3964\n",
      "INFO:tensorflow:loss = 4.843791, step = 17300 (71.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37347\n",
      "INFO:tensorflow:loss = 5.1654162, step = 17400 (72.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38402\n",
      "INFO:tensorflow:loss = 5.1551876, step = 17700 (72.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40102\n",
      "INFO:tensorflow:loss = 5.038622, step = 17800 (71.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40092\n",
      "INFO:tensorflow:loss = 6.9584627, step = 17900 (71.397 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.17122\n",
      "INFO:tensorflow:loss = 5.470486, step = 18000 (85.366 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T02:15:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-02:21:19\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 6.152365, metrics-onlinereview/targets/accuracy = 0.14529835, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3023625, metrics-onlinereview/targets/approx_bleu_score = 0.0055779703, metrics-onlinereview/targets/neg_log_perplexity = -6.065924, metrics-onlinereview/targets/rouge_2_fscore = 0.025530465, metrics-onlinereview/targets/rouge_L_fscore = 0.14003389\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_file_v1/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18001): loss = 6.152365, metrics-onlinereview/targets/neg_log_perplexity = -6.065924, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 18000, metrics-onlinereview/targets/approx_bleu_score = 0.0055779703, metrics-onlinereview/targets/accuracy_top5 = 0.3023625, metrics-onlinereview/targets/rouge_2_fscore = 0.025530465, metrics-onlinereview/targets/accuracy = 0.14529835, metrics-onlinereview/targets/rouge_L_fscore = 0.14003389\n",
      "INFO:tensorflow:global_step/sec: 0.230865\n",
      "INFO:tensorflow:loss = 4.972527, step = 18100 (433.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36873\n",
      "INFO:tensorflow:loss = 5.535204, step = 18200 (73.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38562\n",
      "INFO:tensorflow:loss = 5.511552, step = 18300 (72.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37464\n",
      "INFO:tensorflow:loss = 5.049222, step = 18400 (72.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40801\n",
      "INFO:tensorflow:loss = 5.3231344, step = 18500 (71.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38276\n",
      "INFO:tensorflow:loss = 5.4581323, step = 18600 (72.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38813\n",
      "INFO:tensorflow:loss = 5.164748, step = 18700 (72.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40965\n",
      "INFO:tensorflow:loss = 5.849754, step = 18800 (70.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37796\n",
      "INFO:tensorflow:loss = 4.493865, step = 18900 (72.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3715\n",
      "INFO:tensorflow:loss = 4.662781, step = 19000 (72.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37602\n",
      "INFO:tensorflow:loss = 5.325846, step = 19100 (72.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37818\n",
      "INFO:tensorflow:loss = 4.891077, step = 19200 (72.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40349\n",
      "INFO:tensorflow:loss = 6.0415034, step = 19300 (71.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30536\n",
      "INFO:tensorflow:loss = 5.662205, step = 19400 (76.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40613\n",
      "INFO:tensorflow:loss = 5.260075, step = 19500 (71.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35825\n",
      "INFO:tensorflow:loss = 5.54129, step = 19600 (73.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38636\n",
      "INFO:tensorflow:loss = 4.887072, step = 19700 (72.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40704\n",
      "INFO:tensorflow:loss = 5.0438476, step = 19800 (71.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39573\n",
      "INFO:tensorflow:loss = 5.402284, step = 19900 (71.647 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23406\n",
      "INFO:tensorflow:loss = 5.527979, step = 20000 (81.032 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T02:45:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-02:51:52\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 6.118474, metrics-onlinereview/targets/accuracy = 0.14646558, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30535063, metrics-onlinereview/targets/approx_bleu_score = 0.006007597, metrics-onlinereview/targets/neg_log_perplexity = -6.0329967, metrics-onlinereview/targets/rouge_2_fscore = 0.026911188, metrics-onlinereview/targets/rouge_L_fscore = 0.14300902\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_file_v1/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20001): loss = 6.118474, metrics-onlinereview/targets/neg_log_perplexity = -6.0329967, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 20000, metrics-onlinereview/targets/approx_bleu_score = 0.006007597, metrics-onlinereview/targets/accuracy_top5 = 0.30535063, metrics-onlinereview/targets/rouge_2_fscore = 0.026911188, metrics-onlinereview/targets/accuracy = 0.14646558, metrics-onlinereview/targets/rouge_L_fscore = 0.14300902\n",
      "INFO:tensorflow:global_step/sec: 0.223464\n",
      "INFO:tensorflow:loss = 4.998704, step = 20100 (447.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.25673\n",
      "INFO:tensorflow:loss = 4.5544934, step = 20200 (79.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42415\n",
      "INFO:tensorflow:loss = 5.473774, step = 20300 (70.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36719\n",
      "INFO:tensorflow:loss = 5.4493146, step = 20400 (73.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35112\n",
      "INFO:tensorflow:loss = 5.4087353, step = 20500 (74.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32143\n",
      "INFO:tensorflow:loss = 7.0962443, step = 20600 (75.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36266\n",
      "INFO:tensorflow:loss = 4.876695, step = 20700 (73.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36535\n",
      "INFO:tensorflow:loss = 5.005794, step = 20800 (73.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35081\n",
      "INFO:tensorflow:loss = 4.8694625, step = 20900 (74.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33795\n",
      "INFO:tensorflow:loss = 4.791682, step = 21000 (74.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42733\n",
      "INFO:tensorflow:loss = 4.8101215, step = 21100 (70.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37701\n",
      "INFO:tensorflow:loss = 5.910554, step = 21200 (72.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34094\n",
      "INFO:tensorflow:loss = 5.157119, step = 21300 (74.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3832\n",
      "INFO:tensorflow:loss = 5.22992, step = 21400 (72.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41083\n",
      "INFO:tensorflow:loss = 4.1434183, step = 21500 (70.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38586\n",
      "INFO:tensorflow:loss = 5.755724, step = 21600 (72.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3265\n",
      "INFO:tensorflow:loss = 6.3688846, step = 21700 (75.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38579\n",
      "INFO:tensorflow:loss = 5.2625136, step = 21800 (72.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40742\n",
      "INFO:tensorflow:loss = 3.8090727, step = 21900 (71.065 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.2129\n",
      "INFO:tensorflow:loss = 4.888192, step = 22000 (82.440 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T03:16:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-03:22:20\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 6.113996, metrics-onlinereview/targets/accuracy = 0.14571856, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30572414, metrics-onlinereview/targets/approx_bleu_score = 0.005521014, metrics-onlinereview/targets/neg_log_perplexity = -6.0330853, metrics-onlinereview/targets/rouge_2_fscore = 0.02506089, metrics-onlinereview/targets/rouge_L_fscore = 0.14009188\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_file_v1/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22001): loss = 6.113996, metrics-onlinereview/targets/neg_log_perplexity = -6.0330853, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 22000, metrics-onlinereview/targets/approx_bleu_score = 0.005521014, metrics-onlinereview/targets/accuracy_top5 = 0.30572414, metrics-onlinereview/targets/rouge_2_fscore = 0.02506089, metrics-onlinereview/targets/accuracy = 0.14571856, metrics-onlinereview/targets/rouge_L_fscore = 0.14009188\n",
      "INFO:tensorflow:global_step/sec: 0.234584\n",
      "INFO:tensorflow:loss = 5.306472, step = 22100 (426.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35695\n",
      "INFO:tensorflow:loss = 5.8229303, step = 22200 (73.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.29992\n",
      "INFO:tensorflow:loss = 6.3522925, step = 22300 (76.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40813\n",
      "INFO:tensorflow:loss = 5.9316516, step = 22400 (71.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38268\n",
      "INFO:tensorflow:loss = 5.0413394, step = 22500 (72.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3854\n",
      "INFO:tensorflow:loss = 4.968439, step = 22600 (72.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3675\n",
      "INFO:tensorflow:loss = 5.720189, step = 22700 (73.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36445\n",
      "INFO:tensorflow:loss = 4.707661, step = 22800 (73.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39407\n",
      "INFO:tensorflow:loss = 5.4192843, step = 22900 (71.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36136\n",
      "INFO:tensorflow:loss = 5.70104, step = 23000 (73.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36415\n",
      "INFO:tensorflow:loss = 5.364554, step = 23100 (73.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41384\n",
      "INFO:tensorflow:loss = 5.6232014, step = 23200 (70.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43405\n",
      "INFO:tensorflow:loss = 5.164052, step = 23300 (69.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36459\n",
      "INFO:tensorflow:loss = 6.287996, step = 23400 (73.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35685\n",
      "INFO:tensorflow:loss = 5.495798, step = 23500 (73.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36859\n",
      "INFO:tensorflow:loss = 5.04962, step = 23600 (73.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34476\n",
      "INFO:tensorflow:loss = 5.589208, step = 23700 (74.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37162\n",
      "INFO:tensorflow:loss = 5.3130007, step = 23800 (72.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36275\n",
      "INFO:tensorflow:loss = 5.036575, step = 23900 (73.382 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23762\n",
      "INFO:tensorflow:loss = 4.896024, step = 24000 (80.797 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T03:46:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-03:53:07\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 6.068777, metrics-onlinereview/targets/accuracy = 0.14669904, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31221402, metrics-onlinereview/targets/approx_bleu_score = 0.0068357377, metrics-onlinereview/targets/neg_log_perplexity = -5.9851894, metrics-onlinereview/targets/rouge_2_fscore = 0.030523842, metrics-onlinereview/targets/rouge_L_fscore = 0.16022521\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_file_v1/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24001): loss = 6.068777, metrics-onlinereview/targets/neg_log_perplexity = -5.9851894, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 24000, metrics-onlinereview/targets/approx_bleu_score = 0.0068357377, metrics-onlinereview/targets/accuracy_top5 = 0.31221402, metrics-onlinereview/targets/rouge_2_fscore = 0.030523842, metrics-onlinereview/targets/accuracy = 0.14669904, metrics-onlinereview/targets/rouge_L_fscore = 0.16022521\n",
      "INFO:tensorflow:global_step/sec: 0.220502\n",
      "INFO:tensorflow:loss = 5.8879495, step = 24100 (453.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39295\n",
      "INFO:tensorflow:loss = 5.3170133, step = 24200 (71.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38124\n",
      "INFO:tensorflow:loss = 5.9134474, step = 24300 (72.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40948\n",
      "INFO:tensorflow:loss = 5.8182487, step = 24400 (70.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36632\n",
      "INFO:tensorflow:loss = 5.2242975, step = 24500 (73.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4067\n",
      "INFO:tensorflow:loss = 5.449936, step = 24600 (71.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40495\n",
      "INFO:tensorflow:loss = 4.6597013, step = 24700 (71.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40178\n",
      "INFO:tensorflow:loss = 3.5587287, step = 24800 (71.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37355\n",
      "INFO:tensorflow:loss = 5.3809724, step = 24900 (72.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39388\n",
      "INFO:tensorflow:loss = 5.234384, step = 25000 (71.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35276\n",
      "INFO:tensorflow:loss = 5.296148, step = 25100 (73.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39112\n",
      "INFO:tensorflow:loss = 8.000368, step = 25200 (71.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37449\n",
      "INFO:tensorflow:loss = 5.5616627, step = 25300 (72.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39214\n",
      "INFO:tensorflow:loss = 5.6034894, step = 25400 (71.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3798\n",
      "INFO:tensorflow:loss = 5.370342, step = 25500 (72.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3588\n",
      "INFO:tensorflow:loss = 5.488964, step = 25600 (73.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41422\n",
      "INFO:tensorflow:loss = 5.541659, step = 25700 (70.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36373\n",
      "INFO:tensorflow:loss = 5.5199175, step = 25800 (73.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41754\n",
      "INFO:tensorflow:loss = 4.658113, step = 25900 (70.546 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23909\n",
      "INFO:tensorflow:loss = 5.1194277, step = 26000 (80.703 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T04:17:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-04:23:01\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 6.082715, metrics-onlinereview/targets/accuracy = 0.1441778, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30530396, metrics-onlinereview/targets/approx_bleu_score = 0.0059212823, metrics-onlinereview/targets/neg_log_perplexity = -6.0017204, metrics-onlinereview/targets/rouge_2_fscore = 0.027421068, metrics-onlinereview/targets/rouge_L_fscore = 0.15074512\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_file_v1/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26001): loss = 6.082715, metrics-onlinereview/targets/neg_log_perplexity = -6.0017204, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 26000, metrics-onlinereview/targets/approx_bleu_score = 0.0059212823, metrics-onlinereview/targets/accuracy_top5 = 0.30530396, metrics-onlinereview/targets/rouge_2_fscore = 0.027421068, metrics-onlinereview/targets/accuracy = 0.1441778, metrics-onlinereview/targets/rouge_L_fscore = 0.15074512\n",
      "INFO:tensorflow:global_step/sec: 0.238842\n",
      "INFO:tensorflow:loss = 5.275516, step = 26100 (418.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42075\n",
      "INFO:tensorflow:loss = 4.457667, step = 26200 (70.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39065\n",
      "INFO:tensorflow:loss = 6.429537, step = 26300 (71.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34847\n",
      "INFO:tensorflow:loss = 4.3254075, step = 26400 (74.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39297\n",
      "INFO:tensorflow:loss = 6.240425, step = 26500 (71.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37292\n",
      "INFO:tensorflow:loss = 5.763892, step = 26600 (72.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39186\n",
      "INFO:tensorflow:loss = 5.1374855, step = 26700 (71.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30972\n",
      "INFO:tensorflow:loss = 6.016756, step = 26800 (76.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38028\n",
      "INFO:tensorflow:loss = 6.0471916, step = 26900 (72.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34162\n",
      "INFO:tensorflow:loss = 5.7513733, step = 27000 (74.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35474\n",
      "INFO:tensorflow:loss = 5.803107, step = 27100 (73.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42569\n",
      "INFO:tensorflow:loss = 5.4543443, step = 27200 (70.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35381\n",
      "INFO:tensorflow:loss = 5.306592, step = 27300 (73.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37776\n",
      "INFO:tensorflow:loss = 5.0368366, step = 27400 (72.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41914\n",
      "INFO:tensorflow:loss = 5.3726525, step = 27500 (70.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37321\n",
      "INFO:tensorflow:loss = 5.732678, step = 27600 (72.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37102\n",
      "INFO:tensorflow:loss = 5.3599114, step = 27700 (72.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33831\n",
      "INFO:tensorflow:loss = 5.404833, step = 27800 (74.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39162\n",
      "INFO:tensorflow:loss = 5.6863723, step = 27900 (71.858 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.23739\n",
      "INFO:tensorflow:loss = 5.4168353, step = 28000 (80.814 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T04:47:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-04:53:23\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 6.0575047, metrics-onlinereview/targets/accuracy = 0.15178822, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31431505, metrics-onlinereview/targets/approx_bleu_score = 0.0062709507, metrics-onlinereview/targets/neg_log_perplexity = -5.9580464, metrics-onlinereview/targets/rouge_2_fscore = 0.02911387, metrics-onlinereview/targets/rouge_L_fscore = 0.1509944\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_file_v1/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28001): loss = 6.0575047, metrics-onlinereview/targets/neg_log_perplexity = -5.9580464, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 28000, metrics-onlinereview/targets/approx_bleu_score = 0.0062709507, metrics-onlinereview/targets/accuracy_top5 = 0.31431505, metrics-onlinereview/targets/rouge_2_fscore = 0.02911387, metrics-onlinereview/targets/accuracy = 0.15178822, metrics-onlinereview/targets/rouge_L_fscore = 0.1509944\n",
      "INFO:tensorflow:global_step/sec: 0.231488\n",
      "INFO:tensorflow:loss = 5.8935614, step = 28100 (431.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.378\n",
      "INFO:tensorflow:loss = 5.5402102, step = 28200 (72.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32119\n",
      "INFO:tensorflow:loss = 4.816077, step = 28300 (75.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40451\n",
      "INFO:tensorflow:loss = 5.3368134, step = 28400 (71.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3998\n",
      "INFO:tensorflow:loss = 5.4371557, step = 28500 (71.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41423\n",
      "INFO:tensorflow:loss = 5.478585, step = 28600 (70.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42917\n",
      "INFO:tensorflow:loss = 7.1852155, step = 28700 (69.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37919\n",
      "INFO:tensorflow:loss = 4.967416, step = 28800 (72.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40606\n",
      "INFO:tensorflow:loss = 5.4134164, step = 28900 (71.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38041\n",
      "INFO:tensorflow:loss = 5.0009193, step = 29000 (72.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38595\n",
      "INFO:tensorflow:loss = 5.372158, step = 29100 (72.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37039\n",
      "INFO:tensorflow:loss = 4.5849514, step = 29200 (72.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37727\n",
      "INFO:tensorflow:loss = 5.1083236, step = 29300 (72.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40238\n",
      "INFO:tensorflow:loss = 6.3812165, step = 29400 (71.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43389\n",
      "INFO:tensorflow:loss = 5.3622456, step = 29500 (69.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35679\n",
      "INFO:tensorflow:loss = 5.690376, step = 29600 (73.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35022\n",
      "INFO:tensorflow:loss = 5.5378056, step = 29700 (74.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36119\n",
      "INFO:tensorflow:loss = 5.4654794, step = 29800 (73.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38792\n",
      "INFO:tensorflow:loss = 6.7704988, step = 29900 (72.051 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_file_v1/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 1.21534\n",
      "INFO:tensorflow:loss = 4.348468, step = 30000 (82.281 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T05:17:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-05:23:59\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 6.0651007, metrics-onlinereview/targets/accuracy = 0.15286207, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31333458, metrics-onlinereview/targets/approx_bleu_score = 0.0057481863, metrics-onlinereview/targets/neg_log_perplexity = -5.9783373, metrics-onlinereview/targets/rouge_2_fscore = 0.025680253, metrics-onlinereview/targets/rouge_L_fscore = 0.14488699\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_file_v1/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30001): loss = 6.0651007, metrics-onlinereview/targets/neg_log_perplexity = -5.9783373, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 30000, metrics-onlinereview/targets/approx_bleu_score = 0.0057481863, metrics-onlinereview/targets/accuracy_top5 = 0.31333458, metrics-onlinereview/targets/rouge_2_fscore = 0.025680253, metrics-onlinereview/targets/accuracy = 0.15286207, metrics-onlinereview/targets/rouge_L_fscore = 0.14488699\n",
      "INFO:tensorflow:global_step/sec: 0.220897\n",
      "INFO:tensorflow:loss = 5.2660165, step = 30100 (452.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37852\n",
      "INFO:tensorflow:loss = 5.178146, step = 30200 (72.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41796\n",
      "INFO:tensorflow:loss = 5.366917, step = 30300 (70.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38855\n",
      "INFO:tensorflow:loss = 5.362253, step = 30400 (72.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39413\n",
      "INFO:tensorflow:loss = 5.162743, step = 30500 (71.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39498\n",
      "INFO:tensorflow:loss = 5.1187124, step = 30600 (71.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39405\n",
      "INFO:tensorflow:loss = 4.6871424, step = 30700 (71.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40701\n",
      "INFO:tensorflow:loss = 5.590024, step = 30800 (71.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38225\n",
      "INFO:tensorflow:loss = 4.925518, step = 30900 (72.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36835\n",
      "INFO:tensorflow:loss = 5.959722, step = 31000 (73.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41065\n",
      "INFO:tensorflow:loss = 5.2878313, step = 31100 (70.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39284\n",
      "INFO:tensorflow:loss = 5.28498, step = 31200 (71.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35436\n",
      "INFO:tensorflow:loss = 5.148059, step = 31300 (73.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33403\n",
      "INFO:tensorflow:loss = 5.526043, step = 31400 (74.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34711\n",
      "INFO:tensorflow:loss = 5.11571, step = 31500 (74.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36179\n",
      "INFO:tensorflow:loss = 5.303258, step = 31600 (73.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41444\n",
      "INFO:tensorflow:loss = 5.3522186, step = 31700 (70.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38635\n",
      "INFO:tensorflow:loss = 6.442797, step = 31800 (72.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40407\n",
      "INFO:tensorflow:loss = 5.446026, step = 31900 (71.221 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.24094\n",
      "INFO:tensorflow:loss = 4.2251577, step = 32000 (80.583 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T05:48:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-05:54:02\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 6.0261726, metrics-onlinereview/targets/accuracy = 0.15552339, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31884396, metrics-onlinereview/targets/approx_bleu_score = 0.006426132, metrics-onlinereview/targets/neg_log_perplexity = -5.948828, metrics-onlinereview/targets/rouge_2_fscore = 0.02875843, metrics-onlinereview/targets/rouge_L_fscore = 0.15556072\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_file_v1/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32001): loss = 6.0261726, metrics-onlinereview/targets/neg_log_perplexity = -5.948828, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 32000, metrics-onlinereview/targets/approx_bleu_score = 0.006426132, metrics-onlinereview/targets/accuracy_top5 = 0.31884396, metrics-onlinereview/targets/rouge_2_fscore = 0.02875843, metrics-onlinereview/targets/accuracy = 0.15552339, metrics-onlinereview/targets/rouge_L_fscore = 0.15556072\n",
      "INFO:tensorflow:global_step/sec: 0.237697\n",
      "INFO:tensorflow:loss = 5.256192, step = 32100 (420.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.421\n",
      "INFO:tensorflow:loss = 5.7276154, step = 32200 (70.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42107\n",
      "INFO:tensorflow:loss = 4.6995454, step = 32300 (70.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37744\n",
      "INFO:tensorflow:loss = 5.3340406, step = 32400 (72.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37721\n",
      "INFO:tensorflow:loss = 5.073787, step = 32500 (72.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37715\n",
      "INFO:tensorflow:loss = 5.8807597, step = 32600 (72.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39444\n",
      "INFO:tensorflow:loss = 5.256448, step = 32700 (71.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38866\n",
      "INFO:tensorflow:loss = 5.3916106, step = 32800 (72.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40448\n",
      "INFO:tensorflow:loss = 5.0629826, step = 32900 (71.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42063\n",
      "INFO:tensorflow:loss = 5.189991, step = 33000 (70.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43035\n",
      "INFO:tensorflow:loss = 3.6237724, step = 33100 (69.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3798\n",
      "INFO:tensorflow:loss = 5.4985385, step = 33200 (72.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37338\n",
      "INFO:tensorflow:loss = 5.6137195, step = 33400 (72.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38825\n",
      "INFO:tensorflow:loss = 5.219327, step = 33500 (72.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.345\n",
      "INFO:tensorflow:loss = 5.635162, step = 33600 (74.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38517\n",
      "INFO:tensorflow:loss = 5.477452, step = 33700 (72.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42283\n",
      "INFO:tensorflow:loss = 5.7903175, step = 33800 (70.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37029\n",
      "INFO:tensorflow:loss = 5.9246955, step = 33900 (72.983 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.25327\n",
      "INFO:tensorflow:loss = 6.1562176, step = 34000 (79.789 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T06:18:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-06:24:09\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 6.02284, metrics-onlinereview/targets/accuracy = 0.15533663, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31954432, metrics-onlinereview/targets/approx_bleu_score = 0.0061465446, metrics-onlinereview/targets/neg_log_perplexity = -5.9320626, metrics-onlinereview/targets/rouge_2_fscore = 0.028424826, metrics-onlinereview/targets/rouge_L_fscore = 0.15083256\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_file_v1/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34001): loss = 6.02284, metrics-onlinereview/targets/neg_log_perplexity = -5.9320626, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 34000, metrics-onlinereview/targets/approx_bleu_score = 0.0061465446, metrics-onlinereview/targets/accuracy_top5 = 0.31954432, metrics-onlinereview/targets/rouge_2_fscore = 0.028424826, metrics-onlinereview/targets/accuracy = 0.15533663, metrics-onlinereview/targets/rouge_L_fscore = 0.15083256\n",
      "INFO:tensorflow:global_step/sec: 0.231263\n",
      "INFO:tensorflow:loss = 5.2730594, step = 34100 (432.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3871\n",
      "INFO:tensorflow:loss = 6.345861, step = 34200 (72.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3771\n",
      "INFO:tensorflow:loss = 5.576519, step = 34300 (72.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35444\n",
      "INFO:tensorflow:loss = 6.889335, step = 34400 (73.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34817\n",
      "INFO:tensorflow:loss = 5.6950045, step = 34500 (74.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38556\n",
      "INFO:tensorflow:loss = 5.0638304, step = 34600 (72.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35289\n",
      "INFO:tensorflow:loss = 3.5467813, step = 34700 (73.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32981\n",
      "INFO:tensorflow:loss = 6.4508224, step = 34800 (75.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40974\n",
      "INFO:tensorflow:loss = 5.3148413, step = 34900 (70.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35126\n",
      "INFO:tensorflow:loss = 5.2206016, step = 35000 (74.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44123\n",
      "INFO:tensorflow:loss = 5.213384, step = 35100 (69.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35754\n",
      "INFO:tensorflow:loss = 5.419023, step = 35200 (73.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40128\n",
      "INFO:tensorflow:loss = 4.805331, step = 35300 (71.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34238\n",
      "INFO:tensorflow:loss = 5.993348, step = 35400 (74.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41861\n",
      "INFO:tensorflow:loss = 6.64602, step = 35500 (70.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37041\n",
      "INFO:tensorflow:loss = 4.8406434, step = 35600 (72.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41827\n",
      "INFO:tensorflow:loss = 5.0790462, step = 35700 (70.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36055\n",
      "INFO:tensorflow:loss = 5.6524987, step = 35800 (73.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39738\n",
      "INFO:tensorflow:loss = 4.7926917, step = 35900 (71.564 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.25188\n",
      "INFO:tensorflow:loss = 5.4292793, step = 36000 (79.880 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T06:48:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-06:54:30\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 6.0233593, metrics-onlinereview/targets/accuracy = 0.1546363, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32071155, metrics-onlinereview/targets/approx_bleu_score = 0.006491999, metrics-onlinereview/targets/neg_log_perplexity = -5.94254, metrics-onlinereview/targets/rouge_2_fscore = 0.029732656, metrics-onlinereview/targets/rouge_L_fscore = 0.15468204\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_file_v1/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36001): loss = 6.0233593, metrics-onlinereview/targets/neg_log_perplexity = -5.94254, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 36000, metrics-onlinereview/targets/approx_bleu_score = 0.006491999, metrics-onlinereview/targets/accuracy_top5 = 0.32071155, metrics-onlinereview/targets/rouge_2_fscore = 0.029732656, metrics-onlinereview/targets/accuracy = 0.1546363, metrics-onlinereview/targets/rouge_L_fscore = 0.15468204\n",
      "INFO:tensorflow:global_step/sec: 0.230434\n",
      "INFO:tensorflow:loss = 5.2909627, step = 36100 (433.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4045\n",
      "INFO:tensorflow:loss = 5.2328277, step = 36200 (71.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34965\n",
      "INFO:tensorflow:loss = 4.58665, step = 36300 (74.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35916\n",
      "INFO:tensorflow:loss = 5.044024, step = 36400 (73.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36999\n",
      "INFO:tensorflow:loss = 5.2340055, step = 36500 (72.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34119\n",
      "INFO:tensorflow:loss = 5.0402484, step = 36600 (74.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3763\n",
      "INFO:tensorflow:loss = 4.8526716, step = 36700 (72.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41651\n",
      "INFO:tensorflow:loss = 5.4500895, step = 36800 (70.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34211\n",
      "INFO:tensorflow:loss = 5.28665, step = 36900 (74.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38738\n",
      "INFO:tensorflow:loss = 4.7183585, step = 37000 (72.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37835\n",
      "INFO:tensorflow:loss = 5.0874853, step = 37100 (72.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40353\n",
      "INFO:tensorflow:loss = 5.621849, step = 37200 (71.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44722\n",
      "INFO:tensorflow:loss = 5.320383, step = 37300 (69.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36741\n",
      "INFO:tensorflow:loss = 5.0989456, step = 37400 (73.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35026\n",
      "INFO:tensorflow:loss = 5.382256, step = 37500 (74.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36917\n",
      "INFO:tensorflow:loss = 4.9294844, step = 37600 (73.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35584\n",
      "INFO:tensorflow:loss = 6.479594, step = 37700 (73.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36613\n",
      "INFO:tensorflow:loss = 4.853098, step = 37800 (73.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43033\n",
      "INFO:tensorflow:loss = 5.1916995, step = 37900 (69.918 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.22077\n",
      "INFO:tensorflow:loss = 4.7059426, step = 38000 (81.911 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T07:18:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_v1/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-07:24:12\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 6.032048, metrics-onlinereview/targets/accuracy = 0.15309553, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32108507, metrics-onlinereview/targets/approx_bleu_score = 0.0066493168, metrics-onlinereview/targets/neg_log_perplexity = -5.9427752, metrics-onlinereview/targets/rouge_2_fscore = 0.029675465, metrics-onlinereview/targets/rouge_L_fscore = 0.15491511\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_file_v1/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38001): loss = 6.032048, metrics-onlinereview/targets/neg_log_perplexity = -5.9427752, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 38000, metrics-onlinereview/targets/approx_bleu_score = 0.0066493168, metrics-onlinereview/targets/accuracy_top5 = 0.32108507, metrics-onlinereview/targets/rouge_2_fscore = 0.029675465, metrics-onlinereview/targets/accuracy = 0.15309553, metrics-onlinereview/targets/rouge_L_fscore = 0.15491511\n",
      "INFO:tensorflow:global_step/sec: 0.252788\n",
      "INFO:tensorflow:loss = 5.265899, step = 38100 (395.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36108\n",
      "INFO:tensorflow:loss = 5.4882274, step = 38200 (73.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38683\n",
      "INFO:tensorflow:loss = 4.780855, step = 38300 (72.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37484\n",
      "INFO:tensorflow:loss = 4.8747888, step = 38400 (72.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35877\n",
      "INFO:tensorflow:loss = 4.7764654, step = 38500 (73.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44771\n",
      "INFO:tensorflow:loss = 5.5853486, step = 38600 (69.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35923\n",
      "INFO:tensorflow:loss = 5.833613, step = 38700 (73.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38781\n",
      "INFO:tensorflow:loss = 5.179281, step = 38800 (72.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36386\n",
      "INFO:tensorflow:loss = 4.901767, step = 38900 (73.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35441\n",
      "INFO:tensorflow:loss = 3.6755784, step = 39000 (73.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36721\n",
      "INFO:tensorflow:loss = 5.2564597, step = 39100 (73.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34129\n",
      "INFO:tensorflow:loss = 5.129712, step = 39200 (74.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4321\n",
      "INFO:tensorflow:loss = 5.651293, step = 39300 (69.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41048\n",
      "INFO:tensorflow:loss = 5.3530693, step = 39400 (70.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37927\n",
      "INFO:tensorflow:loss = 5.111057, step = 39500 (72.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39652\n",
      "INFO:tensorflow:loss = 5.1932178, step = 39600 (71.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35044\n",
      "INFO:tensorflow:loss = 5.3295856, step = 39700 (74.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39587\n",
      "INFO:tensorflow:loss = 5.0200243, step = 39800 (71.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40781\n",
      "INFO:tensorflow:loss = 4.9016533, step = 39900 (71.035 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_v1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.653999.\n",
      "Time: 27279.99 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_v1'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 2048 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "# hparams.num_encoder_layers = 2\n",
    "# hparams.num_hidden_layers = 6\n",
    "# hparams.num_decoder_layers = 2 \n",
    "# hparams.dropout =0.4\n",
    "# hparams.num_heads =16\n",
    "# hparams.attention_dropout = 0.5 ##\n",
    "# hparams.max_input_seq_length = ????\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40000,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=1000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     checkpoints = []\n",
    "#     if not os.path.exists('Data/Checkpoints/'):\n",
    "#         os.makedirs('Data/Checkpoints/')\n",
    "#     checkpoints.append(ModelCheckpoint('Data/Checkpoints/best_weights.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1))\n",
    "#     checkpoints.append(TensorBoard(log_dir='Data/Checkpoints/./logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------decoding check-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_file_v1', '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None, 'use_tpu': False, '_save_checkpoints_steps': 1000, '_tf_random_seed': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_task_id': 0, '_task_type': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_device_fn': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_master': '', '_num_ps_replicas': 0, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc3e2d59908>, '_evaluation_master': '', '_environment': 'local', '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc27bb07b70>, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc4843c0c80>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_v1\") #model.ckpt\n",
    "\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# #Restore and summarize\n",
    "# def summarize(inputs):\n",
    "#     encoded_inputs = encode(inputs)\n",
    "#     with tfe.restore_variables_on_create(ckpt_path):\n",
    "#         model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "#     return decode(model_output)\n",
    "\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "# # inputs = '''\n",
    "# # happy with purchase even though it came a lot later than expected.'''\n",
    "# outputs = summarize(inputs)\n",
    "\n",
    "# print(\"Inputs: %s\" % inputs)\n",
    "# print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_file_v1/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"they the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\"\tScore:-273.903870\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\"they the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the a\"\tScore:-275.411835\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">q\n"
     ]
    }
   ],
   "source": [
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_file_v1/model.ckpt-40000'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create hparams and the model\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=ende_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_v1/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "\n",
      "Outputs: to a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = t2t_model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "# inputs = '''\n",
    "# happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
      "\n",
      "Outputs: peter peter;the muppetical american novel features a protagonist protagonist muppetan afterthought in which realworld both physical and moral challenges and through which through which receivers with a buddhist spirit, by the eduble of muppets with beads, both real and ignored  create florida engaging water for learning is an nonprofamerican work, set, set in the depths of the depression and featuring a young man whose assistance d create create create create create create create of faith him into a and unknown way of life life remaining;\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n",
    "\n",
    "\n",
    "inputs = '''\n",
    "the archetypical american novel features a solitary protagonist undertaking an odyssey in which heshe confronts both physical and moral challenges and through which heshe emerges with a renewed spirit, transformed by the crucible of confrontations with adversaries, both real and imagined  sara gruens engaging water for elephants is an eminently american work, set in the depths of the depression and featuring a brokenhearted young man whose unplanned existential leap of faith catapults him into a chaotic and unknown way of life\n",
    "'''\n",
    "# inputs = '''\n",
    "# happy with purchase even though it came a lot later than expected.'''\n",
    "outputs = summarize(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc51491b320>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fc51491b278>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc5147b6ba8>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fc5147b6ba8>}), ('was_copy', False), ('was_reversed', False)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.problem_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_smoothing': 0.1, 'learning_rate_constant': 1.0, 'optimizer_multistep_accumulate_steps': None, 'learning_rate_warmup_steps': 8000, 'optimizer_adafactor_decay_type': 'pow', 'use_fixed_batch_size': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'multiply_embedding_mode': 'sqrt_depth', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'parameter_attention_key_channels': 0, 'summarize_grads': False, 'num_hidden_layers': 6, 'pad_batch': False, 'weight_noise': 0.0, 'learning_rate_decay_scheme': 'noam', 'multiproblem_fixed_train_length': -1, 'max_target_seq_length': 0, 'kernel_height': 3, 'dropout': 0.2, 'grad_noise_scale': 0.0, 'learning_rate_minimum': None, 'ffn_layer': 'dense_relu_dense', 'optimizer_adafactor_memory_exponent': 0.8, 'force_full_predict': False, 'multiproblem_mixing_schedule': 'constant', 'min_length': 0, 'shared_embedding': False, 'optimizer_adam_beta1': 0.9, 'num_decoder_layers': 0, 'factored_logits': False, 'layer_preprocess_sequence': 'n', 'proximity_bias': False, 'attention_key_channels': 0, 'kernel_width': 1, 'layer_prepostprocess_dropout': 0.1, 'conv_first_kernel': 3, 'video_num_input_frames': 1, 'learning_rate': 0.1, 'moe_overhead_train': 1.0, 'norm_type': 'layer', 'mlperf_mode': False, 'optimizer_adafactor_beta1': 0.0, 'split_to_length': 0, 'attention_value_channels': 0, 'eval_run_autoregressive': False, 'num_heads': 8, 'attention_dropout_broadcast_dims': '', 'unidirectional_encoder': False, 'vocab_divisor': 1, 'weight_dtype': 'float32', 'max_relative_position': 0, 'relu_dropout_broadcast_dims': '', 'tpu_enable_host_call': False, 'causal_decoder_self_attention': True, 'add_relative_to_values': False, 'layer_prepostprocess_dropout_broadcast_dims': '', 'symbol_modality_skip_top': False, 'optimizer_adafactor_factored': True, 'multiproblem_vocab_size': -1, 'eval_drop_long_sequences': False, 'clip_grad_norm': 0.0, 'nbr_decoder_problems': 1, 'multiproblem_reweight_label_loss': False, 'optimizer_adafactor_beta2': 0.999, 'norm_epsilon': 1e-06, 'learning_rate_decay_steps': 5000, 'heads_share_relative_embedding': False, 'num_encoder_layers': 0, 'symbol_modality_num_shards': 16, 'symbol_dropout': 0.0, 'max_length': 0, 'moe_k': 2, 'length_bucket_step': 1.1, 'layer_postprocess_sequence': 'da', 'multiproblem_max_input_length': -1, 'summarize_vars': False, 'multiproblem_schedule_max_examples': 10000000.0, 'max_input_seq_length': 1024, 'learning_rate_cosine_cycle_steps': 250000, 'pretrained_model_dir': '', 'overload_eval_metric_name': '', 'sampling_method': 'argmax', 'learning_rate_decay_staircase': False, 'activation_dtype': 'float32', 'multiproblem_max_target_length': -1, 'moe_num_experts': 16, 'use_pad_remover': True, 'sampling_temp': 1.0, 'learning_rate_schedule': 'legacy', 'attention_dropout': 0.2, 'modality': {}, 'hidden_size': 512, 'weight_decay': 0.0, 'no_data_parallelism': False, 'pos': 'timing', 'initializer': 'uniform_unit_scaling', 'use_target_space_embedding': True, 'batch_shuffle_size': 512, 'multiproblem_target_eval_only': False, 'attention_variables_3d': False, 'scheduled_sampling_warmup_steps': 50000, 'optimizer_adafactor_clipping_threshold': 1.0, 'shared_embedding_and_softmax_weights': True, 'moe_loss_coef': 0.001, 'batch_size': 2048, 'optimizer_zero_grads': False, 'optimizer_momentum_momentum': 0.9, 'initializer_gain': 1.0, 'multiproblem_schedule_threshold': 0.5, 'filter_size': 2048, 'moe_overhead_eval': 2.0, 'parameter_attention_value_channels': 0, 'video_num_target_frames': 1, 'multiproblem_label_weight': 0.5, 'optimizer_adam_epsilon': 1e-09, 'optimizer_adam_beta2': 0.98, 'warm_start_from_second': '', 'compress_steps': 0, 'min_length_bucket': 8, 'multiproblem_per_task_threshold': '', 'learning_rate_decay_rate': 1.0, 'relu_dropout': 0.1, 'scheduled_sampling_prob': 0.0, 'moe_hidden_sizes': '2048', 'optimizer_momentum_nesterov': False, 'self_attention_type': 'dot_product', 'optimizer': 'Adam', 'prepend_mode': 'prepend_inputs_full_attention', 'daisy_chain_variables': True}\n",
      "{'decode_to_file': None, 'max_input_size': -1, 'eos_penalty': 0.0, 'shard_google_format': False, 'guess_and_check_top_k': 0, 'identity_output': False, 'batch_size': 0, 'mlperf_decode_step': 0.0, 'alpha': 0.6, 'num_samples': -1, 'write_beam_scores': False, 'log_results': True, 'max_display_outputs': 10, 'force_decode_length': False, 'beam_size': 4, 'vgg_ckpt_path': '', 'shards': 1, 'guess_and_check_epsilon': -1, 'decode_timeout_mins': 240, 'save_images': False, 'shard_id': 0, 'decode_in_memory': False, 'frames_per_second': 10, 'extra_length': 100, 'display_decoded_images': False, 'mlperf_threshold': 25.0, 'block_size': 0, 'border_percent': 2, 'delimiter': '\\n', 'mlperf_success': False, 'summaries_log_dir': 'decode', 'multiproblem_task_id': -1, 'max_display_decodes': 5, 'num_decodes': 1, 'skip_eos_postprocess': False, 'return_beams': True, 'shards_start_offset': 0}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f338c30b470>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_keep_checkpoint_max': 20, '_num_ps_replicas': 0, '_train_distribute': None, '_master': '', '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, 't2t_device_info': {'num_async_replicas': 1}, '_log_step_count_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f338c30b4a8>, '_tf_random_seed': None, '_model_dir': 'model_file_1024', '_is_chief': True, '_save_checkpoints_steps': 2000, '_protocol': None, 'use_tpu': False, '_evaluation_master': '', '_task_type': None, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f338dd6b8c8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f338c30b240>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f338c30b2e8>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9e80>, 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9e80>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.770576, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.29689\n",
      "INFO:tensorflow:loss = 8.474687, step = 100 (77.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43305\n",
      "INFO:tensorflow:loss = 7.4154024, step = 200 (69.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45241\n",
      "INFO:tensorflow:loss = 7.140645, step = 300 (68.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4319\n",
      "INFO:tensorflow:loss = 6.9852133, step = 400 (69.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46155\n",
      "INFO:tensorflow:loss = 6.3340445, step = 500 (68.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39018\n",
      "INFO:tensorflow:loss = 6.7953463, step = 600 (71.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42654\n",
      "INFO:tensorflow:loss = 6.0979958, step = 700 (70.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46319\n",
      "INFO:tensorflow:loss = 5.415983, step = 800 (68.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46071\n",
      "INFO:tensorflow:loss = 5.648411, step = 900 (68.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43433\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T08:31:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-08:34:51\n",
      "INFO:tensorflow:Saving dict for global step 0: global_step = 0, loss = 11.0515995, metrics-onlinereview/targets/accuracy = 0.0005135867, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.0005135867, metrics-onlinereview/targets/approx_bleu_score = 0.9623243, metrics-onlinereview/targets/neg_log_perplexity = -11.070524, metrics-onlinereview/targets/rouge_2_fscore = 0.9815187, metrics-onlinereview/targets/rouge_L_fscore = 0.96953005\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: model_file_1024/model.ckpt-0\n",
      "INFO:tensorflow:Validation (step 1000): metrics-onlinereview/targets/accuracy = 0.0005135867, metrics-onlinereview/targets/rouge_L_fscore = 0.96953005, metrics-onlinereview/targets/approx_bleu_score = 0.9623243, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 0, loss = 11.0515995, metrics-onlinereview/targets/rouge_2_fscore = 0.9815187, metrics-onlinereview/targets/neg_log_perplexity = -11.070524, metrics-onlinereview/targets/accuracy_top5 = 0.0005135867\n",
      "INFO:tensorflow:loss = 6.0966616, step = 1000 (299.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.335307\n",
      "INFO:tensorflow:loss = 6.0009837, step = 1100 (68.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4323\n",
      "INFO:tensorflow:loss = 6.0174203, step = 1200 (69.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46812\n",
      "INFO:tensorflow:loss = 6.114157, step = 1300 (68.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42044\n",
      "INFO:tensorflow:loss = 6.485152, step = 1400 (70.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45493\n",
      "INFO:tensorflow:loss = 5.2633862, step = 1500 (68.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43675\n",
      "INFO:tensorflow:loss = 5.589402, step = 1600 (69.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46726\n",
      "INFO:tensorflow:loss = 6.446329, step = 1700 (68.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42254\n",
      "INFO:tensorflow:loss = 7.1443377, step = 1800 (70.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48515\n",
      "INFO:tensorflow:loss = 5.257056, step = 1900 (67.336 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28452\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T08:46:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-08:50:29\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.5215197, metrics-onlinereview/targets/accuracy = 0.11667756, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.24698852, metrics-onlinereview/targets/approx_bleu_score = 0.0035763844, metrics-onlinereview/targets/neg_log_perplexity = -6.465775, metrics-onlinereview/targets/rouge_2_fscore = 0.015278744, metrics-onlinereview/targets/rouge_L_fscore = 0.10692082\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_1024/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-onlinereview/targets/accuracy = 0.11667756, metrics-onlinereview/targets/rouge_L_fscore = 0.10692082, metrics-onlinereview/targets/approx_bleu_score = 0.0035763844, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 2000, loss = 6.5215197, metrics-onlinereview/targets/rouge_2_fscore = 0.015278744, metrics-onlinereview/targets/neg_log_perplexity = -6.465775, metrics-onlinereview/targets/accuracy_top5 = 0.24698852\n",
      "INFO:tensorflow:loss = 6.103618, step = 2000 (317.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.324196\n",
      "INFO:tensorflow:loss = 5.945787, step = 2100 (69.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48592\n",
      "INFO:tensorflow:loss = 6.1591687, step = 2200 (67.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44197\n",
      "INFO:tensorflow:loss = 5.7320733, step = 2300 (69.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41844\n",
      "INFO:tensorflow:loss = 6.049508, step = 2400 (70.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40872\n",
      "INFO:tensorflow:loss = 5.8643894, step = 2500 (70.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4581\n",
      "INFO:tensorflow:loss = 5.735228, step = 2600 (68.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4443\n",
      "INFO:tensorflow:loss = 5.455402, step = 2700 (69.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45994\n",
      "INFO:tensorflow:loss = 5.8682413, step = 2800 (68.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45167\n",
      "INFO:tensorflow:loss = 4.5194893, step = 2900 (68.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47318\n",
      "INFO:tensorflow:loss = 6.584581, step = 3000 (67.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42075\n",
      "INFO:tensorflow:loss = 5.8924537, step = 3100 (70.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44141\n",
      "INFO:tensorflow:loss = 5.059181, step = 3200 (69.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45052\n",
      "INFO:tensorflow:loss = 5.6358476, step = 3300 (68.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44366\n",
      "INFO:tensorflow:loss = 5.2168803, step = 3400 (69.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44541\n",
      "INFO:tensorflow:loss = 6.069017, step = 3500 (69.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42193\n",
      "INFO:tensorflow:loss = 6.601388, step = 3600 (70.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44604\n",
      "INFO:tensorflow:loss = 5.3086915, step = 3700 (69.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42842\n",
      "INFO:tensorflow:loss = 5.761847, step = 3800 (70.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44877\n",
      "INFO:tensorflow:loss = 4.8947954, step = 3900 (69.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29786\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T09:13:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-09:17:43\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 6.3023176, metrics-onlinereview/targets/accuracy = 0.13161826, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.27897096, metrics-onlinereview/targets/approx_bleu_score = 0.007836981, metrics-onlinereview/targets/neg_log_perplexity = -6.2329416, metrics-onlinereview/targets/rouge_2_fscore = 0.032367717, metrics-onlinereview/targets/rouge_L_fscore = 0.15846929\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_1024/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-onlinereview/targets/accuracy = 0.13161826, metrics-onlinereview/targets/rouge_L_fscore = 0.15846929, metrics-onlinereview/targets/approx_bleu_score = 0.007836981, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 4000, loss = 6.3023176, metrics-onlinereview/targets/rouge_2_fscore = 0.032367717, metrics-onlinereview/targets/neg_log_perplexity = -6.2329416, metrics-onlinereview/targets/accuracy_top5 = 0.27897096\n",
      "INFO:tensorflow:loss = 4.304379, step = 4000 (317.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.323442\n",
      "INFO:tensorflow:loss = 4.093212, step = 4100 (68.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43183\n",
      "INFO:tensorflow:loss = 6.1118064, step = 4200 (69.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46332\n",
      "INFO:tensorflow:loss = 5.3247337, step = 4300 (68.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42205\n",
      "INFO:tensorflow:loss = 5.24512, step = 4400 (70.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45273\n",
      "INFO:tensorflow:loss = 6.1704507, step = 4500 (68.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44917\n",
      "INFO:tensorflow:loss = 6.2087417, step = 4600 (68.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44543\n",
      "INFO:tensorflow:loss = 4.8068466, step = 4700 (69.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43643\n",
      "INFO:tensorflow:loss = 6.3497024, step = 4800 (69.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45181\n",
      "INFO:tensorflow:loss = 5.6760216, step = 4900 (68.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40716\n",
      "INFO:tensorflow:loss = 6.027562, step = 5000 (71.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41046\n",
      "INFO:tensorflow:loss = 5.375517, step = 5100 (70.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44989\n",
      "INFO:tensorflow:loss = 5.963265, step = 5200 (68.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43721\n",
      "INFO:tensorflow:loss = 5.466444, step = 5300 (69.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45018\n",
      "INFO:tensorflow:loss = 5.7370815, step = 5400 (68.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43402\n",
      "INFO:tensorflow:loss = 5.341766, step = 5500 (69.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42859\n",
      "INFO:tensorflow:loss = 5.6707344, step = 5600 (69.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46657\n",
      "INFO:tensorflow:loss = 5.1341405, step = 5700 (68.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44643\n",
      "INFO:tensorflow:loss = 5.030021, step = 5800 (69.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46242\n",
      "INFO:tensorflow:loss = 6.3985853, step = 5900 (68.378 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28752\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T09:41:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-09:44:59\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 6.297705, metrics-onlinereview/targets/accuracy = 0.13535345, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.28438696, metrics-onlinereview/targets/approx_bleu_score = 0.0060779965, metrics-onlinereview/targets/neg_log_perplexity = -6.218066, metrics-onlinereview/targets/rouge_2_fscore = 0.02686138, metrics-onlinereview/targets/rouge_L_fscore = 0.1471846\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_1024/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-onlinereview/targets/accuracy = 0.13535345, metrics-onlinereview/targets/rouge_L_fscore = 0.1471846, metrics-onlinereview/targets/approx_bleu_score = 0.0060779965, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 6000, loss = 6.297705, metrics-onlinereview/targets/rouge_2_fscore = 0.02686138, metrics-onlinereview/targets/neg_log_perplexity = -6.218066, metrics-onlinereview/targets/accuracy_top5 = 0.28438696\n",
      "INFO:tensorflow:loss = 5.3594885, step = 6000 (319.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.321398\n",
      "INFO:tensorflow:loss = 5.543237, step = 6100 (69.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45603\n",
      "INFO:tensorflow:loss = 5.363432, step = 6200 (68.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42449\n",
      "INFO:tensorflow:loss = 5.229918, step = 6300 (70.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44854\n",
      "INFO:tensorflow:loss = 5.9069057, step = 6400 (69.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49185\n",
      "INFO:tensorflow:loss = 5.8393736, step = 6500 (67.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41731\n",
      "INFO:tensorflow:loss = 5.9459743, step = 6600 (70.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46593\n",
      "INFO:tensorflow:loss = 5.7445073, step = 6700 (68.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4629\n",
      "INFO:tensorflow:loss = 5.659652, step = 6800 (68.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46161\n",
      "INFO:tensorflow:loss = 6.29222, step = 6900 (68.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44072\n",
      "INFO:tensorflow:loss = 5.128782, step = 7000 (69.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45667\n",
      "INFO:tensorflow:loss = 6.9421644, step = 7100 (68.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44679\n",
      "INFO:tensorflow:loss = 5.3076425, step = 7200 (69.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.423\n",
      "INFO:tensorflow:loss = 5.9486914, step = 7300 (70.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40875\n",
      "INFO:tensorflow:loss = 5.275352, step = 7400 (70.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46435\n",
      "INFO:tensorflow:loss = 5.2331333, step = 7500 (68.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46359\n",
      "INFO:tensorflow:loss = 5.4384637, step = 7600 (68.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47257\n",
      "INFO:tensorflow:loss = 6.199023, step = 7700 (67.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43053\n",
      "INFO:tensorflow:loss = 5.5056577, step = 7800 (69.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4279\n",
      "INFO:tensorflow:loss = 5.1543703, step = 7900 (70.031 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28058\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T10:08:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-10:12:18\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 6.192898, metrics-onlinereview/targets/accuracy = 0.14086282, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.2951256, metrics-onlinereview/targets/approx_bleu_score = 0.007178058, metrics-onlinereview/targets/neg_log_perplexity = -6.103052, metrics-onlinereview/targets/rouge_2_fscore = 0.032307442, metrics-onlinereview/targets/rouge_L_fscore = 0.16124889\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_file_1024/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-onlinereview/targets/accuracy = 0.14086282, metrics-onlinereview/targets/rouge_L_fscore = 0.16124889, metrics-onlinereview/targets/approx_bleu_score = 0.007178058, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 8000, loss = 6.192898, metrics-onlinereview/targets/rouge_2_fscore = 0.032307442, metrics-onlinereview/targets/neg_log_perplexity = -6.103052, metrics-onlinereview/targets/accuracy_top5 = 0.2951256\n",
      "INFO:tensorflow:loss = 5.105674, step = 8000 (325.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.315769\n",
      "INFO:tensorflow:loss = 5.0658717, step = 8100 (69.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4771\n",
      "INFO:tensorflow:loss = 5.585265, step = 8200 (67.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42815\n",
      "INFO:tensorflow:loss = 4.9085226, step = 8300 (70.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47569\n",
      "INFO:tensorflow:loss = 5.4031005, step = 8400 (67.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44615\n",
      "INFO:tensorflow:loss = 7.0974736, step = 8500 (69.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43366\n",
      "INFO:tensorflow:loss = 4.7616, step = 8600 (69.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43682\n",
      "INFO:tensorflow:loss = 4.797701, step = 8700 (69.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49153\n",
      "INFO:tensorflow:loss = 6.1875443, step = 8800 (67.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46188\n",
      "INFO:tensorflow:loss = 5.080865, step = 8900 (68.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45429\n",
      "INFO:tensorflow:loss = 5.163539, step = 9000 (68.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45228\n",
      "INFO:tensorflow:loss = 4.752872, step = 9100 (68.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46916\n",
      "INFO:tensorflow:loss = 6.111898, step = 9200 (68.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43627\n",
      "INFO:tensorflow:loss = 5.032136, step = 9300 (69.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4608\n",
      "INFO:tensorflow:loss = 5.361062, step = 9400 (68.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45906\n",
      "INFO:tensorflow:loss = 6.3446107, step = 9500 (68.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41775\n",
      "INFO:tensorflow:loss = 5.407556, step = 9600 (70.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43605\n",
      "INFO:tensorflow:loss = 5.452623, step = 9700 (69.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42303\n",
      "INFO:tensorflow:loss = 5.100716, step = 9800 (70.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46019\n",
      "INFO:tensorflow:loss = 5.4086623, step = 9900 (68.485 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29129\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T10:35:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-10:39:33\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 6.1126122, metrics-onlinereview/targets/accuracy = 0.15169483, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.30259594, metrics-onlinereview/targets/approx_bleu_score = 0.0068740374, metrics-onlinereview/targets/neg_log_perplexity = -6.0281157, metrics-onlinereview/targets/rouge_2_fscore = 0.030308122, metrics-onlinereview/targets/rouge_L_fscore = 0.15593894\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_file_1024/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-onlinereview/targets/accuracy = 0.15169483, metrics-onlinereview/targets/rouge_L_fscore = 0.15593894, metrics-onlinereview/targets/approx_bleu_score = 0.0068740374, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 10000, loss = 6.1126122, metrics-onlinereview/targets/rouge_2_fscore = 0.030308122, metrics-onlinereview/targets/neg_log_perplexity = -6.0281157, metrics-onlinereview/targets/accuracy_top5 = 0.30259594\n",
      "INFO:tensorflow:loss = 5.2055845, step = 10000 (324.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.315917\n",
      "INFO:tensorflow:loss = 4.5901747, step = 10100 (69.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43277\n",
      "INFO:tensorflow:loss = 5.107212, step = 10200 (69.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44082\n",
      "INFO:tensorflow:loss = 5.3095565, step = 10300 (69.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43882\n",
      "INFO:tensorflow:loss = 4.331663, step = 10400 (69.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45516\n",
      "INFO:tensorflow:loss = 5.6070566, step = 10500 (68.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45179\n",
      "INFO:tensorflow:loss = 5.5458517, step = 10600 (68.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42999\n",
      "INFO:tensorflow:loss = 5.1919146, step = 10700 (69.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45623\n",
      "INFO:tensorflow:loss = 5.444103, step = 10800 (68.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.433\n",
      "INFO:tensorflow:loss = 5.4508023, step = 10900 (69.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40235\n",
      "INFO:tensorflow:loss = 5.051626, step = 11000 (71.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42092\n",
      "INFO:tensorflow:loss = 5.290074, step = 11100 (70.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4312\n",
      "INFO:tensorflow:loss = 5.121175, step = 11200 (69.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41639\n",
      "INFO:tensorflow:loss = 4.8975368, step = 11300 (70.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41843\n",
      "INFO:tensorflow:loss = 4.525736, step = 11400 (70.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45968\n",
      "INFO:tensorflow:loss = 6.2388773, step = 11500 (68.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40887\n",
      "INFO:tensorflow:loss = 5.445615, step = 11600 (70.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45351\n",
      "INFO:tensorflow:loss = 5.471923, step = 11700 (68.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41945\n",
      "INFO:tensorflow:loss = 5.150622, step = 11800 (70.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42679\n",
      "INFO:tensorflow:loss = 6.5163326, step = 11900 (70.090 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.26982\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T11:03:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-11:06:58\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 6.0685377, metrics-onlinereview/targets/accuracy = 0.14945373, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3140816, metrics-onlinereview/targets/approx_bleu_score = 0.0065573025, metrics-onlinereview/targets/neg_log_perplexity = -5.9846625, metrics-onlinereview/targets/rouge_2_fscore = 0.03142793, metrics-onlinereview/targets/rouge_L_fscore = 0.15420105\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_file_1024/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-onlinereview/targets/accuracy = 0.14945373, metrics-onlinereview/targets/rouge_L_fscore = 0.15420105, metrics-onlinereview/targets/approx_bleu_score = 0.0065573025, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 12000, loss = 6.0685377, metrics-onlinereview/targets/rouge_2_fscore = 0.03142793, metrics-onlinereview/targets/neg_log_perplexity = -5.9846625, metrics-onlinereview/targets/accuracy_top5 = 0.3140816\n",
      "INFO:tensorflow:loss = 5.8580008, step = 12000 (320.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.323674\n",
      "INFO:tensorflow:loss = 6.077808, step = 12100 (67.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46191\n",
      "INFO:tensorflow:loss = 5.5282516, step = 12200 (68.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45706\n",
      "INFO:tensorflow:loss = 4.499129, step = 12300 (68.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44669\n",
      "INFO:tensorflow:loss = 4.917034, step = 12400 (69.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44145\n",
      "INFO:tensorflow:loss = 4.5351176, step = 12500 (69.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43465\n",
      "INFO:tensorflow:loss = 5.488203, step = 12600 (69.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44415\n",
      "INFO:tensorflow:loss = 5.315154, step = 12700 (69.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4542\n",
      "INFO:tensorflow:loss = 6.0830183, step = 12800 (68.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42049\n",
      "INFO:tensorflow:loss = 5.7929273, step = 12900 (70.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43146\n",
      "INFO:tensorflow:loss = 5.0163393, step = 13000 (69.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43715\n",
      "INFO:tensorflow:loss = 4.965904, step = 13100 (69.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46118\n",
      "INFO:tensorflow:loss = 5.2292414, step = 13200 (68.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4101\n",
      "INFO:tensorflow:loss = 4.752645, step = 13300 (70.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45568\n",
      "INFO:tensorflow:loss = 4.873629, step = 13400 (68.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45297\n",
      "INFO:tensorflow:loss = 6.7284503, step = 13500 (68.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4399\n",
      "INFO:tensorflow:loss = 4.6238637, step = 13600 (69.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42889\n",
      "INFO:tensorflow:loss = 5.8172803, step = 13700 (69.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42719\n",
      "INFO:tensorflow:loss = 6.273542, step = 13800 (70.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42308\n",
      "INFO:tensorflow:loss = 4.709913, step = 13900 (70.270 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.26887\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T11:30:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-11:34:16\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 6.063507, metrics-onlinereview/targets/accuracy = 0.15421608, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31170043, metrics-onlinereview/targets/approx_bleu_score = 0.007472696, metrics-onlinereview/targets/neg_log_perplexity = -5.9796333, metrics-onlinereview/targets/rouge_2_fscore = 0.033762313, metrics-onlinereview/targets/rouge_L_fscore = 0.15894845\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_file_1024/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-onlinereview/targets/accuracy = 0.15421608, metrics-onlinereview/targets/rouge_L_fscore = 0.15894845, metrics-onlinereview/targets/approx_bleu_score = 0.007472696, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 14000, loss = 6.063507, metrics-onlinereview/targets/rouge_2_fscore = 0.033762313, metrics-onlinereview/targets/neg_log_perplexity = -5.9796333, metrics-onlinereview/targets/accuracy_top5 = 0.31170043\n",
      "INFO:tensorflow:loss = 6.2074223, step = 14000 (320.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.322404\n",
      "INFO:tensorflow:loss = 4.8176236, step = 14100 (68.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43303\n",
      "INFO:tensorflow:loss = 5.3861074, step = 14200 (69.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46781\n",
      "INFO:tensorflow:loss = 4.4412293, step = 14300 (68.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45751\n",
      "INFO:tensorflow:loss = 5.249289, step = 14400 (68.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45577\n",
      "INFO:tensorflow:loss = 4.85845, step = 14500 (68.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44141\n",
      "INFO:tensorflow:loss = 5.004478, step = 14600 (69.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42879\n",
      "INFO:tensorflow:loss = 5.081585, step = 14700 (69.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43564\n",
      "INFO:tensorflow:loss = 5.799625, step = 14800 (69.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4304\n",
      "INFO:tensorflow:loss = 5.006578, step = 14900 (69.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45736\n",
      "INFO:tensorflow:loss = 5.28285, step = 15000 (68.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4164\n",
      "INFO:tensorflow:loss = 5.362399, step = 15100 (70.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4397\n",
      "INFO:tensorflow:loss = 4.7875166, step = 15200 (69.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45692\n",
      "INFO:tensorflow:loss = 5.018182, step = 15300 (68.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40884\n",
      "INFO:tensorflow:loss = 4.3207517, step = 15400 (70.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44814\n",
      "INFO:tensorflow:loss = 5.6340256, step = 15500 (69.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43204\n",
      "INFO:tensorflow:loss = 6.242541, step = 15600 (69.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44294\n",
      "INFO:tensorflow:loss = 5.6172447, step = 15700 (69.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45401\n",
      "INFO:tensorflow:loss = 5.045605, step = 15800 (68.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41595\n",
      "INFO:tensorflow:loss = 5.451747, step = 15900 (70.625 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.26134\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T11:57:41Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-12:01:29\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 6.043327, metrics-onlinereview/targets/accuracy = 0.14880008, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31174713, metrics-onlinereview/targets/approx_bleu_score = 0.008397646, metrics-onlinereview/targets/neg_log_perplexity = -5.952726, metrics-onlinereview/targets/rouge_2_fscore = 0.033551868, metrics-onlinereview/targets/rouge_L_fscore = 0.16979842\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_file_1024/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-onlinereview/targets/accuracy = 0.14880008, metrics-onlinereview/targets/rouge_L_fscore = 0.16979842, metrics-onlinereview/targets/approx_bleu_score = 0.008397646, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 16000, loss = 6.043327, metrics-onlinereview/targets/rouge_2_fscore = 0.033551868, metrics-onlinereview/targets/neg_log_perplexity = -5.952726, metrics-onlinereview/targets/accuracy_top5 = 0.31174713\n",
      "INFO:tensorflow:loss = 4.923867, step = 16000 (314.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329665\n",
      "INFO:tensorflow:loss = 6.624532, step = 16100 (68.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41575\n",
      "INFO:tensorflow:loss = 5.2180004, step = 16200 (70.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42582\n",
      "INFO:tensorflow:loss = 4.4500756, step = 16300 (70.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47881\n",
      "INFO:tensorflow:loss = 4.827623, step = 16400 (67.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44705\n",
      "INFO:tensorflow:loss = 5.6687727, step = 16500 (69.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43965\n",
      "INFO:tensorflow:loss = 5.442421, step = 16600 (69.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45377\n",
      "INFO:tensorflow:loss = 4.71094, step = 16700 (68.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43284\n",
      "INFO:tensorflow:loss = 5.841444, step = 16800 (69.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45703\n",
      "INFO:tensorflow:loss = 5.5121427, step = 16900 (68.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4275\n",
      "INFO:tensorflow:loss = 5.4383144, step = 17000 (70.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44615\n",
      "INFO:tensorflow:loss = 4.6214466, step = 17100 (69.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46744\n",
      "INFO:tensorflow:loss = 5.3002944, step = 17200 (68.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44549\n",
      "INFO:tensorflow:loss = 5.1049113, step = 17300 (69.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42535\n",
      "INFO:tensorflow:loss = 4.952604, step = 17400 (70.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4485\n",
      "INFO:tensorflow:loss = 5.84659, step = 17500 (69.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46158\n",
      "INFO:tensorflow:loss = 5.101609, step = 17600 (68.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43912\n",
      "INFO:tensorflow:loss = 6.21156, step = 17700 (69.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46351\n",
      "INFO:tensorflow:loss = 5.1439896, step = 17800 (68.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45897\n",
      "INFO:tensorflow:loss = 5.39197, step = 17900 (68.541 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.252\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T12:24:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-12:28:36\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 6.0337963, metrics-onlinereview/targets/accuracy = 0.15356243, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32029134, metrics-onlinereview/targets/approx_bleu_score = 0.007525772, metrics-onlinereview/targets/neg_log_perplexity = -5.9491854, metrics-onlinereview/targets/rouge_2_fscore = 0.0350646, metrics-onlinereview/targets/rouge_L_fscore = 0.17079763\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_file_1024/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-onlinereview/targets/accuracy = 0.15356243, metrics-onlinereview/targets/rouge_L_fscore = 0.17079763, metrics-onlinereview/targets/approx_bleu_score = 0.007525772, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 18000, loss = 6.0337963, metrics-onlinereview/targets/rouge_2_fscore = 0.0350646, metrics-onlinereview/targets/neg_log_perplexity = -5.9491854, metrics-onlinereview/targets/accuracy_top5 = 0.32029134\n",
      "INFO:tensorflow:loss = 5.7261124, step = 18000 (313.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329974\n",
      "INFO:tensorflow:loss = 5.6021996, step = 18100 (69.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46853\n",
      "INFO:tensorflow:loss = 5.6818123, step = 18200 (68.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46028\n",
      "INFO:tensorflow:loss = 6.099424, step = 18300 (68.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4443\n",
      "INFO:tensorflow:loss = 4.9972196, step = 18400 (69.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45517\n",
      "INFO:tensorflow:loss = 4.6506996, step = 18500 (68.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42499\n",
      "INFO:tensorflow:loss = 5.3661246, step = 18600 (70.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4522\n",
      "INFO:tensorflow:loss = 6.4020905, step = 18700 (68.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41729\n",
      "INFO:tensorflow:loss = 5.9485893, step = 18800 (70.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44896\n",
      "INFO:tensorflow:loss = 4.9090486, step = 18900 (69.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41819\n",
      "INFO:tensorflow:loss = 4.70453, step = 19000 (70.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45889\n",
      "INFO:tensorflow:loss = 5.56942, step = 19100 (68.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42459\n",
      "INFO:tensorflow:loss = 5.142416, step = 19200 (70.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46948\n",
      "INFO:tensorflow:loss = 6.2952633, step = 19300 (68.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45574\n",
      "INFO:tensorflow:loss = 4.6777525, step = 19400 (68.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42066\n",
      "INFO:tensorflow:loss = 4.614853, step = 19500 (70.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46405\n",
      "INFO:tensorflow:loss = 3.3138192, step = 19600 (68.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4885\n",
      "INFO:tensorflow:loss = 5.420281, step = 19700 (67.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42806\n",
      "INFO:tensorflow:loss = 4.80111, step = 19800 (70.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41002\n",
      "INFO:tensorflow:loss = 5.8126316, step = 19900 (70.924 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.28588\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T12:51:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-12:55:44\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 6.002579, metrics-onlinereview/targets/accuracy = 0.15510318, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3196377, metrics-onlinereview/targets/approx_bleu_score = 0.008219458, metrics-onlinereview/targets/neg_log_perplexity = -5.926431, metrics-onlinereview/targets/rouge_2_fscore = 0.03615849, metrics-onlinereview/targets/rouge_L_fscore = 0.17452545\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_file_1024/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-onlinereview/targets/accuracy = 0.15510318, metrics-onlinereview/targets/rouge_L_fscore = 0.17452545, metrics-onlinereview/targets/approx_bleu_score = 0.008219458, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 20000, loss = 6.002579, metrics-onlinereview/targets/rouge_2_fscore = 0.03615849, metrics-onlinereview/targets/neg_log_perplexity = -5.926431, metrics-onlinereview/targets/accuracy_top5 = 0.3196377\n",
      "INFO:tensorflow:loss = 5.324378, step = 20000 (313.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.32823\n",
      "INFO:tensorflow:loss = 6.132631, step = 20100 (68.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44643\n",
      "INFO:tensorflow:loss = 4.932728, step = 20200 (69.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43681\n",
      "INFO:tensorflow:loss = 4.665776, step = 20300 (69.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44581\n",
      "INFO:tensorflow:loss = 5.0754647, step = 20400 (69.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41433\n",
      "INFO:tensorflow:loss = 5.548028, step = 20500 (70.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46168\n",
      "INFO:tensorflow:loss = 5.7195053, step = 20600 (68.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48364\n",
      "INFO:tensorflow:loss = 5.4425225, step = 20700 (67.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43269\n",
      "INFO:tensorflow:loss = 5.0265026, step = 20800 (69.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42053\n",
      "INFO:tensorflow:loss = 5.4467263, step = 20900 (70.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43632\n",
      "INFO:tensorflow:loss = 5.2612567, step = 21000 (69.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43581\n",
      "INFO:tensorflow:loss = 5.175757, step = 21100 (69.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43454\n",
      "INFO:tensorflow:loss = 4.8582144, step = 21200 (69.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44215\n",
      "INFO:tensorflow:loss = 4.9423685, step = 21400 (69.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47564\n",
      "INFO:tensorflow:loss = 4.8593316, step = 21500 (67.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46642\n",
      "INFO:tensorflow:loss = 5.2674346, step = 21600 (68.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42966\n",
      "INFO:tensorflow:loss = 5.105188, step = 21700 (69.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48239\n",
      "INFO:tensorflow:loss = 4.432801, step = 21800 (67.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.3987\n",
      "INFO:tensorflow:loss = 5.0301614, step = 21900 (71.499 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29198\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T13:19:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-13:22:57\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 6.011952, metrics-onlinereview/targets/accuracy = 0.15813802, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32239237, metrics-onlinereview/targets/approx_bleu_score = 0.007004881, metrics-onlinereview/targets/neg_log_perplexity = -5.927717, metrics-onlinereview/targets/rouge_2_fscore = 0.031659868, metrics-onlinereview/targets/rouge_L_fscore = 0.15863447\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_file_1024/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-onlinereview/targets/accuracy = 0.15813802, metrics-onlinereview/targets/rouge_L_fscore = 0.15863447, metrics-onlinereview/targets/approx_bleu_score = 0.007004881, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 22000, loss = 6.011952, metrics-onlinereview/targets/rouge_2_fscore = 0.031659868, metrics-onlinereview/targets/neg_log_perplexity = -5.927717, metrics-onlinereview/targets/accuracy_top5 = 0.32239237\n",
      "INFO:tensorflow:loss = 4.95845, step = 22000 (315.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.326106\n",
      "INFO:tensorflow:loss = 5.936863, step = 22100 (68.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47475\n",
      "INFO:tensorflow:loss = 6.0109754, step = 22200 (67.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42586\n",
      "INFO:tensorflow:loss = 6.089514, step = 22300 (70.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46121\n",
      "INFO:tensorflow:loss = 5.4540815, step = 22400 (68.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40539\n",
      "INFO:tensorflow:loss = 5.803571, step = 22500 (71.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47033\n",
      "INFO:tensorflow:loss = 4.950421, step = 22600 (68.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42208\n",
      "INFO:tensorflow:loss = 5.032919, step = 22700 (70.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43834\n",
      "INFO:tensorflow:loss = 4.567685, step = 22800 (69.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43523\n",
      "INFO:tensorflow:loss = 5.056297, step = 22900 (69.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41125\n",
      "INFO:tensorflow:loss = 6.378318, step = 23000 (71.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47554\n",
      "INFO:tensorflow:loss = 5.7975087, step = 23100 (67.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46004\n",
      "INFO:tensorflow:loss = 5.3395495, step = 23200 (68.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45001\n",
      "INFO:tensorflow:loss = 5.3709974, step = 23300 (68.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43901\n",
      "INFO:tensorflow:loss = 5.820514, step = 23400 (69.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42397\n",
      "INFO:tensorflow:loss = 5.243031, step = 23500 (70.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47464\n",
      "INFO:tensorflow:loss = 6.6599827, step = 23600 (67.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43537\n",
      "INFO:tensorflow:loss = 5.9939795, step = 23700 (69.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42594\n",
      "INFO:tensorflow:loss = 5.1627913, step = 23800 (70.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43642\n",
      "INFO:tensorflow:loss = 5.706682, step = 23900 (69.632 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30627\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T13:46:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-13:50:04\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 5.9728026, metrics-onlinereview/targets/accuracy = 0.1573443, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3228593, metrics-onlinereview/targets/approx_bleu_score = 0.0065374784, metrics-onlinereview/targets/neg_log_perplexity = -5.8901834, metrics-onlinereview/targets/rouge_2_fscore = 0.03012637, metrics-onlinereview/targets/rouge_L_fscore = 0.15433027\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_file_1024/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-onlinereview/targets/accuracy = 0.1573443, metrics-onlinereview/targets/rouge_L_fscore = 0.15433027, metrics-onlinereview/targets/approx_bleu_score = 0.0065374784, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 24000, loss = 5.9728026, metrics-onlinereview/targets/rouge_2_fscore = 0.03012637, metrics-onlinereview/targets/neg_log_perplexity = -5.8901834, metrics-onlinereview/targets/accuracy_top5 = 0.3228593\n",
      "INFO:tensorflow:loss = 5.1218863, step = 24000 (311.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329865\n",
      "INFO:tensorflow:loss = 5.6156764, step = 24100 (68.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40403\n",
      "INFO:tensorflow:loss = 5.4833727, step = 24200 (71.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44794\n",
      "INFO:tensorflow:loss = 6.0890226, step = 24300 (69.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4503\n",
      "INFO:tensorflow:loss = 5.803597, step = 24400 (68.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45871\n",
      "INFO:tensorflow:loss = 5.3451586, step = 24500 (68.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49082\n",
      "INFO:tensorflow:loss = 5.081483, step = 24600 (67.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46921\n",
      "INFO:tensorflow:loss = 5.6177044, step = 24700 (68.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42696\n",
      "INFO:tensorflow:loss = 4.694119, step = 24800 (70.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42939\n",
      "INFO:tensorflow:loss = 5.8861046, step = 24900 (69.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49774\n",
      "INFO:tensorflow:loss = 5.4680934, step = 25000 (67.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43311\n",
      "INFO:tensorflow:loss = 5.002526, step = 25100 (69.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4574\n",
      "INFO:tensorflow:loss = 6.172061, step = 25200 (68.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41715\n",
      "INFO:tensorflow:loss = 5.8083024, step = 25300 (70.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46637\n",
      "INFO:tensorflow:loss = 4.686273, step = 25400 (68.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48763\n",
      "INFO:tensorflow:loss = 5.087484, step = 25500 (67.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39726\n",
      "INFO:tensorflow:loss = 5.6317325, step = 25600 (71.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42791\n",
      "INFO:tensorflow:loss = 5.371612, step = 25700 (70.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47607\n",
      "INFO:tensorflow:loss = 5.240768, step = 25800 (67.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43704\n",
      "INFO:tensorflow:loss = 5.1325407, step = 25900 (69.588 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29008\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T14:13:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-14:17:09\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 6.000366, metrics-onlinereview/targets/accuracy = 0.15790457, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32612756, metrics-onlinereview/targets/approx_bleu_score = 0.0072176675, metrics-onlinereview/targets/neg_log_perplexity = -5.91726, metrics-onlinereview/targets/rouge_2_fscore = 0.03288804, metrics-onlinereview/targets/rouge_L_fscore = 0.16356736\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_file_1024/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-onlinereview/targets/accuracy = 0.15790457, metrics-onlinereview/targets/rouge_L_fscore = 0.16356736, metrics-onlinereview/targets/approx_bleu_score = 0.0072176675, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 26000, loss = 6.000366, metrics-onlinereview/targets/rouge_2_fscore = 0.03288804, metrics-onlinereview/targets/neg_log_perplexity = -5.91726, metrics-onlinereview/targets/accuracy_top5 = 0.32612756\n",
      "INFO:tensorflow:loss = 5.2140937, step = 26000 (313.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.328985\n",
      "INFO:tensorflow:loss = 5.397033, step = 26100 (68.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45347\n",
      "INFO:tensorflow:loss = 5.012558, step = 26200 (68.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39189\n",
      "INFO:tensorflow:loss = 5.084871, step = 26300 (71.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43243\n",
      "INFO:tensorflow:loss = 5.122351, step = 26400 (69.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44483\n",
      "INFO:tensorflow:loss = 5.336405, step = 26500 (69.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43275\n",
      "INFO:tensorflow:loss = 4.8035836, step = 26600 (69.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48914\n",
      "INFO:tensorflow:loss = 6.343443, step = 26700 (67.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40824\n",
      "INFO:tensorflow:loss = 7.525537, step = 26800 (71.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45527\n",
      "INFO:tensorflow:loss = 5.525395, step = 26900 (68.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44562\n",
      "INFO:tensorflow:loss = 5.522787, step = 27000 (69.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43154\n",
      "INFO:tensorflow:loss = 5.606523, step = 27100 (70.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43098\n",
      "INFO:tensorflow:loss = 6.3081994, step = 27200 (69.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42355\n",
      "INFO:tensorflow:loss = 3.7584395, step = 27300 (70.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41793\n",
      "INFO:tensorflow:loss = 6.21327, step = 27400 (70.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45353\n",
      "INFO:tensorflow:loss = 5.275637, step = 27500 (68.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40364\n",
      "INFO:tensorflow:loss = 5.377768, step = 27600 (71.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46562\n",
      "INFO:tensorflow:loss = 4.654789, step = 27700 (68.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44774\n",
      "INFO:tensorflow:loss = 6.2305226, step = 27800 (69.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40669\n",
      "INFO:tensorflow:loss = 4.979254, step = 27900 (71.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30422\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T14:40:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-14:44:25\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 5.987508, metrics-onlinereview/targets/accuracy = 0.16131291, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32659444, metrics-onlinereview/targets/approx_bleu_score = 0.00713956, metrics-onlinereview/targets/neg_log_perplexity = -5.9161625, metrics-onlinereview/targets/rouge_2_fscore = 0.032589585, metrics-onlinereview/targets/rouge_L_fscore = 0.16146216\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_file_1024/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-onlinereview/targets/accuracy = 0.16131291, metrics-onlinereview/targets/rouge_L_fscore = 0.16146216, metrics-onlinereview/targets/approx_bleu_score = 0.00713956, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 28000, loss = 5.987508, metrics-onlinereview/targets/rouge_2_fscore = 0.032589585, metrics-onlinereview/targets/neg_log_perplexity = -5.9161625, metrics-onlinereview/targets/accuracy_top5 = 0.32659444\n",
      "INFO:tensorflow:loss = 5.111837, step = 28000 (313.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.327894\n",
      "INFO:tensorflow:loss = 5.121701, step = 28100 (68.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41284\n",
      "INFO:tensorflow:loss = 5.085155, step = 28200 (70.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46761\n",
      "INFO:tensorflow:loss = 4.9560027, step = 28300 (68.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41872\n",
      "INFO:tensorflow:loss = 5.057991, step = 28400 (70.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45674\n",
      "INFO:tensorflow:loss = 4.4066005, step = 28500 (68.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44716\n",
      "INFO:tensorflow:loss = 5.199949, step = 28600 (69.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40569\n",
      "INFO:tensorflow:loss = 6.1696935, step = 28700 (71.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43407\n",
      "INFO:tensorflow:loss = 4.976958, step = 28800 (69.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.433\n",
      "INFO:tensorflow:loss = 4.8853126, step = 28900 (69.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44536\n",
      "INFO:tensorflow:loss = 4.736077, step = 29000 (69.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44641\n",
      "INFO:tensorflow:loss = 4.731477, step = 29100 (69.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44276\n",
      "INFO:tensorflow:loss = 3.2524943, step = 29200 (69.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41002\n",
      "INFO:tensorflow:loss = 4.6983266, step = 29300 (70.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47055\n",
      "INFO:tensorflow:loss = 5.0824018, step = 29400 (67.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44351\n",
      "INFO:tensorflow:loss = 5.4241486, step = 29500 (69.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47384\n",
      "INFO:tensorflow:loss = 5.732973, step = 29600 (67.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42426\n",
      "INFO:tensorflow:loss = 4.9666066, step = 29700 (70.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43567\n",
      "INFO:tensorflow:loss = 5.207524, step = 29800 (69.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44618\n",
      "INFO:tensorflow:loss = 5.481906, step = 29900 (69.151 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.27\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T15:07:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-15:11:38\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 5.9701967, metrics-onlinereview/targets/accuracy = 0.16149968, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3304697, metrics-onlinereview/targets/approx_bleu_score = 0.007436079, metrics-onlinereview/targets/neg_log_perplexity = -5.8823113, metrics-onlinereview/targets/rouge_2_fscore = 0.03409414, metrics-onlinereview/targets/rouge_L_fscore = 0.16833045\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_file_1024/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-onlinereview/targets/accuracy = 0.16149968, metrics-onlinereview/targets/rouge_L_fscore = 0.16833045, metrics-onlinereview/targets/approx_bleu_score = 0.007436079, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 30000, loss = 5.9701967, metrics-onlinereview/targets/rouge_2_fscore = 0.03409414, metrics-onlinereview/targets/neg_log_perplexity = -5.8823113, metrics-onlinereview/targets/accuracy_top5 = 0.3304697\n",
      "INFO:tensorflow:loss = 5.1504064, step = 30000 (313.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329195\n",
      "INFO:tensorflow:loss = 4.8344617, step = 30100 (68.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45789\n",
      "INFO:tensorflow:loss = 5.526994, step = 30200 (68.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44842\n",
      "INFO:tensorflow:loss = 4.538605, step = 30300 (69.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46997\n",
      "INFO:tensorflow:loss = 4.8907113, step = 30400 (68.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47635\n",
      "INFO:tensorflow:loss = 5.43333, step = 30500 (67.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44562\n",
      "INFO:tensorflow:loss = 4.968667, step = 30600 (69.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43806\n",
      "INFO:tensorflow:loss = 5.2410603, step = 30700 (69.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45524\n",
      "INFO:tensorflow:loss = 5.5204864, step = 30800 (68.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47016\n",
      "INFO:tensorflow:loss = 4.803669, step = 30900 (68.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40317\n",
      "INFO:tensorflow:loss = 5.2728834, step = 31000 (71.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47818\n",
      "INFO:tensorflow:loss = 4.032076, step = 31100 (67.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4266\n",
      "INFO:tensorflow:loss = 4.8367615, step = 31200 (70.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43215\n",
      "INFO:tensorflow:loss = 5.213784, step = 31300 (69.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42957\n",
      "INFO:tensorflow:loss = 5.3658514, step = 31400 (69.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41211\n",
      "INFO:tensorflow:loss = 4.8552456, step = 31500 (70.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47277\n",
      "INFO:tensorflow:loss = 5.0132957, step = 31600 (67.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42619\n",
      "INFO:tensorflow:loss = 5.0184283, step = 31700 (70.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40859\n",
      "INFO:tensorflow:loss = 5.0598025, step = 31800 (70.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47371\n",
      "INFO:tensorflow:loss = 4.8953624, step = 31900 (67.862 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.27599\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T15:34:58Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-15:38:44\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 5.927443, metrics-onlinereview/targets/accuracy = 0.16397423, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.33205715, metrics-onlinereview/targets/approx_bleu_score = 0.00726938, metrics-onlinereview/targets/neg_log_perplexity = -5.8496966, metrics-onlinereview/targets/rouge_2_fscore = 0.032726485, metrics-onlinereview/targets/rouge_L_fscore = 0.16292448\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_file_1024/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-onlinereview/targets/accuracy = 0.16397423, metrics-onlinereview/targets/rouge_L_fscore = 0.16292448, metrics-onlinereview/targets/approx_bleu_score = 0.00726938, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 32000, loss = 5.927443, metrics-onlinereview/targets/rouge_2_fscore = 0.032726485, metrics-onlinereview/targets/neg_log_perplexity = -5.8496966, metrics-onlinereview/targets/accuracy_top5 = 0.33205715\n",
      "INFO:tensorflow:loss = 4.9640107, step = 32000 (312.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.331409\n",
      "INFO:tensorflow:loss = 5.5631804, step = 32100 (68.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48006\n",
      "INFO:tensorflow:loss = 4.760596, step = 32200 (67.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44505\n",
      "INFO:tensorflow:loss = 5.1540465, step = 32300 (69.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41753\n",
      "INFO:tensorflow:loss = 5.5570626, step = 32400 (70.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43141\n",
      "INFO:tensorflow:loss = 5.7112465, step = 32500 (69.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46124\n",
      "INFO:tensorflow:loss = 5.053082, step = 32600 (68.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41403\n",
      "INFO:tensorflow:loss = 5.427329, step = 32700 (70.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4036\n",
      "INFO:tensorflow:loss = 5.550207, step = 32800 (71.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43496\n",
      "INFO:tensorflow:loss = 5.08343, step = 32900 (69.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42634\n",
      "INFO:tensorflow:loss = 4.462511, step = 33000 (70.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41049\n",
      "INFO:tensorflow:loss = 5.046847, step = 33100 (70.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45941\n",
      "INFO:tensorflow:loss = 4.962405, step = 33200 (68.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45144\n",
      "INFO:tensorflow:loss = 5.5032063, step = 33300 (68.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45271\n",
      "INFO:tensorflow:loss = 5.536225, step = 33400 (68.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44306\n",
      "INFO:tensorflow:loss = 5.3308144, step = 33500 (69.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44936\n",
      "INFO:tensorflow:loss = 5.058494, step = 33600 (68.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43842\n",
      "INFO:tensorflow:loss = 6.816619, step = 33700 (69.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46672\n",
      "INFO:tensorflow:loss = 5.361608, step = 33800 (68.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43397\n",
      "INFO:tensorflow:loss = 5.778666, step = 33900 (69.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.2979\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T16:02:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-16:05:54\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 5.9630303, metrics-onlinereview/targets/accuracy = 0.16187319, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3314502, metrics-onlinereview/targets/approx_bleu_score = 0.0071745687, metrics-onlinereview/targets/neg_log_perplexity = -5.8672395, metrics-onlinereview/targets/rouge_2_fscore = 0.03264477, metrics-onlinereview/targets/rouge_L_fscore = 0.16098127\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_file_1024/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-onlinereview/targets/accuracy = 0.16187319, metrics-onlinereview/targets/rouge_L_fscore = 0.16098127, metrics-onlinereview/targets/approx_bleu_score = 0.0071745687, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 34000, loss = 5.9630303, metrics-onlinereview/targets/rouge_2_fscore = 0.03264477, metrics-onlinereview/targets/neg_log_perplexity = -5.8672395, metrics-onlinereview/targets/accuracy_top5 = 0.3314502\n",
      "INFO:tensorflow:loss = 5.8242974, step = 34000 (311.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.32771\n",
      "INFO:tensorflow:loss = 6.171229, step = 34100 (70.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41596\n",
      "INFO:tensorflow:loss = 4.5307674, step = 34200 (70.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43221\n",
      "INFO:tensorflow:loss = 5.2019877, step = 34300 (69.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42869\n",
      "INFO:tensorflow:loss = 5.191807, step = 34400 (69.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42832\n",
      "INFO:tensorflow:loss = 4.74556, step = 34500 (70.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45716\n",
      "INFO:tensorflow:loss = 6.3597302, step = 34600 (68.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45369\n",
      "INFO:tensorflow:loss = 6.2945523, step = 34700 (68.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43768\n",
      "INFO:tensorflow:loss = 5.868195, step = 34800 (69.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41738\n",
      "INFO:tensorflow:loss = 4.8166013, step = 34900 (70.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46767\n",
      "INFO:tensorflow:loss = 4.828045, step = 35000 (68.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43436\n",
      "INFO:tensorflow:loss = 4.773371, step = 35100 (69.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46101\n",
      "INFO:tensorflow:loss = 4.8284197, step = 35200 (68.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43137\n",
      "INFO:tensorflow:loss = 5.696464, step = 35300 (69.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41356\n",
      "INFO:tensorflow:loss = 5.1974344, step = 35400 (70.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4223\n",
      "INFO:tensorflow:loss = 4.8679633, step = 35500 (70.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45821\n",
      "INFO:tensorflow:loss = 5.5732336, step = 35600 (68.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45228\n",
      "INFO:tensorflow:loss = 6.1135488, step = 35700 (68.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40995\n",
      "INFO:tensorflow:loss = 4.966718, step = 35800 (70.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46219\n",
      "INFO:tensorflow:loss = 5.8636675, step = 35900 (68.398 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31236\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T16:29:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-16:33:07\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 5.9799123, metrics-onlinereview/targets/accuracy = 0.16280699, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.33126342, metrics-onlinereview/targets/approx_bleu_score = 0.008165897, metrics-onlinereview/targets/neg_log_perplexity = -5.8790317, metrics-onlinereview/targets/rouge_2_fscore = 0.036699418, metrics-onlinereview/targets/rouge_L_fscore = 0.17361273\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_file_1024/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-onlinereview/targets/accuracy = 0.16280699, metrics-onlinereview/targets/rouge_L_fscore = 0.17361273, metrics-onlinereview/targets/approx_bleu_score = 0.008165897, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 36000, loss = 5.9799123, metrics-onlinereview/targets/rouge_2_fscore = 0.036699418, metrics-onlinereview/targets/neg_log_perplexity = -5.8790317, metrics-onlinereview/targets/accuracy_top5 = 0.33126342\n",
      "INFO:tensorflow:loss = 5.185281, step = 36000 (310.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.331099\n",
      "INFO:tensorflow:loss = 4.851425, step = 36100 (67.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49253\n",
      "INFO:tensorflow:loss = 5.379012, step = 36200 (66.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42527\n",
      "INFO:tensorflow:loss = 5.608263, step = 36300 (70.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45085\n",
      "INFO:tensorflow:loss = 5.0922866, step = 36400 (68.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4478\n",
      "INFO:tensorflow:loss = 5.235683, step = 36500 (69.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43816\n",
      "INFO:tensorflow:loss = 5.3230815, step = 36600 (69.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43274\n",
      "INFO:tensorflow:loss = 5.0816607, step = 36700 (69.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44735\n",
      "INFO:tensorflow:loss = 6.104564, step = 36800 (69.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47029\n",
      "INFO:tensorflow:loss = 4.6244545, step = 36900 (68.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46618\n",
      "INFO:tensorflow:loss = 5.165022, step = 37000 (68.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43941\n",
      "INFO:tensorflow:loss = 5.241523, step = 37100 (69.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4534\n",
      "INFO:tensorflow:loss = 3.8189843, step = 37200 (68.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44984\n",
      "INFO:tensorflow:loss = 4.8430834, step = 37300 (68.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41635\n",
      "INFO:tensorflow:loss = 4.9214168, step = 37400 (70.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44973\n",
      "INFO:tensorflow:loss = 5.3521733, step = 37500 (68.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44717\n",
      "INFO:tensorflow:loss = 4.38858, step = 37600 (69.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4221\n",
      "INFO:tensorflow:loss = 5.386729, step = 37700 (70.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42199\n",
      "INFO:tensorflow:loss = 5.0689206, step = 37800 (70.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49105\n",
      "INFO:tensorflow:loss = 5.218135, step = 37900 (67.069 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_file_1024/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.27523\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T16:56:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_1024/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-17:00:11\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 5.919916, metrics-onlinereview/targets/accuracy = 0.16416098, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3345784, metrics-onlinereview/targets/approx_bleu_score = 0.007694773, metrics-onlinereview/targets/neg_log_perplexity = -5.837925, metrics-onlinereview/targets/rouge_2_fscore = 0.032571167, metrics-onlinereview/targets/rouge_L_fscore = 0.16052724\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_file_1024/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-onlinereview/targets/accuracy = 0.16416098, metrics-onlinereview/targets/rouge_L_fscore = 0.16052724, metrics-onlinereview/targets/approx_bleu_score = 0.007694773, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 38000, loss = 5.919916, metrics-onlinereview/targets/rouge_2_fscore = 0.032571167, metrics-onlinereview/targets/neg_log_perplexity = -5.837925, metrics-onlinereview/targets/accuracy_top5 = 0.3345784\n",
      "INFO:tensorflow:loss = 4.607046, step = 38000 (313.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.328234\n",
      "INFO:tensorflow:loss = 5.6715407, step = 38100 (69.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44268\n",
      "INFO:tensorflow:loss = 5.125754, step = 38200 (69.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4394\n",
      "INFO:tensorflow:loss = 4.7525, step = 38300 (69.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43865\n",
      "INFO:tensorflow:loss = 6.0949054, step = 38400 (69.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43857\n",
      "INFO:tensorflow:loss = 5.1377006, step = 38500 (69.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44312\n",
      "INFO:tensorflow:loss = 5.836142, step = 38600 (69.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43772\n",
      "INFO:tensorflow:loss = 5.274136, step = 38700 (69.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44942\n",
      "INFO:tensorflow:loss = 5.3284984, step = 38800 (68.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43877\n",
      "INFO:tensorflow:loss = 5.157766, step = 38900 (69.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44126\n",
      "INFO:tensorflow:loss = 5.211857, step = 39000 (69.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45301\n",
      "INFO:tensorflow:loss = 4.8680763, step = 39100 (68.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.44677\n",
      "INFO:tensorflow:loss = 5.2262454, step = 39200 (69.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41895\n",
      "INFO:tensorflow:loss = 5.2413063, step = 39300 (70.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46195\n",
      "INFO:tensorflow:loss = 5.0902467, step = 39400 (68.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40543\n",
      "INFO:tensorflow:loss = 5.0667396, step = 39500 (71.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47684\n",
      "INFO:tensorflow:loss = 5.599395, step = 39600 (67.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41302\n",
      "INFO:tensorflow:loss = 6.280602, step = 39700 (70.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43591\n",
      "INFO:tensorflow:loss = 4.578023, step = 39800 (69.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48288\n",
      "INFO:tensorflow:loss = 5.237047, step = 39900 (67.435 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_1024/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 4.8786154.\n",
      "Time: 32721.31 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_1024'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 2048 #2048 #512 \n",
    "hparams.learning_rate = 0.1 \n",
    "# hparams.num_encoder_layers = 2\n",
    "# hparams.num_hidden_layers = 6\n",
    "# hparams.num_decoder_layers = 2 \n",
    "hparams.dropout =0.2\n",
    "# hparams.num_heads =16\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_input_seq_length = 1024\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_1024 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40000,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=1000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_1024.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max len 512 -Prepend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_smoothing': 0.1, 'learning_rate_constant': 1.0, 'optimizer_multistep_accumulate_steps': None, 'learning_rate_warmup_steps': 8000, 'optimizer_adafactor_decay_type': 'pow', 'use_fixed_batch_size': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'multiply_embedding_mode': 'sqrt_depth', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'parameter_attention_key_channels': 0, 'summarize_grads': False, 'num_hidden_layers': 6, 'pad_batch': False, 'weight_noise': 0.0, 'learning_rate_decay_scheme': 'noam', 'multiproblem_fixed_train_length': -1, 'max_target_seq_length': 0, 'kernel_height': 3, 'dropout': 0.3, 'grad_noise_scale': 0.0, 'learning_rate_minimum': None, 'ffn_layer': 'dense_relu_dense', 'optimizer_adafactor_memory_exponent': 0.8, 'force_full_predict': False, 'multiproblem_mixing_schedule': 'constant', 'min_length': 0, 'shared_embedding': False, 'optimizer_adam_beta1': 0.9, 'num_decoder_layers': 6, 'factored_logits': False, 'layer_preprocess_sequence': 'n', 'proximity_bias': False, 'attention_key_channels': 0, 'kernel_width': 1, 'layer_prepostprocess_dropout': 0.1, 'conv_first_kernel': 3, 'video_num_input_frames': 1, 'learning_rate': 0.05, 'moe_overhead_train': 1.0, 'norm_type': 'layer', 'mlperf_mode': False, 'optimizer_adafactor_beta1': 0.0, 'split_to_length': 0, 'attention_value_channels': 0, 'eval_run_autoregressive': False, 'num_heads': 8, 'attention_dropout_broadcast_dims': '', 'unidirectional_encoder': False, 'vocab_divisor': 1, 'weight_dtype': 'float32', 'max_relative_position': 0, 'relu_dropout_broadcast_dims': '', 'tpu_enable_host_call': False, 'causal_decoder_self_attention': True, 'add_relative_to_values': False, 'layer_prepostprocess_dropout_broadcast_dims': '', 'symbol_modality_skip_top': False, 'optimizer_adafactor_factored': True, 'multiproblem_vocab_size': -1, 'eval_drop_long_sequences': False, 'clip_grad_norm': 0.0, 'nbr_decoder_problems': 1, 'multiproblem_reweight_label_loss': False, 'optimizer_adafactor_beta2': 0.999, 'norm_epsilon': 1e-06, 'learning_rate_decay_steps': 5000, 'heads_share_relative_embedding': False, 'num_encoder_layers': 6, 'symbol_modality_num_shards': 16, 'symbol_dropout': 0.0, 'max_length': 0, 'moe_k': 2, 'length_bucket_step': 1.1, 'layer_postprocess_sequence': 'da', 'multiproblem_max_input_length': -1, 'summarize_vars': False, 'multiproblem_schedule_max_examples': 10000000.0, 'max_input_seq_length': 512, 'learning_rate_cosine_cycle_steps': 250000, 'pretrained_model_dir': '', 'overload_eval_metric_name': '', 'sampling_method': 'argmax', 'learning_rate_decay_staircase': False, 'activation_dtype': 'float32', 'multiproblem_max_target_length': -1, 'moe_num_experts': 16, 'use_pad_remover': True, 'sampling_temp': 1.0, 'learning_rate_schedule': 'legacy', 'attention_dropout': 0.2, 'modality': {}, 'hidden_size': 512, 'weight_decay': 0.0, 'no_data_parallelism': False, 'pos': 'timing', 'initializer': 'uniform_unit_scaling', 'use_target_space_embedding': True, 'batch_shuffle_size': 512, 'multiproblem_target_eval_only': False, 'attention_variables_3d': False, 'scheduled_sampling_warmup_steps': 50000, 'optimizer_adafactor_clipping_threshold': 1.0, 'shared_embedding_and_softmax_weights': True, 'moe_loss_coef': 0.001, 'batch_size': 2048, 'optimizer_zero_grads': False, 'optimizer_momentum_momentum': 0.9, 'initializer_gain': 1.0, 'multiproblem_schedule_threshold': 0.5, 'filter_size': 2048, 'moe_overhead_eval': 2.0, 'parameter_attention_value_channels': 0, 'video_num_target_frames': 1, 'multiproblem_label_weight': 0.5, 'optimizer_adam_epsilon': 1e-09, 'optimizer_adam_beta2': 0.98, 'warm_start_from_second': '', 'compress_steps': 0, 'min_length_bucket': 8, 'multiproblem_per_task_threshold': '', 'learning_rate_decay_rate': 1.0, 'relu_dropout': 0.1, 'scheduled_sampling_prob': 0.0, 'moe_hidden_sizes': '2048', 'optimizer_momentum_nesterov': False, 'self_attention_type': 'dot_product', 'optimizer': 'Adam', 'prepend_mode': 'prepend_inputs_full_attention', 'daisy_chain_variables': True}\n",
      "{'decode_to_file': None, 'max_input_size': -1, 'eos_penalty': 0.0, 'shard_google_format': False, 'guess_and_check_top_k': 0, 'identity_output': False, 'batch_size': 0, 'mlperf_decode_step': 0.0, 'alpha': 0.6, 'num_samples': -1, 'write_beam_scores': False, 'log_results': True, 'max_display_outputs': 10, 'force_decode_length': False, 'beam_size': 2, 'vgg_ckpt_path': '', 'shards': 1, 'guess_and_check_epsilon': -1, 'decode_timeout_mins': 240, 'save_images': False, 'shard_id': 0, 'decode_in_memory': False, 'frames_per_second': 10, 'extra_length': 100, 'display_decoded_images': False, 'mlperf_threshold': 25.0, 'block_size': 0, 'border_percent': 2, 'delimiter': '\\n', 'mlperf_success': False, 'summaries_log_dir': 'decode', 'multiproblem_task_id': -1, 'max_display_decodes': 5, 'num_decodes': 1, 'skip_eos_postprocess': False, 'return_beams': True, 'shards_start_offset': 0}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3101c55f98>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_keep_checkpoint_max': 20, '_num_ps_replicas': 0, '_train_distribute': None, '_master': '', '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, 't2t_device_info': {'num_async_replicas': 1}, '_log_step_count_steps': 100, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f3101c55fd0>, '_tf_random_seed': None, '_model_dir': 'model_file_512', '_is_chief': True, '_save_checkpoints_steps': 2000, '_protocol': None, 'use_tpu': False, '_evaluation_master': '', '_task_type': None, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f32a311bc80>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f3101c55d68>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f3101c55e10>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9cc0>, 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f338c5b9cc0>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.050000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.654486, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.35093\n",
      "INFO:tensorflow:loss = 8.656198, step = 100 (74.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54083\n",
      "INFO:tensorflow:loss = 8.078813, step = 200 (64.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49276\n",
      "INFO:tensorflow:loss = 7.880606, step = 300 (66.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47041\n",
      "INFO:tensorflow:loss = 7.304089, step = 400 (68.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50496\n",
      "INFO:tensorflow:loss = 6.934419, step = 500 (66.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47781\n",
      "INFO:tensorflow:loss = 6.2114887, step = 600 (67.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5107\n",
      "INFO:tensorflow:loss = 6.257911, step = 700 (66.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47691\n",
      "INFO:tensorflow:loss = 6.2291884, step = 800 (67.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48053\n",
      "INFO:tensorflow:loss = 6.28161, step = 900 (67.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48697\n",
      "INFO:tensorflow:loss = 6.1255293, step = 1000 (67.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47714\n",
      "INFO:tensorflow:loss = 6.0599184, step = 1100 (67.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47681\n",
      "INFO:tensorflow:loss = 5.93154, step = 1200 (67.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46841\n",
      "INFO:tensorflow:loss = 6.5152, step = 1300 (68.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49326\n",
      "INFO:tensorflow:loss = 6.704829, step = 1400 (66.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45834\n",
      "INFO:tensorflow:loss = 5.8276787, step = 1500 (68.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49353\n",
      "INFO:tensorflow:loss = 5.9881473, step = 1600 (66.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47379\n",
      "INFO:tensorflow:loss = 5.845578, step = 1700 (67.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47935\n",
      "INFO:tensorflow:loss = 5.7483573, step = 1800 (67.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47333\n",
      "INFO:tensorflow:loss = 6.3365674, step = 1900 (67.875 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.318\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T17:47:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-17:50:46\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.4515486, metrics-onlinereview/targets/accuracy = 0.12568305, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.26580513, metrics-onlinereview/targets/approx_bleu_score = 0.005627802, metrics-onlinereview/targets/neg_log_perplexity = -6.4053545, metrics-onlinereview/targets/rouge_2_fscore = 0.025895845, metrics-onlinereview/targets/rouge_L_fscore = 0.15256143\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_512/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2000): metrics-onlinereview/targets/accuracy = 0.12568305, metrics-onlinereview/targets/rouge_L_fscore = 0.15256143, metrics-onlinereview/targets/approx_bleu_score = 0.005627802, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 2000, loss = 6.4515486, metrics-onlinereview/targets/rouge_2_fscore = 0.025895845, metrics-onlinereview/targets/neg_log_perplexity = -6.4053545, metrics-onlinereview/targets/accuracy_top5 = 0.26580513\n",
      "INFO:tensorflow:loss = 5.489689, step = 2000 (259.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.398991\n",
      "INFO:tensorflow:loss = 5.998634, step = 2100 (66.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48082\n",
      "INFO:tensorflow:loss = 5.3882527, step = 2200 (67.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47563\n",
      "INFO:tensorflow:loss = 5.5590267, step = 2300 (67.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49081\n",
      "INFO:tensorflow:loss = 5.7816625, step = 2400 (67.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50553\n",
      "INFO:tensorflow:loss = 5.4538355, step = 2500 (66.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50221\n",
      "INFO:tensorflow:loss = 5.7310066, step = 2600 (66.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49572\n",
      "INFO:tensorflow:loss = 5.4543858, step = 2700 (66.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49147\n",
      "INFO:tensorflow:loss = 4.940754, step = 2800 (67.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45657\n",
      "INFO:tensorflow:loss = 6.682967, step = 2900 (68.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47884\n",
      "INFO:tensorflow:loss = 6.325022, step = 3000 (67.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49803\n",
      "INFO:tensorflow:loss = 5.1473417, step = 3100 (66.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50093\n",
      "INFO:tensorflow:loss = 6.1184874, step = 3200 (66.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5057\n",
      "INFO:tensorflow:loss = 5.1359386, step = 3300 (66.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51108\n",
      "INFO:tensorflow:loss = 5.640804, step = 3400 (66.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49608\n",
      "INFO:tensorflow:loss = 5.32197, step = 3500 (66.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49328\n",
      "INFO:tensorflow:loss = 5.405191, step = 3600 (66.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48819\n",
      "INFO:tensorflow:loss = 5.3277464, step = 3700 (67.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47347\n",
      "INFO:tensorflow:loss = 5.8195605, step = 3800 (67.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47592\n",
      "INFO:tensorflow:loss = 5.562814, step = 3900 (67.756 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32579\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T18:13:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-18:16:19\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 6.1941586, metrics-onlinereview/targets/accuracy = 0.14167763, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.29727572, metrics-onlinereview/targets/approx_bleu_score = 0.006567325, metrics-onlinereview/targets/neg_log_perplexity = -6.1311007, metrics-onlinereview/targets/rouge_2_fscore = 0.028980125, metrics-onlinereview/targets/rouge_L_fscore = 0.16235875\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_512/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4000): metrics-onlinereview/targets/accuracy = 0.14167763, metrics-onlinereview/targets/rouge_L_fscore = 0.16235875, metrics-onlinereview/targets/approx_bleu_score = 0.006567325, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 4000, loss = 6.1941586, metrics-onlinereview/targets/rouge_2_fscore = 0.028980125, metrics-onlinereview/targets/neg_log_perplexity = -6.1311007, metrics-onlinereview/targets/accuracy_top5 = 0.29727572\n",
      "INFO:tensorflow:loss = 5.5108385, step = 4000 (258.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39876\n",
      "INFO:tensorflow:loss = 5.836657, step = 4100 (67.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47861\n",
      "INFO:tensorflow:loss = 5.1099815, step = 4200 (67.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47719\n",
      "INFO:tensorflow:loss = 6.4796753, step = 4300 (67.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5146\n",
      "INFO:tensorflow:loss = 5.16279, step = 4400 (66.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48382\n",
      "INFO:tensorflow:loss = 6.039131, step = 4500 (67.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48194\n",
      "INFO:tensorflow:loss = 5.051485, step = 4600 (67.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47878\n",
      "INFO:tensorflow:loss = 5.3959174, step = 4700 (67.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48253\n",
      "INFO:tensorflow:loss = 5.4881616, step = 4800 (67.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49844\n",
      "INFO:tensorflow:loss = 5.3756957, step = 4900 (66.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49642\n",
      "INFO:tensorflow:loss = 6.8377514, step = 5000 (66.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49885\n",
      "INFO:tensorflow:loss = 3.969979, step = 5100 (66.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49197\n",
      "INFO:tensorflow:loss = 5.573962, step = 5200 (67.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47993\n",
      "INFO:tensorflow:loss = 5.3365026, step = 5300 (67.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47484\n",
      "INFO:tensorflow:loss = 5.0400186, step = 5400 (67.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45641\n",
      "INFO:tensorflow:loss = 5.1513352, step = 5500 (68.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48546\n",
      "INFO:tensorflow:loss = 4.6894217, step = 5600 (67.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47323\n",
      "INFO:tensorflow:loss = 4.746397, step = 5700 (67.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4806\n",
      "INFO:tensorflow:loss = 5.799064, step = 5800 (67.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48774\n",
      "INFO:tensorflow:loss = 5.2054605, step = 5900 (67.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33504\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T18:39:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-18:41:55\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 6.1146007, metrics-onlinereview/targets/accuracy = 0.15001395, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31191418, metrics-onlinereview/targets/approx_bleu_score = 0.0061012106, metrics-onlinereview/targets/neg_log_perplexity = -6.0485616, metrics-onlinereview/targets/rouge_2_fscore = 0.026924923, metrics-onlinereview/targets/rouge_L_fscore = 0.15827425\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_512/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6000): metrics-onlinereview/targets/accuracy = 0.15001395, metrics-onlinereview/targets/rouge_L_fscore = 0.15827425, metrics-onlinereview/targets/approx_bleu_score = 0.0061012106, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 6000, loss = 6.1146007, metrics-onlinereview/targets/rouge_2_fscore = 0.026924923, metrics-onlinereview/targets/neg_log_perplexity = -6.0485616, metrics-onlinereview/targets/accuracy_top5 = 0.31191418\n",
      "INFO:tensorflow:loss = 5.3700056, step = 6000 (255.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.403233\n",
      "INFO:tensorflow:loss = 5.539827, step = 6100 (67.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46792\n",
      "INFO:tensorflow:loss = 4.7662306, step = 6200 (68.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5042\n",
      "INFO:tensorflow:loss = 4.7392726, step = 6300 (66.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46818\n",
      "INFO:tensorflow:loss = 5.334494, step = 6400 (68.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5\n",
      "INFO:tensorflow:loss = 5.731506, step = 6500 (66.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49192\n",
      "INFO:tensorflow:loss = 4.6899576, step = 6600 (67.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48475\n",
      "INFO:tensorflow:loss = 5.878016, step = 6700 (67.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50114\n",
      "INFO:tensorflow:loss = 4.7679553, step = 6800 (66.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48448\n",
      "INFO:tensorflow:loss = 5.1010556, step = 6900 (67.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48429\n",
      "INFO:tensorflow:loss = 5.0082374, step = 7000 (67.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48453\n",
      "INFO:tensorflow:loss = 6.677371, step = 7100 (67.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47356\n",
      "INFO:tensorflow:loss = 4.928766, step = 7200 (67.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5\n",
      "INFO:tensorflow:loss = 4.7393537, step = 7300 (66.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50294\n",
      "INFO:tensorflow:loss = 4.91656, step = 7400 (66.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4587\n",
      "INFO:tensorflow:loss = 5.084554, step = 7500 (68.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48178\n",
      "INFO:tensorflow:loss = 4.6284075, step = 7600 (67.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49175\n",
      "INFO:tensorflow:loss = 5.6290507, step = 7700 (67.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49948\n",
      "INFO:tensorflow:loss = 5.8600836, step = 7800 (66.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47471\n",
      "INFO:tensorflow:loss = 6.036185, step = 7900 (67.810 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33847\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T19:04:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-19:07:32\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 6.0247126, metrics-onlinereview/targets/accuracy = 0.15480037, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3192932, metrics-onlinereview/targets/approx_bleu_score = 0.0068069124, metrics-onlinereview/targets/neg_log_perplexity = -5.9496055, metrics-onlinereview/targets/rouge_2_fscore = 0.03010694, metrics-onlinereview/targets/rouge_L_fscore = 0.1605822\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: model_file_512/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8000): metrics-onlinereview/targets/accuracy = 0.15480037, metrics-onlinereview/targets/rouge_L_fscore = 0.1605822, metrics-onlinereview/targets/approx_bleu_score = 0.0068069124, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 8000, loss = 6.0247126, metrics-onlinereview/targets/rouge_2_fscore = 0.03010694, metrics-onlinereview/targets/neg_log_perplexity = -5.9496055, metrics-onlinereview/targets/accuracy_top5 = 0.3192932\n",
      "INFO:tensorflow:loss = 5.1643014, step = 8000 (258.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39735\n",
      "INFO:tensorflow:loss = 6.1296773, step = 8100 (67.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52153\n",
      "INFO:tensorflow:loss = 5.854442, step = 8200 (65.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48429\n",
      "INFO:tensorflow:loss = 5.069006, step = 8300 (67.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48688\n",
      "INFO:tensorflow:loss = 5.347451, step = 8400 (67.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4862\n",
      "INFO:tensorflow:loss = 5.453908, step = 8500 (67.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45559\n",
      "INFO:tensorflow:loss = 5.230478, step = 8600 (68.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49786\n",
      "INFO:tensorflow:loss = 5.0310807, step = 8700 (66.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50358\n",
      "INFO:tensorflow:loss = 5.163292, step = 8800 (66.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47364\n",
      "INFO:tensorflow:loss = 4.863632, step = 8900 (67.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48156\n",
      "INFO:tensorflow:loss = 5.122403, step = 9000 (67.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47318\n",
      "INFO:tensorflow:loss = 5.6323733, step = 9100 (67.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47298\n",
      "INFO:tensorflow:loss = 5.526429, step = 9200 (67.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49864\n",
      "INFO:tensorflow:loss = 4.6986794, step = 9300 (66.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50217\n",
      "INFO:tensorflow:loss = 5.735426, step = 9400 (66.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50332\n",
      "INFO:tensorflow:loss = 4.936908, step = 9500 (66.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48062\n",
      "INFO:tensorflow:loss = 5.5933623, step = 9600 (67.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48266\n",
      "INFO:tensorflow:loss = 4.603574, step = 9700 (67.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47191\n",
      "INFO:tensorflow:loss = 5.201209, step = 9800 (67.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47392\n",
      "INFO:tensorflow:loss = 5.7649384, step = 9900 (67.847 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31446\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T19:30:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-19:33:13\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 5.9721575, metrics-onlinereview/targets/accuracy = 0.16154122, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.31981173, metrics-onlinereview/targets/approx_bleu_score = 0.0076858504, metrics-onlinereview/targets/neg_log_perplexity = -5.9031587, metrics-onlinereview/targets/rouge_2_fscore = 0.034135822, metrics-onlinereview/targets/rouge_L_fscore = 0.16919631\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: model_file_512/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10000): metrics-onlinereview/targets/accuracy = 0.16154122, metrics-onlinereview/targets/rouge_L_fscore = 0.16919631, metrics-onlinereview/targets/approx_bleu_score = 0.0076858504, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 10000, loss = 5.9721575, metrics-onlinereview/targets/rouge_2_fscore = 0.034135822, metrics-onlinereview/targets/neg_log_perplexity = -5.9031587, metrics-onlinereview/targets/accuracy_top5 = 0.31981173\n",
      "INFO:tensorflow:loss = 4.8092628, step = 10000 (261.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.396938\n",
      "INFO:tensorflow:loss = 5.6422596, step = 10100 (66.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4836\n",
      "INFO:tensorflow:loss = 4.9892616, step = 10200 (67.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48455\n",
      "INFO:tensorflow:loss = 5.8348093, step = 10300 (67.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48769\n",
      "INFO:tensorflow:loss = 5.911745, step = 10400 (67.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49172\n",
      "INFO:tensorflow:loss = 4.8244324, step = 10500 (67.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48691\n",
      "INFO:tensorflow:loss = 5.034621, step = 10600 (67.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49259\n",
      "INFO:tensorflow:loss = 5.4485106, step = 10700 (66.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50061\n",
      "INFO:tensorflow:loss = 4.9355135, step = 10800 (66.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46576\n",
      "INFO:tensorflow:loss = 4.8996124, step = 10900 (68.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47425\n",
      "INFO:tensorflow:loss = 5.4927006, step = 11000 (67.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50882\n",
      "INFO:tensorflow:loss = 5.1593986, step = 11100 (66.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51258\n",
      "INFO:tensorflow:loss = 4.911454, step = 11200 (66.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45281\n",
      "INFO:tensorflow:loss = 5.368621, step = 11300 (68.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46523\n",
      "INFO:tensorflow:loss = 5.265393, step = 11400 (68.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49021\n",
      "INFO:tensorflow:loss = 5.061565, step = 11500 (67.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50911\n",
      "INFO:tensorflow:loss = 4.722021, step = 11600 (66.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47618\n",
      "INFO:tensorflow:loss = 5.7551913, step = 11700 (67.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48272\n",
      "INFO:tensorflow:loss = 5.179935, step = 11800 (67.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47411\n",
      "INFO:tensorflow:loss = 5.5330772, step = 11900 (67.837 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33947\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T19:55:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-19:58:52\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 5.888302, metrics-onlinereview/targets/accuracy = 0.16860117, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.33955565, metrics-onlinereview/targets/approx_bleu_score = 0.008743093, metrics-onlinereview/targets/neg_log_perplexity = -5.8121552, metrics-onlinereview/targets/rouge_2_fscore = 0.03841544, metrics-onlinereview/targets/rouge_L_fscore = 0.1780571\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: model_file_512/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12000): metrics-onlinereview/targets/accuracy = 0.16860117, metrics-onlinereview/targets/rouge_L_fscore = 0.1780571, metrics-onlinereview/targets/approx_bleu_score = 0.008743093, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 12000, loss = 5.888302, metrics-onlinereview/targets/rouge_2_fscore = 0.03841544, metrics-onlinereview/targets/neg_log_perplexity = -5.8121552, metrics-onlinereview/targets/accuracy_top5 = 0.33955565\n",
      "INFO:tensorflow:loss = 5.942033, step = 12000 (261.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39235\n",
      "INFO:tensorflow:loss = 4.839759, step = 12100 (67.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51382\n",
      "INFO:tensorflow:loss = 5.7831903, step = 12200 (66.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48371\n",
      "INFO:tensorflow:loss = 4.585309, step = 12300 (67.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.487\n",
      "INFO:tensorflow:loss = 5.260409, step = 12400 (67.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47118\n",
      "INFO:tensorflow:loss = 6.1303463, step = 12500 (67.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48733\n",
      "INFO:tensorflow:loss = 5.355536, step = 12600 (67.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50438\n",
      "INFO:tensorflow:loss = 5.202258, step = 12700 (66.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48939\n",
      "INFO:tensorflow:loss = 5.1634192, step = 12800 (67.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48869\n",
      "INFO:tensorflow:loss = 5.56127, step = 12900 (67.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48306\n",
      "INFO:tensorflow:loss = 5.1089725, step = 13000 (67.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48314\n",
      "INFO:tensorflow:loss = 5.3180957, step = 13100 (67.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47023\n",
      "INFO:tensorflow:loss = 5.4897127, step = 13200 (68.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47982\n",
      "INFO:tensorflow:loss = 4.833177, step = 13300 (67.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48735\n",
      "INFO:tensorflow:loss = 4.9067, step = 13400 (67.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4976\n",
      "INFO:tensorflow:loss = 5.2310643, step = 13500 (66.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51825\n",
      "INFO:tensorflow:loss = 4.729617, step = 13600 (65.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4933\n",
      "INFO:tensorflow:loss = 5.0100636, step = 13700 (66.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46202\n",
      "INFO:tensorflow:loss = 4.9768686, step = 13800 (68.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48876\n",
      "INFO:tensorflow:loss = 5.2820654, step = 13900 (67.171 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32959\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T20:21:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-20:24:31\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 5.8435073, metrics-onlinereview/targets/accuracy = 0.17382634, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.34721392, metrics-onlinereview/targets/approx_bleu_score = 0.008406743, metrics-onlinereview/targets/neg_log_perplexity = -5.7673225, metrics-onlinereview/targets/rouge_2_fscore = 0.036379334, metrics-onlinereview/targets/rouge_L_fscore = 0.17327946\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: model_file_512/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14000): metrics-onlinereview/targets/accuracy = 0.17382634, metrics-onlinereview/targets/rouge_L_fscore = 0.17327946, metrics-onlinereview/targets/approx_bleu_score = 0.008406743, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 14000, loss = 5.8435073, metrics-onlinereview/targets/rouge_2_fscore = 0.036379334, metrics-onlinereview/targets/neg_log_perplexity = -5.7673225, metrics-onlinereview/targets/accuracy_top5 = 0.34721392\n",
      "INFO:tensorflow:loss = 4.558926, step = 14000 (261.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.394352\n",
      "INFO:tensorflow:loss = 4.9269376, step = 14100 (67.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48813\n",
      "INFO:tensorflow:loss = 5.9511847, step = 14200 (67.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49164\n",
      "INFO:tensorflow:loss = 5.53206, step = 14300 (67.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49091\n",
      "INFO:tensorflow:loss = 5.494746, step = 14400 (67.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48774\n",
      "INFO:tensorflow:loss = 4.950574, step = 14500 (67.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49008\n",
      "INFO:tensorflow:loss = 5.5850825, step = 14600 (67.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48657\n",
      "INFO:tensorflow:loss = 5.195501, step = 14700 (67.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48772\n",
      "INFO:tensorflow:loss = 5.343928, step = 14800 (67.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49845\n",
      "INFO:tensorflow:loss = 4.7751846, step = 14900 (66.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48568\n",
      "INFO:tensorflow:loss = 3.7587965, step = 15000 (67.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48574\n",
      "INFO:tensorflow:loss = 4.722055, step = 15100 (67.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46976\n",
      "INFO:tensorflow:loss = 5.304425, step = 15200 (68.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49365\n",
      "INFO:tensorflow:loss = 5.425795, step = 15300 (66.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49983\n",
      "INFO:tensorflow:loss = 4.9951134, step = 15400 (66.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50529\n",
      "INFO:tensorflow:loss = 5.4982862, step = 15500 (66.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4815\n",
      "INFO:tensorflow:loss = 5.503653, step = 15600 (67.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47974\n",
      "INFO:tensorflow:loss = 5.5489182, step = 15700 (67.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4603\n",
      "INFO:tensorflow:loss = 4.712205, step = 15800 (68.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50071\n",
      "INFO:tensorflow:loss = 5.436945, step = 15900 (66.637 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30006\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T20:47:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-20:50:12\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 5.7998366, metrics-onlinereview/targets/accuracy = 0.17741613, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.35411432, metrics-onlinereview/targets/approx_bleu_score = 0.007360437, metrics-onlinereview/targets/neg_log_perplexity = -5.7181864, metrics-onlinereview/targets/rouge_2_fscore = 0.033012684, metrics-onlinereview/targets/rouge_L_fscore = 0.16316362\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: model_file_512/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16000): metrics-onlinereview/targets/accuracy = 0.17741613, metrics-onlinereview/targets/rouge_L_fscore = 0.16316362, metrics-onlinereview/targets/approx_bleu_score = 0.007360437, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 16000, loss = 5.7998366, metrics-onlinereview/targets/rouge_2_fscore = 0.033012684, metrics-onlinereview/targets/neg_log_perplexity = -5.7181864, metrics-onlinereview/targets/accuracy_top5 = 0.35411432\n",
      "INFO:tensorflow:loss = 5.4518747, step = 16000 (263.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.394024\n",
      "INFO:tensorflow:loss = 5.3454914, step = 16100 (67.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45802\n",
      "INFO:tensorflow:loss = 4.862818, step = 16200 (68.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47553\n",
      "INFO:tensorflow:loss = 5.291992, step = 16300 (67.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49409\n",
      "INFO:tensorflow:loss = 4.8902683, step = 16400 (66.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49023\n",
      "INFO:tensorflow:loss = 5.58996, step = 16500 (67.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5024\n",
      "INFO:tensorflow:loss = 5.2281866, step = 16600 (66.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47988\n",
      "INFO:tensorflow:loss = 4.7916927, step = 16700 (67.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49106\n",
      "INFO:tensorflow:loss = 4.621133, step = 16800 (67.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49495\n",
      "INFO:tensorflow:loss = 4.8892493, step = 16900 (66.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48889\n",
      "INFO:tensorflow:loss = 4.8045263, step = 17000 (67.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50641\n",
      "INFO:tensorflow:loss = 4.9748735, step = 17100 (66.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49556\n",
      "INFO:tensorflow:loss = 5.650028, step = 17200 (66.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50366\n",
      "INFO:tensorflow:loss = 5.6305065, step = 17300 (66.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47646\n",
      "INFO:tensorflow:loss = 4.797312, step = 17400 (67.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48615\n",
      "INFO:tensorflow:loss = 5.1564956, step = 17500 (67.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47748\n",
      "INFO:tensorflow:loss = 5.6628137, step = 17600 (67.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48085\n",
      "INFO:tensorflow:loss = 6.1294503, step = 17700 (67.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48798\n",
      "INFO:tensorflow:loss = 4.875013, step = 17800 (67.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48805\n",
      "INFO:tensorflow:loss = 5.3958917, step = 17900 (67.204 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32615\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T21:12:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-21:15:51\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 5.7679844, metrics-onlinereview/targets/accuracy = 0.18375812, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3643652, metrics-onlinereview/targets/approx_bleu_score = 0.008046566, metrics-onlinereview/targets/neg_log_perplexity = -5.690407, metrics-onlinereview/targets/rouge_2_fscore = 0.031805422, metrics-onlinereview/targets/rouge_L_fscore = 0.16082157\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: model_file_512/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18000): metrics-onlinereview/targets/accuracy = 0.18375812, metrics-onlinereview/targets/rouge_L_fscore = 0.16082157, metrics-onlinereview/targets/approx_bleu_score = 0.008046566, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 18000, loss = 5.7679844, metrics-onlinereview/targets/rouge_2_fscore = 0.031805422, metrics-onlinereview/targets/neg_log_perplexity = -5.690407, metrics-onlinereview/targets/accuracy_top5 = 0.3643652\n",
      "INFO:tensorflow:loss = 4.660479, step = 18000 (261.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.394865\n",
      "INFO:tensorflow:loss = 5.0459385, step = 18100 (67.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48102\n",
      "INFO:tensorflow:loss = 4.5519505, step = 18200 (67.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4888\n",
      "INFO:tensorflow:loss = 5.173895, step = 18300 (67.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48429\n",
      "INFO:tensorflow:loss = 4.758399, step = 18400 (67.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47704\n",
      "INFO:tensorflow:loss = 6.204877, step = 18500 (67.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48933\n",
      "INFO:tensorflow:loss = 4.8584404, step = 18600 (67.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4801\n",
      "INFO:tensorflow:loss = 5.329815, step = 18700 (67.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4873\n",
      "INFO:tensorflow:loss = 4.8687325, step = 18800 (67.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49403\n",
      "INFO:tensorflow:loss = 4.9688096, step = 18900 (66.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.471\n",
      "INFO:tensorflow:loss = 4.7541943, step = 19000 (67.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48546\n",
      "INFO:tensorflow:loss = 4.629081, step = 19100 (67.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45295\n",
      "INFO:tensorflow:loss = 5.2006407, step = 19200 (68.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47348\n",
      "INFO:tensorflow:loss = 4.9305887, step = 19300 (67.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48099\n",
      "INFO:tensorflow:loss = 4.9546714, step = 19400 (67.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49014\n",
      "INFO:tensorflow:loss = 4.9344506, step = 19500 (67.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50565\n",
      "INFO:tensorflow:loss = 4.859984, step = 19600 (66.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46449\n",
      "INFO:tensorflow:loss = 5.149105, step = 19700 (68.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50651\n",
      "INFO:tensorflow:loss = 4.548, step = 19800 (66.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47945\n",
      "INFO:tensorflow:loss = 4.2897267, step = 19900 (67.595 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31868\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T21:38:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-21:41:34\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 5.7247906, metrics-onlinereview/targets/accuracy = 0.18778668, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.36823422, metrics-onlinereview/targets/approx_bleu_score = 0.008419151, metrics-onlinereview/targets/neg_log_perplexity = -5.6535544, metrics-onlinereview/targets/rouge_2_fscore = 0.03615847, metrics-onlinereview/targets/rouge_L_fscore = 0.16460909\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: model_file_512/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20000): metrics-onlinereview/targets/accuracy = 0.18778668, metrics-onlinereview/targets/rouge_L_fscore = 0.16460909, metrics-onlinereview/targets/approx_bleu_score = 0.008419151, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 20000, loss = 5.7247906, metrics-onlinereview/targets/rouge_2_fscore = 0.03615847, metrics-onlinereview/targets/neg_log_perplexity = -5.6535544, metrics-onlinereview/targets/accuracy_top5 = 0.36823422\n",
      "INFO:tensorflow:loss = 5.5388966, step = 20000 (262.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39409\n",
      "INFO:tensorflow:loss = 4.2200394, step = 20100 (67.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49922\n",
      "INFO:tensorflow:loss = 4.776902, step = 20200 (66.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50475\n",
      "INFO:tensorflow:loss = 4.711614, step = 20300 (66.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48751\n",
      "INFO:tensorflow:loss = 5.1289077, step = 20400 (67.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48975\n",
      "INFO:tensorflow:loss = 6.011681, step = 20500 (67.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48011\n",
      "INFO:tensorflow:loss = 4.453381, step = 20600 (67.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49486\n",
      "INFO:tensorflow:loss = 4.820993, step = 20700 (66.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49796\n",
      "INFO:tensorflow:loss = 5.107766, step = 20800 (66.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48818\n",
      "INFO:tensorflow:loss = 4.4117517, step = 20900 (67.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49979\n",
      "INFO:tensorflow:loss = 4.9866347, step = 21000 (66.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49247\n",
      "INFO:tensorflow:loss = 4.987914, step = 21100 (67.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47537\n",
      "INFO:tensorflow:loss = 4.3517447, step = 21200 (67.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.501\n",
      "INFO:tensorflow:loss = 5.768038, step = 21300 (66.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47627\n",
      "INFO:tensorflow:loss = 4.995862, step = 21400 (67.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46781\n",
      "INFO:tensorflow:loss = 5.232364, step = 21500 (68.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48025\n",
      "INFO:tensorflow:loss = 5.4026175, step = 21600 (67.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50679\n",
      "INFO:tensorflow:loss = 4.535718, step = 21700 (66.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50435\n",
      "INFO:tensorflow:loss = 5.725147, step = 21800 (66.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46675\n",
      "INFO:tensorflow:loss = 5.1692, step = 21900 (68.177 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.3252\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T22:04:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-22:07:10\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 5.701307, metrics-onlinereview/targets/accuracy = 0.19006023, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37086675, metrics-onlinereview/targets/approx_bleu_score = 0.007915966, metrics-onlinereview/targets/neg_log_perplexity = -5.619588, metrics-onlinereview/targets/rouge_2_fscore = 0.034012757, metrics-onlinereview/targets/rouge_L_fscore = 0.16400017\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: model_file_512/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22000): metrics-onlinereview/targets/accuracy = 0.19006023, metrics-onlinereview/targets/rouge_L_fscore = 0.16400017, metrics-onlinereview/targets/approx_bleu_score = 0.007915966, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 22000, loss = 5.701307, metrics-onlinereview/targets/rouge_2_fscore = 0.034012757, metrics-onlinereview/targets/neg_log_perplexity = -5.619588, metrics-onlinereview/targets/accuracy_top5 = 0.37086675\n",
      "INFO:tensorflow:loss = 5.092459, step = 22000 (260.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.396949\n",
      "INFO:tensorflow:loss = 5.124733, step = 22100 (66.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47876\n",
      "INFO:tensorflow:loss = 4.06077, step = 22200 (67.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47807\n",
      "INFO:tensorflow:loss = 4.969809, step = 22300 (67.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49439\n",
      "INFO:tensorflow:loss = 4.727132, step = 22400 (66.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47906\n",
      "INFO:tensorflow:loss = 5.01583, step = 22500 (67.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48861\n",
      "INFO:tensorflow:loss = 5.469768, step = 22600 (67.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46621\n",
      "INFO:tensorflow:loss = 4.695943, step = 22700 (68.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4693\n",
      "INFO:tensorflow:loss = 5.3774867, step = 22800 (68.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47315\n",
      "INFO:tensorflow:loss = 5.050478, step = 22900 (67.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50278\n",
      "INFO:tensorflow:loss = 4.735502, step = 23000 (66.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50505\n",
      "INFO:tensorflow:loss = 5.1722546, step = 23100 (66.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47884\n",
      "INFO:tensorflow:loss = 4.9339247, step = 23200 (67.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49116\n",
      "INFO:tensorflow:loss = 5.5601254, step = 23300 (67.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4947\n",
      "INFO:tensorflow:loss = 4.8831677, step = 23400 (66.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51127\n",
      "INFO:tensorflow:loss = 3.9832253, step = 23500 (66.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50412\n",
      "INFO:tensorflow:loss = 4.7824903, step = 23600 (66.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48947\n",
      "INFO:tensorflow:loss = 5.2789993, step = 23700 (67.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47588\n",
      "INFO:tensorflow:loss = 5.6743984, step = 23800 (67.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49226\n",
      "INFO:tensorflow:loss = 5.685864, step = 23900 (67.013 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31219\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T22:29:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-22:32:51\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 5.6593714, metrics-onlinereview/targets/accuracy = 0.19173548, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37629133, metrics-onlinereview/targets/approx_bleu_score = 0.007936861, metrics-onlinereview/targets/neg_log_perplexity = -5.5836167, metrics-onlinereview/targets/rouge_2_fscore = 0.033289578, metrics-onlinereview/targets/rouge_L_fscore = 0.15846902\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: model_file_512/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24000): metrics-onlinereview/targets/accuracy = 0.19173548, metrics-onlinereview/targets/rouge_L_fscore = 0.15846902, metrics-onlinereview/targets/approx_bleu_score = 0.007936861, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 24000, loss = 5.6593714, metrics-onlinereview/targets/rouge_2_fscore = 0.033289578, metrics-onlinereview/targets/neg_log_perplexity = -5.5836167, metrics-onlinereview/targets/accuracy_top5 = 0.37629133\n",
      "INFO:tensorflow:loss = 4.365264, step = 24000 (263.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.39276\n",
      "INFO:tensorflow:loss = 5.1992826, step = 24100 (66.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48075\n",
      "INFO:tensorflow:loss = 5.869078, step = 24200 (67.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47979\n",
      "INFO:tensorflow:loss = 4.9233756, step = 24300 (67.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49978\n",
      "INFO:tensorflow:loss = 6.0976806, step = 24400 (66.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47983\n",
      "INFO:tensorflow:loss = 5.393106, step = 24500 (67.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4826\n",
      "INFO:tensorflow:loss = 4.600236, step = 24600 (67.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49631\n",
      "INFO:tensorflow:loss = 5.5819044, step = 24700 (66.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49356\n",
      "INFO:tensorflow:loss = 4.167716, step = 24800 (66.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50537\n",
      "INFO:tensorflow:loss = 4.4065843, step = 24900 (66.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48695\n",
      "INFO:tensorflow:loss = 4.444923, step = 25000 (67.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48881\n",
      "INFO:tensorflow:loss = 4.737345, step = 25100 (67.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48884\n",
      "INFO:tensorflow:loss = 4.5668306, step = 25200 (67.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50186\n",
      "INFO:tensorflow:loss = 5.12888, step = 25300 (66.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49781\n",
      "INFO:tensorflow:loss = 4.7743993, step = 25400 (66.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48387\n",
      "INFO:tensorflow:loss = 4.921939, step = 25500 (67.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46631\n",
      "INFO:tensorflow:loss = 6.3783417, step = 25600 (68.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46999\n",
      "INFO:tensorflow:loss = 4.9049273, step = 25700 (68.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48155\n",
      "INFO:tensorflow:loss = 6.0891957, step = 25800 (67.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48087\n",
      "INFO:tensorflow:loss = 4.93602, step = 25900 (67.526 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.33722\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T22:55:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-22:58:30\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 5.63562, metrics-onlinereview/targets/accuracy = 0.19388935, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37808624, metrics-onlinereview/targets/approx_bleu_score = 0.009198895, metrics-onlinereview/targets/neg_log_perplexity = -5.5528107, metrics-onlinereview/targets/rouge_2_fscore = 0.03920489, metrics-onlinereview/targets/rouge_L_fscore = 0.17137934\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: model_file_512/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26000): metrics-onlinereview/targets/accuracy = 0.19388935, metrics-onlinereview/targets/rouge_L_fscore = 0.17137934, metrics-onlinereview/targets/approx_bleu_score = 0.009198895, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 26000, loss = 5.63562, metrics-onlinereview/targets/rouge_2_fscore = 0.03920489, metrics-onlinereview/targets/neg_log_perplexity = -5.5528107, metrics-onlinereview/targets/accuracy_top5 = 0.37808624\n",
      "INFO:tensorflow:loss = 4.844414, step = 26000 (260.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.393338\n",
      "INFO:tensorflow:loss = 4.428263, step = 26100 (68.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48181\n",
      "INFO:tensorflow:loss = 5.2506876, step = 26200 (67.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50577\n",
      "INFO:tensorflow:loss = 4.6190405, step = 26300 (66.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48162\n",
      "INFO:tensorflow:loss = 5.0217824, step = 26400 (67.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48485\n",
      "INFO:tensorflow:loss = 4.9839177, step = 26500 (67.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47983\n",
      "INFO:tensorflow:loss = 5.2767773, step = 26600 (67.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46994\n",
      "INFO:tensorflow:loss = 4.646066, step = 26700 (68.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49542\n",
      "INFO:tensorflow:loss = 4.8190494, step = 26800 (66.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48668\n",
      "INFO:tensorflow:loss = 4.793758, step = 26900 (67.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50535\n",
      "INFO:tensorflow:loss = 4.6381364, step = 27000 (66.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48828\n",
      "INFO:tensorflow:loss = 5.3087177, step = 27100 (67.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50504\n",
      "INFO:tensorflow:loss = 5.2769823, step = 27200 (66.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48492\n",
      "INFO:tensorflow:loss = 5.002012, step = 27300 (67.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50967\n",
      "INFO:tensorflow:loss = 4.69773, step = 27400 (66.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51553\n",
      "INFO:tensorflow:loss = 5.264971, step = 27500 (65.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48369\n",
      "INFO:tensorflow:loss = 4.8241343, step = 27600 (67.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49793\n",
      "INFO:tensorflow:loss = 4.8665075, step = 27700 (66.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48734\n",
      "INFO:tensorflow:loss = 5.5071716, step = 27800 (67.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49921\n",
      "INFO:tensorflow:loss = 4.1744995, step = 27900 (66.704 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30593\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T23:21:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-23:24:07\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 5.6238055, metrics-onlinereview/targets/accuracy = 0.19632244, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38458776, metrics-onlinereview/targets/approx_bleu_score = 0.009757901, metrics-onlinereview/targets/neg_log_perplexity = -5.5472364, metrics-onlinereview/targets/rouge_2_fscore = 0.04055389, metrics-onlinereview/targets/rouge_L_fscore = 0.17839287\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: model_file_512/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28000): metrics-onlinereview/targets/accuracy = 0.19632244, metrics-onlinereview/targets/rouge_L_fscore = 0.17839287, metrics-onlinereview/targets/approx_bleu_score = 0.009757901, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 28000, loss = 5.6238055, metrics-onlinereview/targets/rouge_2_fscore = 0.04055389, metrics-onlinereview/targets/neg_log_perplexity = -5.5472364, metrics-onlinereview/targets/accuracy_top5 = 0.38458776\n",
      "INFO:tensorflow:loss = 4.8593154, step = 28000 (262.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.393715\n",
      "INFO:tensorflow:loss = 4.9248323, step = 28100 (67.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47473\n",
      "INFO:tensorflow:loss = 5.268981, step = 28200 (67.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46602\n",
      "INFO:tensorflow:loss = 5.076331, step = 28300 (68.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4802\n",
      "INFO:tensorflow:loss = 5.0212474, step = 28400 (67.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51557\n",
      "INFO:tensorflow:loss = 4.6751127, step = 28500 (65.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46845\n",
      "INFO:tensorflow:loss = 4.618636, step = 28600 (68.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49293\n",
      "INFO:tensorflow:loss = 4.327935, step = 28700 (66.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49343\n",
      "INFO:tensorflow:loss = 4.619907, step = 28800 (66.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49107\n",
      "INFO:tensorflow:loss = 4.5850215, step = 28900 (67.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47355\n",
      "INFO:tensorflow:loss = 4.8841434, step = 29000 (67.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45566\n",
      "INFO:tensorflow:loss = 4.659264, step = 29100 (68.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48372\n",
      "INFO:tensorflow:loss = 4.7801642, step = 29200 (67.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48147\n",
      "INFO:tensorflow:loss = 5.182662, step = 29300 (67.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4988\n",
      "INFO:tensorflow:loss = 4.4825287, step = 29400 (66.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48783\n",
      "INFO:tensorflow:loss = 4.9284782, step = 29500 (67.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49837\n",
      "INFO:tensorflow:loss = 4.1343756, step = 29600 (66.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47374\n",
      "INFO:tensorflow:loss = 5.362726, step = 29700 (67.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48875\n",
      "INFO:tensorflow:loss = 5.035307, step = 29800 (67.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45887\n",
      "INFO:tensorflow:loss = 4.8132296, step = 29900 (68.548 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31075\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T23:46:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-23:49:53\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 5.601707, metrics-onlinereview/targets/accuracy = 0.19819713, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38622314, metrics-onlinereview/targets/approx_bleu_score = 0.009441368, metrics-onlinereview/targets/neg_log_perplexity = -5.5225873, metrics-onlinereview/targets/rouge_2_fscore = 0.039573018, metrics-onlinereview/targets/rouge_L_fscore = 0.17741816\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: model_file_512/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30000): metrics-onlinereview/targets/accuracy = 0.19819713, metrics-onlinereview/targets/rouge_L_fscore = 0.17741816, metrics-onlinereview/targets/approx_bleu_score = 0.009441368, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 30000, loss = 5.601707, metrics-onlinereview/targets/rouge_2_fscore = 0.039573018, metrics-onlinereview/targets/neg_log_perplexity = -5.5225873, metrics-onlinereview/targets/accuracy_top5 = 0.38622314\n",
      "INFO:tensorflow:loss = 4.907816, step = 30000 (264.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.393004\n",
      "INFO:tensorflow:loss = 4.9657264, step = 30100 (66.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49085\n",
      "INFO:tensorflow:loss = 4.834134, step = 30200 (67.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49274\n",
      "INFO:tensorflow:loss = 5.0629177, step = 30300 (66.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48796\n",
      "INFO:tensorflow:loss = 5.817253, step = 30400 (67.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48486\n",
      "INFO:tensorflow:loss = 4.8284974, step = 30500 (67.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50327\n",
      "INFO:tensorflow:loss = 4.987588, step = 30600 (66.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46047\n",
      "INFO:tensorflow:loss = 5.6307635, step = 30700 (68.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53299\n",
      "INFO:tensorflow:loss = 4.6352224, step = 30800 (65.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51746\n",
      "INFO:tensorflow:loss = 5.0453916, step = 30900 (65.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.478\n",
      "INFO:tensorflow:loss = 4.8477683, step = 31000 (67.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47991\n",
      "INFO:tensorflow:loss = 5.7603297, step = 31100 (67.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47207\n",
      "INFO:tensorflow:loss = 4.629049, step = 31200 (67.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49283\n",
      "INFO:tensorflow:loss = 5.3933277, step = 31300 (66.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48759\n",
      "INFO:tensorflow:loss = 4.8707557, step = 31400 (67.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50574\n",
      "INFO:tensorflow:loss = 4.352401, step = 31500 (66.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47413\n",
      "INFO:tensorflow:loss = 5.1423173, step = 31600 (67.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52807\n",
      "INFO:tensorflow:loss = 4.9398365, step = 31700 (65.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50434\n",
      "INFO:tensorflow:loss = 5.201266, step = 31800 (66.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49624\n",
      "INFO:tensorflow:loss = 3.8214562, step = 31900 (66.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.29909\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T00:12:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-00:15:30\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 5.5817995, metrics-onlinereview/targets/accuracy = 0.19995214, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38737985, metrics-onlinereview/targets/approx_bleu_score = 0.008773056, metrics-onlinereview/targets/neg_log_perplexity = -5.5065694, metrics-onlinereview/targets/rouge_2_fscore = 0.03742939, metrics-onlinereview/targets/rouge_L_fscore = 0.17144422\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: model_file_512/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32000): metrics-onlinereview/targets/accuracy = 0.19995214, metrics-onlinereview/targets/rouge_L_fscore = 0.17144422, metrics-onlinereview/targets/approx_bleu_score = 0.008773056, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 32000, loss = 5.5817995, metrics-onlinereview/targets/rouge_2_fscore = 0.03742939, metrics-onlinereview/targets/neg_log_perplexity = -5.5065694, metrics-onlinereview/targets/accuracy_top5 = 0.38737985\n",
      "INFO:tensorflow:loss = 4.3416786, step = 32000 (264.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.391425\n",
      "INFO:tensorflow:loss = 4.768297, step = 32100 (67.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50259\n",
      "INFO:tensorflow:loss = 4.8599715, step = 32200 (66.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5069\n",
      "INFO:tensorflow:loss = 4.416666, step = 32300 (66.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47823\n",
      "INFO:tensorflow:loss = 4.8626285, step = 32400 (67.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49857\n",
      "INFO:tensorflow:loss = 4.6943755, step = 32500 (66.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48549\n",
      "INFO:tensorflow:loss = 5.1740303, step = 32600 (67.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49807\n",
      "INFO:tensorflow:loss = 5.116475, step = 32700 (66.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46625\n",
      "INFO:tensorflow:loss = 5.150635, step = 32800 (68.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4806\n",
      "INFO:tensorflow:loss = 5.027944, step = 32900 (67.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48473\n",
      "INFO:tensorflow:loss = 4.1525264, step = 33000 (67.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48374\n",
      "INFO:tensorflow:loss = 5.693417, step = 33100 (67.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49799\n",
      "INFO:tensorflow:loss = 4.589471, step = 33200 (66.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48276\n",
      "INFO:tensorflow:loss = 4.3746767, step = 33300 (67.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49141\n",
      "INFO:tensorflow:loss = 5.2135224, step = 33400 (67.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46736\n",
      "INFO:tensorflow:loss = 4.982939, step = 33500 (68.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50816\n",
      "INFO:tensorflow:loss = 6.047804, step = 33600 (66.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47284\n",
      "INFO:tensorflow:loss = 5.6194124, step = 33700 (67.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48635\n",
      "INFO:tensorflow:loss = 4.562308, step = 33800 (67.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49352\n",
      "INFO:tensorflow:loss = 5.3348002, step = 33900 (66.956 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31502\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T00:38:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-00:41:11\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 5.5612984, metrics-onlinereview/targets/accuracy = 0.20342228, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38965338, metrics-onlinereview/targets/approx_bleu_score = 0.00981635, metrics-onlinereview/targets/neg_log_perplexity = -5.4831653, metrics-onlinereview/targets/rouge_2_fscore = 0.04012339, metrics-onlinereview/targets/rouge_L_fscore = 0.17349893\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: model_file_512/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34000): metrics-onlinereview/targets/accuracy = 0.20342228, metrics-onlinereview/targets/rouge_L_fscore = 0.17349893, metrics-onlinereview/targets/approx_bleu_score = 0.00981635, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 34000, loss = 5.5612984, metrics-onlinereview/targets/rouge_2_fscore = 0.04012339, metrics-onlinereview/targets/neg_log_perplexity = -5.4831653, metrics-onlinereview/targets/accuracy_top5 = 0.38965338\n",
      "INFO:tensorflow:loss = 4.397624, step = 34000 (263.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.392716\n",
      "INFO:tensorflow:loss = 4.775798, step = 34100 (66.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48387\n",
      "INFO:tensorflow:loss = 4.445285, step = 34200 (67.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50247\n",
      "INFO:tensorflow:loss = 5.2567363, step = 34300 (66.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50986\n",
      "INFO:tensorflow:loss = 4.903633, step = 34400 (66.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4661\n",
      "INFO:tensorflow:loss = 5.1837354, step = 34500 (68.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46477\n",
      "INFO:tensorflow:loss = 5.0366488, step = 34600 (68.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49524\n",
      "INFO:tensorflow:loss = 5.049615, step = 34700 (66.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49011\n",
      "INFO:tensorflow:loss = 6.057758, step = 34800 (67.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50037\n",
      "INFO:tensorflow:loss = 4.3067894, step = 34900 (66.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4926\n",
      "INFO:tensorflow:loss = 6.2460604, step = 35000 (66.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47048\n",
      "INFO:tensorflow:loss = 4.844031, step = 35100 (68.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50102\n",
      "INFO:tensorflow:loss = 5.7682004, step = 35200 (66.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47399\n",
      "INFO:tensorflow:loss = 4.6180434, step = 35300 (67.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48918\n",
      "INFO:tensorflow:loss = 4.572449, step = 35400 (67.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4804\n",
      "INFO:tensorflow:loss = 4.4533896, step = 35500 (67.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47797\n",
      "INFO:tensorflow:loss = 4.6911554, step = 35600 (67.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47022\n",
      "INFO:tensorflow:loss = 4.831323, step = 35700 (68.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49952\n",
      "INFO:tensorflow:loss = 5.1370687, step = 35800 (66.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48037\n",
      "INFO:tensorflow:loss = 4.3721237, step = 35900 (67.553 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.3218\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T01:03:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-01:06:52\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 5.54368, metrics-onlinereview/targets/accuracy = 0.2057756, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39196682, metrics-onlinereview/targets/approx_bleu_score = 0.009108487, metrics-onlinereview/targets/neg_log_perplexity = -5.470333, metrics-onlinereview/targets/rouge_2_fscore = 0.037886232, metrics-onlinereview/targets/rouge_L_fscore = 0.17249538\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: model_file_512/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36000): metrics-onlinereview/targets/accuracy = 0.2057756, metrics-onlinereview/targets/rouge_L_fscore = 0.17249538, metrics-onlinereview/targets/approx_bleu_score = 0.009108487, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 36000, loss = 5.54368, metrics-onlinereview/targets/rouge_2_fscore = 0.037886232, metrics-onlinereview/targets/neg_log_perplexity = -5.470333, metrics-onlinereview/targets/accuracy_top5 = 0.39196682\n",
      "INFO:tensorflow:loss = 4.370446, step = 36000 (262.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.395279\n",
      "INFO:tensorflow:loss = 5.1066203, step = 36100 (66.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47584\n",
      "INFO:tensorflow:loss = 5.232556, step = 36200 (67.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46755\n",
      "INFO:tensorflow:loss = 4.210358, step = 36300 (68.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50682\n",
      "INFO:tensorflow:loss = 4.588856, step = 36400 (66.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5082\n",
      "INFO:tensorflow:loss = 4.532184, step = 36500 (66.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48105\n",
      "INFO:tensorflow:loss = 5.84898, step = 36600 (67.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46446\n",
      "INFO:tensorflow:loss = 5.253609, step = 36700 (68.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4766\n",
      "INFO:tensorflow:loss = 4.8054447, step = 36800 (67.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50191\n",
      "INFO:tensorflow:loss = 5.335325, step = 36900 (66.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.465\n",
      "INFO:tensorflow:loss = 4.7245674, step = 37000 (68.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49833\n",
      "INFO:tensorflow:loss = 4.7486167, step = 37100 (66.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48747\n",
      "INFO:tensorflow:loss = 4.834613, step = 37200 (67.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46233\n",
      "INFO:tensorflow:loss = 5.191928, step = 37300 (68.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47288\n",
      "INFO:tensorflow:loss = 5.486403, step = 37400 (67.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49016\n",
      "INFO:tensorflow:loss = 5.1019516, step = 37500 (67.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47737\n",
      "INFO:tensorflow:loss = 5.0009956, step = 37600 (67.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50345\n",
      "INFO:tensorflow:loss = 5.284436, step = 37700 (66.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48928\n",
      "INFO:tensorflow:loss = 4.1280866, step = 37800 (67.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48565\n",
      "INFO:tensorflow:loss = 4.710208, step = 37900 (67.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.30987\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-04T01:29:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_512/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-04-01:32:37\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 5.528153, metrics-onlinereview/targets/accuracy = 0.20685254, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3953572, metrics-onlinereview/targets/approx_bleu_score = 0.009839934, metrics-onlinereview/targets/neg_log_perplexity = -5.4478498, metrics-onlinereview/targets/rouge_2_fscore = 0.040919136, metrics-onlinereview/targets/rouge_L_fscore = 0.1762026\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: model_file_512/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38000): metrics-onlinereview/targets/accuracy = 0.20685254, metrics-onlinereview/targets/rouge_L_fscore = 0.1762026, metrics-onlinereview/targets/approx_bleu_score = 0.009839934, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, global_step = 38000, loss = 5.528153, metrics-onlinereview/targets/rouge_2_fscore = 0.040919136, metrics-onlinereview/targets/neg_log_perplexity = -5.4478498, metrics-onlinereview/targets/accuracy_top5 = 0.3953572\n",
      "INFO:tensorflow:loss = 4.426422, step = 38000 (266.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.388219\n",
      "INFO:tensorflow:loss = 4.3290596, step = 38100 (67.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47827\n",
      "INFO:tensorflow:loss = 5.0493565, step = 38200 (67.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50226\n",
      "INFO:tensorflow:loss = 5.213697, step = 38300 (66.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50447\n",
      "INFO:tensorflow:loss = 4.6889834, step = 38400 (66.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49118\n",
      "INFO:tensorflow:loss = 4.5424767, step = 38500 (67.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49249\n",
      "INFO:tensorflow:loss = 5.138793, step = 38600 (67.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47385\n",
      "INFO:tensorflow:loss = 4.862534, step = 38700 (67.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47925\n",
      "INFO:tensorflow:loss = 5.451172, step = 38800 (67.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47637\n",
      "INFO:tensorflow:loss = 4.530423, step = 38900 (67.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47779\n",
      "INFO:tensorflow:loss = 4.8707747, step = 39000 (67.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52438\n",
      "INFO:tensorflow:loss = 5.4296746, step = 39100 (65.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47416\n",
      "INFO:tensorflow:loss = 4.076049, step = 39200 (67.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50849\n",
      "INFO:tensorflow:loss = 4.368683, step = 39300 (66.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46426\n",
      "INFO:tensorflow:loss = 3.9241366, step = 39400 (68.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49014\n",
      "INFO:tensorflow:loss = 5.91794, step = 39500 (67.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49808\n",
      "INFO:tensorflow:loss = 4.17875, step = 39600 (66.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46211\n",
      "INFO:tensorflow:loss = 5.2239223, step = 39700 (68.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49489\n",
      "INFO:tensorflow:loss = 5.1912007, step = 39800 (66.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46656\n",
      "INFO:tensorflow:loss = 5.6639066, step = 39900 (68.190 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_512/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.467051.\n",
      "Time: 30702.57 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_512'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 2048 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "hparams.num_encoder_layers = 6\n",
    "# hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.3\n",
    "# hparams.num_heads =16\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_input_seq_length = 512\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_512 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40000,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_512.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_zero_grads': False, 'multiproblem_per_task_threshold': '', 'force_full_predict': False, 'pretrained_model_dir': '', 'layer_prepostprocess_dropout_broadcast_dims': '', 'multiproblem_max_input_length': -1, 'hidden_size': 512, 'scheduled_sampling_warmup_steps': 50000, 'batch_size': 1024, 'multiproblem_label_weight': 0.5, 'max_relative_position': 0, 'norm_type': 'layer', 'symbol_modality_num_shards': 16, 'min_length': 0, 'attention_key_channels': 0, 'layer_preprocess_sequence': 'n', 'use_pad_remover': True, 'video_num_target_frames': 1, 'moe_overhead_train': 1.0, 'optimizer_adafactor_beta1': 0.0, 'weight_decay': 0.0, 'sampling_temp': 1.0, 'max_target_seq_length': 0, 'learning_rate': 0.1, 'weight_dtype': 'float32', 'max_length': 512, 'factored_logits': False, 'multiproblem_max_target_length': -1, 'heads_share_relative_embedding': False, 'max_input_seq_length': 0, 'eval_drop_long_sequences': False, 'moe_overhead_eval': 2.0, 'activation_dtype': 'float32', 'shared_embedding': False, 'layer_postprocess_sequence': 'da', 'nbr_decoder_problems': 1, 'optimizer_adam_epsilon': 1e-09, 'optimizer_adam_beta2': 0.98, 'learning_rate_decay_staircase': False, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'optimizer_adafactor_beta2': 0.999, 'multiply_embedding_mode': 'sqrt_depth', 'relu_dropout_broadcast_dims': '', 'optimizer_adafactor_decay_type': 'pow', 'scheduled_sampling_gold_mixin_prob': 0.5, 'optimizer_adafactor_memory_exponent': 0.8, 'initializer': 'uniform_unit_scaling', 'multiproblem_vocab_size': -1, 'optimizer_adafactor_factored': True, 'kernel_width': 1, 'mlperf_mode': False, 'optimizer_adam_beta1': 0.9, 'multiproblem_fixed_train_length': -1, 'moe_hidden_sizes': '2048', 'learning_rate_warmup_steps': 4000, 'causal_decoder_self_attention': True, 'multiproblem_target_eval_only': False, 'overload_eval_metric_name': '', 'batch_shuffle_size': 512, 'pos': 'timing', 'clip_grad_norm': 0.0, 'warm_start_from_second': '', 'vocab_divisor': 1, 'learning_rate_constant': 1.0, 'sampling_method': 'argmax', 'add_relative_to_values': False, 'unidirectional_encoder': False, 'conv_first_kernel': 3, 'use_target_space_embedding': True, 'learning_rate_decay_rate': 1.0, 'num_encoder_layers': 0, 'ffn_layer': 'dense_relu_dense', 'optimizer_momentum_momentum': 0.9, 'attention_dropout_broadcast_dims': '', 'symbol_modality_skip_top': False, 'daisy_chain_variables': True, 'multiproblem_reweight_label_loss': False, 'learning_rate_minimum': None, 'proximity_bias': False, 'modality': {}, 'parameter_attention_key_channels': 0, 'self_attention_type': 'dot_product', 'multiproblem_mixing_schedule': 'constant', 'optimizer_adafactor_clipping_threshold': 1.0, 'min_length_bucket': 8, 'video_num_input_frames': 1, 'symbol_dropout': 0.0, 'learning_rate_decay_scheme': 'noam', 'summarize_vars': False, 'compress_steps': 0, 'filter_size': 2048, 'attention_dropout': 0.1, 'split_to_length': 0, 'shared_embedding_and_softmax_weights': True, 'moe_num_experts': 16, 'weight_noise': 0.0, 'label_smoothing': 0.1, 'pad_batch': False, 'optimizer_momentum_nesterov': False, 'learning_rate_cosine_cycle_steps': 250000, 'kernel_height': 3, 'moe_k': 2, 'summarize_grads': False, 'num_hidden_layers': 6, 'norm_epsilon': 1e-06, 'initializer_gain': 1.0, 'moe_loss_coef': 0.001, 'dropout': 0.1, 'attention_variables_3d': False, 'learning_rate_decay_steps': 5000, 'multiproblem_schedule_threshold': 0.5, 'use_fixed_batch_size': False, 'scheduled_sampling_prob': 0.0, 'optimizer': 'Adam', 'parameter_attention_value_channels': 0, 'num_decoder_layers': 0, 'grad_noise_scale': 0.0, 'no_data_parallelism': False, 'prepend_mode': 'prepend_inputs_full_attention', 'optimizer_multistep_accumulate_steps': None, 'length_bucket_step': 1.1, 'tpu_enable_host_call': False, 'layer_prepostprocess_dropout': 0.1, 'eval_run_autoregressive': False, 'num_heads': 8, 'multiproblem_schedule_max_examples': 10000000.0, 'learning_rate_schedule': 'legacy', 'relu_dropout': 0.1, 'attention_value_channels': 0}\n",
      "{'delimiter': '\\n', 'max_display_outputs': 10, 'alpha': 0.6, 'batch_size': 0, 'shard_google_format': False, 'save_images': False, 'eos_penalty': 0.0, 'force_decode_length': False, 'decode_in_memory': False, 'guess_and_check_epsilon': -1, 'display_decoded_images': False, 'decode_to_file': None, 'frames_per_second': 10, 'beam_size': 4, 'max_display_decodes': 5, 'summaries_log_dir': 'decode', 'return_beams': True, 'num_samples': -1, 'vgg_ckpt_path': '', 'block_size': 0, 'max_input_size': -1, 'border_percent': 2, 'identity_output': False, 'shards': 1, 'write_beam_scores': False, 'extra_length': 100, 'guess_and_check_top_k': 0, 'mlperf_threshold': 25.0, 'log_results': True, 'mlperf_decode_step': 0.0, 'shard_id': 0, 'decode_timeout_mins': 240, 'skip_eos_postprocess': False, 'num_decodes': 1, 'shards_start_offset': 0, 'mlperf_success': False, 'multiproblem_task_id': -1}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', 'use_tpu': False, '_keep_checkpoint_max': 20, '_train_distribute': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_environment': 'local', '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'model_file_prepend512', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4afc0eba90>, '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f495d8894a8>, '_tf_random_seed': None, '_eval_distribute': None, '_save_checkpoints_secs': None, '_task_type': None, '_protocol': None, '_num_worker_replicas': 0, '_device_fn': None, '_save_checkpoints_steps': 2000, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_master': '', '_num_ps_replicas': 0}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f495d888d08>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4afc0eb908>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f4afc0eb860>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4b74580b70>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f4b74580b70>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.100000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_prepend512/model.ckpt-40000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into model_file_prepend512/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-05T05:05:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_prepend512/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-05-05:09:37\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 5.990597, metrics-onlinereview/targets/accuracy = 0.15677562, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.32315138, metrics-onlinereview/targets/approx_bleu_score = 0.007165591, metrics-onlinereview/targets/neg_log_perplexity = -5.940348, metrics-onlinereview/targets/rouge_2_fscore = 0.030034041, metrics-onlinereview/targets/rouge_L_fscore = 0.15056887\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: model_file_prepend512/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40001): metrics-onlinereview/targets/rouge_2_fscore = 0.030034041, metrics-onlinereview/targets/approx_bleu_score = 0.007165591, loss = 5.990597, metrics-onlinereview/targets/neg_log_perplexity = -5.940348, metrics-onlinereview/targets/rouge_L_fscore = 0.15056887, metrics-onlinereview/targets/accuracy = 0.15677562, global_step = 40000, metrics-onlinereview/targets/accuracy_top5 = 0.32315138, metrics-onlinereview/targets/accuracy_per_sequence = 0.0\n",
      "INFO:tensorflow:loss = 5.0733676, step = 40000\n",
      "INFO:tensorflow:global_step/sec: 0.348408\n",
      "INFO:tensorflow:loss = 4.3935795, step = 40100 (40.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82878\n",
      "INFO:tensorflow:loss = 4.632827, step = 40200 (35.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9359\n",
      "INFO:tensorflow:loss = 4.8310237, step = 40300 (34.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81873\n",
      "INFO:tensorflow:loss = 5.0208144, step = 40400 (35.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87922\n",
      "INFO:tensorflow:loss = 5.2621737, step = 40500 (34.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83139\n",
      "INFO:tensorflow:loss = 5.2876277, step = 40600 (35.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90993\n",
      "INFO:tensorflow:loss = 4.8899364, step = 40700 (34.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85136\n",
      "INFO:tensorflow:loss = 5.004295, step = 40800 (35.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82626\n",
      "INFO:tensorflow:loss = 4.5516586, step = 40900 (35.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85191\n",
      "INFO:tensorflow:loss = 6.933868, step = 41000 (35.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89183\n",
      "INFO:tensorflow:loss = 5.290287, step = 41100 (34.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82649\n",
      "INFO:tensorflow:loss = 6.3045483, step = 41200 (35.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88374\n",
      "INFO:tensorflow:loss = 6.127219, step = 41300 (34.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83752\n",
      "INFO:tensorflow:loss = 5.649909, step = 41400 (35.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83442\n",
      "INFO:tensorflow:loss = 5.559731, step = 41500 (35.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85224\n",
      "INFO:tensorflow:loss = 4.6881843, step = 41600 (35.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84436\n",
      "INFO:tensorflow:loss = 5.075343, step = 41700 (35.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8595\n",
      "INFO:tensorflow:loss = 5.766638, step = 41800 (34.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80339\n",
      "INFO:tensorflow:loss = 4.5548086, step = 41900 (35.673 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42000 into model_file_prepend512/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.26823\n",
      "INFO:tensorflow:loss = 6.422028, step = 42000 (44.087 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42001 into model_file_prepend512/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.422028.\n",
      "Time: 1036.76 s\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_prepend512'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 1024 #2048 #512 \n",
    "hparams.learning_rate_warmup_steps = 4000\n",
    "hparams.learning_rate = 0.1 \n",
    "# hparams.num_encoder_layers = 6\n",
    "hparams.num_hidden_layers = 6\n",
    "# hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.1\n",
    "# hparams.num_heads =16\n",
    "hparams.attention_dropout = 0.1 ##\n",
    "hparams.max_length = 512\n",
    "# hparams.max_input_seq_length = 512\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "# decode_hp.block_size =6\n",
    "decode_hp.return_beams = True #True\n",
    "decode_hp.beam_size = 4\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_prepend512 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=42001,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_prepend512.train_and_evaluate()\n",
    "\n",
    "# running time check (running on 1GPU server)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} s'.format(round(stop - start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Decoding check 1--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_file_prepend512/model.ckpt-40000\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "DATA_LOC = './data' \n",
    "t2t_problem = problems.problem('onlinereview')\n",
    "vocab_name = \"./data/vocab.onlinereview.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "model = registry.model(MODEL)(hparams, Modes.EVAL) #tensorflow_exp_fn\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint('model_file_prepend512') #model.ckpt\n",
    "print(ckpt_path)\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create('./model_file_prepend512/model.ckpt-40000'):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.\n",
      "Pred_summary: but not but not but i have ever ever ever not have have have ever not i have not i have not but i have ever not good but i have ever not was not but i have ever not i have ever not was not was not but i have ever not but i have ever not i have ever not but i have ever not i have ever not good but i have ever not i have ever not but i have ever not but i have ever not i have ever not i have ever not was not i have ever not i have\n",
      "Gold_summary:i was disappointed that you would only allow me to purchase 4 when your inventory showed that you had 14 available\n",
      "-------------------------------------------------- \n",
      "\n",
      "Review: \n",
      "my daughter wore this every other day for maybe half an hour at most the waistband has completely separated from the elastic after two weeks of this light use\n",
      "\n",
      "Pred_summary: but not but not but not but not but i have not have not i have not i have not but i have not but i have ever not my service i have ever used my service not my service i have ever used my service i have ever used my service i have ever made my service i have ever made my service i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever made\n",
      "Gold_summary:this was great until it fell apart two weeks later\n",
      "-------------------------------------------------- \n",
      "\n",
      "Review: \n",
      "unfortunately this skirts elastic is not stretchy enough to accommodate the 29 year old range , this is crazy i would say it only stretches through about 1 size i would throw this in a costume play chest with a safety pin handy and call it a day  \n",
      "\n",
      "Pred_summary: but not but not but not but i have ever not have not love i have not i have not not but i have not my service i have ever used it was not my service i have ever used my service i have ever used my service i have ever used it was not my service i have ever used it was a good for my phone to use it is not work well, but i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever\n",
      "Gold_summary:i should have paid more attention to the age range\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "review1 = '''\n",
    "we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.'''\n",
    "\n",
    "gold1 = '''i was disappointed that you would only allow me to purchase 4 when your inventory showed that you had 14 available'''\n",
    "\n",
    "review2 = '''\n",
    "my daughter wore this every other day for maybe half an hour at most the waistband has completely separated from the elastic after two weeks of this light use\n",
    "'''\n",
    "gold2 = '''this was great until it fell apart two weeks later'''\n",
    "\n",
    "review3 = '''\n",
    "unfortunately this skirts elastic is not stretchy enough to accommodate the 29 year old range , this is crazy i would say it only stretches through about 1 size i would throw this in a costume play chest with a safety pin handy and call it a day  \n",
    "'''\n",
    "gold3 = '''i should have paid more attention to the age range'''\n",
    "\n",
    "for review, summary in [(review1,gold1), (review2, gold2), (review3, gold3)]:\n",
    "    pred_summary = summarize(review)\n",
    "    print(\"Review: %s\" % review)\n",
    "    print(\"Pred_summary: %s\" % pred_summary)\n",
    "    print(\"Gold_summary:%s\" % summary)\n",
    "    print('-----'*10, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---decoding check 2---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', 'use_tpu': False, '_keep_checkpoint_max': 20, '_train_distribute': None, '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_environment': 'local', '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'model_file_prepend512', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4bdac577f0>, '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f495e77c438>, '_tf_random_seed': None, '_eval_distribute': None, '_save_checkpoints_secs': None, '_task_type': None, '_protocol': None, '_num_worker_replicas': 0, '_device_fn': None, '_save_checkpoints_steps': 1000, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_master': '', '_num_ps_replicas': 0}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f4b40fa97b8>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">we have many of the old, old issue. but the number had depleted. there were not  enough books to allow us to use them regularly. with the additional supply the books will be used more often.  they arre a good old standby for gospel singing.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_file_prepend512/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"but not but not but i have got i have got i have i have i have not but i have not but i have found i have found i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever not i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever not i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever not i have ever ever ever ever ever ever ever ever ever not i have ever not i have ever not i have ever not i have ever not i have ever not i have ever not i have ever not i have ever not i have\"\tScore:-324.506226\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\"but not but not but i have got i have got i have i have i have not but i have not but i have found i have found i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever not i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever not i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever not i have ever ever ever ever ever ever ever ever ever not i have ever not i have ever not i have ever not i have ever not i have ever not i have ever not i have ever not i have ever not i was\"\tScore:-325.607788\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">my daughter wore this every other day for maybe half an hour at most the waistband has completely separated from the elastic after two weeks of this light use\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"but not but i have ever not have have have have ever not have not have not i have not but i have not but i have ever ever ever ever not got i have ever ever not i have had i have have have have have have ever ever ever not my service\"\tScore:-36.584007\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\"but not but i have ever not have have have have ever not have not have not i have not but i have not but i have ever ever ever ever not got i have ever ever not i have had i have have have have have have ever ever ever not my service i have ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever ever used\"\tScore:-54.223686\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">unfortunately this skirts elastic is not stretchy enough to accommodate the 29 year old range , this is crazy i would say it only stretches through about 1 size i would throw this in a costume play chest with a safety pin handy and call it a day\n",
      "INFO:tensorflow:BEAM 0:\n",
      "INFO:tensorflow:\"but not but i have ever not have have have have not have ever not have not i have not but i have not my service i have ever used it works well, but i have ever used it is a little small\"\tScore:-32.378811\n",
      "INFO:tensorflow:BEAM 1:\n",
      "INFO:tensorflow:\"<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\tScore:-10000000.000000\n",
      "INTERACTIVE MODE  num_samples=1  decode_length=100  \n",
      "  it=<input_type>     ('text' or 'image' or 'label', default: text)\n",
      "  ns=<num_samples>    (changes number of samples, default: 1)\n",
      "  dl=<decode_length>  (changes decode length, default: 100)\n",
      "  <source_string>                (decode)\n",
      "  q                   (quit)\n",
      ">q\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.utils import trainer_lib, decoding\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(\"./model_file_prepend512\") #model.ckpt\n",
    "\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "\n",
    "def create_decode_hparams():\n",
    "    decode_hp = decoding.decode_hparams()\n",
    "    decode_hp.shards = 1 #tf.flags.FLAGS.decode_shards\n",
    "#     decode_hp.shard_id = flags.FLAGS.worker_id\n",
    "    decode_in_memory = decode_hp.decode_in_memory\n",
    "    decode_hp.decode_in_memory = decode_in_memory\n",
    "    decode_hp.return_beams =True\n",
    "    decode_hp.beam_size = 2\n",
    "#     decode_hp.decode_to_file = FLAGS.decode_to_file\n",
    "#     decode_hp.decode_reference = FLAGS.decode_reference\n",
    "    return decode_hp\n",
    "decode_hp = create_decode_hparams()\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,)\n",
    "\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    MODEL,\n",
    "    hparams,\n",
    "    RUN_CONFIG, #t2t_trainer.create_run_config(hparams),\n",
    "    decode_hparams=decode_hp)\n",
    "\n",
    "decoding.decode_interactively(estimator, hparams, decode_hp, checkpoint_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxlen 256 -prepend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_adafactor_beta1': 0.0, 'multiproblem_schedule_threshold': 0.5, 'video_num_target_frames': 1, 'attention_value_channels': 0, 'moe_num_experts': 16, 'eval_run_autoregressive': False, 'grad_noise_scale': 0.0, 'learning_rate_minimum': None, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'attention_dropout_broadcast_dims': '', 'weight_dtype': 'float32', 'dropout': 0.3, 'num_hidden_layers': 6, 'use_fixed_batch_size': False, 'initializer': 'uniform_unit_scaling', 'moe_overhead_eval': 2.0, 'causal_decoder_self_attention': True, 'sampling_temp': 1.0, 'conv_first_kernel': 3, 'min_length': 0, 'scheduled_sampling_prob': 0.0, 'optimizer_zero_grads': False, 'multiproblem_mixing_schedule': 'constant', 'max_length': 256, 'max_target_seq_length': 0, 'moe_hidden_sizes': '2048', 'symbol_modality_skip_top': False, 'self_attention_type': 'dot_product', 'multiproblem_schedule_max_examples': 10000000.0, 'mlperf_mode': False, 'relu_dropout_broadcast_dims': '', 'optimizer_adafactor_clipping_threshold': 1.0, 'optimizer_adafactor_beta2': 0.999, 'parameter_attention_key_channels': 0, 'length_bucket_step': 1.1, 'moe_overhead_train': 1.0, 'split_to_length': 0, 'pos': 'timing', 'optimizer_adafactor_memory_exponent': 0.8, 'scheduled_sampling_warmup_steps': 50000, 'shared_embedding': False, 'norm_type': 'layer', 'moe_k': 2, 'learning_rate_schedule': 'legacy', 'compress_steps': 0, 'shared_embedding_and_softmax_weights': True, 'use_target_space_embedding': True, 'activation_dtype': 'float32', 'video_num_input_frames': 1, 'learning_rate_cosine_cycle_steps': 250000, 'vocab_divisor': 1, 'tpu_enable_host_call': False, 'min_length_bucket': 8, 'multiply_embedding_mode': 'sqrt_depth', 'batch_shuffle_size': 512, 'learning_rate_decay_staircase': False, 'layer_preprocess_sequence': 'n', 'kernel_height': 3, 'summarize_vars': False, 'use_pad_remover': True, 'max_input_seq_length': 0, 'scheduled_sampling_gold_mixin_prob': 0.5, 'heads_share_relative_embedding': False, 'optimizer_momentum_momentum': 0.9, 'hidden_size': 512, 'num_encoder_layers': 6, 'initializer_gain': 1.0, 'relu_dropout': 0.1, 'learning_rate_decay_scheme': 'noam', 'clip_grad_norm': 0.0, 'max_relative_position': 0, 'learning_rate_decay_rate': 1.0, 'symbol_modality_num_shards': 16, 'moe_loss_coef': 0.001, 'weight_decay': 0.0, 'multiproblem_label_weight': 0.5, 'summarize_grads': False, 'learning_rate_decay_steps': 5000, 'daisy_chain_variables': True, 'optimizer': 'Adam', 'num_decoder_layers': 6, 'sampling_method': 'argmax', 'ffn_layer': 'dense_relu_dense', 'layer_prepostprocess_dropout': 0.1, 'learning_rate_warmup_steps': 8000, 'no_data_parallelism': False, 'eval_drop_long_sequences': False, 'multiproblem_per_task_threshold': '', 'optimizer_adam_epsilon': 1e-09, 'pretrained_model_dir': '', 'proximity_bias': False, 'attention_variables_3d': False, 'multiproblem_max_input_length': -1, 'factored_logits': False, 'unidirectional_encoder': False, 'multiproblem_fixed_train_length': -1, 'num_heads': 8, 'attention_key_channels': 0, 'optimizer_adam_beta1': 0.9, 'optimizer_adam_beta2': 0.98, 'nbr_decoder_problems': 1, 'prepend_mode': 'prepend_inputs_full_attention', 'multiproblem_max_target_length': -1, 'learning_rate': 0.05, 'batch_size': 1024, 'warm_start_from_second': '', 'kernel_width': 1, 'multiproblem_vocab_size': -1, 'attention_dropout': 0.2, 'multiproblem_target_eval_only': False, 'weight_noise': 0.0, 'modality': {}, 'layer_postprocess_sequence': 'da', 'optimizer_momentum_nesterov': False, 'parameter_attention_value_channels': 0, 'label_smoothing': 0.1, 'norm_epsilon': 1e-06, 'force_full_predict': False, 'filter_size': 2048, 'add_relative_to_values': False, 'optimizer_adafactor_factored': True, 'learning_rate_constant': 1.0, 'optimizer_multistep_accumulate_steps': None, 'layer_prepostprocess_dropout_broadcast_dims': '', 'pad_batch': False, 'symbol_dropout': 0.0, 'optimizer_adafactor_decay_type': 'pow', 'overload_eval_metric_name': '', 'multiproblem_reweight_label_loss': False}\n",
      "{'identity_output': False, 'decode_in_memory': False, 'block_size': 0, 'shards': 1, 'guess_and_check_top_k': 0, 'mlperf_decode_step': 0.0, 'mlperf_threshold': 25.0, 'save_images': False, 'log_results': True, 'force_decode_length': False, 'num_decodes': 1, 'max_input_size': -1, 'extra_length': 100, 'max_display_outputs': 10, 'num_samples': -1, 'multiproblem_task_id': -1, 'vgg_ckpt_path': '', 'decode_to_file': None, 'eos_penalty': 0.0, 'delimiter': '\\n', 'shard_google_format': False, 'display_decoded_images': False, 'skip_eos_postprocess': False, 'max_display_decodes': 5, 'shards_start_offset': 0, 'shard_id': 0, 'guess_and_check_epsilon': -1, 'write_beam_scores': False, 'mlperf_success': False, 'beam_size': 2, 'batch_size': 0, 'alpha': 0.6, 'return_beams': True, 'border_percent': 2, 'summaries_log_dir': 'decode', 'decode_timeout_mins': 240, 'frames_per_second': 10}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_file_256', '_tf_random_seed': None, '_keep_checkpoint_max': 20, '_evaluation_master': '', '_device_fn': None, '_save_checkpoints_secs': None, '_master': '', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_type': None, '_is_chief': True, '_save_summary_steps': 100, 'use_tpu': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f68691d7d68>, 't2t_device_info': {'num_async_replicas': 1}, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_environment': 'local', '_task_id': 0, '_protocol': None, '_eval_distribute': None, '_num_ps_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_train_distribute': None, '_save_checkpoints_steps': 2000, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f68691d7da0>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f6869402d08>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f68691d7be0>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7f68691d7b38>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f68693ff860>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7f68693ff860>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.050000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_file_256/model.ckpt-2000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model_file_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-06T14:16:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_256/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-06-14:24:38\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 6.3921523, metrics-onlinereview/targets/accuracy = 0.12664446, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.27386865, metrics-onlinereview/targets/approx_bleu_score = 0.004910959, metrics-onlinereview/targets/neg_log_perplexity = -6.379136, metrics-onlinereview/targets/rouge_2_fscore = 0.024990408, metrics-onlinereview/targets/rouge_L_fscore = 0.13308798\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: model_file_256/model.ckpt-2000\n",
      "INFO:tensorflow:Validation (step 2001): metrics-onlinereview/targets/rouge_L_fscore = 0.13308798, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy = 0.12664446, metrics-onlinereview/targets/approx_bleu_score = 0.004910959, metrics-onlinereview/targets/accuracy_top5 = 0.27386865, global_step = 2000, metrics-onlinereview/targets/rouge_2_fscore = 0.024990408, metrics-onlinereview/targets/neg_log_perplexity = -6.379136, loss = 6.3921523\n",
      "INFO:tensorflow:loss = 5.855402, step = 2000\n",
      "INFO:tensorflow:global_step/sec: 0.186467\n",
      "INFO:tensorflow:loss = 4.925283, step = 2100 (39.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92703\n",
      "INFO:tensorflow:loss = 5.6862545, step = 2200 (34.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96751\n",
      "INFO:tensorflow:loss = 5.3832054, step = 2300 (33.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95003\n",
      "INFO:tensorflow:loss = 5.549893, step = 2400 (33.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98441\n",
      "INFO:tensorflow:loss = 5.210897, step = 2500 (33.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93151\n",
      "INFO:tensorflow:loss = 4.80753, step = 2600 (34.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94119\n",
      "INFO:tensorflow:loss = 5.129966, step = 2700 (33.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93672\n",
      "INFO:tensorflow:loss = 5.3809705, step = 2800 (34.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95121\n",
      "INFO:tensorflow:loss = 5.6696377, step = 2900 (33.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96291\n",
      "INFO:tensorflow:loss = 5.6236453, step = 3000 (33.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92342\n",
      "INFO:tensorflow:loss = 5.2288613, step = 3100 (34.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91628\n",
      "INFO:tensorflow:loss = 5.3854256, step = 3200 (34.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93364\n",
      "INFO:tensorflow:loss = 5.05598, step = 3300 (34.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93232\n",
      "INFO:tensorflow:loss = 5.553885, step = 3400 (34.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94951\n",
      "INFO:tensorflow:loss = 5.777521, step = 3500 (33.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95188\n",
      "INFO:tensorflow:loss = 6.1027155, step = 3600 (33.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92223\n",
      "INFO:tensorflow:loss = 4.82012, step = 3700 (34.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93437\n",
      "INFO:tensorflow:loss = 5.078138, step = 3800 (34.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92547\n",
      "INFO:tensorflow:loss = 4.890728, step = 3900 (34.183 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36585\n",
      "INFO:tensorflow:loss = 4.711343, step = 4000 (42.268 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-06T14:36:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_256/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-06-14:46:37\n",
      "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 6.1225104, metrics-onlinereview/targets/accuracy = 0.15148206, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3045472, metrics-onlinereview/targets/approx_bleu_score = 0.0063934014, metrics-onlinereview/targets/neg_log_perplexity = -6.0973153, metrics-onlinereview/targets/rouge_2_fscore = 0.03102391, metrics-onlinereview/targets/rouge_L_fscore = 0.1443206\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model_file_256/model.ckpt-4000\n",
      "INFO:tensorflow:Validation (step 4001): metrics-onlinereview/targets/rouge_L_fscore = 0.1443206, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy = 0.15148206, metrics-onlinereview/targets/approx_bleu_score = 0.0063934014, metrics-onlinereview/targets/accuracy_top5 = 0.3045472, global_step = 4000, metrics-onlinereview/targets/rouge_2_fscore = 0.03102391, metrics-onlinereview/targets/neg_log_perplexity = -6.0973153, loss = 6.1225104\n",
      "INFO:tensorflow:global_step/sec: 0.151854\n",
      "INFO:tensorflow:loss = 5.1791787, step = 4100 (658.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93437\n",
      "INFO:tensorflow:loss = 4.8349805, step = 4200 (34.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94166\n",
      "INFO:tensorflow:loss = 5.5511823, step = 4300 (33.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98023\n",
      "INFO:tensorflow:loss = 5.077014, step = 4400 (33.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95162\n",
      "INFO:tensorflow:loss = 5.253662, step = 4500 (33.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97495\n",
      "INFO:tensorflow:loss = 5.252309, step = 4600 (33.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91891\n",
      "INFO:tensorflow:loss = 4.9610643, step = 4700 (34.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97021\n",
      "INFO:tensorflow:loss = 5.151682, step = 4800 (33.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98019\n",
      "INFO:tensorflow:loss = 5.3316174, step = 4900 (33.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92278\n",
      "INFO:tensorflow:loss = 5.181095, step = 5000 (34.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91543\n",
      "INFO:tensorflow:loss = 6.0455565, step = 5100 (34.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91993\n",
      "INFO:tensorflow:loss = 4.7018924, step = 5200 (34.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92711\n",
      "INFO:tensorflow:loss = 4.99054, step = 5300 (34.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93509\n",
      "INFO:tensorflow:loss = 5.2184267, step = 5400 (34.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90972\n",
      "INFO:tensorflow:loss = 5.283453, step = 5500 (34.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95825\n",
      "INFO:tensorflow:loss = 5.7036443, step = 5600 (33.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93991\n",
      "INFO:tensorflow:loss = 4.8702173, step = 5700 (34.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93137\n",
      "INFO:tensorflow:loss = 4.6799283, step = 5800 (34.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93433\n",
      "INFO:tensorflow:loss = 6.33673, step = 5900 (34.080 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36306\n",
      "INFO:tensorflow:loss = 5.2410145, step = 6000 (42.317 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-06T14:58:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_256/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-06-15:12:55\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 6.0323424, metrics-onlinereview/targets/accuracy = 0.15879688, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3169933, metrics-onlinereview/targets/approx_bleu_score = 0.0078654485, metrics-onlinereview/targets/neg_log_perplexity = -6.0046387, metrics-onlinereview/targets/rouge_2_fscore = 0.035207447, metrics-onlinereview/targets/rouge_L_fscore = 0.15114479\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: model_file_256/model.ckpt-6000\n",
      "INFO:tensorflow:Validation (step 6001): metrics-onlinereview/targets/rouge_L_fscore = 0.15114479, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy = 0.15879688, metrics-onlinereview/targets/approx_bleu_score = 0.0078654485, metrics-onlinereview/targets/accuracy_top5 = 0.3169933, global_step = 6000, metrics-onlinereview/targets/rouge_2_fscore = 0.035207447, metrics-onlinereview/targets/neg_log_perplexity = -6.0046387, loss = 6.0323424\n",
      "INFO:tensorflow:global_step/sec: 0.108152\n",
      "INFO:tensorflow:loss = 5.459616, step = 6100 (924.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98282\n",
      "INFO:tensorflow:loss = 5.7565355, step = 6200 (33.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94671\n",
      "INFO:tensorflow:loss = 4.8189235, step = 6300 (33.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96526\n",
      "INFO:tensorflow:loss = 5.192948, step = 6400 (33.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90792\n",
      "INFO:tensorflow:loss = 5.3796344, step = 6500 (34.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94954\n",
      "INFO:tensorflow:loss = 5.8380136, step = 6600 (33.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95228\n",
      "INFO:tensorflow:loss = 6.438981, step = 6700 (33.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94986\n",
      "INFO:tensorflow:loss = 5.0803466, step = 6800 (33.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91208\n",
      "INFO:tensorflow:loss = 4.803201, step = 6900 (34.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97331\n",
      "INFO:tensorflow:loss = 4.256648, step = 7000 (33.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96069\n",
      "INFO:tensorflow:loss = 5.4222503, step = 7100 (33.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93938\n",
      "INFO:tensorflow:loss = 5.485466, step = 7200 (34.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88809\n",
      "INFO:tensorflow:loss = 4.8654966, step = 7300 (34.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95416\n",
      "INFO:tensorflow:loss = 5.8902397, step = 7400 (33.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92652\n",
      "INFO:tensorflow:loss = 5.6201863, step = 7500 (34.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94566\n",
      "INFO:tensorflow:loss = 5.414527, step = 7600 (33.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99006\n",
      "INFO:tensorflow:loss = 4.9196353, step = 7700 (33.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92027\n",
      "INFO:tensorflow:loss = 5.2078557, step = 7800 (34.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92137\n",
      "INFO:tensorflow:loss = 4.3221135, step = 7900 (34.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.366\n",
      "INFO:tensorflow:loss = 5.304382, step = 8000 (42.266 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-06T15:24:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_file_256/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-88c75428b7e3>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[{{node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-88c75428b7e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mt2t_model_256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m                          \u001b[0;34m\"model evaluation. Assuming ValidationMonitor present \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                          \"in train_hooks.\")\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_steps)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         max_steps=max_steps or self._train_spec.max_steps)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1333\u001b[0m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m               run_metadata=run_metadata))\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mafter_run\u001b[0;34m(self, run_context, run_values)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \"monitors\"] if \"monitors\" in run_values.results else {}\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m       \u001b[0minduce_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minduce_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mstep_end\u001b[0;34m(self, step, output)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEveryN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_every_n_step_begin_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevery_n_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mevery_n_step_end\u001b[0;34m(self, step, outputs)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# Run evaluation and log it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m     \u001b[0mvalidation_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36m_evaluate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m           name=self.name)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._estimator.evaluate(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    467\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m   def _actual_eval(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[0;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[0;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m         config=self._session_config)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-88c75428b7e3>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = 'model_file_256'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 1024 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "hparams.num_encoder_layers = 6\n",
    "# hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.3\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_length = 256\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40200,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "#         eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'symbol_modality_num_shards': 16, 'multiproblem_label_weight': 0.5, 'mlperf_mode': False, 'shared_embedding': False, 'length_bucket_step': 1.1, 'grad_noise_scale': 0.0, 'multiproblem_schedule_threshold': 0.5, 'learning_rate_decay_rate': 1.0, 'initializer_gain': 1.0, 'layer_prepostprocess_dropout_broadcast_dims': '', 'symbol_dropout': 0.0, 'moe_hidden_sizes': '2048', 'use_target_space_embedding': True, 'layer_postprocess_sequence': 'da', 'initializer': 'uniform_unit_scaling', 'conv_first_kernel': 3, 'force_full_predict': False, 'optimizer_adafactor_decay_type': 'pow', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'relu_dropout': 0.1, 'video_num_target_frames': 1, 'learning_rate': 0.05, 'activation_dtype': 'float32', 'kernel_height': 3, 'ffn_layer': 'dense_relu_dense', 'optimizer_momentum_momentum': 0.9, 'attention_dropout': 0.2, 'hidden_size': 512, 'scheduled_sampling_gold_mixin_prob': 0.5, 'num_hidden_layers': 6, 'batch_size': 1024, 'num_heads': 8, 'symbol_modality_skip_top': False, 'unidirectional_encoder': False, 'max_relative_position': 0, 'multiproblem_mixing_schedule': 'constant', 'shared_embedding_and_softmax_weights': True, 'batch_shuffle_size': 512, 'no_data_parallelism': False, 'learning_rate_minimum': None, 'split_to_length': 0, 'video_num_input_frames': 1, 'optimizer_adafactor_memory_exponent': 0.8, 'add_relative_to_values': False, 'weight_decay': 0.0, 'optimizer_adam_beta1': 0.9, 'multiproblem_max_target_length': -1, 'causal_decoder_self_attention': True, 'max_length': 256, 'daisy_chain_variables': True, 'warm_start_from_second': '', 'moe_loss_coef': 0.001, 'attention_dropout_broadcast_dims': '', 'relu_dropout_broadcast_dims': '', 'summarize_grads': False, 'sampling_method': 'argmax', 'num_decoder_layers': 6, 'factored_logits': False, 'moe_overhead_eval': 2.0, 'eval_drop_long_sequences': False, 'prepend_mode': 'prepend_inputs_full_attention', 'nbr_decoder_problems': 1, 'modality': {}, 'multiproblem_schedule_max_examples': 10000000.0, 'optimizer_adafactor_clipping_threshold': 1.0, 'multiproblem_max_input_length': -1, 'learning_rate_cosine_cycle_steps': 250000, 'clip_grad_norm': 0.0, 'optimizer_adam_epsilon': 1e-09, 'learning_rate_decay_scheme': 'noam', 'sampling_temp': 1.0, 'max_target_seq_length': 0, 'optimizer_adam_beta2': 0.98, 'dropout': 0.3, 'kernel_width': 1, 'attention_value_channels': 0, 'min_length': 0, 'filter_size': 2048, 'multiproblem_vocab_size': -1, 'num_encoder_layers': 6, 'learning_rate_decay_staircase': False, 'self_attention_type': 'dot_product', 'weight_dtype': 'float32', 'attention_key_channels': 0, 'multiply_embedding_mode': 'sqrt_depth', 'weight_noise': 0.0, 'proximity_bias': False, 'layer_preprocess_sequence': 'n', 'scheduled_sampling_prob': 0.0, 'moe_k': 2, 'norm_type': 'layer', 'moe_num_experts': 16, 'attention_variables_3d': False, 'use_pad_remover': True, 'learning_rate_schedule': 'legacy', 'use_fixed_batch_size': False, 'pos': 'timing', 'multiproblem_reweight_label_loss': False, 'pretrained_model_dir': '', 'learning_rate_constant': 1.0, 'pad_batch': False, 'multiproblem_target_eval_only': False, 'optimizer_momentum_nesterov': False, 'parameter_attention_key_channels': 0, 'summarize_vars': False, 'learning_rate_warmup_steps': 8000, 'optimizer_adafactor_beta1': 0.0, 'moe_overhead_train': 1.0, 'label_smoothing': 0.1, 'scheduled_sampling_warmup_steps': 50000, 'optimizer_zero_grads': False, 'layer_prepostprocess_dropout': 0.1, 'optimizer': 'Adam', 'overload_eval_metric_name': '', 'multiproblem_fixed_train_length': -1, 'min_length_bucket': 8, 'tpu_enable_host_call': False, 'optimizer_multistep_accumulate_steps': None, 'multiproblem_per_task_threshold': '', 'parameter_attention_value_channels': 0, 'optimizer_adafactor_beta2': 0.999, 'max_input_seq_length': 0, 'norm_epsilon': 1e-06, 'compress_steps': 0, 'heads_share_relative_embedding': False, 'learning_rate_decay_steps': 5000, 'optimizer_adafactor_factored': True, 'vocab_divisor': 1, 'eval_run_autoregressive': False}\n",
      "{'border_percent': 2, 'shard_google_format': False, 'beam_size': 2, 'mlperf_decode_step': 0.0, 'decode_in_memory': False, 'extra_length': 100, 'guess_and_check_top_k': 0, 'delimiter': '\\n', 'num_decodes': 1, 'mlperf_success': False, 'decode_timeout_mins': 240, 'shards_start_offset': 0, 'vgg_ckpt_path': '', 'shards': 1, 'num_samples': -1, 'summaries_log_dir': 'decode', 'eos_penalty': 0.0, 'log_results': True, 'multiproblem_task_id': -1, 'force_decode_length': False, 'display_decoded_images': False, 'max_input_size': -1, 'shard_id': 0, 'skip_eos_postprocess': False, 'guess_and_check_epsilon': -1, 'frames_per_second': 10, 'alpha': 0.6, 'block_size': 0, 'return_beams': True, 'mlperf_threshold': 25.0, 'max_display_decodes': 5, 'batch_size': 0, 'write_beam_scores': False, 'max_display_outputs': 10, 'identity_output': False, 'decode_to_file': None, 'save_images': False}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_protocol': None, '_train_distribute': None, '_keep_checkpoint_max': 20, '_eval_distribute': None, '_is_chief': True, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_save_summary_steps': 100, '_num_worker_replicas': 0, '_model_dir': '../model_file_256', '_evaluation_master': '', 't2t_device_info': {'num_async_replicas': 1}, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdbb7e38c50>, 'use_tpu': False, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fdbb7e38c88>, '_save_checkpoints_secs': None, '_task_id': 0, '_tf_random_seed': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_steps': 2000, '_num_ps_replicas': 0, '_log_step_count_steps': 100}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fdbb805ce18>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fdbb7e38ac8>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fdbb7e38a20>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fdbb805a668>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fdbb805a668>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.050000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-8000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:235: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-06T22:02:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-06-22:22:39\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 5.9406834, metrics-onlinereview/targets/accuracy = 0.16447404, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.33266008, metrics-onlinereview/targets/approx_bleu_score = 0.008010928, metrics-onlinereview/targets/neg_log_perplexity = -5.9085355, metrics-onlinereview/targets/rouge_2_fscore = 0.036010183, metrics-onlinereview/targets/rouge_L_fscore = 0.15720846\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: ../model_file_256/model.ckpt-8000\n",
      "INFO:tensorflow:Validation (step 8001): loss = 5.9406834, metrics-onlinereview/targets/accuracy = 0.16447404, metrics-onlinereview/targets/rouge_2_fscore = 0.036010183, metrics-onlinereview/targets/neg_log_perplexity = -5.9085355, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/approx_bleu_score = 0.008010928, global_step = 8000, metrics-onlinereview/targets/rouge_L_fscore = 0.15720846, metrics-onlinereview/targets/accuracy_top5 = 0.33266008\n",
      "INFO:tensorflow:loss = 4.4792256, step = 8000\n",
      "INFO:tensorflow:global_step/sec: 0.0780929\n",
      "INFO:tensorflow:loss = 5.021349, step = 8100 (39.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94197\n",
      "INFO:tensorflow:loss = 4.8469973, step = 8200 (33.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9716\n",
      "INFO:tensorflow:loss = 4.7716107, step = 8300 (33.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94057\n",
      "INFO:tensorflow:loss = 4.6776867, step = 8400 (34.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95158\n",
      "INFO:tensorflow:loss = 5.2970896, step = 8500 (33.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93983\n",
      "INFO:tensorflow:loss = 5.332196, step = 8600 (34.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00788\n",
      "INFO:tensorflow:loss = 4.9074764, step = 9100 (33.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94686\n",
      "INFO:tensorflow:loss = 4.4099064, step = 9200 (33.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9327\n",
      "INFO:tensorflow:loss = 4.6747055, step = 9300 (34.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93263\n",
      "INFO:tensorflow:loss = 4.782093, step = 9400 (34.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96609\n",
      "INFO:tensorflow:loss = 5.1267195, step = 9500 (33.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94401\n",
      "INFO:tensorflow:loss = 4.564038, step = 9600 (33.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93656\n",
      "INFO:tensorflow:loss = 5.1242404, step = 9700 (34.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96373\n",
      "INFO:tensorflow:loss = 4.961239, step = 9800 (33.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93608\n",
      "INFO:tensorflow:loss = 4.8741245, step = 9900 (34.059 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.33661\n",
      "INFO:tensorflow:loss = 4.4748254, step = 10000 (42.797 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-06T22:34:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-06-23:24:53\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 5.9287586, metrics-onlinereview/targets/accuracy = 0.16993286, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.34194008, metrics-onlinereview/targets/approx_bleu_score = 0.008061685, metrics-onlinereview/targets/neg_log_perplexity = -5.8737497, metrics-onlinereview/targets/rouge_2_fscore = 0.035471145, metrics-onlinereview/targets/rouge_L_fscore = 0.14353904\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: ../model_file_256/model.ckpt-10000\n",
      "INFO:tensorflow:Validation (step 10001): loss = 5.9287586, metrics-onlinereview/targets/accuracy = 0.16993286, metrics-onlinereview/targets/rouge_2_fscore = 0.035471145, metrics-onlinereview/targets/neg_log_perplexity = -5.8737497, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/approx_bleu_score = 0.008061685, global_step = 10000, metrics-onlinereview/targets/rouge_L_fscore = 0.14353904, metrics-onlinereview/targets/accuracy_top5 = 0.34194008\n",
      "INFO:tensorflow:global_step/sec: 0.0325166\n",
      "INFO:tensorflow:loss = 4.434739, step = 10100 (3075.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98647\n",
      "INFO:tensorflow:loss = 5.7730684, step = 10200 (33.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97057\n",
      "INFO:tensorflow:loss = 4.2777114, step = 10300 (33.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98028\n",
      "INFO:tensorflow:loss = 4.9943047, step = 10400 (33.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95955\n",
      "INFO:tensorflow:loss = 5.247266, step = 10500 (33.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93485\n",
      "INFO:tensorflow:loss = 5.7641134, step = 10600 (34.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89504\n",
      "INFO:tensorflow:loss = 5.352359, step = 10700 (34.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96805\n",
      "INFO:tensorflow:loss = 4.677504, step = 10800 (33.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93813\n",
      "INFO:tensorflow:loss = 5.0796256, step = 10900 (34.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91236\n",
      "INFO:tensorflow:loss = 6.019457, step = 11000 (34.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93257\n",
      "INFO:tensorflow:loss = 4.2506423, step = 11100 (34.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96338\n",
      "INFO:tensorflow:loss = 5.232544, step = 11200 (33.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88925\n",
      "INFO:tensorflow:loss = 4.6581597, step = 11300 (34.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94746\n",
      "INFO:tensorflow:loss = 5.0883417, step = 11400 (33.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93621\n",
      "INFO:tensorflow:loss = 4.8670354, step = 11500 (34.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94378\n",
      "INFO:tensorflow:loss = 4.388318, step = 11600 (33.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97332\n",
      "INFO:tensorflow:loss = 4.678161, step = 11700 (33.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95061\n",
      "INFO:tensorflow:loss = 4.73132, step = 11800 (33.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97724\n",
      "INFO:tensorflow:loss = 5.242983, step = 11900 (33.588 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.37598\n",
      "INFO:tensorflow:loss = 4.922665, step = 12000 (42.088 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-06T23:36:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-de1da961ed56>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[{{node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-de1da961ed56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mt2t_model_256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m                          \u001b[0;34m\"model evaluation. Assuming ValidationMonitor present \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                          \"in train_hooks.\")\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_steps)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         max_steps=max_steps or self._train_spec.max_steps)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1333\u001b[0m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m               run_metadata=run_metadata))\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mafter_run\u001b[0;34m(self, run_context, run_values)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \"monitors\"] if \"monitors\" in run_values.results else {}\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m       \u001b[0minduce_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minduce_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mstep_end\u001b[0;34m(self, step, output)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEveryN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_every_n_step_begin_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevery_n_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mevery_n_step_end\u001b[0;34m(self, step, outputs)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# Run evaluation and log it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m     \u001b[0mvalidation_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36m_evaluate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m           name=self.name)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._estimator.evaluate(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    467\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m   def _actual_eval(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[0;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[0;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m         config=self._session_config)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-de1da961ed56>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1934816720 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = '../model_file_256'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 1024 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "hparams.num_encoder_layers = 6\n",
    "# hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.3\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_length = 256\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40200,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "#         eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_momentum_nesterov': False, 'attention_dropout_broadcast_dims': '', 'batch_size': 1024, 'scheduled_sampling_gold_mixin_prob': 0.5, 'norm_type': 'layer', 'layer_preprocess_sequence': 'n', 'warm_start_from_second': '', 'length_bucket_step': 1.1, 'multiproblem_schedule_max_examples': 10000000.0, 'optimizer_adam_beta2': 0.98, 'learning_rate': 0.05, 'learning_rate_schedule': 'legacy', 'optimizer_adam_beta1': 0.9, 'label_smoothing': 0.1, 'multiproblem_target_eval_only': False, 'optimizer_adafactor_memory_exponent': 0.8, 'hidden_size': 512, 'video_num_input_frames': 1, 'unidirectional_encoder': False, 'optimizer_adafactor_factored': True, 'multiproblem_max_input_length': -1, 'kernel_height': 3, 'num_heads': 8, 'heads_share_relative_embedding': False, 'symbol_dropout': 0.0, 'eval_run_autoregressive': False, 'use_fixed_batch_size': False, 'add_relative_to_values': False, 'optimizer_zero_grads': False, 'multiproblem_label_weight': 0.5, 'layer_prepostprocess_dropout': 0.1, 'moe_overhead_train': 1.0, 'learning_rate_cosine_cycle_steps': 250000, 'moe_loss_coef': 0.001, 'multiproblem_reweight_label_loss': False, 'pos': 'timing', 'scheduled_sampling_prob': 0.0, 'moe_k': 2, 'pad_batch': False, 'num_decoder_layers': 6, 'video_num_target_frames': 1, 'mlperf_mode': False, 'causal_decoder_self_attention': True, 'modality': {}, 'force_full_predict': False, 'learning_rate_decay_scheme': 'noam', 'layer_prepostprocess_dropout_broadcast_dims': '', 'overload_eval_metric_name': '', 'parameter_attention_key_channels': 0, 'ffn_layer': 'dense_relu_dense', 'relu_dropout_broadcast_dims': '', 'scheduled_sampling_warmup_steps': 50000, 'relu_dropout': 0.1, 'optimizer_adafactor_decay_type': 'pow', 'optimizer_adafactor_beta2': 0.999, 'weight_dtype': 'float32', 'use_pad_remover': True, 'optimizer': 'Adam', 'dropout': 0.3, 'learning_rate_constant': 1.0, 'nbr_decoder_problems': 1, 'grad_noise_scale': 0.0, 'norm_epsilon': 1e-06, 'layer_postprocess_sequence': 'da', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'symbol_modality_skip_top': False, 'attention_dropout': 0.2, 'multiply_embedding_mode': 'sqrt_depth', 'weight_noise': 0.0, 'moe_num_experts': 16, 'clip_grad_norm': 0.0, 'learning_rate_minimum': None, 'num_encoder_layers': 6, 'learning_rate_decay_staircase': False, 'parameter_attention_value_channels': 0, 'initializer': 'uniform_unit_scaling', 'optimizer_multistep_accumulate_steps': None, 'pretrained_model_dir': '', 'activation_dtype': 'float32', 'num_hidden_layers': 6, 'max_target_seq_length': 0, 'multiproblem_max_target_length': -1, 'factored_logits': False, 'sampling_temp': 1.0, 'min_length_bucket': 8, 'attention_value_channels': 0, 'conv_first_kernel': 3, 'multiproblem_schedule_threshold': 0.5, 'self_attention_type': 'dot_product', 'prepend_mode': 'prepend_inputs_full_attention', 'compress_steps': 0, 'learning_rate_warmup_steps': 8000, 'learning_rate_decay_steps': 5000, 'daisy_chain_variables': True, 'sampling_method': 'argmax', 'multiproblem_mixing_schedule': 'constant', 'attention_key_channels': 0, 'multiproblem_per_task_threshold': '', 'learning_rate_decay_rate': 1.0, 'shared_embedding': False, 'multiproblem_fixed_train_length': -1, 'proximity_bias': False, 'optimizer_adafactor_beta1': 0.0, 'no_data_parallelism': False, 'split_to_length': 0, 'moe_overhead_eval': 2.0, 'tpu_enable_host_call': False, 'summarize_grads': False, 'attention_variables_3d': False, 'vocab_divisor': 1, 'max_length': 256, 'eval_drop_long_sequences': False, 'use_target_space_embedding': True, 'summarize_vars': False, 'max_relative_position': 0, 'weight_decay': 0.0, 'batch_shuffle_size': 512, 'shared_embedding_and_softmax_weights': True, 'optimizer_momentum_momentum': 0.9, 'min_length': 0, 'symbol_modality_num_shards': 16, 'kernel_width': 1, 'initializer_gain': 1.0, 'moe_hidden_sizes': '2048', 'filter_size': 2048, 'max_input_seq_length': 0, 'multiproblem_vocab_size': -1, 'optimizer_adam_epsilon': 1e-09, 'optimizer_adafactor_clipping_threshold': 1.0}\n",
      "{'block_size': 0, 'save_images': False, 'identity_output': False, 'decode_timeout_mins': 240, 'shards': 1, 'beam_size': 2, 'alpha': 0.6, 'frames_per_second': 10, 'shards_start_offset': 0, 'guess_and_check_top_k': 0, 'mlperf_decode_step': 0.0, 'skip_eos_postprocess': False, 'shard_id': 0, 'summaries_log_dir': 'decode', 'delimiter': '\\n', 'num_decodes': 1, 'max_input_size': -1, 'num_samples': -1, 'mlperf_threshold': 25.0, 'decode_in_memory': False, 'border_percent': 2, 'display_decoded_images': False, 'extra_length': 100, 'log_results': True, 'force_decode_length': False, 'guess_and_check_epsilon': -1, 'return_beams': True, 'shard_google_format': False, 'eos_penalty': 0.0, 'decode_to_file': None, 'write_beam_scores': False, 'max_display_decodes': 5, 'max_display_outputs': 10, 'batch_size': 0, 'multiproblem_task_id': -1, 'mlperf_success': False, 'vgg_ckpt_path': ''}\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_master': '', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_is_chief': True, '_evaluation_master': '', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_model_dir': '../model_file_256', '_log_step_count_steps': 100, '_keep_checkpoint_max': 20, '_task_id': 0, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fb1b16d0400>, '_eval_distribute': None, '_environment': 'local', '_num_worker_replicas': 0, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_checkpoints_steps': 2000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb1b16d0438>, '_protocol': None, 'use_tpu': False, '_train_distribute': None, '_device_fn': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fb1cc698620>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fb1b16d0278>, 'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fb1b16d01d0>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fb258639358>, 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fb258639358>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.050000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T00:57:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-01:05:15\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, loss = 5.8405457, metrics-onlinereview/targets/accuracy = 0.1749203, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.35439435, metrics-onlinereview/targets/approx_bleu_score = 0.008242097, metrics-onlinereview/targets/neg_log_perplexity = -5.7626023, metrics-onlinereview/targets/rouge_2_fscore = 0.034431674, metrics-onlinereview/targets/rouge_L_fscore = 0.14671299\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: ../model_file_256/model.ckpt-12000\n",
      "INFO:tensorflow:Validation (step 12001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/neg_log_perplexity = -5.7626023, metrics-onlinereview/targets/approx_bleu_score = 0.008242097, global_step = 12000, metrics-onlinereview/targets/rouge_2_fscore = 0.034431674, loss = 5.8405457, metrics-onlinereview/targets/accuracy_top5 = 0.35439435, metrics-onlinereview/targets/rouge_L_fscore = 0.14671299, metrics-onlinereview/targets/accuracy = 0.1749203\n",
      "INFO:tensorflow:loss = 5.132378, step = 12000\n",
      "INFO:tensorflow:global_step/sec: 0.200494\n",
      "INFO:tensorflow:loss = 4.844146, step = 12100 (39.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94721\n",
      "INFO:tensorflow:loss = 5.5187364, step = 12200 (33.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9872\n",
      "INFO:tensorflow:loss = 5.3956633, step = 12300 (33.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95526\n",
      "INFO:tensorflow:loss = 6.1747932, step = 12400 (33.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94797\n",
      "INFO:tensorflow:loss = 4.747535, step = 12500 (33.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92022\n",
      "INFO:tensorflow:loss = 5.046329, step = 12600 (34.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91411\n",
      "INFO:tensorflow:loss = 4.5477595, step = 12700 (34.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90526\n",
      "INFO:tensorflow:loss = 5.289351, step = 12800 (34.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95349\n",
      "INFO:tensorflow:loss = 4.5338116, step = 12900 (33.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96955\n",
      "INFO:tensorflow:loss = 4.7538996, step = 13000 (33.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00166\n",
      "INFO:tensorflow:loss = 4.9503016, step = 13100 (33.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93604\n",
      "INFO:tensorflow:loss = 5.0916114, step = 13200 (34.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93233\n",
      "INFO:tensorflow:loss = 5.1752443, step = 13300 (34.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.89771\n",
      "INFO:tensorflow:loss = 5.042676, step = 13400 (34.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97347\n",
      "INFO:tensorflow:loss = 4.934655, step = 13500 (33.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94875\n",
      "INFO:tensorflow:loss = 5.006637, step = 13600 (33.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97319\n",
      "INFO:tensorflow:loss = 5.093439, step = 13700 (33.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96094\n",
      "INFO:tensorflow:loss = 4.9601965, step = 13800 (33.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96761\n",
      "INFO:tensorflow:loss = 5.2288938, step = 13900 (33.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.3394\n",
      "INFO:tensorflow:loss = 4.280496, step = 14000 (42.746 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T01:16:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-f5bbd9511fb8>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[{{node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f5bbd9511fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mt2t_model_256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m                          \u001b[0;34m\"model evaluation. Assuming ValidationMonitor present \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                          \"in train_hooks.\")\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_steps)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         max_steps=max_steps or self._train_spec.max_steps)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1333\u001b[0m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m               run_metadata=run_metadata))\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mafter_run\u001b[0;34m(self, run_context, run_values)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \"monitors\"] if \"monitors\" in run_values.results else {}\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m       \u001b[0minduce_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minduce_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mstep_end\u001b[0;34m(self, step, output)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEveryN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_every_n_step_begin_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevery_n_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mevery_n_step_end\u001b[0;34m(self, step, outputs)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# Run evaluation and log it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m     \u001b[0mvalidation_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36m_evaluate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m           name=self.name)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._estimator.evaluate(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    467\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m   def _actual_eval(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[0;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[0;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m         config=self._session_config)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-f5bbd9511fb8>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = '../model_file_256'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 1024 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "hparams.num_encoder_layers = 6\n",
    "# hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.3\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_length = 256\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40200,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clip_grad_norm': 0.0, 'moe_loss_coef': 0.001, 'multiproblem_fixed_train_length': -1, 'nbr_decoder_problems': 1, 'multiproblem_schedule_max_examples': 10000000.0, 'batch_size': 1024, 'weight_noise': 0.0, 'optimizer_adam_beta2': 0.98, 'multiproblem_target_eval_only': False, 'shared_embedding': False, 'add_relative_to_values': False, 'moe_overhead_eval': 2.0, 'symbol_dropout': 0.0, 'optimizer_adafactor_memory_exponent': 0.8, 'daisy_chain_variables': True, 'shared_embedding_and_softmax_weights': True, 'norm_type': 'layer', 'symbol_modality_skip_top': False, 'multiply_embedding_mode': 'sqrt_depth', 'summarize_vars': False, 'scheduled_sampling_prob': 0.0, 'multiproblem_per_task_threshold': '', 'optimizer_zero_grads': False, 'num_heads': 8, 'proximity_bias': False, 'mlperf_mode': False, 'eval_drop_long_sequences': False, 'optimizer_multistep_accumulate_steps': None, 'multiproblem_vocab_size': -1, 'attention_dropout_broadcast_dims': '', 'multiproblem_reweight_label_loss': False, 'pad_batch': False, 'attention_key_channels': 0, 'length_bucket_step': 1.1, 'num_hidden_layers': 6, 'summarize_grads': False, 'pretrained_model_dir': '', 'moe_hidden_sizes': '2048', 'optimizer_adafactor_decay_type': 'pow', 'layer_prepostprocess_dropout_broadcast_dims': '', 'num_decoder_layers': 6, 'optimizer_adam_epsilon': 1e-09, 'grad_noise_scale': 0.0, 'attention_value_channels': 0, 'attention_variables_3d': False, 'learning_rate_decay_steps': 5000, 'num_encoder_layers': 6, 'weight_dtype': 'float32', 'moe_num_experts': 16, 'attention_dropout': 0.2, 'max_target_seq_length': 0, 'conv_first_kernel': 3, 'optimizer_adafactor_factored': True, 'no_data_parallelism': False, 'scheduled_sampling_gold_mixin_prob': 0.5, 'compress_steps': 0, 'unidirectional_encoder': False, 'learning_rate_minimum': None, 'layer_postprocess_sequence': 'da', 'tpu_enable_host_call': False, 'optimizer_adafactor_beta1': 0.0, 'moe_overhead_train': 1.0, 'initializer': 'uniform_unit_scaling', 'parameter_attention_value_channels': 0, 'initializer_gain': 1.0, 'parameter_attention_key_channels': 0, 'multiproblem_schedule_threshold': 0.5, 'video_num_input_frames': 1, 'relu_dropout_broadcast_dims': '', 'prepend_mode': 'prepend_inputs_full_attention', 'scheduled_sampling_warmup_steps': 50000, 'norm_epsilon': 1e-06, 'multiproblem_label_weight': 0.5, 'use_pad_remover': True, 'learning_rate_cosine_cycle_steps': 250000, 'optimizer_adam_beta1': 0.9, 'kernel_height': 3, 'causal_decoder_self_attention': True, 'batch_shuffle_size': 512, 'layer_preprocess_sequence': 'n', 'optimizer_adafactor_clipping_threshold': 1.0, 'multiproblem_mixing_schedule': 'constant', 'optimizer_adafactor_multiply_by_parameter_scale': True, 'label_smoothing': 0.1, 'pos': 'timing', 'optimizer_momentum_momentum': 0.9, 'optimizer_adafactor_beta2': 0.999, 'eval_run_autoregressive': False, 'min_length_bucket': 8, 'max_input_seq_length': 0, 'video_num_target_frames': 1, 'use_target_space_embedding': True, 'split_to_length': 0, 'use_fixed_batch_size': False, 'learning_rate_constant': 1.0, 'optimizer': 'Adam', 'optimizer_momentum_nesterov': False, 'symbol_modality_num_shards': 16, 'heads_share_relative_embedding': False, 'relu_dropout': 0.1, 'factored_logits': False, 'multiproblem_max_target_length': -1, 'moe_k': 2, 'learning_rate_warmup_steps': 8000, 'learning_rate': 0.05, 'hidden_size': 512, 'learning_rate_decay_staircase': False, 'sampling_method': 'argmax', 'activation_dtype': 'float32', 'max_length': 256, 'filter_size': 2048, 'dropout': 0.3, 'learning_rate_decay_scheme': 'noam', 'self_attention_type': 'dot_product', 'sampling_temp': 1.0, 'min_length': 0, 'force_full_predict': False, 'layer_prepostprocess_dropout': 0.1, 'ffn_layer': 'dense_relu_dense', 'overload_eval_metric_name': '', 'weight_decay': 0.0, 'learning_rate_schedule': 'legacy', 'kernel_width': 1, 'vocab_divisor': 1, 'multiproblem_max_input_length': -1, 'learning_rate_decay_rate': 1.0, 'modality': {}, 'max_relative_position': 0, 'warm_start_from_second': ''}\n",
      "{'identity_output': False, 'extra_length': 100, 'vgg_ckpt_path': '', 'delimiter': '\\n', 'frames_per_second': 10, 'guess_and_check_top_k': 0, 'max_display_decodes': 5, 'multiproblem_task_id': -1, 'return_beams': True, 'shards_start_offset': 0, 'block_size': 0, 'summaries_log_dir': 'decode', 'decode_in_memory': False, 'save_images': False, 'write_beam_scores': False, 'batch_size': 0, 'num_samples': -1, 'shard_id': 0, 'mlperf_success': False, 'decode_to_file': None, 'mlperf_threshold': 25.0, 'shard_google_format': False, 'display_decoded_images': False, 'alpha': 0.6, 'num_decodes': 1, 'max_input_size': -1, 'decode_timeout_mins': 240, 'beam_size': 2, 'guess_and_check_epsilon': -1, 'force_decode_length': False, 'log_results': True, 'shards': 1, 'skip_eos_postprocess': False, 'border_percent': 2, 'max_display_outputs': 10, 'eos_penalty': 0.0, 'mlperf_decode_step': 0.0}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': 2000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faac2fe0d30>, '_device_fn': None, '_save_summary_steps': 100, '_eval_distribute': None, '_num_ps_replicas': 0, '_model_dir': '../model_file_256', '_log_step_count_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_task_id': 0, '_keep_checkpoint_max': 20, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_master': '', '_tf_random_seed': None, '_save_checkpoints_secs': None, 'use_tpu': False, '_environment': 'local', '_protocol': None, '_num_worker_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_is_chief': True, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7faac2fe0d68>, '_task_type': None, '_evaluation_master': ''}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7faac320c378>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7faac2fe0ba8>, 'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7faac2fe0b00>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7faac320d7b8>, 'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7faac320d7b8>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.050000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-14000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T01:26:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-01:33:57\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, loss = 5.796618, metrics-onlinereview/targets/accuracy = 0.18158014, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.36008653, metrics-onlinereview/targets/approx_bleu_score = 0.008999923, metrics-onlinereview/targets/neg_log_perplexity = -5.714514, metrics-onlinereview/targets/rouge_2_fscore = 0.038266815, metrics-onlinereview/targets/rouge_L_fscore = 0.15558214\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: ../model_file_256/model.ckpt-14000\n",
      "INFO:tensorflow:Validation (step 14001): global_step = 14000, metrics-onlinereview/targets/accuracy_top5 = 0.36008653, metrics-onlinereview/targets/approx_bleu_score = 0.008999923, metrics-onlinereview/targets/accuracy = 0.18158014, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, loss = 5.796618, metrics-onlinereview/targets/rouge_2_fscore = 0.038266815, metrics-onlinereview/targets/rouge_L_fscore = 0.15558214, metrics-onlinereview/targets/neg_log_perplexity = -5.714514\n",
      "INFO:tensorflow:loss = 4.5339484, step = 14000\n",
      "INFO:tensorflow:global_step/sec: 0.198914\n",
      "INFO:tensorflow:loss = 4.9778624, step = 14100 (39.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97791\n",
      "INFO:tensorflow:loss = 5.097277, step = 14200 (33.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96302\n",
      "INFO:tensorflow:loss = 5.199542, step = 14300 (33.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92008\n",
      "INFO:tensorflow:loss = 4.792647, step = 14400 (34.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93638\n",
      "INFO:tensorflow:loss = 4.5183845, step = 14500 (34.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9487\n",
      "INFO:tensorflow:loss = 6.1516767, step = 14600 (33.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93305\n",
      "INFO:tensorflow:loss = 5.192736, step = 14700 (34.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95169\n",
      "INFO:tensorflow:loss = 5.228339, step = 14800 (33.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99937\n",
      "INFO:tensorflow:loss = 4.436489, step = 14900 (33.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94677\n",
      "INFO:tensorflow:loss = 4.730353, step = 15000 (33.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9745\n",
      "INFO:tensorflow:loss = 4.795986, step = 15100 (33.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94065\n",
      "INFO:tensorflow:loss = 4.734781, step = 15200 (34.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92887\n",
      "INFO:tensorflow:loss = 4.905589, step = 15300 (34.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96565\n",
      "INFO:tensorflow:loss = 5.545827, step = 15400 (33.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92943\n",
      "INFO:tensorflow:loss = 3.7808867, step = 15500 (34.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9239\n",
      "INFO:tensorflow:loss = 5.680817, step = 15600 (34.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90594\n",
      "INFO:tensorflow:loss = 5.199458, step = 15700 (34.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96385\n",
      "INFO:tensorflow:loss = 4.286885, step = 15800 (33.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95616\n",
      "INFO:tensorflow:loss = 4.6098356, step = 15900 (33.828 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36564\n",
      "INFO:tensorflow:loss = 4.6939025, step = 16000 (42.271 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T01:45:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-f5bbd9511fb8>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[{{node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f5bbd9511fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mt2t_model_256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m                          \u001b[0;34m\"model evaluation. Assuming ValidationMonitor present \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                          \"in train_hooks.\")\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_steps)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         max_steps=max_steps or self._train_spec.max_steps)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1333\u001b[0m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m               run_metadata=run_metadata))\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mafter_run\u001b[0;34m(self, run_context, run_values)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \"monitors\"] if \"monitors\" in run_values.results else {}\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m       \u001b[0minduce_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minduce_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mstep_end\u001b[0;34m(self, step, output)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEveryN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_every_n_step_begin_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevery_n_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mevery_n_step_end\u001b[0;34m(self, step, outputs)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# Run evaluation and log it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m     \u001b[0mvalidation_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36m_evaluate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m           name=self.name)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._estimator.evaluate(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    467\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m   def _actual_eval(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[0;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[0;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m         config=self._session_config)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-f5bbd9511fb8>\", line 63, in <module>\n    t2t_model_256.train_and_evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 446, in train_and_evaluate\n    self.train()\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 454, in train\n    max_steps=max_steps or self._train_spec.max_steps)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n    saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n    run_metadata=run_metadata))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1294, in after_run\n    induce_stop = m.step_end(self._last_step, result)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 368, in step_end\n    return self.every_n_step_end(step, output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 753, in every_n_step_end\n    validation_outputs = self._evaluate_estimator()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 708, in _evaluate_estimator\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n    return _evaluate()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1429, in estimator_model_fn\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn\n    losses[\"training\"] = self.loss(logits, features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss\n    weights=features.get(\"targets_mask\"))\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/t2t_model.py\", line 587, in _loss_single\n    loss_num, loss_den = target_modality.loss(logits, feature)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/modality.py\", line 188, in loss\n    weights_fn=weights_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1736, in padded_cross_entropy\n    logits, labels, vocab_size, confidence, gaussian=gaussian)\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py\", line 1993, in smoothing_cross_entropy\n    logits=logits, labels=soft_targets)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7862, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 1729735120 bytes for \n\t [[node transformer/parallel_0_5/transformer/transformer/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1993) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = '../model_file_256'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 1024 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "hparams.num_encoder_layers = 6\n",
    "# hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.3\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_length = 256\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40200,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_postprocess_sequence': 'da', 'symbol_modality_skip_top': False, 'heads_share_relative_embedding': False, 'use_pad_remover': True, 'moe_overhead_eval': 2.0, 'moe_k': 2, 'tpu_enable_host_call': False, 'compress_steps': 0, 'layer_preprocess_sequence': 'n', 'parameter_attention_key_channels': 0, 'attention_value_channels': 0, 'video_num_input_frames': 1, 'symbol_dropout': 0.0, 'force_full_predict': False, 'layer_prepostprocess_dropout_broadcast_dims': '', 'relu_dropout': 0.1, 'max_target_seq_length': 0, 'scheduled_sampling_gold_mixin_prob': 0.5, 'learning_rate_constant': 1.0, 'multiproblem_target_eval_only': False, 'max_input_seq_length': 512, 'weight_decay': 0.0, 'multiproblem_schedule_threshold': 0.5, 'dropout': 0.3, 'symbol_modality_num_shards': 16, 'conv_first_kernel': 3, 'batch_shuffle_size': 512, 'learning_rate_decay_scheme': 'noam', 'summarize_vars': False, 'optimizer_adam_epsilon': 1e-09, 'kernel_width': 1, 'summarize_grads': False, 'multiproblem_reweight_label_loss': False, 'multiply_embedding_mode': 'sqrt_depth', 'kernel_height': 3, 'multiproblem_schedule_max_examples': 10000000.0, 'causal_decoder_self_attention': True, 'optimizer_momentum_nesterov': False, 'use_fixed_batch_size': False, 'shared_embedding': False, 'attention_dropout_broadcast_dims': '', 'self_attention_type': 'dot_product', 'attention_key_channels': 0, 'unidirectional_encoder': False, 'learning_rate_cosine_cycle_steps': 250000, 'pos': 'timing', 'multiproblem_fixed_train_length': -1, 'norm_epsilon': 1e-06, 'multiproblem_mixing_schedule': 'constant', 'sampling_method': 'argmax', 'num_encoder_layers': 6, 'optimizer_adafactor_decay_type': 'pow', 'learning_rate_schedule': 'legacy', 'batch_size': 1024, 'attention_variables_3d': False, 'moe_loss_coef': 0.001, 'shared_embedding_and_softmax_weights': True, 'optimizer_adam_beta2': 0.98, 'learning_rate_warmup_steps': 8000, 'learning_rate': 0.05, 'factored_logits': False, 'num_hidden_layers': 6, 'no_data_parallelism': False, 'optimizer_multistep_accumulate_steps': None, 'layer_prepostprocess_dropout': 0.1, 'moe_num_experts': 16, 'learning_rate_decay_rate': 1.0, 'attention_dropout': 0.2, 'eval_drop_long_sequences': False, 'daisy_chain_variables': True, 'multiproblem_per_task_threshold': '', 'clip_grad_norm': 0.0, 'norm_type': 'layer', 'learning_rate_decay_steps': 5000, 'sampling_temp': 1.0, 'min_length': 0, 'eval_run_autoregressive': False, 'mlperf_mode': False, 'grad_noise_scale': 0.0, 'optimizer_adafactor_multiply_by_parameter_scale': True, 'max_length': 256, 'filter_size': 2048, 'activation_dtype': 'float32', 'learning_rate_minimum': None, 'optimizer_adafactor_clipping_threshold': 1.0, 'split_to_length': 0, 'nbr_decoder_problems': 1, 'min_length_bucket': 8, 'scheduled_sampling_prob': 0.0, 'optimizer': 'Adam', 'hidden_size': 512, 'overload_eval_metric_name': '', 'optimizer_zero_grads': False, 'pad_batch': False, 'add_relative_to_values': False, 'moe_hidden_sizes': '2048', 'optimizer_adam_beta1': 0.9, 'moe_overhead_train': 1.0, 'prepend_mode': 'prepend_inputs_full_attention', 'optimizer_adafactor_factored': True, 'proximity_bias': False, 'pretrained_model_dir': '', 'length_bucket_step': 1.1, 'multiproblem_vocab_size': -1, 'optimizer_adafactor_beta2': 0.999, 'warm_start_from_second': '', 'multiproblem_max_target_length': -1, 'relu_dropout_broadcast_dims': '', 'ffn_layer': 'dense_relu_dense', 'optimizer_adafactor_beta1': 0.0, 'num_heads': 8, 'weight_noise': 0.0, 'learning_rate_decay_staircase': False, 'parameter_attention_value_channels': 0, 'modality': {}, 'initializer_gain': 1.0, 'video_num_target_frames': 1, 'use_target_space_embedding': True, 'multiproblem_max_input_length': -1, 'weight_dtype': 'float32', 'label_smoothing': 0.1, 'vocab_divisor': 1, 'max_relative_position': 0, 'initializer': 'uniform_unit_scaling', 'optimizer_adafactor_memory_exponent': 0.8, 'optimizer_momentum_momentum': 0.9, 'scheduled_sampling_warmup_steps': 50000, 'multiproblem_label_weight': 0.5, 'num_decoder_layers': 6}\n",
      "{'mlperf_decode_step': 0.0, 'log_results': True, 'beam_size': 2, 'save_images': False, 'return_beams': True, 'num_samples': -1, 'shard_id': 0, 'decode_to_file': None, 'force_decode_length': False, 'write_beam_scores': False, 'max_display_decodes': 5, 'num_decodes': 1, 'display_decoded_images': False, 'eos_penalty': 0.0, 'vgg_ckpt_path': '', 'guess_and_check_epsilon': -1, 'frames_per_second': 10, 'max_display_outputs': 10, 'multiproblem_task_id': -1, 'batch_size': 0, 'extra_length': 100, 'decode_in_memory': False, 'guess_and_check_top_k': 0, 'max_input_size': -1, 'summaries_log_dir': 'decode', 'border_percent': 2, 'shards_start_offset': 0, 'mlperf_threshold': 25.0, 'shards': 1, 'alpha': 0.6, 'mlperf_success': False, 'decode_timeout_mins': 240, 'identity_output': False, 'delimiter': '\\n', 'block_size': 0, 'shard_google_format': False, 'skip_eos_postprocess': False}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:278: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fb30463bda0>, '_device_fn': None, '_train_distribute': None, '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_master': '', '_task_type': None, '_tf_random_seed': None, 'use_tpu': False, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_eval_distribute': None, '_save_checkpoints_secs': None, '_evaluation_master': '', '_model_dir': '../model_file_256', '_save_summary_steps': 100, '_environment': 'local', '_protocol': None, '_num_ps_replicas': 0, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", 't2t_device_info': {'num_async_replicas': 1}, '_keep_checkpoint_max': 20, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb30463bdd8>, '_is_chief': True, '_save_checkpoints_steps': 2000}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fb30485fd90>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using ValidationMonitor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "\n",
      " hparams.problem_hparams \n",
      " [('batch_size_multiplier', 1), ('input_space_id', 0), ('loss_multiplier', 1.0), ('modality', {'targets': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fb30463bc18>, 'inputs': <tensor2tensor.layers.modalities.SymbolModality object at 0x7fb30463bb70>}), ('stop_at_eos', 1), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fb30485e6a0>, 'inputs': <tensor2tensor.data_generators.text_encoder.SubwordTextEncoder object at 0x7fb30485e6a0>}), ('was_copy', False), ('was_reversed', False)]\n",
      "WARNING:tensorflow:EvalSpec not provided. Estimator will not manage model evaluation. Assuming ValidationMonitor present in train_hooks.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from ./data/onlinereview-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py:161: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:2935: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Base learning rate: 0.050000\n",
      "INFO:tensorflow:Trainable Variables Total size: 64628224\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-16000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T01:54:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-01:57:03\n",
      "INFO:tensorflow:Saving dict for global step 16000: global_step = 16000, loss = 5.782768, metrics-onlinereview/targets/accuracy = 0.18465392, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.36452642, metrics-onlinereview/targets/approx_bleu_score = 0.009631386, metrics-onlinereview/targets/neg_log_perplexity = -5.6959558, metrics-onlinereview/targets/rouge_2_fscore = 0.037847046, metrics-onlinereview/targets/rouge_L_fscore = 0.1654233\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: ../model_file_256/model.ckpt-16000\n",
      "INFO:tensorflow:Validation (step 16001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.36452642, global_step = 16000, metrics-onlinereview/targets/rouge_L_fscore = 0.1654233, loss = 5.782768, metrics-onlinereview/targets/approx_bleu_score = 0.009631386, metrics-onlinereview/targets/rouge_2_fscore = 0.037847046, metrics-onlinereview/targets/accuracy = 0.18465392, metrics-onlinereview/targets/neg_log_perplexity = -5.6959558\n",
      "INFO:tensorflow:loss = 4.971323, step = 16000\n",
      "INFO:tensorflow:global_step/sec: 0.476082\n",
      "INFO:tensorflow:loss = 4.9298644, step = 16100 (39.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95142\n",
      "INFO:tensorflow:loss = 4.4460106, step = 16200 (33.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95448\n",
      "INFO:tensorflow:loss = 4.519505, step = 16300 (33.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94604\n",
      "INFO:tensorflow:loss = 4.6850057, step = 16400 (33.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96635\n",
      "INFO:tensorflow:loss = 4.3012743, step = 16500 (33.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97007\n",
      "INFO:tensorflow:loss = 4.4331713, step = 16600 (33.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94159\n",
      "INFO:tensorflow:loss = 4.5461597, step = 16700 (33.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96317\n",
      "INFO:tensorflow:loss = 4.605194, step = 16800 (33.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94787\n",
      "INFO:tensorflow:loss = 4.609302, step = 16900 (33.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94206\n",
      "INFO:tensorflow:loss = 4.6867023, step = 17000 (33.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94312\n",
      "INFO:tensorflow:loss = 4.962367, step = 17100 (33.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96951\n",
      "INFO:tensorflow:loss = 4.2164574, step = 17200 (33.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95791\n",
      "INFO:tensorflow:loss = 4.9390144, step = 17300 (33.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92746\n",
      "INFO:tensorflow:loss = 4.8417435, step = 17400 (34.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94101\n",
      "INFO:tensorflow:loss = 4.8836136, step = 17500 (34.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90822\n",
      "INFO:tensorflow:loss = 5.2780347, step = 17600 (34.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94582\n",
      "INFO:tensorflow:loss = 4.739343, step = 17700 (33.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94075\n",
      "INFO:tensorflow:loss = 4.323979, step = 17800 (34.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93852\n",
      "INFO:tensorflow:loss = 5.4455094, step = 17900 (34.031 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.37118\n",
      "INFO:tensorflow:loss = 4.2724266, step = 18000 (42.173 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T02:08:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-18000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-02:11:19\n",
      "INFO:tensorflow:Saving dict for global step 18000: global_step = 18000, loss = 5.7460523, metrics-onlinereview/targets/accuracy = 0.18732923, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37021858, metrics-onlinereview/targets/approx_bleu_score = 0.00974787, metrics-onlinereview/targets/neg_log_perplexity = -5.649398, metrics-onlinereview/targets/rouge_2_fscore = 0.038229004, metrics-onlinereview/targets/rouge_L_fscore = 0.16769189\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: ../model_file_256/model.ckpt-18000\n",
      "INFO:tensorflow:Validation (step 18001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37021858, global_step = 18000, metrics-onlinereview/targets/rouge_L_fscore = 0.16769189, loss = 5.7460523, metrics-onlinereview/targets/approx_bleu_score = 0.00974787, metrics-onlinereview/targets/rouge_2_fscore = 0.038229004, metrics-onlinereview/targets/accuracy = 0.18732923, metrics-onlinereview/targets/neg_log_perplexity = -5.649398\n",
      "INFO:tensorflow:global_step/sec: 0.507967\n",
      "INFO:tensorflow:loss = 4.696738, step = 18100 (196.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96959\n",
      "INFO:tensorflow:loss = 4.2435155, step = 18200 (33.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99151\n",
      "INFO:tensorflow:loss = 4.3743544, step = 18300 (33.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92529\n",
      "INFO:tensorflow:loss = 4.8170986, step = 18400 (34.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95347\n",
      "INFO:tensorflow:loss = 4.535869, step = 18500 (33.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96387\n",
      "INFO:tensorflow:loss = 5.191714, step = 18600 (33.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95547\n",
      "INFO:tensorflow:loss = 4.587193, step = 18700 (33.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94142\n",
      "INFO:tensorflow:loss = 4.789253, step = 18800 (33.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97655\n",
      "INFO:tensorflow:loss = 4.829575, step = 18900 (33.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94152\n",
      "INFO:tensorflow:loss = 5.248538, step = 19000 (33.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97341\n",
      "INFO:tensorflow:loss = 4.410502, step = 19100 (33.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95135\n",
      "INFO:tensorflow:loss = 4.9253025, step = 19200 (33.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96365\n",
      "INFO:tensorflow:loss = 4.7166233, step = 19300 (33.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94612\n",
      "INFO:tensorflow:loss = 4.814544, step = 19400 (33.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94018\n",
      "INFO:tensorflow:loss = 4.453407, step = 19500 (34.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9387\n",
      "INFO:tensorflow:loss = 5.0932693, step = 19600 (34.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9322\n",
      "INFO:tensorflow:loss = 4.266458, step = 19700 (34.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93822\n",
      "INFO:tensorflow:loss = 4.6404233, step = 19800 (34.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95987\n",
      "INFO:tensorflow:loss = 4.7330956, step = 19900 (33.785 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.3597\n",
      "INFO:tensorflow:loss = 4.6995516, step = 20000 (42.378 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T02:22:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-02:25:28\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 5.7025065, metrics-onlinereview/targets/accuracy = 0.18943533, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37357697, metrics-onlinereview/targets/approx_bleu_score = 0.010965364, metrics-onlinereview/targets/neg_log_perplexity = -5.6134496, metrics-onlinereview/targets/rouge_2_fscore = 0.040301573, metrics-onlinereview/targets/rouge_L_fscore = 0.16769922\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: ../model_file_256/model.ckpt-20000\n",
      "INFO:tensorflow:Validation (step 20001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37357697, global_step = 20000, metrics-onlinereview/targets/rouge_L_fscore = 0.16769922, loss = 5.7025065, metrics-onlinereview/targets/approx_bleu_score = 0.010965364, metrics-onlinereview/targets/rouge_2_fscore = 0.040301573, metrics-onlinereview/targets/accuracy = 0.18943533, metrics-onlinereview/targets/neg_log_perplexity = -5.6134496\n",
      "INFO:tensorflow:global_step/sec: 0.505663\n",
      "INFO:tensorflow:loss = 5.3140535, step = 20100 (197.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9596\n",
      "INFO:tensorflow:loss = 4.673552, step = 20200 (33.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90498\n",
      "INFO:tensorflow:loss = 4.7561264, step = 20300 (34.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96776\n",
      "INFO:tensorflow:loss = 4.2110305, step = 20400 (33.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94502\n",
      "INFO:tensorflow:loss = 5.50538, step = 20500 (33.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93533\n",
      "INFO:tensorflow:loss = 5.2715335, step = 20600 (34.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9723\n",
      "INFO:tensorflow:loss = 4.521278, step = 20700 (33.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94692\n",
      "INFO:tensorflow:loss = 4.8436646, step = 20800 (33.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92101\n",
      "INFO:tensorflow:loss = 4.505867, step = 20900 (34.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94996\n",
      "INFO:tensorflow:loss = 5.153555, step = 21000 (33.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96377\n",
      "INFO:tensorflow:loss = 4.3595786, step = 21100 (33.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9185\n",
      "INFO:tensorflow:loss = 4.7578034, step = 21200 (34.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9429\n",
      "INFO:tensorflow:loss = 4.4920626, step = 21300 (33.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94673\n",
      "INFO:tensorflow:loss = 4.3199, step = 21400 (33.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97799\n",
      "INFO:tensorflow:loss = 4.567076, step = 21500 (33.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92291\n",
      "INFO:tensorflow:loss = 4.4401116, step = 21600 (34.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94054\n",
      "INFO:tensorflow:loss = 4.879985, step = 21700 (34.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94463\n",
      "INFO:tensorflow:loss = 4.5464754, step = 21800 (33.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97162\n",
      "INFO:tensorflow:loss = 5.0846763, step = 21900 (33.652 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.37393\n",
      "INFO:tensorflow:loss = 4.3154087, step = 22000 (42.124 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T02:37:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-02:39:39\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 5.6769238, metrics-onlinereview/targets/accuracy = 0.1901184, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37864298, metrics-onlinereview/targets/approx_bleu_score = 0.009994693, metrics-onlinereview/targets/neg_log_perplexity = -5.591115, metrics-onlinereview/targets/rouge_2_fscore = 0.038343493, metrics-onlinereview/targets/rouge_L_fscore = 0.16918176\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: ../model_file_256/model.ckpt-22000\n",
      "INFO:tensorflow:Validation (step 22001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.37864298, global_step = 22000, metrics-onlinereview/targets/rouge_L_fscore = 0.16918176, loss = 5.6769238, metrics-onlinereview/targets/approx_bleu_score = 0.009994693, metrics-onlinereview/targets/rouge_2_fscore = 0.038343493, metrics-onlinereview/targets/accuracy = 0.1901184, metrics-onlinereview/targets/neg_log_perplexity = -5.591115\n",
      "INFO:tensorflow:global_step/sec: 0.503776\n",
      "INFO:tensorflow:loss = 4.745808, step = 22100 (198.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94627\n",
      "INFO:tensorflow:loss = 5.0072007, step = 22200 (33.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9571\n",
      "INFO:tensorflow:loss = 5.153283, step = 22300 (33.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96019\n",
      "INFO:tensorflow:loss = 4.3652277, step = 22400 (33.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96672\n",
      "INFO:tensorflow:loss = 5.18782, step = 22500 (33.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90829\n",
      "INFO:tensorflow:loss = 4.8804274, step = 22600 (34.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9734\n",
      "INFO:tensorflow:loss = 4.704016, step = 22700 (33.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96885\n",
      "INFO:tensorflow:loss = 4.5888724, step = 22800 (33.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9207\n",
      "INFO:tensorflow:loss = 4.960044, step = 22900 (34.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96077\n",
      "INFO:tensorflow:loss = 4.998308, step = 23000 (33.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95388\n",
      "INFO:tensorflow:loss = 4.116237, step = 23100 (33.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96642\n",
      "INFO:tensorflow:loss = 5.8488407, step = 23200 (33.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9311\n",
      "INFO:tensorflow:loss = 5.318313, step = 23300 (34.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97875\n",
      "INFO:tensorflow:loss = 4.4484005, step = 23400 (33.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98867\n",
      "INFO:tensorflow:loss = 4.7074246, step = 23500 (33.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.971\n",
      "INFO:tensorflow:loss = 5.3843613, step = 23600 (33.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93471\n",
      "INFO:tensorflow:loss = 4.5738387, step = 23700 (34.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95158\n",
      "INFO:tensorflow:loss = 5.0693107, step = 23800 (33.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9226\n",
      "INFO:tensorflow:loss = 5.002629, step = 23900 (34.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.33227\n",
      "INFO:tensorflow:loss = 6.220688, step = 24000 (42.876 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T02:51:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-02:53:49\n",
      "INFO:tensorflow:Saving dict for global step 24000: global_step = 24000, loss = 5.6657405, metrics-onlinereview/targets/accuracy = 0.19484289, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38325363, metrics-onlinereview/targets/approx_bleu_score = 0.010556985, metrics-onlinereview/targets/neg_log_perplexity = -5.574447, metrics-onlinereview/targets/rouge_2_fscore = 0.041042794, metrics-onlinereview/targets/rouge_L_fscore = 0.16816269\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: ../model_file_256/model.ckpt-24000\n",
      "INFO:tensorflow:Validation (step 24001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.38325363, global_step = 24000, metrics-onlinereview/targets/rouge_L_fscore = 0.16816269, loss = 5.6657405, metrics-onlinereview/targets/approx_bleu_score = 0.010556985, metrics-onlinereview/targets/rouge_2_fscore = 0.041042794, metrics-onlinereview/targets/accuracy = 0.19484289, metrics-onlinereview/targets/neg_log_perplexity = -5.574447\n",
      "INFO:tensorflow:global_step/sec: 0.507077\n",
      "INFO:tensorflow:loss = 5.0011287, step = 24100 (197.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96537\n",
      "INFO:tensorflow:loss = 4.602381, step = 24200 (33.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93456\n",
      "INFO:tensorflow:loss = 4.221954, step = 24300 (34.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97492\n",
      "INFO:tensorflow:loss = 4.4734282, step = 24400 (33.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96685\n",
      "INFO:tensorflow:loss = 4.806064, step = 24500 (33.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93834\n",
      "INFO:tensorflow:loss = 4.507626, step = 24600 (34.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95647\n",
      "INFO:tensorflow:loss = 4.362678, step = 24700 (33.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92185\n",
      "INFO:tensorflow:loss = 5.176393, step = 24800 (34.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95308\n",
      "INFO:tensorflow:loss = 4.9493556, step = 24900 (33.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91917\n",
      "INFO:tensorflow:loss = 4.3702755, step = 25000 (34.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92483\n",
      "INFO:tensorflow:loss = 5.0491843, step = 25100 (34.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98708\n",
      "INFO:tensorflow:loss = 5.184001, step = 25200 (33.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9228\n",
      "INFO:tensorflow:loss = 5.1106176, step = 25300 (34.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97089\n",
      "INFO:tensorflow:loss = 5.1854916, step = 25400 (33.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95564\n",
      "INFO:tensorflow:loss = 4.2261267, step = 25500 (33.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93275\n",
      "INFO:tensorflow:loss = 5.3074923, step = 25600 (34.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95811\n",
      "INFO:tensorflow:loss = 5.1267724, step = 25700 (33.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96692\n",
      "INFO:tensorflow:loss = 4.876354, step = 25800 (33.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95655\n",
      "INFO:tensorflow:loss = 4.591698, step = 25900 (33.823 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.37105\n",
      "INFO:tensorflow:loss = 4.3510294, step = 26000 (42.175 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T03:05:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-03:08:01\n",
      "INFO:tensorflow:Saving dict for global step 26000: global_step = 26000, loss = 5.62064, metrics-onlinereview/targets/accuracy = 0.1977459, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3857582, metrics-onlinereview/targets/approx_bleu_score = 0.0106818555, metrics-onlinereview/targets/neg_log_perplexity = -5.5201335, metrics-onlinereview/targets/rouge_2_fscore = 0.04041418, metrics-onlinereview/targets/rouge_L_fscore = 0.16683084\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26000: ../model_file_256/model.ckpt-26000\n",
      "INFO:tensorflow:Validation (step 26001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3857582, global_step = 26000, metrics-onlinereview/targets/rouge_L_fscore = 0.16683084, loss = 5.62064, metrics-onlinereview/targets/approx_bleu_score = 0.0106818555, metrics-onlinereview/targets/rouge_2_fscore = 0.04041418, metrics-onlinereview/targets/accuracy = 0.1977459, metrics-onlinereview/targets/neg_log_perplexity = -5.5201335\n",
      "INFO:tensorflow:global_step/sec: 0.503414\n",
      "INFO:tensorflow:loss = 5.3105855, step = 26100 (198.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9357\n",
      "INFO:tensorflow:loss = 4.8089933, step = 26200 (34.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92401\n",
      "INFO:tensorflow:loss = 4.4802766, step = 26300 (34.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96116\n",
      "INFO:tensorflow:loss = 3.9930484, step = 26400 (33.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9579\n",
      "INFO:tensorflow:loss = 4.946327, step = 26500 (33.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93191\n",
      "INFO:tensorflow:loss = 5.339378, step = 26600 (34.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98137\n",
      "INFO:tensorflow:loss = 4.807097, step = 26700 (33.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94106\n",
      "INFO:tensorflow:loss = 4.470777, step = 26800 (34.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96394\n",
      "INFO:tensorflow:loss = 4.955381, step = 26900 (33.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90535\n",
      "INFO:tensorflow:loss = 4.378408, step = 27000 (34.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94296\n",
      "INFO:tensorflow:loss = 4.799518, step = 27100 (33.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96269\n",
      "INFO:tensorflow:loss = 5.2209077, step = 27200 (33.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94529\n",
      "INFO:tensorflow:loss = 4.581047, step = 27300 (33.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97914\n",
      "INFO:tensorflow:loss = 4.655744, step = 27400 (33.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96289\n",
      "INFO:tensorflow:loss = 4.734697, step = 27500 (33.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9869\n",
      "INFO:tensorflow:loss = 5.258384, step = 27600 (33.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96869\n",
      "INFO:tensorflow:loss = 4.412008, step = 27700 (33.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95148\n",
      "INFO:tensorflow:loss = 4.0297623, step = 27800 (33.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94993\n",
      "INFO:tensorflow:loss = 5.0822167, step = 27900 (33.899 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.34935\n",
      "INFO:tensorflow:loss = 4.211359, step = 28000 (42.565 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T03:19:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-28000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-03:22:10\n",
      "INFO:tensorflow:Saving dict for global step 28000: global_step = 28000, loss = 5.5950646, metrics-onlinereview/targets/accuracy = 0.20053506, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39093807, metrics-onlinereview/targets/approx_bleu_score = 0.011326389, metrics-onlinereview/targets/neg_log_perplexity = -5.4961796, metrics-onlinereview/targets/rouge_2_fscore = 0.043905515, metrics-onlinereview/targets/rouge_L_fscore = 0.1768647\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 28000: ../model_file_256/model.ckpt-28000\n",
      "INFO:tensorflow:Validation (step 28001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39093807, global_step = 28000, metrics-onlinereview/targets/rouge_L_fscore = 0.1768647, loss = 5.5950646, metrics-onlinereview/targets/approx_bleu_score = 0.011326389, metrics-onlinereview/targets/rouge_2_fscore = 0.043905515, metrics-onlinereview/targets/accuracy = 0.20053506, metrics-onlinereview/targets/neg_log_perplexity = -5.4961796\n",
      "INFO:tensorflow:global_step/sec: 0.506419\n",
      "INFO:tensorflow:loss = 4.429636, step = 28100 (197.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92653\n",
      "INFO:tensorflow:loss = 4.1581883, step = 28200 (34.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92816\n",
      "INFO:tensorflow:loss = 4.1564384, step = 28300 (34.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99024\n",
      "INFO:tensorflow:loss = 5.1699686, step = 28400 (33.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96837\n",
      "INFO:tensorflow:loss = 5.109169, step = 28500 (33.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93002\n",
      "INFO:tensorflow:loss = 5.006343, step = 28600 (34.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91573\n",
      "INFO:tensorflow:loss = 4.9867043, step = 28700 (34.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93482\n",
      "INFO:tensorflow:loss = 4.5262256, step = 28800 (34.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98992\n",
      "INFO:tensorflow:loss = 4.3661647, step = 28900 (33.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95661\n",
      "INFO:tensorflow:loss = 4.2925787, step = 29000 (33.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92567\n",
      "INFO:tensorflow:loss = 5.3602457, step = 29100 (34.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94859\n",
      "INFO:tensorflow:loss = 5.186501, step = 29200 (33.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94764\n",
      "INFO:tensorflow:loss = 4.1398587, step = 29300 (33.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93241\n",
      "INFO:tensorflow:loss = 4.562427, step = 29400 (34.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93902\n",
      "INFO:tensorflow:loss = 4.554145, step = 29500 (34.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98389\n",
      "INFO:tensorflow:loss = 4.2402263, step = 29600 (33.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96107\n",
      "INFO:tensorflow:loss = 5.0526905, step = 29700 (33.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92135\n",
      "INFO:tensorflow:loss = 5.2509527, step = 29800 (34.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95994\n",
      "INFO:tensorflow:loss = 4.6993604, step = 29900 (33.784 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.37809\n",
      "INFO:tensorflow:loss = 4.857372, step = 30000 (42.050 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T03:33:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-03:36:20\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 5.5936337, metrics-onlinereview/targets/accuracy = 0.20150273, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39293033, metrics-onlinereview/targets/approx_bleu_score = 0.010975426, metrics-onlinereview/targets/neg_log_perplexity = -5.493355, metrics-onlinereview/targets/rouge_2_fscore = 0.0402697, metrics-onlinereview/targets/rouge_L_fscore = 0.16900009\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: ../model_file_256/model.ckpt-30000\n",
      "INFO:tensorflow:Validation (step 30001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39293033, global_step = 30000, metrics-onlinereview/targets/rouge_L_fscore = 0.16900009, loss = 5.5936337, metrics-onlinereview/targets/approx_bleu_score = 0.010975426, metrics-onlinereview/targets/rouge_2_fscore = 0.0402697, metrics-onlinereview/targets/accuracy = 0.20150273, metrics-onlinereview/targets/neg_log_perplexity = -5.493355\n",
      "INFO:tensorflow:global_step/sec: 0.506089\n",
      "INFO:tensorflow:loss = 5.012668, step = 30100 (197.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9542\n",
      "INFO:tensorflow:loss = 4.7176313, step = 30200 (33.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90887\n",
      "INFO:tensorflow:loss = 4.192987, step = 30300 (34.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94837\n",
      "INFO:tensorflow:loss = 4.363307, step = 30400 (33.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94901\n",
      "INFO:tensorflow:loss = 4.1722193, step = 30500 (33.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.90591\n",
      "INFO:tensorflow:loss = 5.0556746, step = 30600 (34.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92828\n",
      "INFO:tensorflow:loss = 4.0338783, step = 30700 (34.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95201\n",
      "INFO:tensorflow:loss = 4.332604, step = 30800 (33.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96105\n",
      "INFO:tensorflow:loss = 4.690308, step = 30900 (33.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94817\n",
      "INFO:tensorflow:loss = 4.6183043, step = 31000 (33.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95185\n",
      "INFO:tensorflow:loss = 5.2504377, step = 31100 (33.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95465\n",
      "INFO:tensorflow:loss = 4.4699807, step = 31200 (33.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94965\n",
      "INFO:tensorflow:loss = 4.1332154, step = 31300 (33.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94723\n",
      "INFO:tensorflow:loss = 4.342022, step = 31400 (33.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97815\n",
      "INFO:tensorflow:loss = 5.9756913, step = 31500 (33.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94775\n",
      "INFO:tensorflow:loss = 5.120012, step = 31600 (33.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95765\n",
      "INFO:tensorflow:loss = 4.304166, step = 31700 (33.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92869\n",
      "INFO:tensorflow:loss = 4.8111563, step = 31800 (34.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92062\n",
      "INFO:tensorflow:loss = 4.462215, step = 31900 (34.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36932\n",
      "INFO:tensorflow:loss = 4.913383, step = 32000 (42.206 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T03:47:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-32000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-03:50:32\n",
      "INFO:tensorflow:Saving dict for global step 32000: global_step = 32000, loss = 5.573442, metrics-onlinereview/targets/accuracy = 0.2013889, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3925888, metrics-onlinereview/targets/approx_bleu_score = 0.010651141, metrics-onlinereview/targets/neg_log_perplexity = -5.4719553, metrics-onlinereview/targets/rouge_2_fscore = 0.040820036, metrics-onlinereview/targets/rouge_L_fscore = 0.1675754\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32000: ../model_file_256/model.ckpt-32000\n",
      "INFO:tensorflow:Validation (step 32001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.3925888, global_step = 32000, metrics-onlinereview/targets/rouge_L_fscore = 0.1675754, loss = 5.573442, metrics-onlinereview/targets/approx_bleu_score = 0.010651141, metrics-onlinereview/targets/rouge_2_fscore = 0.040820036, metrics-onlinereview/targets/accuracy = 0.2013889, metrics-onlinereview/targets/neg_log_perplexity = -5.4719553\n",
      "INFO:tensorflow:global_step/sec: 0.504301\n",
      "INFO:tensorflow:loss = 4.7887363, step = 32100 (198.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95894\n",
      "INFO:tensorflow:loss = 4.9807405, step = 32200 (33.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95245\n",
      "INFO:tensorflow:loss = 3.6443589, step = 32300 (33.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92836\n",
      "INFO:tensorflow:loss = 6.0333967, step = 32400 (34.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94512\n",
      "INFO:tensorflow:loss = 4.5772743, step = 32500 (33.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99951\n",
      "INFO:tensorflow:loss = 4.493587, step = 32600 (33.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93077\n",
      "INFO:tensorflow:loss = 5.180258, step = 32700 (34.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94702\n",
      "INFO:tensorflow:loss = 4.897347, step = 32800 (33.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94765\n",
      "INFO:tensorflow:loss = 4.2742844, step = 32900 (33.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96866\n",
      "INFO:tensorflow:loss = 4.5073423, step = 33000 (33.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93198\n",
      "INFO:tensorflow:loss = 6.0581923, step = 33100 (34.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96717\n",
      "INFO:tensorflow:loss = 4.5161877, step = 33200 (33.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92744\n",
      "INFO:tensorflow:loss = 4.2745857, step = 33300 (34.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93592\n",
      "INFO:tensorflow:loss = 4.758164, step = 33400 (34.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95202\n",
      "INFO:tensorflow:loss = 5.3538065, step = 33500 (33.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95975\n",
      "INFO:tensorflow:loss = 5.0430837, step = 33600 (33.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97485\n",
      "INFO:tensorflow:loss = 4.335621, step = 33700 (33.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9238\n",
      "INFO:tensorflow:loss = 4.698941, step = 33800 (34.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92227\n",
      "INFO:tensorflow:loss = 4.7572913, step = 33900 (34.220 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36335\n",
      "INFO:tensorflow:loss = 5.143404, step = 34000 (42.313 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T04:02:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-34000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-04:04:42\n",
      "INFO:tensorflow:Saving dict for global step 34000: global_step = 34000, loss = 5.546009, metrics-onlinereview/targets/accuracy = 0.20713797, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39537796, metrics-onlinereview/targets/approx_bleu_score = 0.011663246, metrics-onlinereview/targets/neg_log_perplexity = -5.4409924, metrics-onlinereview/targets/rouge_2_fscore = 0.042835265, metrics-onlinereview/targets/rouge_L_fscore = 0.17394236\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34000: ../model_file_256/model.ckpt-34000\n",
      "INFO:tensorflow:Validation (step 34001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.39537796, global_step = 34000, metrics-onlinereview/targets/rouge_L_fscore = 0.17394236, loss = 5.546009, metrics-onlinereview/targets/approx_bleu_score = 0.011663246, metrics-onlinereview/targets/rouge_2_fscore = 0.042835265, metrics-onlinereview/targets/accuracy = 0.20713797, metrics-onlinereview/targets/neg_log_perplexity = -5.4409924\n",
      "INFO:tensorflow:global_step/sec: 0.507296\n",
      "INFO:tensorflow:loss = 5.045532, step = 34100 (197.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97035\n",
      "INFO:tensorflow:loss = 4.1061916, step = 34200 (33.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95068\n",
      "INFO:tensorflow:loss = 4.993737, step = 34300 (33.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94033\n",
      "INFO:tensorflow:loss = 4.8559904, step = 34400 (34.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95757\n",
      "INFO:tensorflow:loss = 4.9159303, step = 34500 (33.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9621\n",
      "INFO:tensorflow:loss = 4.1242394, step = 34600 (33.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95522\n",
      "INFO:tensorflow:loss = 4.08377, step = 34700 (33.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95909\n",
      "INFO:tensorflow:loss = 4.6037974, step = 34800 (33.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95284\n",
      "INFO:tensorflow:loss = 4.844635, step = 34900 (33.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94774\n",
      "INFO:tensorflow:loss = 5.1666493, step = 35000 (33.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96776\n",
      "INFO:tensorflow:loss = 4.1310353, step = 35100 (33.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98528\n",
      "INFO:tensorflow:loss = 4.4824047, step = 35200 (33.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9791\n",
      "INFO:tensorflow:loss = 4.0333724, step = 35300 (33.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87102\n",
      "INFO:tensorflow:loss = 5.496772, step = 35400 (34.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96942\n",
      "INFO:tensorflow:loss = 4.4438148, step = 35500 (33.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93906\n",
      "INFO:tensorflow:loss = 4.5093884, step = 35600 (34.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94001\n",
      "INFO:tensorflow:loss = 5.620168, step = 35700 (34.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94785\n",
      "INFO:tensorflow:loss = 4.633125, step = 35800 (33.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95184\n",
      "INFO:tensorflow:loss = 4.847777, step = 35900 (33.877 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36961\n",
      "INFO:tensorflow:loss = 4.896391, step = 36000 (42.201 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T04:16:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-04:18:51\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 5.5474553, metrics-onlinereview/targets/accuracy = 0.206398, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.40061477, metrics-onlinereview/targets/approx_bleu_score = 0.011132354, metrics-onlinereview/targets/neg_log_perplexity = -5.439974, metrics-onlinereview/targets/rouge_2_fscore = 0.04085103, metrics-onlinereview/targets/rouge_L_fscore = 0.16975792\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: ../model_file_256/model.ckpt-36000\n",
      "INFO:tensorflow:Validation (step 36001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.40061477, global_step = 36000, metrics-onlinereview/targets/rouge_L_fscore = 0.16975792, loss = 5.5474553, metrics-onlinereview/targets/approx_bleu_score = 0.011132354, metrics-onlinereview/targets/rouge_2_fscore = 0.04085103, metrics-onlinereview/targets/accuracy = 0.206398, metrics-onlinereview/targets/neg_log_perplexity = -5.439974\n",
      "INFO:tensorflow:global_step/sec: 0.507244\n",
      "INFO:tensorflow:loss = 4.381696, step = 36100 (197.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9296\n",
      "INFO:tensorflow:loss = 4.481171, step = 36200 (34.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9401\n",
      "INFO:tensorflow:loss = 4.3604803, step = 36300 (34.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96003\n",
      "INFO:tensorflow:loss = 4.7101502, step = 36400 (33.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92004\n",
      "INFO:tensorflow:loss = 3.9124265, step = 36500 (34.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94402\n",
      "INFO:tensorflow:loss = 3.2282355, step = 36600 (33.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94256\n",
      "INFO:tensorflow:loss = 5.1275635, step = 36700 (33.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98273\n",
      "INFO:tensorflow:loss = 4.825971, step = 36800 (33.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94197\n",
      "INFO:tensorflow:loss = 4.790794, step = 36900 (33.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.99438\n",
      "INFO:tensorflow:loss = 4.679726, step = 37000 (33.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93778\n",
      "INFO:tensorflow:loss = 4.503519, step = 37100 (34.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92001\n",
      "INFO:tensorflow:loss = 4.556368, step = 37200 (34.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96691\n",
      "INFO:tensorflow:loss = 4.428646, step = 37300 (33.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.909\n",
      "INFO:tensorflow:loss = 5.305707, step = 37400 (34.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9599\n",
      "INFO:tensorflow:loss = 4.8408604, step = 37500 (33.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.959\n",
      "INFO:tensorflow:loss = 4.7098866, step = 37600 (33.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94216\n",
      "INFO:tensorflow:loss = 5.570266, step = 37700 (33.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94224\n",
      "INFO:tensorflow:loss = 6.153113, step = 37800 (33.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95087\n",
      "INFO:tensorflow:loss = 4.219497, step = 37900 (33.888 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.36011\n",
      "INFO:tensorflow:loss = 3.9698982, step = 38000 (42.370 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T04:30:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-38000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-04:33:03\n",
      "INFO:tensorflow:Saving dict for global step 38000: global_step = 38000, loss = 5.5458245, metrics-onlinereview/targets/accuracy = 0.20907332, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.40072858, metrics-onlinereview/targets/approx_bleu_score = 0.012371559, metrics-onlinereview/targets/neg_log_perplexity = -5.439243, metrics-onlinereview/targets/rouge_2_fscore = 0.044692926, metrics-onlinereview/targets/rouge_L_fscore = 0.17655371\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38000: ../model_file_256/model.ckpt-38000\n",
      "INFO:tensorflow:Validation (step 38001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.40072858, global_step = 38000, metrics-onlinereview/targets/rouge_L_fscore = 0.17655371, loss = 5.5458245, metrics-onlinereview/targets/approx_bleu_score = 0.012371559, metrics-onlinereview/targets/rouge_2_fscore = 0.044692926, metrics-onlinereview/targets/accuracy = 0.20907332, metrics-onlinereview/targets/neg_log_perplexity = -5.439243\n",
      "INFO:tensorflow:global_step/sec: 0.50135\n",
      "INFO:tensorflow:loss = 4.724944, step = 38100 (199.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98693\n",
      "INFO:tensorflow:loss = 5.0573, step = 38200 (33.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94834\n",
      "INFO:tensorflow:loss = 5.488204, step = 38300 (33.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97401\n",
      "INFO:tensorflow:loss = 4.5786834, step = 38400 (33.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94589\n",
      "INFO:tensorflow:loss = 5.23613, step = 38500 (33.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96014\n",
      "INFO:tensorflow:loss = 4.2214813, step = 38600 (33.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9366\n",
      "INFO:tensorflow:loss = 4.219287, step = 38700 (34.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96482\n",
      "INFO:tensorflow:loss = 4.897781, step = 38800 (33.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94903\n",
      "INFO:tensorflow:loss = 4.9204345, step = 38900 (33.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93666\n",
      "INFO:tensorflow:loss = 4.920672, step = 39000 (34.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95831\n",
      "INFO:tensorflow:loss = 4.5416045, step = 39100 (33.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95839\n",
      "INFO:tensorflow:loss = 4.193889, step = 39200 (33.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93413\n",
      "INFO:tensorflow:loss = 4.5745487, step = 39300 (34.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97972\n",
      "INFO:tensorflow:loss = 4.54566, step = 39400 (33.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97561\n",
      "INFO:tensorflow:loss = 4.435538, step = 39500 (33.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92189\n",
      "INFO:tensorflow:loss = 4.3955407, step = 39600 (34.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91404\n",
      "INFO:tensorflow:loss = 3.791992, step = 39700 (34.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93188\n",
      "INFO:tensorflow:loss = 4.5954003, step = 39800 (34.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94887\n",
      "INFO:tensorflow:loss = 4.562045, step = 39900 (33.912 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into ../model_file_256/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 2.35959\n",
      "INFO:tensorflow:loss = 4.6778374, step = 40000 (42.379 sec)\n",
      "INFO:tensorflow:Reading data files from ./data/onlinereview-test*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_40055_512.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_40055_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_40055_512.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-07T04:44:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../model_file_256/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-07-04:47:13\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 5.498601, metrics-onlinereview/targets/accuracy = 0.21106558, metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.4049408, metrics-onlinereview/targets/approx_bleu_score = 0.011791886, metrics-onlinereview/targets/neg_log_perplexity = -5.3902187, metrics-onlinereview/targets/rouge_2_fscore = 0.044179734, metrics-onlinereview/targets/rouge_L_fscore = 0.17490685\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: ../model_file_256/model.ckpt-40000\n",
      "INFO:tensorflow:Validation (step 40001): metrics-onlinereview/targets/accuracy_per_sequence = 0.0, metrics-onlinereview/targets/accuracy_top5 = 0.4049408, global_step = 40000, metrics-onlinereview/targets/rouge_L_fscore = 0.17490685, loss = 5.498601, metrics-onlinereview/targets/approx_bleu_score = 0.011791886, metrics-onlinereview/targets/rouge_2_fscore = 0.044179734, metrics-onlinereview/targets/accuracy = 0.21106558, metrics-onlinereview/targets/neg_log_perplexity = -5.3902187\n",
      "INFO:tensorflow:global_step/sec: 0.505242\n",
      "INFO:tensorflow:loss = 4.2902956, step = 40100 (197.926 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40200 into ../model_file_256/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.341067.\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import problems\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils import registry, trainer_lib, decoding\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams, create_run_config, create_experiment\n",
    "import json\n",
    "\n",
    "MODEL = 'transformer'\n",
    "TRAIN_DIR = '../model_file_256'\n",
    "DATA_LOC = './data'\n",
    "PROBLEM = 'onlinereview'\n",
    "\n",
    "# Define hparams\n",
    "HPARAMS = 'transformer_prepend'\n",
    "hparams = create_hparams(HPARAMS)\n",
    "hparams.prepend_mode = 'prepend_inputs_full_attention'\n",
    "hparams.batch_size = 1024 #2048 #512 \n",
    "hparams.learning_rate = 0.05 \n",
    "hparams.num_encoder_layers = 6\n",
    "# hparams.num_hidden_layers = 6\n",
    "hparams.num_decoder_layers = 6\n",
    "hparams.dropout =0.3\n",
    "hparams.attention_dropout = 0.2 ##\n",
    "hparams.max_length = 256\n",
    "hparams.max_input_seq_length =512\n",
    "\n",
    "decode_hp = decoding.decode_hparams()\n",
    "decode_hp.return_beams = True\n",
    "decode_hp.beam_size = 2\n",
    "\n",
    "# print out all Hparams\n",
    "print(json.loads(hparams.to_json()))\n",
    "print(json.loads(decode_hp.to_json()))\n",
    "\n",
    "import timeit\n",
    "# running time calculation\n",
    "start = timeit.default_timer()\n",
    "\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "RUN_CONFIG = create_run_config(\n",
    "    model_name=MODEL,\n",
    "    model_dir=TRAIN_DIR,\n",
    "    save_checkpoints_steps=2000,\n",
    "    )\n",
    "\n",
    "t2t_model_256 = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        decode_hparams=decode_hp,\n",
    "        problem_name=t2t_problem,\n",
    "        model_name=MODEL,\n",
    "        data_dir=DATA_LOC, \n",
    "        train_steps=40200,\n",
    "        eval_steps=200,\n",
    "        min_eval_frequency=2000,\n",
    "        eval_use_test_set=True,\n",
    "    )\n",
    "\n",
    "# hparams.problem_hparams.was_reversed =False\n",
    "print('\\n hparams.problem_hparams \\n',hparams.problem_hparams)\n",
    "\n",
    "# training\n",
    "t2t_model_256.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- ###########-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: ./data/vocab.online_revew_project_usyd.32768.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['./data/online_revew_project_usyd-unshuffled-train-00000-of-00009', './data/online_revew_project_usyd-unshuffled-train-00001-of-00009', './data/online_revew_project_usyd-unshuffled-train-00002-of-00009', './data/online_revew_project_usyd-unshuffled-train-00003-of-00009', './data/online_revew_project_usyd-unshuffled-train-00004-of-00009', './data/online_revew_project_usyd-unshuffled-train-00005-of-00009', './data/online_revew_project_usyd-unshuffled-train-00006-of-00009', './data/online_revew_project_usyd-unshuffled-train-00007-of-00009', './data/online_revew_project_usyd-unshuffled-train-00008-of-00009', './data/online_revew_project_usyd-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor.utils.trainer_lib import create_hparams\n",
    "import generate_problem\n",
    "USR_DIR= './'\n",
    "PROBLEM = 'OnlineRevewProjectUSYD_v4'\n",
    "TMP_DIR = './tmp' \n",
    "DATA_LOC = './data' \n",
    "\n",
    "t2t_problem = generate_problem.OnlineRevewProjectUSYD(PROBLEM)\n",
    "t2t_problem.generate_data(DATA_LOC, TMP_DIR) \n",
    "\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_prepend'\n",
    "TRAIN_DIR = 'model_files_2014'\n",
    "\n",
    "hparams = create_hparams(HPARAMS, data_dir=DATA_LOC, problem_name=t2t_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab_name = \"vocab.online_revew_project_usyd.32768.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = t2t_problem.feature_encoders(DATA_LOC)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  \n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  \n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "#Restore and summarize\n",
    "def summarize(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "        model_output = model.infer(encoded_inputs)[\"outputs\"]\n",
    "    return decode(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registry.model(MODEL)(hparams, Modes.PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_files_1024/model.ckpt-40001'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint(\"./model_files_1024/\") #model.ckpt\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWS: \n",
      "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
      "\n",
      "PRED_SUMMARY: read 10; i the the did not get the item i ordered.  when its company they got back with me me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase the has 10;\n",
      "GOLD_SUMMARY: \n",
      "happy with purchase even though it came a lot later than expected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review1 = '''\n",
    "we have many of the old , old issue but the number had depleted there were not enough books to allow us to use them regularly with the additional supply the books will be used more often they are a good old standby for gospel singing\n",
    "'''\n",
    "review2 = '''\n",
    "i origonally did not get the item i ordered.  when contacting the company they got back with me quickly.  it turned out the item was out of stock.  they sent it once it came in stock.  this was not a problem for me since i ordered the item way in advance for my daughters birthday.  i would recommend this selling but ordered ahead of time just incase.\n",
    "'''\n",
    "s2 = '''\n",
    "happy with purchase even though it came a lot later than expected.\n",
    "'''\n",
    "\n",
    "summary = summarize(review2)\n",
    "\n",
    "print(\"REVIEWS: %s\" % review2)\n",
    "print(\"PRED_SUMMARY: %s\" % summary)\n",
    "print(\"GOLD_SUMMARY: %s\" % s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
